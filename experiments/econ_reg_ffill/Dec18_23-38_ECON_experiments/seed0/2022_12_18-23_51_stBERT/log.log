2022-12-18 23:51:37,236 INFO 

		 *** NEW EXPERIMENT ***
args=Namespace(adam_epsilon=1e-08, convert_abstain_to_random=False, datapath='../data', dataset='econ_reg_ffill', debug=False, device=device(type='cuda'), downsample=1.0, eval_batch_size=16, experiment_folder='../experiments/econ_reg_ffill', finetuning_rate=0.0001, fp16=False, hard_student_rule=False, learning_rate=0.0001, logdir='../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT', logging_steps=500, loss_weights=False, lower_case=False, max_grad_norm=1.0, max_rule_seq_length=10, max_seq_length=64, max_size=1000, metric='mse', n_gpu=1, no_cuda=False, num_epochs=15, num_iter=25, num_labels=1, num_supervised_trials=5, num_unsup_epochs=25, oversample=1, overwrite=False, sample_size=16384, seed=0, soft_labels=False, student_name='bert', teacher_name='ran', tokenizer_method='clean', train_batch_size=16, unsup_batch_size=128, warmup_steps=0, weak_sources=None, weight_decay=0.0)
2022-12-18 23:51:37,236 INFO building student: bert
2022-12-18 23:51:37,237 INFO building teacher
2022-12-18 23:51:37,237 INFO No weak sources specified for Teacher. Using default: ['econ_reg_ffillrules']
2022-12-18 23:51:37,237 INFO loading data
2022-12-18 23:51:37,239 INFO Pre-processing train data for student...
2022-12-18 23:51:37,239 INFO train DATASET: 247 examples
2022-12-18 23:51:37,239 INFO train LABELS:
3.338052914979758
2022-12-18 23:51:37,240 INFO Pre-processing dev data for student...
2022-12-18 23:51:37,240 INFO dev DATASET: 18 examples
2022-12-18 23:51:37,240 INFO dev LABELS:
2.138967777777778
2022-12-18 23:51:37,240 INFO [4.57732, 5.39412, 3.88678, 0.93698, -1.04081, -0.58869, -1.53302, 3.76668, 7.29736, 10.30496, 13.36852, 10.56301, 9.14988, 7.2547, 5.47138, 5.17, 3.60142, 2.24206, 5.36784, 6.19179, 6.78258, 5.42076, 0.52335, -1.7829, -2.43001, -0.76976, 2.72709, 6.16873, 7.77884, 8.0145, 6.57755, 3.21555, 2.40215, 0.9469, 1.99603, 3.04933, 1.98087, 3.07291, 0.35513, -2.87143, -2.01841, -0.7248, 2.65814, 7.41665, 9.1219, 6.73, 4.58866, 4.92542, 2.05821, 2.48539, 0.88268, -0.66913, 1.56445, 3.00992, 6.39553, 7.56728, 6.72769, 6.00401, 4.3071, 3.59787, 3.82216, 4.81693, 5.15824, 6.21582, 6.18075, 5.51983, 5.15634, 5.47714, 5.65928, 6.3469, 8.46216, 8.4775, 7.49014, 6.04287, 4.50502, 2.92504, 2.63752, 2.73849, 2.67084, 3.84521, 5.51558, 5.33667, 4.95957, 4.4716, 3.06714, 2.9501, 2.04665, 0.32493, 0.16284, 0.42258, -0.1667, 2.69724, 3.10661, 3.00589, 4.3672, 3.47607, 5.25519, 5.38194, 6.89448, 7.56189, 6.31966, 4.77109, 4.02376, 0.63877, -0.20842, -0.629, -1.94545, -2.29905, -1.83426, 0.79868, 2.55402, 6.15239, 6.17259, 4.95864, 4.31481, 3.22596, 4.46632, 5.7709, 5.01203, 4.11706, 6.07815, 5.24577, 6.6581, 6.50991, 2.65686, 2.38992, 1.28456, 1.42078, -0.77506, -1.6238, -0.03913, 1.59998, 2.9687, 4.32577, 1.2999, -2.19035, -1.01057, -2.55592, -1.44316, 1.43146, 3.26853, 5.73717, 7.89997, 8.57828, 7.9967, 6.90084, 5.5758, 4.55509, 3.68422, 4.26244, 4.18227, 4.14559, 3.70158, 3.11924, 2.90803, 2.71584, 3.35848, 3.26693, 4.47902, 4.24219, 4.4846, 4.19287, 3.79897, 4.31524, 3.74829, 3.90811, 2.7438, 2.8213, 2.41277, 1.72722, 0.60286, -0.95024, -0.53889, -0.10272, 1.1665, 2.85887, 3.16976, 3.66532, 4.38259, 3.31998, 2.80667, 2.28652, 2.60762, 3.43052, 4.2254, 4.33678, 4.11593, 3.48113, 2.40217, 2.67311, 2.19958, 2.6011, 4.00213, 4.04992, 4.42131, 4.31413, 4.30807, 4.6738, 4.48768, 4.85501, 4.09573, 4.09777, 4.87954, 4.82186, 4.72753, 4.80021, 4.82763, 4.22596, 5.24468, 3.97408, 2.90162, 2.19554, 0.99193, 0.48735, 0.17064, 1.32881, 1.32288, 2.14067, 1.99129, 1.67619, 1.95699, 3.23991, 4.29508, 4.35338, 4.23481, 3.49083, 3.35577, 3.90862, 3.60741, 3.44767, 2.98267, 3.22486, 2.97727, 2.32829, 2.6089, 1.54072, 1.93864, 2.39856, 2.16088, 1.4468, 1.38013, 0.2422, -2.54034, -3.28239, -3.9955, -3.13768, 0.08166]
2022-12-18 23:51:37,242 INFO Pre-processing test data for student...
2022-12-18 23:51:37,242 INFO test DATASET: 32 examples
2022-12-18 23:51:37,242 INFO test LABELS:
2.1615075
2022-12-18 23:51:37,244 INFO Pre-processing unlabeled data for student...
2022-12-18 23:51:37,244 INFO unlabeled DATASET: 444 examples
2022-12-18 23:51:37,244 INFO unlabeled LABELS:
-999.0
2022-12-18 23:51:37,244 INFO creating pseudo-dataset
2022-12-18 23:51:37,244 INFO copying data from unlabeled dataset
2022-12-18 23:51:37,254 INFO done
2022-12-18 23:51:37,257 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
-999.0
2022-12-18 23:51:37,257 INFO copying data from train dataset
2022-12-18 23:51:37,262 INFO done
2022-12-18 23:51:37,264 INFO PSEUDO-DATASET:
247 examples
 with mean PSEUDO-LABELS:
3.3380529149797575
2022-12-18 23:51:37,264 INFO Class labels: 1
2022-12-18 23:51:37,265 INFO X Train Shape (247, 7) (247,)
2022-12-18 23:51:37,265 INFO X Dev Shape (18, 7) (18,)
2022-12-18 23:51:44,126 INFO Saving supervised_student to ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/supervised_student
2022-12-18 23:51:44,126 INFO Saving model at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/supervised_student/final_model.h5
2022-12-18 23:51:44,137 INFO 

	*** Evaluating on dev data ***
2022-12-18 23:51:44,137 INFO Predicting labels for 18 texts
2022-12-18 23:51:44,247 INFO Evaluating student dev on 18 examples
2022-12-18 23:51:44,248 INFO student dev performance: 12.72
2022-12-18 23:51:44,248 INFO {'mse': 12.724145315072679, 'r2': 16.943265386491813, 'var_explained': 17.69760274046067, 'ignored': 0, 'total': 18, 'perf': 12.724145315072679}
2022-12-18 23:51:44,248 INFO 

	*** Evaluating on test data ***
2022-12-18 23:51:44,248 INFO Predicting labels for 32 texts
2022-12-18 23:51:44,353 INFO Evaluating student test on 32 examples
2022-12-18 23:51:44,354 INFO student test performance: 1.67
2022-12-18 23:51:44,355 INFO initializing teacher on unlabeled data with majority voting
2022-12-18 23:51:44,355 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:51:44,355 INFO There are 3/7 active rules
2022-12-18 23:51:44,355 INFO Coverage: 100.0% (444/444)
2022-12-18 23:51:44,360 INFO evaluating majority voting
2022-12-18 23:51:44,360 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:51:44,361 INFO There are 7/7 active rules
2022-12-18 23:51:44,361 INFO Coverage: 100.0% (247/247)
2022-12-18 23:51:44,364 INFO Evaluating teacher train on 247 examples
2022-12-18 23:51:44,365 INFO teacher train performance: 1.96
2022-12-18 23:51:44,365 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:51:44,365 INFO There are 7/7 active rules
2022-12-18 23:51:44,365 INFO Coverage: 100.0% (18/18)
2022-12-18 23:51:44,366 INFO Evaluating teacher dev on 18 examples
2022-12-18 23:51:44,366 INFO teacher dev performance: 10.07
2022-12-18 23:51:44,366 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:51:44,367 INFO There are 7/7 active rules
2022-12-18 23:51:44,367 INFO Coverage: 100.0% (32/32)
2022-12-18 23:51:44,367 INFO Evaluating teacher test on 32 examples
2022-12-18 23:51:44,368 INFO teacher test performance: 0.29
2022-12-18 23:51:44,368 INFO 

	 *** Starting loop 0 ***
2022-12-18 23:51:44,368 INFO Adding Student as extra rule in Teacher
2022-12-18 23:51:44,368 INFO Getting rule predictions
2022-12-18 23:51:44,368 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:51:44,369 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:51:44,369 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:51:44,369 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:51:44,370 INFO Predicting labels for 247 texts
2022-12-18 23:51:44,479 INFO Predicting labels for 18 texts
2022-12-18 23:51:45,610 INFO Predicting labels for 444 texts
2022-12-18 23:51:45,718 INFO Training Rule Attention Network
2022-12-18 23:51:45,720 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:51:45,720 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:51:45,725 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:51:45,793 INFO 

		*** Training RAN ***
2022-12-18 23:51:47,011 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:51:47,012 INFO Predicting labels for 444 texts
2022-12-18 23:51:47,124 INFO There are 3/7 active rules
2022-12-18 23:51:47,125 INFO Coverage: 100.0% (444/444)
2022-12-18 23:51:47,127 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:51:47,197 INFO DONE, Getting attention scores...
2022-12-18 23:51:47,252 INFO the attention scores are
2022-12-18 23:51:47,252 INFO [[0.00994388 0.85256493 0.32759413 ... 0.32759413 0.32759413 0.32759413]
 [0.01040888 0.8551844  0.33888343 ... 0.33888343 0.33888343 0.33888343]
 [0.10230307 0.7330744  0.48757598 ... 0.48757598 0.48757598 0.48757598]
 ...
 [0.00662456 0.9698261  0.03933145 ... 0.7999456  0.7999456  0.7999456 ]
 [0.0118391  0.93751884 0.01839911 ... 0.8341616  0.8341616  0.8341616 ]
 [0.01469655 0.9253486  0.02174288 ... 0.8312731  0.8312731  0.8312731 ]]
2022-12-18 23:51:47,253 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:51:47,254 INFO Predicting labels for 18 texts
2022-12-18 23:51:47,475 INFO There are 7/7 active rules
2022-12-18 23:51:47,475 INFO Coverage: 100.0% (18/18)
2022-12-18 23:51:47,475 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:51:47,499 INFO DONE, Getting attention scores...
2022-12-18 23:51:47,556 INFO the attention scores are
2022-12-18 23:51:47,556 INFO [[5.3723417e-02 1.3477899e-01 6.3111268e-02 3.8762575e-01 8.8197178e-01
  8.8354719e-01 2.3376143e-02 1.6028376e-01]
 [4.0740941e-02 1.1382458e-01 4.8462428e-02 3.7465113e-01 9.0374303e-01
  9.0739030e-01 1.4979325e-02 1.3739873e-01]
 [3.5218328e-02 9.9648580e-02 4.6792351e-02 3.5555586e-01 8.9564747e-01
  9.1595358e-01 1.2871119e-02 1.2468673e-01]
 [3.3962023e-02 1.0462410e-01 6.2516920e-02 3.1979880e-01 8.6815619e-01
  9.0837914e-01 1.6112668e-02 8.9194775e-02]
 [4.0076837e-02 1.2361473e-01 7.1812414e-02 2.8325006e-01 8.7038088e-01
  8.9247358e-01 1.9016717e-02 1.1816560e-01]
 [4.8507601e-02 1.4685948e-01 9.0079762e-02 2.9171506e-01 8.3449829e-01
  8.6975384e-01 2.8515849e-02 1.3194112e-01]
 [5.9833508e-02 1.6940850e-01 9.0549126e-02 3.4123674e-01 8.4424275e-01
  8.5938692e-01 3.1837616e-02 1.5593913e-01]
 [6.1313141e-02 1.6020522e-01 8.1406951e-02 3.6467594e-01 8.6856532e-01
  8.6202490e-01 2.9263880e-02 1.7295483e-01]
 [4.5540015e-04 7.8550959e-01 1.6454633e-02 2.9009204e-02 6.0903543e-01
  6.6837949e-01 6.9799566e-01 6.1414714e-05]
 [2.1298236e-04 9.7355765e-01 8.4344983e-02 2.8263652e-01 9.4975787e-01
  7.5371844e-01 9.9541301e-01 1.3634249e-06]
 [4.7889180e-03 9.8890215e-01 2.5708260e-02 5.1135242e-02 9.6287107e-01
  2.6072055e-01 9.7669959e-01 7.5906707e-04]
 [8.3711268e-03 7.1356809e-01 6.2473873e-03 3.0000302e-01 5.6198853e-01
  2.8406137e-01 9.4291705e-01 1.2779674e-02]
 [1.0623895e-02 9.8350551e-03 3.0294633e-03 4.2802632e-01 9.9887568e-01
  6.1710066e-01 9.3884274e-02 3.4546757e-03]
 [2.0726002e-03 6.9704428e-03 1.1018184e-03 3.8601857e-01 9.9951506e-01
  9.3931413e-01 2.8648896e-03 1.2929960e-01]
 [3.1926758e-03 3.3483685e-03 1.3949488e-04 3.8891679e-01 9.9866450e-01
  9.8428935e-01 3.8950267e-04 6.0581253e-03]
 [4.9985846e-04 7.0033115e-03 3.7536825e-04 2.0374328e-01 9.9927074e-01
  9.9312639e-01 3.0342402e-05 6.5383292e-03]
 [7.4998016e-04 2.1979604e-02 8.1020994e-03 8.9152887e-02 9.9678683e-01
  9.4384867e-01 2.0248204e-04 5.7275114e-03]
 [5.6208703e-03 7.0791148e-02 1.4280504e-02 1.4628796e-01 9.8728406e-01
  9.5355487e-01 8.3370641e-04 1.9317217e-02]]
2022-12-18 23:51:47,559 INFO Evaluating teacher dev iter0 on 18 examples
2022-12-18 23:51:47,560 INFO teacher dev iter0 performance: 25.70
2022-12-18 23:51:47,560 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:51:47,560 INFO Predicting labels for 32 texts
2022-12-18 23:51:48,689 INFO There are 7/7 active rules
2022-12-18 23:51:48,689 INFO Coverage: 100.0% (32/32)
2022-12-18 23:51:48,689 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:51:48,718 INFO DONE, Getting attention scores...
2022-12-18 23:51:48,773 INFO the attention scores are
2022-12-18 23:51:48,773 INFO [[0.03786503 0.58794105 0.02817274 0.22582103 0.7109297  0.4453884
  0.94865113 0.02220009]
 [0.10168408 0.1480924  0.05061034 0.30244547 0.80106556 0.48902422
  0.52756333 0.1097442 ]
 [0.12508333 0.1179624  0.06578422 0.45653436 0.8874832  0.6653553
  0.14161938 0.14166571]
 [0.1031959  0.10995854 0.05174105 0.4827904  0.8855356  0.82628864
  0.04611821 0.20498365]
 [0.05694998 0.09674425 0.05150187 0.4480195  0.89022917 0.869316
  0.02712424 0.14663547]
 [0.04723542 0.11688091 0.07961166 0.3684109  0.89022785 0.8452496
  0.02489285 0.12883805]
 [0.05376272 0.17037089 0.12051232 0.32211176 0.8583479  0.78130853
  0.03578973 0.13177676]
 [0.07560483 0.23679726 0.1643266  0.33451456 0.84630424 0.7254206
  0.05790958 0.12548931]
 [0.1022803  0.26097843 0.15478012 0.32290637 0.8477364  0.71835774
  0.06654946 0.19638334]
 [0.09328435 0.20095444 0.10707361 0.3786256  0.8753074  0.7583172
  0.06178117 0.24318059]
 [0.08188818 0.16053686 0.07589083 0.4331393  0.89001095 0.8073347
  0.0431092  0.1735392 ]
 [0.06153614 0.13863255 0.06592976 0.40489215 0.9092684  0.84792805
  0.02920028 0.17688915]
 [0.05937809 0.17514749 0.10878141 0.3610901  0.85787976 0.7914051
  0.04049138 0.12237545]
 [0.07670009 0.20099147 0.13287315 0.33957878 0.844666   0.7730405
  0.04737951 0.16974826]
 [0.09995758 0.22809684 0.16682106 0.3559606  0.83494264 0.7237617
  0.07054978 0.18689671]
 [0.11206372 0.23562153 0.14749278 0.38517508 0.823813   0.73978376
  0.07659856 0.23848313]
 [0.09454191 0.17166556 0.09788648 0.41409928 0.8893262  0.7957243
  0.05864129 0.26049533]
 [0.09562136 0.17087243 0.09436727 0.42831206 0.8886926  0.80404395
  0.04748077 0.15375718]
 [0.07702425 0.18245833 0.10324696 0.3507466  0.88742334 0.8026743
  0.0418712  0.23210436]
 [0.06832646 0.14378287 0.07803272 0.3887955  0.9093037  0.8130033
  0.04073404 0.21944013]
 [0.06811374 0.12584911 0.05982608 0.4447142  0.9014131  0.84817487
  0.03160996 0.1645581 ]
 [0.04238626 0.10772014 0.04870514 0.3818385  0.9165328  0.870508
  0.01974565 0.18957247]
 [0.03843168 0.09097155 0.04289448 0.38863856 0.9254749  0.8809859
  0.01710118 0.13322008]
 [0.03572265 0.11017017 0.05531572 0.36845782 0.9159974  0.8719733
  0.01661179 0.1005761 ]
 [0.04225892 0.15055853 0.09579944 0.2931047  0.8979291  0.81869847
  0.02257653 0.12156425]
 [0.06294888 0.20349291 0.12770453 0.31511244 0.84088504 0.7727748
  0.04296483 0.1430231 ]
 [0.0867416  0.23593648 0.14322445 0.34262502 0.82746917 0.7554535
  0.05735197 0.16316979]
 [0.09610391 0.25857916 0.1474747  0.34573117 0.8054331  0.73850733
  0.06749423 0.18232282]
 [0.09421196 0.23779461 0.12961514 0.3728703  0.8134009  0.76157737
  0.06391685 0.19303355]
 [0.101794   0.20574543 0.11729713 0.40030226 0.8441898  0.8076888
  0.05664399 0.20107107]
 [0.09210339 0.19392827 0.11930154 0.38902232 0.82664084 0.81600785
  0.05146062 0.20580225]
 [0.08219534 0.18057843 0.10846238 0.3837488  0.84565216 0.82531565
  0.04466065 0.21251251]]
2022-12-18 23:51:48,778 INFO Evaluating teacher test iter0 on 32 examples
2022-12-18 23:51:48,779 INFO teacher test iter0 performance: 1.97
2022-12-18 23:51:48,780 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:51:48,785 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.951247215270996
2022-12-18 23:51:48,785 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:51:49,594 INFO fine-tuning the student on clean labeled data
2022-12-18 23:51:51,438 INFO Predicting labels for 18 texts
2022-12-18 23:51:51,568 INFO Evaluating student dev iter0 on 18 examples
2022-12-18 23:51:51,569 INFO student dev iter0 performance: 12.71
2022-12-18 23:51:51,569 INFO Predicting labels for 32 texts
2022-12-18 23:51:51,674 INFO Evaluating student test iter0 on 32 examples
2022-12-18 23:51:51,675 INFO student test iter0 performance: 1.32
2022-12-18 23:51:51,675 INFO Student Dev performance on iter 0: 12.710674436239168
2022-12-18 23:51:51,675 INFO Student Test performance on iter 0: 1.3221550267137934
2022-12-18 23:51:51,675 INFO Improved dev performance from 12.72 to 12.71
2022-12-18 23:51:51,676 INFO Saving student_best to ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/student_best
2022-12-18 23:51:51,676 INFO Saving model at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/student_best/final_model.h5
2022-12-18 23:51:51,689 INFO Saving teacher at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_best
2022-12-18 23:51:51,690 INFO Saving rule attention network at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_best/rule_attention_network.h5
2022-12-18 23:51:51,706 INFO 

	 *** Starting loop 1 ***
2022-12-18 23:51:51,706 INFO Adding Student as extra rule in Teacher
2022-12-18 23:51:51,706 INFO Getting rule predictions
2022-12-18 23:51:51,706 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:51:51,707 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:51:51,707 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:51:51,707 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:51:51,707 INFO Predicting labels for 247 texts
2022-12-18 23:51:51,860 INFO Predicting labels for 18 texts
2022-12-18 23:51:51,969 INFO Predicting labels for 444 texts
2022-12-18 23:51:52,080 INFO Training Rule Attention Network
2022-12-18 23:51:52,081 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:51:52,082 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:51:52,084 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:51:52,084 INFO 

		*** Training RAN ***
2022-12-18 23:51:53,224 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:51:53,225 INFO Predicting labels for 444 texts
2022-12-18 23:51:53,331 INFO There are 3/7 active rules
2022-12-18 23:51:53,331 INFO Coverage: 100.0% (444/444)
2022-12-18 23:51:53,334 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:51:53,409 INFO DONE, Getting attention scores...
2022-12-18 23:51:53,464 INFO the attention scores are
2022-12-18 23:51:53,465 INFO [[7.4524381e-05 9.8059940e-01 2.5376576e-01 ... 2.5376576e-01
  2.5376576e-01 2.5376576e-01]
 [8.3323204e-05 9.8100084e-01 2.6739332e-01 ... 2.6739332e-01
  2.6739332e-01 2.6739332e-01]
 [4.1124476e-03 8.1038052e-01 2.2865134e-01 ... 2.2865134e-01
  2.2865134e-01 2.2865134e-01]
 ...
 [1.7385295e-05 9.9367529e-01 5.0851149e-03 ... 3.4863400e-01
  3.4863400e-01 3.4863400e-01]
 [4.3468095e-05 9.6647167e-01 1.4825452e-03 ... 4.5208204e-01
  4.5208204e-01 4.5208204e-01]
 [6.4343956e-05 9.5705354e-01 1.6416212e-03 ... 4.7524938e-01
  4.7524938e-01 4.7524938e-01]]
2022-12-18 23:51:53,466 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:51:53,466 INFO Predicting labels for 18 texts
2022-12-18 23:51:53,569 INFO There are 7/7 active rules
2022-12-18 23:51:53,569 INFO Coverage: 100.0% (18/18)
2022-12-18 23:51:53,569 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:51:53,594 INFO DONE, Getting attention scores...
2022-12-18 23:51:53,650 INFO the attention scores are
2022-12-18 23:51:53,651 INFO [[1.95157435e-02 2.67289039e-02 1.40003085e-01 4.44611460e-01
  8.95284295e-01 8.61866176e-01 4.72972095e-02 1.26094922e-01]
 [1.26906093e-02 1.91467386e-02 1.14687711e-01 4.43419307e-01
  9.18806314e-01 8.85165393e-01 3.28472108e-02 1.04111142e-01]
 [9.97654628e-03 1.77166536e-02 1.15333125e-01 4.34435636e-01
  9.09084022e-01 8.83233786e-01 3.23936418e-02 8.17405954e-02]
 [1.05534466e-02 2.60408372e-02 1.57345548e-01 3.89730603e-01
  8.65175486e-01 8.22022259e-01 5.21042421e-02 4.84376252e-02]
 [1.19152358e-02 3.28810886e-02 1.62328988e-01 3.71137172e-01
  8.78229558e-01 8.05941701e-01 5.12025058e-02 6.04626834e-02]
 [1.65075790e-02 4.03956398e-02 1.99290439e-01 3.61232281e-01
  8.36078525e-01 7.70546317e-01 8.30060169e-02 7.31715634e-02]
 [2.46940777e-02 4.12863865e-02 1.93144917e-01 3.95533115e-01
  8.58473837e-01 7.92666554e-01 8.03441107e-02 1.04293615e-01]
 [2.41258983e-02 3.71507443e-02 1.62143618e-01 4.20588106e-01
  8.86374652e-01 8.28160167e-01 5.92652746e-02 1.22787610e-01]
 [1.34832203e-06 9.69703913e-01 2.51910180e-01 4.43891436e-03
  9.26558733e-01 2.00538468e-02 9.99960899e-01 2.75258518e-08]
 [1.10686543e-07 9.99191701e-01 8.95930678e-02 8.06421712e-02
  9.96743798e-01 1.46044316e-02 9.99999881e-01 4.23643195e-12]
 [1.25978761e-06 9.99360144e-01 9.67809465e-04 6.39021099e-02
  9.97198939e-01 7.57098012e-03 9.99999046e-01 2.48014107e-08]
 [4.82283613e-05 4.75913972e-01 7.71599414e-04 1.06890537e-01
  9.05378580e-01 2.07816914e-01 9.99909282e-01 1.59544725e-04]
 [8.49821881e-05 2.99566658e-04 8.60029948e-04 1.71306934e-02
  9.99996185e-01 9.99711812e-01 6.39671013e-02 4.41167355e-02]
 [5.99795494e-05 3.77914948e-05 1.91087986e-03 6.99889883e-02
  9.99960184e-01 9.99777496e-01 5.25615644e-04 3.85269225e-01]
 [5.07369055e-04 8.03602743e-05 3.07099451e-03 1.23204023e-01
  9.99624848e-01 9.99362648e-01 2.48924922e-03 7.26347556e-03]
 [4.01323668e-05 1.67019782e-04 5.34618879e-03 3.22077304e-01
  9.99669194e-01 9.94899213e-01 1.22622892e-04 2.94106128e-03]
 [3.63323416e-05 1.98591733e-03 2.69778352e-02 2.33322546e-01
  9.95463431e-01 9.33212996e-01 6.33585965e-04 5.32185659e-04]
 [7.32405926e-04 1.15984660e-02 5.69728538e-02 3.02297056e-01
  9.89987910e-01 8.93820763e-01 3.78868869e-03 2.87841656e-03]]
2022-12-18 23:51:53,653 INFO Evaluating teacher dev iter1 on 18 examples
2022-12-18 23:51:53,654 INFO teacher dev iter1 performance: 13.87
2022-12-18 23:51:53,655 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:51:53,655 INFO Predicting labels for 32 texts
2022-12-18 23:51:53,761 INFO There are 7/7 active rules
2022-12-18 23:51:53,761 INFO Coverage: 100.0% (32/32)
2022-12-18 23:51:53,761 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:51:53,785 INFO DONE, Getting attention scores...
2022-12-18 23:51:53,838 INFO the attention scores are
2022-12-18 23:51:53,838 INFO [[0.00106239 0.40996632 0.0037026  0.0898091  0.9700748  0.4242636
  0.9995042  0.00312428]
 [0.03607481 0.03394587 0.04411082 0.09978807 0.9401455  0.85125333
  0.90255016 0.33493152]
 [0.07954444 0.03230778 0.16727631 0.19690551 0.94727415 0.9002058
  0.2835404  0.23187219]
 [0.05007722 0.02751393 0.14257137 0.4256106  0.89779294 0.890457
  0.05712304 0.21342613]
 [0.02236165 0.02766433 0.12817846 0.44445357 0.90085804 0.8777708
  0.03791658 0.10017554]
 [0.01540036 0.04650837 0.15742746 0.4335783  0.8963071  0.81368756
  0.04010428 0.05124532]
 [0.02050665 0.06883959 0.21540831 0.40047503 0.8590898  0.7291796
  0.0671456  0.05457398]
 [0.0344119  0.12382028 0.262123   0.3862385  0.84165096 0.66101944
  0.09960959 0.04724412]
 [0.04644174 0.1065936  0.2534462  0.37874836 0.8707465  0.6970233
  0.09650099 0.10400137]
 [0.04731607 0.05247999 0.17976598 0.3928832  0.9046018  0.81288934
  0.07592767 0.1862653 ]
 [0.04951021 0.0418211  0.15934153 0.4039363  0.9050781  0.8360463
  0.06301647 0.14355272]
 [0.02675219 0.03481593 0.1352674  0.42162213 0.9253965  0.85660523
  0.03970895 0.11597081]
 [0.02611254 0.07596224 0.22004905 0.4096993  0.84857064 0.7346689
  0.0803218  0.05426523]
 [0.03271157 0.08369898 0.22364552 0.41341546 0.86002755 0.73029673
  0.07733355 0.08156846]
 [0.04566837 0.10855766 0.24293084 0.40823627 0.84165746 0.7064126
  0.09051876 0.08968714]
 [0.06069432 0.08905178 0.23811784 0.41538876 0.8474474  0.73647475
  0.10255757 0.16500911]
 [0.04405253 0.04693783 0.1471939  0.4189076  0.9148992  0.84748375
  0.05251351 0.1779359 ]
 [0.04114573 0.06491577 0.16489081 0.41737407 0.90539825 0.8041506
  0.05609021 0.0801708 ]
 [0.02850048 0.05231627 0.17117712 0.41534668 0.9159977  0.8216723
  0.04785852 0.14281692]
 [0.02668236 0.03458725 0.12392003 0.42209202 0.9277131  0.86896044
  0.03628027 0.13674118]
 [0.03187009 0.03329859 0.13467267 0.42790252 0.91314536 0.86280566
  0.04287048 0.11747785]
 [0.01437295 0.01980755 0.11714468 0.43740302 0.9349912  0.8958334
  0.02503269 0.14183003]
 [0.01325106 0.02206339 0.10547336 0.43096903 0.9302572  0.8877384
  0.02409786 0.07118902]
 [0.01222423 0.03671411 0.13916211 0.42136836 0.9216139  0.8345969
  0.03277645 0.0421615 ]
 [0.01335765 0.05087593 0.16770485 0.39600146 0.9084892  0.7821422
  0.03926625 0.04430277]
 [0.02774486 0.07793871 0.23607205 0.38634413 0.8439678  0.7053045
  0.08709156 0.06425139]
 [0.04275715 0.1015909  0.25504458 0.39464235 0.83195114 0.68845195
  0.10790034 0.07936972]
 [0.05212807 0.09510797 0.27591428 0.38171008 0.8127838  0.67661875
  0.13993673 0.1074812 ]
 [0.05360176 0.07697479 0.253388   0.39273968 0.8210792  0.7198669
  0.13026449 0.13856944]
 [0.0502069  0.07237393 0.19588503 0.43096372 0.8575961  0.7801016
  0.08672712 0.14035754]
 [0.04271636 0.06484002 0.20040472 0.43244457 0.8478355  0.7794412
  0.087827   0.1455027 ]
 [0.03553749 0.0541967  0.17794983 0.43029448 0.8692971  0.80865926
  0.07155099 0.14460734]]
2022-12-18 23:51:53,843 INFO Evaluating teacher test iter1 on 32 examples
2022-12-18 23:51:53,844 INFO teacher test iter1 performance: 1.56
2022-12-18 23:51:53,844 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:51:53,849 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9280165433883667
2022-12-18 23:51:53,850 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:51:54,633 INFO fine-tuning the student on clean labeled data
2022-12-18 23:51:56,523 INFO Predicting labels for 18 texts
2022-12-18 23:51:56,637 INFO Evaluating student dev iter1 on 18 examples
2022-12-18 23:51:56,638 INFO student dev iter1 performance: 12.78
2022-12-18 23:51:56,638 INFO Predicting labels for 32 texts
2022-12-18 23:51:56,744 INFO Evaluating student test iter1 on 32 examples
2022-12-18 23:51:56,745 INFO student test iter1 performance: 1.06
2022-12-18 23:51:56,745 INFO Student Dev performance on iter 1: 12.779571103368271
2022-12-18 23:51:56,745 INFO Student Test performance on iter 1: 1.062718319254087
2022-12-18 23:51:56,746 INFO 

	 *** Starting loop 2 ***
2022-12-18 23:51:56,746 INFO Adding Student as extra rule in Teacher
2022-12-18 23:51:56,746 INFO Getting rule predictions
2022-12-18 23:51:56,746 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:51:56,746 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:51:56,746 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:51:56,747 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:51:56,747 INFO Predicting labels for 247 texts
2022-12-18 23:51:56,856 INFO Predicting labels for 18 texts
2022-12-18 23:51:56,968 INFO Predicting labels for 444 texts
2022-12-18 23:51:57,085 INFO Training Rule Attention Network
2022-12-18 23:51:57,087 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:51:57,087 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:51:57,089 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:51:57,090 INFO 

		*** Training RAN ***
2022-12-18 23:51:58,250 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:51:58,251 INFO Predicting labels for 444 texts
2022-12-18 23:51:58,363 INFO There are 3/7 active rules
2022-12-18 23:51:58,364 INFO Coverage: 100.0% (444/444)
2022-12-18 23:51:58,366 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:51:58,437 INFO DONE, Getting attention scores...
2022-12-18 23:51:58,490 INFO the attention scores are
2022-12-18 23:51:58,491 INFO [[2.1920982e-06 9.9908078e-01 3.3746701e-01 ... 3.3746701e-01
  3.3746701e-01 3.3746701e-01]
 [2.5862987e-06 9.9905974e-01 3.5664189e-01 ... 3.5664189e-01
  3.5664189e-01 3.5664189e-01]
 [7.5024064e-04 9.7457480e-01 1.9821946e-01 ... 1.9821946e-01
  1.9821946e-01 1.9821946e-01]
 ...
 [3.7572971e-07 9.9992311e-01 1.1954570e-05 ... 2.2429800e-01
  2.2429800e-01 2.2429800e-01]
 [7.0203225e-07 9.9929726e-01 1.6101465e-06 ... 3.9556551e-01
  3.9556551e-01 3.9556551e-01]
 [1.1913913e-06 9.9886572e-01 1.7267463e-06 ... 4.3719846e-01
  4.3719846e-01 4.3719846e-01]]
2022-12-18 23:51:58,492 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:51:58,492 INFO Predicting labels for 18 texts
2022-12-18 23:51:58,602 INFO There are 7/7 active rules
2022-12-18 23:51:58,603 INFO Coverage: 100.0% (18/18)
2022-12-18 23:51:58,603 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:51:58,627 INFO DONE, Getting attention scores...
2022-12-18 23:51:58,685 INFO the attention scores are
2022-12-18 23:51:58,685 INFO [[5.68604423e-03 4.01934125e-02 8.03100541e-02 4.93911684e-01
  8.92123640e-01 8.21195245e-01 3.86006832e-02 6.53164834e-02]
 [3.12364986e-03 2.94232536e-02 6.23441972e-02 4.98112321e-01
  9.19182837e-01 8.45802486e-01 2.63405573e-02 4.86634448e-02]
 [2.29038205e-03 2.96675917e-02 6.27955124e-02 4.93401438e-01
  9.15392280e-01 8.32342982e-01 2.55401377e-02 3.46470252e-02]
 [2.59489357e-03 4.58285809e-02 8.69163573e-02 4.62274551e-01
  8.81927133e-01 7.54270494e-01 3.84308659e-02 2.09248513e-02]
 [2.84333434e-03 4.86988015e-02 8.02598596e-02 4.55178171e-01
  8.93086016e-01 7.64696002e-01 3.67048457e-02 2.77976505e-02]
 [4.72340360e-03 6.31964579e-02 1.00772917e-01 4.48907554e-01
  8.47570777e-01 7.20251441e-01 5.35392016e-02 3.92922983e-02]
 [7.51136011e-03 6.18335530e-02 1.06982216e-01 4.57617223e-01
  8.59668911e-01 7.50298738e-01 5.72744533e-02 5.76527938e-02]
 [7.25363847e-03 5.10747768e-02 9.21167880e-02 4.77076739e-01
  8.85702014e-01 8.02645743e-01 4.74918559e-02 6.38533384e-02]
 [7.79048737e-09 9.99800742e-01 3.80528122e-02 7.34074565e-04
  9.96201932e-01 1.71187843e-04 9.99905705e-01 6.13736839e-11]
 [1.37287168e-10 9.99997854e-01 1.41361612e-04 3.57410274e-02
  9.99995470e-01 5.99662133e-04 9.99999881e-01 1.12903283e-14]
 [1.37645477e-08 9.99997497e-01 5.12085353e-06 2.21573740e-01
  9.99986887e-01 5.42336900e-04 9.99998093e-01 6.46133425e-10]
 [2.61079026e-06 8.85854661e-01 2.84497423e-06 3.67208757e-02
  9.93036091e-01 1.92491841e-02 9.99419332e-01 2.75449602e-05]
 [1.38002122e-07 1.56789902e-05 2.86934733e-06 7.32527599e-02
  9.99999881e-01 9.99979138e-01 2.43729883e-04 2.19681129e-01]
 [9.13754889e-07 6.85797204e-06 6.93444526e-05 1.99232519e-01
  9.99981046e-01 9.99838233e-01 7.64100041e-05 2.01389626e-01]
 [5.12100542e-06 1.58224520e-05 2.09801132e-03 2.00743869e-01
  9.99820292e-01 9.98280883e-01 2.79297179e-04 2.89467024e-03]
 [1.35967753e-06 2.21845359e-04 1.81856367e-03 5.71799695e-01
  9.99762952e-01 9.93495464e-01 1.65822348e-04 2.29208192e-04]
 [6.30128284e-07 1.86002057e-03 8.96939263e-03 5.44328451e-01
  9.96511400e-01 9.39837694e-01 3.90914181e-04 2.19374379e-05]
 [4.83471194e-05 8.31805170e-03 1.53472442e-02 4.42406178e-01
  9.94167328e-01 9.26899076e-01 2.41995137e-03 9.06326051e-04]]
2022-12-18 23:51:58,688 INFO Evaluating teacher dev iter2 on 18 examples
2022-12-18 23:51:58,689 INFO teacher dev iter2 performance: 13.08
2022-12-18 23:51:58,689 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:51:58,689 INFO Predicting labels for 32 texts
2022-12-18 23:51:58,806 INFO There are 7/7 active rules
2022-12-18 23:51:58,806 INFO Coverage: 100.0% (32/32)
2022-12-18 23:51:58,807 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:51:58,832 INFO DONE, Getting attention scores...
2022-12-18 23:51:58,886 INFO the attention scores are
2022-12-18 23:51:58,886 INFO [[6.67647037e-05 7.76161373e-01 2.44516432e-05 7.41278827e-02
  9.97522295e-01 1.05709888e-01 9.96444285e-01 2.79119750e-03]
 [7.15883262e-03 1.79555882e-02 5.57964761e-03 9.96769890e-02
  9.67008948e-01 7.71873176e-01 4.84924674e-01 4.48561400e-01]
 [2.29971875e-02 1.74726751e-02 8.89911652e-02 2.55825043e-01
  9.53146935e-01 8.70915353e-01 9.54035670e-02 3.27622116e-01]
 [1.73623748e-02 3.74697149e-02 1.16452843e-01 4.87528801e-01
  8.87098372e-01 8.41340661e-01 6.37467206e-02 1.13469176e-01]
 [6.78493641e-03 4.65560369e-02 1.09616734e-01 5.10122716e-01
  8.95585299e-01 8.18074644e-01 4.94323261e-02 3.85421440e-02]
 [4.72119823e-03 5.93976416e-02 1.27802223e-01 4.86144453e-01
  9.01622653e-01 7.68781662e-01 4.50220518e-02 1.87152512e-02]
 [6.97377091e-03 8.27113092e-02 1.69908479e-01 4.57022011e-01
  8.62448514e-01 6.90676510e-01 6.92307204e-02 1.81342494e-02]
 [1.20726237e-02 1.19047195e-01 1.91355363e-01 4.50428724e-01
  8.51148665e-01 6.70801520e-01 8.75352472e-02 2.13421695e-02]
 [1.79856122e-02 9.93638411e-02 1.63366452e-01 4.57238078e-01
  8.74939978e-01 7.31634378e-01 8.56608599e-02 5.41714467e-02]
 [1.52828777e-02 5.58748581e-02 1.10696860e-01 4.75957483e-01
  8.93938661e-01 8.19225132e-01 6.44691214e-02 9.53119174e-02]
 [1.46125657e-02 4.29412723e-02 1.11386165e-01 4.75425541e-01
  9.02286291e-01 8.24245095e-01 5.40585034e-02 7.81556219e-02]
 [8.22087098e-03 4.41932790e-02 1.00393809e-01 4.89127487e-01
  9.25745308e-01 8.39978456e-01 4.19316925e-02 5.00302017e-02]
 [9.54991858e-03 8.77288505e-02 1.73469171e-01 4.52785730e-01
  8.46482635e-01 7.07194626e-01 7.64278769e-02 2.55401079e-02]
 [1.31636588e-02 9.03423056e-02 1.70477286e-01 4.57271636e-01
  8.66573453e-01 7.18282342e-01 7.86971599e-02 3.63411866e-02]
 [1.54708140e-02 1.05752550e-01 1.76323995e-01 4.68600035e-01
  8.49282086e-01 7.12543428e-01 8.17614347e-02 4.07050475e-02]
 [2.70367134e-02 9.92802382e-02 1.77286595e-01 4.67001200e-01
  8.45915496e-01 7.37339795e-01 1.00387819e-01 8.52809325e-02]
 [1.23143792e-02 5.13507016e-02 1.00303434e-01 4.88386691e-01
  9.13912356e-01 8.41320992e-01 5.09559885e-02 7.71140456e-02]
 [1.11940121e-02 5.69029115e-02 1.19283900e-01 4.65523988e-01
  9.18485284e-01 7.99340129e-01 5.22403494e-02 4.15330864e-02]
 [9.92703158e-03 5.77637516e-02 1.12768210e-01 4.90680099e-01
  9.19486105e-01 8.21793735e-01 5.10863662e-02 5.75380065e-02]
 [5.92025789e-03 3.84941362e-02 8.11786428e-02 4.91719574e-01
  9.29109871e-01 8.61998916e-01 3.65268104e-02 4.95821349e-02]
 [9.75592434e-03 4.51403931e-02 1.09385677e-01 4.88923997e-01
  9.12339151e-01 8.28229010e-01 4.78001349e-02 5.13382517e-02]
 [4.22266964e-03 3.07095367e-02 8.01509172e-02 5.14059365e-01
  9.28994358e-01 8.63693178e-01 2.95891557e-02 4.72953618e-02]
 [3.01965000e-03 2.94483397e-02 7.78995976e-02 4.90281820e-01
  9.31105852e-01 8.56973648e-01 2.68650558e-02 2.50228979e-02]
 [3.56692425e-03 4.55281697e-02 1.10742629e-01 4.73230362e-01
  9.25694466e-01 8.00002038e-01 3.73457745e-02 1.60056856e-02]
 [3.39441304e-03 5.50110303e-02 1.12291574e-01 4.71352518e-01
  9.13636148e-01 7.65666723e-01 3.70556079e-02 1.43927364e-02]
 [9.80765373e-03 8.92246887e-02 1.67019457e-01 4.40064132e-01
  8.39421809e-01 6.90140367e-01 7.75191933e-02 2.84224153e-02]
 [1.71662960e-02 1.07088380e-01 1.76660091e-01 4.42129403e-01
  8.36563289e-01 7.01194108e-01 9.45085883e-02 4.55483757e-02]
 [2.36033611e-02 1.13097146e-01 1.93195835e-01 4.34607327e-01
  8.01487029e-01 6.72147334e-01 1.20909885e-01 6.22423217e-02]
 [2.30193064e-02 9.53398570e-02 1.69048131e-01 4.49037790e-01
  8.05287242e-01 7.06714272e-01 1.05859682e-01 8.58092830e-02]
 [1.78994071e-02 7.95547590e-02 1.27521977e-01 4.71238196e-01
  8.60697627e-01 7.76858568e-01 7.38967955e-02 8.60315710e-02]
 [1.65386815e-02 8.12312216e-02 1.35729119e-01 4.72726911e-01
  8.47427726e-01 7.58346796e-01 7.83187002e-02 8.39959905e-02]
 [1.21404938e-02 6.78546801e-02 1.12228237e-01 4.82010871e-01
  8.65078390e-01 7.92172968e-01 6.25799373e-02 7.82810599e-02]]
2022-12-18 23:51:58,890 INFO Evaluating teacher test iter2 on 32 examples
2022-12-18 23:51:58,891 INFO teacher test iter2 performance: 1.30
2022-12-18 23:51:58,892 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:51:58,896 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9352829456329346
2022-12-18 23:51:58,897 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:51:59,698 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:00,498 INFO Predicting labels for 18 texts
2022-12-18 23:52:00,607 INFO Evaluating student dev iter2 on 18 examples
2022-12-18 23:52:00,608 INFO student dev iter2 performance: 12.89
2022-12-18 23:52:00,608 INFO Predicting labels for 32 texts
2022-12-18 23:52:00,714 INFO Evaluating student test iter2 on 32 examples
2022-12-18 23:52:00,715 INFO student test iter2 performance: 0.87
2022-12-18 23:52:00,715 INFO Student Dev performance on iter 2: 12.893538571084346
2022-12-18 23:52:00,715 INFO Student Test performance on iter 2: 0.8666216385974859
2022-12-18 23:52:00,716 INFO 

	 *** Starting loop 3 ***
2022-12-18 23:52:00,716 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:00,716 INFO Getting rule predictions
2022-12-18 23:52:00,716 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:00,716 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:00,716 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:00,717 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:00,717 INFO Predicting labels for 247 texts
2022-12-18 23:52:00,827 INFO Predicting labels for 18 texts
2022-12-18 23:52:00,930 INFO Predicting labels for 444 texts
2022-12-18 23:52:01,041 INFO Training Rule Attention Network
2022-12-18 23:52:01,043 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:01,043 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:01,045 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:01,046 INFO 

		*** Training RAN ***
2022-12-18 23:52:02,318 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:02,319 INFO Predicting labels for 444 texts
2022-12-18 23:52:02,438 INFO There are 3/7 active rules
2022-12-18 23:52:02,438 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:02,440 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:02,517 INFO DONE, Getting attention scores...
2022-12-18 23:52:02,573 INFO the attention scores are
2022-12-18 23:52:02,573 INFO [[1.6797362e-07 8.2476914e-01 3.3593204e-02 ... 3.3593204e-02
  3.3593204e-02 3.3593204e-02]
 [1.9603338e-07 8.3548957e-01 3.7495118e-02 ... 3.7495118e-02
  3.7495118e-02 3.7495118e-02]
 [1.3205470e-04 2.5754663e-01 2.0469004e-02 ... 2.0469004e-02
  2.0469004e-02 2.0469004e-02]
 ...
 [9.8210116e-09 4.0330055e-01 5.1614111e-06 ... 4.8196800e-03
  4.8196800e-03 4.8196800e-03]
 [3.7728149e-08 2.6198575e-02 4.8031814e-07 ... 1.9050471e-02
  1.9050471e-02 1.9050471e-02]
 [9.1357393e-08 2.3559365e-02 4.6013636e-07 ... 2.4800362e-02
  2.4800362e-02 2.4800362e-02]]
2022-12-18 23:52:02,574 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:02,574 INFO Predicting labels for 18 texts
2022-12-18 23:52:02,681 INFO There are 7/7 active rules
2022-12-18 23:52:02,681 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:02,681 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:02,705 INFO DONE, Getting attention scores...
2022-12-18 23:52:02,762 INFO the attention scores are
2022-12-18 23:52:02,762 INFO [[1.83483877e-03 9.29041393e-03 3.16128917e-02 4.69236463e-01
  9.47890580e-01 9.17156100e-01 7.28244195e-03 4.10628952e-02]
 [8.82677035e-04 5.88331884e-03 2.05873977e-02 4.76212561e-01
  9.64532852e-01 9.37762260e-01 4.11378592e-03 2.85561010e-02]
 [7.05841696e-04 5.98570937e-03 2.00774819e-02 4.74193275e-01
  9.63226736e-01 9.32121396e-01 4.34779935e-03 2.13858616e-02]
 [1.01860962e-03 8.06838088e-03 3.19147930e-02 4.39220935e-01
  9.46502030e-01 8.82830262e-01 8.22298974e-03 1.30626932e-02]
 [1.08792726e-03 9.03454889e-03 2.80454177e-02 4.37593818e-01
  9.51280355e-01 8.93006444e-01 7.55992765e-03 1.62827466e-02]
 [2.19919835e-03 1.31320562e-02 4.64327186e-02 4.18458521e-01
  9.20235991e-01 8.48655999e-01 1.45479403e-02 2.43736487e-02]
 [3.31868301e-03 1.46756331e-02 5.37938662e-02 4.31224614e-01
  9.25112963e-01 8.66298020e-01 1.55255273e-02 3.45753282e-02]
 [2.55825487e-03 1.19380550e-02 4.11309265e-02 4.54426914e-01
  9.42032456e-01 9.04469013e-01 9.99187864e-03 3.93359065e-02]
 [7.08947068e-11 6.96290195e-01 5.73694110e-01 1.07417865e-04
  9.95737672e-01 2.98584113e-03 9.99279559e-01 5.65523214e-13]
 [1.77027718e-12 9.28126514e-01 9.92067362e-05 6.74298080e-03
  9.99997616e-01 2.59877652e-01 9.99999762e-01 7.30951317e-17]
 [3.80805582e-10 9.01119113e-01 6.55119095e-07 2.20534354e-01
  9.99968529e-01 1.01519436e-01 9.99995828e-01 2.37306789e-11]
 [4.72740744e-08 1.08723983e-03 2.07783933e-06 5.04860329e-03
  9.86303389e-01 8.13522518e-01 9.98332202e-01 1.56203969e-05]
 [4.98928854e-09 1.43720085e-08 1.08509823e-08 6.37701005e-02
  1.00000000e+00 1.00000000e+00 3.45667281e-08 5.77436745e-01]
 [7.18336990e-09 3.40488739e-08 1.04175183e-06 1.34870887e-01
  9.99993443e-01 9.99998569e-01 2.27973729e-08 1.50333598e-01]
 [1.20325626e-06 1.11246365e-07 5.21735230e-04 2.87570506e-01
  9.99928355e-01 9.99953985e-01 1.07715709e-06 3.62528884e-03]
 [3.34335795e-08 1.87464218e-06 1.14849565e-04 5.78189254e-01
  9.99961734e-01 9.99683142e-01 6.92189190e-07 3.74412739e-05]
 [2.56342183e-08 3.66753702e-05 5.02047827e-04 6.20325565e-01
  9.99406457e-01 9.98360336e-01 5.00199667e-06 6.18969534e-06]
 [5.13156056e-06 2.62825051e-04 2.52483366e-03 4.66410428e-01
  9.98706579e-01 9.92687583e-01 1.05686646e-04 2.24577758e-04]]
2022-12-18 23:52:02,765 INFO Evaluating teacher dev iter3 on 18 examples
2022-12-18 23:52:02,766 INFO teacher dev iter3 performance: 13.81
2022-12-18 23:52:02,766 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:02,766 INFO Predicting labels for 32 texts
2022-12-18 23:52:02,874 INFO There are 7/7 active rules
2022-12-18 23:52:02,874 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:02,874 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:02,898 INFO DONE, Getting attention scores...
2022-12-18 23:52:02,950 INFO the attention scores are
2022-12-18 23:52:02,951 INFO [[1.38027881e-05 1.30686199e-03 1.26959994e-05 1.77045427e-02
  9.97748077e-01 9.23382759e-01 9.77340221e-01 1.63856000e-02]
 [3.62588139e-03 5.26199641e-04 4.63036215e-03 2.69455966e-02
  9.84535515e-01 9.82108474e-01 6.98412210e-02 8.03846896e-01]
 [1.30586475e-02 2.31898972e-03 4.75990660e-02 1.86796233e-01
  9.65676785e-01 9.56220210e-01 1.74038149e-02 4.73352700e-01]
 [5.45903621e-03 1.00027379e-02 5.17407507e-02 4.91083294e-01
  9.13266063e-01 9.27688241e-01 1.18726892e-02 1.12310924e-01]
 [1.93549413e-03 1.24937408e-02 5.06309010e-02 5.05349755e-01
  9.27137136e-01 9.18286324e-01 9.22876038e-03 3.32506262e-02]
 [1.41390401e-03 1.45158451e-02 5.45755401e-02 5.02264500e-01
  9.35172200e-01 9.04692590e-01 8.84569064e-03 1.21027399e-02]
 [2.57814978e-03 2.23220848e-02 9.45440382e-02 4.44449812e-01
  9.01377082e-01 8.41567874e-01 2.02587359e-02 1.11720394e-02]
 [5.25773643e-03 3.19401212e-02 1.27310589e-01 4.42731351e-01
  9.00649786e-01 8.28084707e-01 2.98236869e-02 1.26929088e-02]
 [6.77910354e-03 2.63479948e-02 1.05602689e-01 4.45957243e-01
  9.16079104e-01 8.70004594e-01 2.57301610e-02 3.40726376e-02]
 [4.40847641e-03 1.19275302e-02 5.74589446e-02 4.59369540e-01
  9.36048031e-01 9.29146826e-01 1.17403846e-02 6.55678436e-02]
 [5.15364949e-03 8.10053200e-03 5.94097674e-02 4.55031902e-01
  9.47334588e-01 9.31052625e-01 9.83721111e-03 6.53247088e-02]
 [2.26527127e-03 9.27476306e-03 4.56671603e-02 4.72880661e-01
  9.56438243e-01 9.36324298e-01 6.73297606e-03 3.78606096e-02]
 [4.45903745e-03 2.31816191e-02 1.14527173e-01 4.34074163e-01
  8.99900317e-01 8.41108978e-01 2.44421959e-02 1.64089873e-02]
 [5.18501503e-03 2.68387385e-02 9.74768028e-02 4.46364373e-01
  9.07150149e-01 8.53692055e-01 2.45314613e-02 2.39317138e-02]
 [6.18165173e-03 3.42030860e-02 9.99662876e-02 4.77030873e-01
  9.03966725e-01 8.66977394e-01 2.54416205e-02 2.69870218e-02]
 [1.12229092e-02 3.19570862e-02 1.19719028e-01 4.45958465e-01
  8.87204587e-01 8.50001872e-01 3.32721211e-02 6.30425662e-02]
 [2.94892606e-03 1.15434555e-02 3.65313515e-02 4.95532721e-01
  9.50171053e-01 9.53287303e-01 8.07247683e-03 6.71175718e-02]
 [3.66228144e-03 1.15296114e-02 5.51369861e-02 4.81519729e-01
  9.54287827e-01 9.37485516e-01 9.35566891e-03 3.04709412e-02]
 [2.72663124e-03 1.49007700e-02 5.37204221e-02 4.80237722e-01
  9.47807074e-01 9.24991906e-01 1.06889457e-02 3.79575118e-02]
 [1.20439357e-03 8.07903148e-03 2.73093209e-02 5.13837159e-01
  9.63467479e-01 9.65888143e-01 4.72990191e-03 3.90002169e-02]
 [2.93639908e-03 9.77939181e-03 5.26892729e-02 4.74007219e-01
  9.45893586e-01 9.29107189e-01 7.97269866e-03 4.38667797e-02]
 [9.18205013e-04 6.72718696e-03 3.31936777e-02 4.89940822e-01
  9.56446528e-01 9.46836293e-01 4.42864932e-03 3.17656621e-02]
 [7.09339452e-04 6.10387372e-03 3.10714897e-02 5.06345987e-01
  9.61607397e-01 9.55369115e-01 3.68240802e-03 1.99461747e-02]
 [1.07001432e-03 9.15610697e-03 4.83704880e-02 4.68358338e-01
  9.56024706e-01 9.23282504e-01 6.76647807e-03 1.03128981e-02]
 [1.00640254e-03 1.18509643e-02 4.79397997e-02 4.76302862e-01
  9.49445367e-01 9.12538707e-01 7.79131427e-03 8.30957200e-03]
 [4.38026292e-03 2.31639408e-02 1.07469507e-01 4.17316616e-01
  8.92094195e-01 8.31101418e-01 2.62427572e-02 1.89809892e-02]
 [8.62291828e-03 3.03469989e-02 1.24548525e-01 4.17307317e-01
  8.92290533e-01 8.24405730e-01 3.34434249e-02 3.11769918e-02]
 [1.28556546e-02 3.25471945e-02 1.59160778e-01 3.96766156e-01
  8.60357404e-01 7.79402792e-01 4.69185188e-02 4.41452079e-02]
 [1.18999975e-02 2.65859440e-02 1.38511136e-01 4.10594702e-01
  8.71429324e-01 8.06434870e-01 3.84479761e-02 5.68466783e-02]
 [7.58547476e-03 2.41582394e-02 7.07040504e-02 4.56163704e-01
  9.18990135e-01 8.80939603e-01 1.99331623e-02 5.82474023e-02]
 [6.96546724e-03 2.53375173e-02 7.19647780e-02 4.52774763e-01
  9.08112168e-01 8.61762106e-01 2.25248374e-02 5.47500961e-02]
 [4.44373395e-03 1.93982571e-02 5.21833152e-02 4.66595650e-01
  9.25040007e-01 8.96894991e-01 1.47788236e-02 5.25473766e-02]]
2022-12-18 23:52:02,955 INFO Evaluating teacher test iter3 on 32 examples
2022-12-18 23:52:02,957 INFO teacher test iter3 performance: 1.50
2022-12-18 23:52:02,957 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:02,962 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9634515047073364
2022-12-18 23:52:02,962 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:03,738 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:04,511 INFO Predicting labels for 18 texts
2022-12-18 23:52:04,620 INFO Evaluating student dev iter3 on 18 examples
2022-12-18 23:52:04,621 INFO student dev iter3 performance: 13.05
2022-12-18 23:52:04,621 INFO Predicting labels for 32 texts
2022-12-18 23:52:04,726 INFO Evaluating student test iter3 on 32 examples
2022-12-18 23:52:04,727 INFO student test iter3 performance: 0.72
2022-12-18 23:52:04,727 INFO Student Dev performance on iter 3: 13.054550715548805
2022-12-18 23:52:04,727 INFO Student Test performance on iter 3: 0.7239477152635393
2022-12-18 23:52:04,727 INFO 

	 *** Starting loop 4 ***
2022-12-18 23:52:04,727 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:04,728 INFO Getting rule predictions
2022-12-18 23:52:04,728 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:04,728 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:04,728 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:04,729 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:04,729 INFO Predicting labels for 247 texts
2022-12-18 23:52:04,837 INFO Predicting labels for 18 texts
2022-12-18 23:52:04,946 INFO Predicting labels for 444 texts
2022-12-18 23:52:05,053 INFO Training Rule Attention Network
2022-12-18 23:52:05,055 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:05,055 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:05,057 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:05,058 INFO 

		*** Training RAN ***
2022-12-18 23:52:06,376 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:06,377 INFO Predicting labels for 444 texts
2022-12-18 23:52:06,494 INFO There are 3/7 active rules
2022-12-18 23:52:06,494 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:06,496 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:06,584 INFO DONE, Getting attention scores...
2022-12-18 23:52:06,672 INFO the attention scores are
2022-12-18 23:52:06,672 INFO [[8.8637995e-09 9.8610771e-01 7.8610100e-02 ... 7.8610100e-02
  7.8610100e-02 7.8610100e-02]
 [1.0392820e-08 9.8570108e-01 8.5895829e-02 ... 8.5895829e-02
  8.5895829e-02 8.5895829e-02]
 [4.9135047e-05 4.4141489e-01 8.7034598e-02 ... 8.7034598e-02
  8.7034598e-02 8.7034598e-02]
 ...
 [4.5157827e-10 9.2523348e-01 1.3239803e-04 ... 5.0228033e-02
  5.0228033e-02 5.0228033e-02]
 [3.0300724e-09 3.0172166e-01 1.1584793e-05 ... 3.4106576e-01
  3.4106576e-01 3.4106576e-01]
 [9.6752819e-09 2.2718194e-01 9.9066538e-06 ... 3.9828670e-01
  3.9828670e-01 3.9828670e-01]]
2022-12-18 23:52:06,673 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:06,674 INFO Predicting labels for 18 texts
2022-12-18 23:52:06,794 INFO There are 7/7 active rules
2022-12-18 23:52:06,794 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:06,794 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:06,817 INFO DONE, Getting attention scores...
2022-12-18 23:52:06,875 INFO the attention scores are
2022-12-18 23:52:06,876 INFO [[3.73666245e-03 1.06787551e-02 2.73962636e-02 4.84254450e-01
  9.08510566e-01 8.95165622e-01 1.69050917e-02 3.51489522e-02]
 [1.84569019e-03 6.44774549e-03 1.67229008e-02 4.93526846e-01
  9.31275070e-01 9.20256078e-01 1.03421509e-02 2.51280162e-02]
 [1.45628699e-03 5.39340079e-03 1.58036631e-02 5.05781233e-01
  9.26119685e-01 9.22652185e-01 9.90219600e-03 2.14735940e-02]
 [2.55525834e-03 8.53184611e-03 2.92891134e-02 4.88261849e-01
  8.72108698e-01 8.85656893e-01 1.94126293e-02 2.05093324e-02]
 [2.43763346e-03 8.39388557e-03 2.55856887e-02 4.81233269e-01
  8.92769933e-01 8.92118096e-01 1.88041627e-02 2.34068725e-02]
 [5.22272382e-03 1.68522988e-02 4.40812558e-02 4.63038534e-01
  8.44150603e-01 8.31874549e-01 3.74322012e-02 3.37005258e-02]
 [7.55867222e-03 1.90613493e-02 5.00322543e-02 4.71281558e-01
  8.49763155e-01 8.39770496e-01 3.54122370e-02 4.48155999e-02]
 [4.91014961e-03 1.29324775e-02 3.46907675e-02 4.71947074e-01
  8.97597909e-01 8.84683907e-01 2.15654820e-02 3.80512178e-02]
 [1.95309535e-13 9.99857068e-01 4.36886907e-01 5.48250409e-06
  9.95208681e-01 2.42174533e-03 9.99994636e-01 2.28282283e-15]
 [2.15751087e-15 9.99437630e-01 3.94751492e-04 4.68815506e-06
  9.99997973e-01 2.98142344e-01 1.00000000e+00 7.21505513e-22]
 [3.28245178e-12 9.98465538e-01 2.51260935e-05 2.22543464e-03
  9.99996543e-01 2.73677930e-02 1.00000000e+00 5.94899403e-15]
 [2.88464062e-08 1.24907575e-03 2.15567401e-04 4.42825076e-05
  9.99339759e-01 6.43613994e-01 9.99912500e-01 1.68228791e-08]
 [1.30178259e-08 7.67683428e-09 4.41295427e-08 7.16279168e-03
  1.00000000e+00 1.00000000e+00 1.40142005e-08 6.01509154e-01]
 [4.10310825e-08 1.29190511e-07 1.42450983e-06 8.72273073e-02
  9.99999762e-01 9.99998450e-01 4.51957021e-07 7.04493523e-02]
 [3.07091773e-06 3.95206740e-07 4.50302294e-04 1.70836225e-01
  9.99971747e-01 9.99976516e-01 4.80795688e-06 6.74386218e-04]
 [5.09243385e-08 4.20773858e-06 3.14995668e-05 5.74746192e-01
  9.99743879e-01 9.99438584e-01 6.03186709e-06 2.83640475e-05]
 [1.65587792e-08 3.10208634e-06 1.54907175e-04 5.75884402e-01
  9.99249160e-01 9.99308467e-01 1.11834443e-05 7.54658504e-06]
 [9.26939447e-06 1.59369418e-04 1.23644259e-03 4.35543358e-01
  9.94938731e-01 9.93401468e-01 4.03302751e-04 3.54546704e-04]]
2022-12-18 23:52:06,879 INFO Evaluating teacher dev iter4 on 18 examples
2022-12-18 23:52:06,880 INFO teacher dev iter4 performance: 13.39
2022-12-18 23:52:06,880 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:06,880 INFO Predicting labels for 32 texts
2022-12-18 23:52:07,001 INFO There are 7/7 active rules
2022-12-18 23:52:07,001 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:07,002 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:07,026 INFO DONE, Getting attention scores...
2022-12-18 23:52:07,081 INFO the attention scores are
2022-12-18 23:52:07,081 INFO [[1.10204319e-05 1.04534235e-02 2.00903203e-04 7.30672502e-04
  9.99938607e-01 9.52550232e-01 9.95569527e-01 1.56099629e-03]
 [1.37874912e-02 3.91833764e-03 4.13541496e-02 8.70758481e-03
  9.98741210e-01 9.91533458e-01 1.43151894e-01 9.52179074e-01]
 [2.62925681e-02 1.53445276e-02 9.67918858e-02 1.17124386e-01
  9.84564066e-01 9.70869660e-01 4.22601700e-02 7.23733962e-01]
 [6.70587271e-03 1.61980297e-02 4.88605946e-02 4.66877639e-01
  9.12427664e-01 9.08237040e-01 2.54110433e-02 5.82692288e-02]
 [1.82441156e-03 7.56508065e-03 2.87013203e-02 5.15135765e-01
  9.21210051e-01 9.28549588e-01 1.27596268e-02 1.90884527e-02]
 [1.28148193e-03 6.89531397e-03 2.98534632e-02 4.94098008e-01
  9.21438575e-01 9.30576801e-01 1.22480458e-02 1.18347146e-02]
 [2.99358857e-03 1.56776309e-02 7.13120997e-02 4.59819108e-01
  8.67205322e-01 8.67877066e-01 2.97340564e-02 1.37524456e-02]
 [6.25524297e-03 2.23948881e-02 1.01152249e-01 4.27838713e-01
  8.59231830e-01 8.50245595e-01 4.38155904e-02 1.50747448e-02]
 [9.95926186e-03 2.56730635e-02 8.02831799e-02 4.40354168e-01
  8.88961732e-01 8.48294854e-01 4.52187210e-02 3.49407792e-02]
 [7.35907163e-03 1.43219503e-02 4.61307541e-02 4.39641237e-01
  9.29115474e-01 9.06326294e-01 2.42529772e-02 4.67694327e-02]
 [7.75560271e-03 1.33731738e-02 4.76336889e-02 4.46335793e-01
  9.23110187e-01 9.06154931e-01 1.89543441e-02 4.13446911e-02]
 [2.85372254e-03 8.44437722e-03 2.90126372e-02 4.67446089e-01
  9.42016423e-01 9.26854134e-01 1.20864231e-02 2.59600338e-02]
 [5.74634131e-03 1.83421299e-02 8.81978720e-02 4.54973757e-01
  8.51206899e-01 8.55979025e-01 3.19186449e-02 1.95616335e-02]
 [6.72685262e-03 2.11091321e-02 7.69252107e-02 4.54276413e-01
  8.67909193e-01 8.50820124e-01 3.74464393e-02 2.74946894e-02]
 [6.99929334e-03 1.82589870e-02 7.30533078e-02 4.56121355e-01
  8.86972606e-01 8.81295919e-01 3.42206843e-02 3.02031860e-02]
 [1.49608599e-02 3.16933505e-02 9.35566127e-02 4.47211206e-01
  8.59907568e-01 8.31431031e-01 5.16660251e-02 5.53032979e-02]
 [3.40359402e-03 8.34413152e-03 2.60696076e-02 4.67124820e-01
  9.53081071e-01 9.44622517e-01 1.30916350e-02 3.35572772e-02]
 [4.40763962e-03 9.00508836e-03 3.61057743e-02 4.51877475e-01
  9.42280293e-01 9.34802711e-01 1.38035798e-02 2.20824908e-02]
 [3.17968335e-03 1.11365709e-02 3.35857533e-02 4.70870554e-01
  9.37109113e-01 9.15850401e-01 1.82042606e-02 2.77274363e-02]
 [1.33526023e-03 3.89118539e-03 1.50722042e-02 4.85345334e-01
  9.67958033e-01 9.66439843e-01 6.80168252e-03 2.16937549e-02]
 [3.46521963e-03 9.40322597e-03 3.41758318e-02 4.72686052e-01
  9.31573629e-01 9.20698464e-01 1.35216368e-02 2.75056437e-02]
 [1.17606961e-03 4.79627540e-03 1.82651244e-02 4.88579214e-01
  9.50221777e-01 9.42859650e-01 8.07976909e-03 2.30232086e-02]
 [7.41413271e-04 2.82697403e-03 1.57045480e-02 5.02195895e-01
  9.60137963e-01 9.61880624e-01 5.03309630e-03 1.20938085e-02]
 [1.13190571e-03 5.65875228e-03 2.71204673e-02 4.86809403e-01
  9.28779960e-01 9.33667660e-01 9.80025157e-03 1.06964717e-02]
 [1.17577834e-03 6.02786848e-03 2.97482815e-02 4.68492329e-01
  9.29983795e-01 9.26304936e-01 1.18673602e-02 1.13674626e-02]
 [6.37399312e-03 2.02659983e-02 9.07990113e-02 4.35064077e-01
  8.40557694e-01 8.35143745e-01 3.94837894e-02 2.32918151e-02]
 [1.28079252e-02 2.94550247e-02 1.08806767e-01 4.32390720e-01
  8.31747353e-01 8.12038541e-01 5.25287725e-02 3.71023230e-02]
 [2.24539768e-02 4.51995283e-02 1.48419589e-01 4.20036465e-01
  7.86481500e-01 7.53288209e-01 8.47757459e-02 5.18275574e-02]
 [2.27797981e-02 3.95754576e-02 1.20871283e-01 4.36439484e-01
  8.00921559e-01 7.76309788e-01 6.89725876e-02 7.05733225e-02]
 [1.16167106e-02 2.25296523e-02 6.00642227e-02 4.54768986e-01
  8.82045567e-01 8.64600539e-01 3.31083946e-02 5.06737456e-02]
 [1.13618644e-02 2.56702118e-02 6.26698062e-02 4.65530992e-01
  8.54728162e-01 8.39529216e-01 4.00400832e-02 5.47297038e-02]
 [6.66725077e-03 1.58067103e-02 4.17167731e-02 4.70992506e-01
  8.93908560e-01 8.85695219e-01 2.55485661e-02 4.38930281e-02]]
2022-12-18 23:52:07,087 INFO Evaluating teacher test iter4 on 32 examples
2022-12-18 23:52:07,088 INFO teacher test iter4 performance: 1.61
2022-12-18 23:52:07,089 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:07,094 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.93851637840271
2022-12-18 23:52:07,094 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:09,022 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:09,793 INFO Predicting labels for 18 texts
2022-12-18 23:52:09,902 INFO Evaluating student dev iter4 on 18 examples
2022-12-18 23:52:09,903 INFO student dev iter4 performance: 13.24
2022-12-18 23:52:09,904 INFO Predicting labels for 32 texts
2022-12-18 23:52:10,010 INFO Evaluating student test iter4 on 32 examples
2022-12-18 23:52:10,011 INFO student test iter4 performance: 0.62
2022-12-18 23:52:10,011 INFO Student Dev performance on iter 4: 13.242729618634646
2022-12-18 23:52:10,011 INFO Student Test performance on iter 4: 0.6245617363022478
2022-12-18 23:52:10,011 INFO 

	 *** Starting loop 5 ***
2022-12-18 23:52:10,011 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:10,011 INFO Getting rule predictions
2022-12-18 23:52:10,011 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:10,011 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:10,012 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:10,012 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:10,012 INFO Predicting labels for 247 texts
2022-12-18 23:52:10,120 INFO Predicting labels for 18 texts
2022-12-18 23:52:10,225 INFO Predicting labels for 444 texts
2022-12-18 23:52:10,342 INFO Training Rule Attention Network
2022-12-18 23:52:10,344 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:10,344 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:10,346 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:10,347 INFO 

		*** Training RAN ***
2022-12-18 23:52:11,573 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:11,575 INFO Predicting labels for 444 texts
2022-12-18 23:52:11,687 INFO There are 3/7 active rules
2022-12-18 23:52:11,688 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:11,690 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:11,763 INFO DONE, Getting attention scores...
2022-12-18 23:52:11,818 INFO the attention scores are
2022-12-18 23:52:11,818 INFO [[3.2914846e-09 9.8571789e-01 8.7276019e-02 ... 8.7276019e-02
  8.7276019e-02 8.7276019e-02]
 [3.9463477e-09 9.8559487e-01 9.4975173e-02 ... 9.4975173e-02
  9.4975173e-02 9.4975173e-02]
 [4.4528453e-05 3.0934736e-01 1.9746490e-01 ... 1.9746490e-01
  1.9746490e-01 1.9746490e-01]
 ...
 [8.1773963e-11 8.9289963e-01 3.6592504e-05 ... 1.2421255e-01
  1.2421255e-01 1.2421255e-01]
 [8.3962670e-10 1.5320985e-01 1.5334572e-06 ... 7.0513773e-01
  7.0513773e-01 7.0513773e-01]
 [2.9842393e-09 1.1681018e-01 1.0591120e-06 ... 7.5559419e-01
  7.5559419e-01 7.5559419e-01]]
2022-12-18 23:52:11,819 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:11,820 INFO Predicting labels for 18 texts
2022-12-18 23:52:11,928 INFO There are 7/7 active rules
2022-12-18 23:52:11,928 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:11,928 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:11,953 INFO DONE, Getting attention scores...
2022-12-18 23:52:12,006 INFO the attention scores are
2022-12-18 23:52:12,007 INFO [[3.4378015e-03 9.4040520e-03 4.2688116e-02 4.5251080e-01 9.0092385e-01
  8.7609136e-01 2.6910450e-02 4.5152705e-02]
 [1.6697843e-03 5.5408371e-03 2.8068811e-02 4.5666802e-01 9.2866552e-01
  9.0375006e-01 1.6671496e-02 3.3721231e-02]
 [1.2684454e-03 4.9799490e-03 3.0636644e-02 4.4988683e-01 9.2293179e-01
  8.9501399e-01 1.6224526e-02 2.7350370e-02]
 [2.3564703e-03 8.2673393e-03 7.6311149e-02 3.9898276e-01 8.5787684e-01
  8.1353116e-01 3.5608195e-02 2.3046721e-02]
 [2.3009956e-03 8.7768231e-03 5.9129078e-02 4.0092415e-01 8.7919843e-01
  8.3403939e-01 3.5065081e-02 2.6291318e-02]
 [5.0659939e-03 1.6868090e-02 9.8877184e-02 3.8228664e-01 8.1190962e-01
  7.5928509e-01 6.7492604e-02 3.3711575e-02]
 [7.2912620e-03 1.7550003e-02 8.9350313e-02 4.0412918e-01 8.3776724e-01
  7.9640764e-01 5.9525527e-02 4.6892639e-02]
 [4.7683497e-03 1.2311289e-02 5.1890384e-02 4.3204263e-01 8.8996738e-01
  8.6189663e-01 3.5697874e-02 4.5829602e-02]
 [3.1943181e-14 9.9874264e-01 9.8430151e-01 4.7450276e-06 9.9482840e-01
  7.7925989e-04 9.9999833e-01 1.3658768e-18]
 [1.6939916e-16 9.9896336e-01 2.5567671e-03 9.1870977e-05 9.9999976e-01
  3.7645525e-01 1.0000000e+00 3.5609004e-27]
 [3.1309965e-12 9.9968386e-01 3.4788318e-06 1.7201132e-01 9.9999905e-01
  1.7009793e-02 1.0000000e+00 8.1878903e-17]
 [1.0359216e-08 8.6616601e-05 6.9038637e-05 3.3327090e-03 9.9932098e-01
  9.3292481e-01 9.9999261e-01 2.1407429e-10]
 [1.0782933e-09 2.3497215e-09 1.8588112e-09 1.8610280e-02 1.0000000e+00
  1.0000000e+00 3.6518447e-08 7.5541478e-01]
 [6.5837163e-08 7.1868534e-08 8.1465276e-07 4.7396608e-02 9.9999988e-01
  9.9999809e-01 1.1527611e-06 4.7730172e-01]
 [7.2336104e-07 1.4483049e-07 2.1193404e-04 2.0307553e-01 9.9991643e-01
  9.9990678e-01 5.4125835e-06 1.2367183e-03]
 [2.4843878e-08 1.8321490e-06 5.3379528e-05 4.1883925e-01 9.9979037e-01
  9.9891615e-01 1.8999182e-05 1.4079083e-04]
 [1.0621902e-08 2.9675759e-06 1.8917299e-04 4.5711944e-01 9.9924231e-01
  9.9874026e-01 2.3095605e-05 5.5038814e-05]
 [9.6588856e-06 1.3828086e-04 2.2915374e-03 3.7703040e-01 9.9443686e-01
  9.9005312e-01 8.1342476e-04 1.3076171e-03]]
2022-12-18 23:52:12,009 INFO Evaluating teacher dev iter5 on 18 examples
2022-12-18 23:52:12,010 INFO teacher dev iter5 performance: 14.61
2022-12-18 23:52:12,010 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:12,011 INFO Predicting labels for 32 texts
2022-12-18 23:52:12,116 INFO There are 7/7 active rules
2022-12-18 23:52:12,117 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:12,117 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:12,140 INFO DONE, Getting attention scores...
2022-12-18 23:52:12,199 INFO the attention scores are
2022-12-18 23:52:12,199 INFO [[1.72776963e-05 3.31229344e-03 5.47208765e-05 1.58198252e-02
  9.99957442e-01 9.52844739e-01 9.99448121e-01 7.12935362e-05]
 [1.42120672e-02 9.10456292e-04 2.67784335e-02 1.40319327e-02
  9.97388065e-01 9.80807483e-01 3.62137139e-01 8.20248544e-01]
 [2.66500376e-02 1.17784748e-02 9.36926380e-02 9.45180506e-02
  9.67960179e-01 9.35593605e-01 8.47879127e-02 6.81990862e-01]
 [4.49364819e-03 1.07552242e-02 3.79429832e-02 4.14244115e-01
  9.19022918e-01 9.02985573e-01 3.37753482e-02 8.50888938e-02]
 [1.38431985e-03 5.84508479e-03 2.87745707e-02 4.53641802e-01
  9.26494062e-01 9.06635404e-01 1.79610625e-02 2.77699735e-02]
 [1.13068684e-03 6.02115877e-03 3.41339186e-02 4.40048516e-01
  9.28407252e-01 9.09577429e-01 1.74491778e-02 1.63744390e-02]
 [2.59074778e-03 1.48764802e-02 9.04847756e-02 3.85065138e-01
  8.66317332e-01 8.35694909e-01 4.58831452e-02 1.93644445e-02]
 [6.09661732e-03 2.15317979e-02 1.34074315e-01 3.86642009e-01
  8.44511151e-01 8.17855597e-01 6.58796951e-02 2.27295645e-02]
 [1.01548703e-02 2.36725938e-02 9.80849788e-02 3.95458847e-01
  8.76070023e-01 8.28422427e-01 6.57467470e-02 4.81812656e-02]
 [7.16045592e-03 1.05579533e-02 6.43409342e-02 3.98034841e-01
  9.19912755e-01 8.87409091e-01 3.43620107e-02 6.46402687e-02]
 [5.72479656e-03 8.20211042e-03 6.29866347e-02 4.22842324e-01
  9.18335557e-01 8.99591684e-01 2.63849366e-02 4.87723388e-02]
 [2.01856135e-03 6.22061128e-03 3.38266157e-02 4.29600954e-01
  9.39350963e-01 9.17241395e-01 1.84501745e-02 3.34743969e-02]
 [4.82969685e-03 1.62411034e-02 1.11664973e-01 3.92454207e-01
  8.49700332e-01 8.27917576e-01 5.06594665e-02 2.57285945e-02]
 [5.99039299e-03 2.05700267e-02 8.96624774e-02 3.93127561e-01
  8.69649887e-01 8.32986355e-01 5.55493757e-02 3.67717557e-02]
 [6.68212865e-03 1.83449425e-02 9.11964029e-02 4.23772275e-01
  8.79230678e-01 8.52765918e-01 4.69256081e-02 3.83252688e-02]
 [1.44004747e-02 2.84142327e-02 1.08225927e-01 4.07453865e-01
  8.46911907e-01 8.09666812e-01 7.18646720e-02 7.09483773e-02]
 [2.78137857e-03 6.24901243e-03 3.54002006e-02 4.29291934e-01
  9.52070653e-01 9.37183142e-01 1.80093814e-02 4.60721552e-02]
 [3.03254556e-03 5.77070983e-03 4.62479629e-02 4.46031153e-01
  9.33450520e-01 9.16358352e-01 1.84137262e-02 2.42728777e-02]
 [2.91783689e-03 1.03354659e-02 3.77761014e-02 4.22899872e-01
  9.35526609e-01 9.02687311e-01 2.60684136e-02 4.50247340e-02]
 [1.02482957e-03 2.89065973e-03 2.10222825e-02 4.40818191e-01
  9.66266870e-01 9.55208004e-01 9.53960977e-03 2.72686221e-02]
 [2.28485558e-03 6.23540580e-03 3.68288644e-02 4.32486564e-01
  9.33343530e-01 9.12604749e-01 1.98509190e-02 3.41875739e-02]
 [8.45638919e-04 4.31251898e-03 2.09356081e-02 4.35187489e-01
  9.53027725e-01 9.33791459e-01 1.13207325e-02 3.44734155e-02]
 [4.86254692e-04 2.19420879e-03 1.78801287e-02 4.49951619e-01
  9.60517764e-01 9.51327622e-01 7.10699940e-03 1.53370863e-02]
 [9.22802486e-04 4.81729489e-03 3.25701386e-02 4.20420080e-01
  9.37395811e-01 9.15048182e-01 1.54787544e-02 1.56545937e-02]
 [9.56246164e-04 5.81566012e-03 3.66725400e-02 4.09728855e-01
  9.32989776e-01 9.10884559e-01 1.82029232e-02 1.64321624e-02]
 [5.46182040e-03 2.03998722e-02 1.18184701e-01 3.70511532e-01
  8.32496524e-01 8.06132317e-01 6.65404722e-02 2.92440224e-02]
 [1.19999368e-02 2.72753313e-02 1.36366084e-01 3.81331503e-01
  8.21164608e-01 7.89391875e-01 8.39420706e-02 4.26135138e-02]
 [2.19765231e-02 4.32890691e-02 1.84559330e-01 3.67518008e-01
  7.64022648e-01 7.23556161e-01 1.31179601e-01 5.76903820e-02]
 [2.24611983e-02 3.71321999e-02 1.58878520e-01 3.88296485e-01
  7.79790878e-01 7.43815601e-01 1.09140590e-01 7.29670078e-02]
 [1.07837589e-02 1.99830085e-02 8.05128515e-02 4.33833361e-01
  8.64734888e-01 8.41950595e-01 5.29747754e-02 5.64900562e-02]
 [1.13225421e-02 2.42250580e-02 8.30800682e-02 4.28409249e-01
  8.47451568e-01 8.15997064e-01 6.28492981e-02 6.17984310e-02]
 [6.47143181e-03 1.60355791e-02 5.60705960e-02 4.42030728e-01
  8.84442866e-01 8.62821341e-01 4.01973315e-02 5.33973761e-02]]
2022-12-18 23:52:12,205 INFO Evaluating teacher test iter5 on 32 examples
2022-12-18 23:52:12,206 INFO teacher test iter5 performance: 1.51
2022-12-18 23:52:12,206 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:12,212 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9263927936553955
2022-12-18 23:52:12,212 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:13,024 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:14,001 INFO Predicting labels for 18 texts
2022-12-18 23:52:14,115 INFO Evaluating student dev iter5 on 18 examples
2022-12-18 23:52:14,116 INFO student dev iter5 performance: 13.44
2022-12-18 23:52:14,117 INFO Predicting labels for 32 texts
2022-12-18 23:52:14,221 INFO Evaluating student test iter5 on 32 examples
2022-12-18 23:52:14,222 INFO student test iter5 performance: 0.57
2022-12-18 23:52:14,222 INFO Student Dev performance on iter 5: 13.444849123420921
2022-12-18 23:52:14,223 INFO Student Test performance on iter 5: 0.565933929536388
2022-12-18 23:52:14,223 INFO 

	 *** Starting loop 6 ***
2022-12-18 23:52:14,223 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:14,223 INFO Getting rule predictions
2022-12-18 23:52:14,223 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:14,223 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:14,223 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:14,224 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:14,224 INFO Predicting labels for 247 texts
2022-12-18 23:52:14,338 INFO Predicting labels for 18 texts
2022-12-18 23:52:14,446 INFO Predicting labels for 444 texts
2022-12-18 23:52:14,555 INFO Training Rule Attention Network
2022-12-18 23:52:14,556 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:14,557 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:14,559 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:14,559 INFO 

		*** Training RAN ***
2022-12-18 23:52:15,695 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:15,697 INFO Predicting labels for 444 texts
2022-12-18 23:52:15,805 INFO There are 3/7 active rules
2022-12-18 23:52:15,805 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:15,808 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:15,878 INFO DONE, Getting attention scores...
2022-12-18 23:52:15,937 INFO the attention scores are
2022-12-18 23:52:15,937 INFO [[1.01303244e-09 9.89258349e-01 5.16903363e-02 ... 5.16903363e-02
  5.16903363e-02 5.16903363e-02]
 [1.23691568e-09 9.89303112e-01 5.72538078e-02 ... 5.72538078e-02
  5.72538078e-02 5.72538078e-02]
 [2.00657942e-05 2.44194373e-01 7.87812695e-02 ... 7.87812695e-02
  7.87812695e-02 7.87812695e-02]
 ...
 [2.44389960e-11 9.11926270e-01 9.50011145e-06 ... 6.12912141e-02
  6.12912141e-02 6.12912141e-02]
 [1.13300223e-10 1.20263964e-01 1.09746179e-06 ... 3.99098098e-01
  3.99098098e-01 3.99098098e-01]
 [4.43781650e-10 8.00087377e-02 1.00630234e-06 ... 4.63651687e-01
  4.63651687e-01 4.63651687e-01]]
2022-12-18 23:52:15,938 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:15,938 INFO Predicting labels for 18 texts
2022-12-18 23:52:16,044 INFO There are 7/7 active rules
2022-12-18 23:52:16,045 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:16,045 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:16,068 INFO DONE, Getting attention scores...
2022-12-18 23:52:16,121 INFO the attention scores are
2022-12-18 23:52:16,121 INFO [[8.04826804e-03 1.11900596e-02 2.26869229e-02 4.16893184e-01
  9.24286306e-01 8.86150002e-01 1.84844341e-02 3.77970524e-02]
 [3.88475345e-03 6.57717604e-03 1.27340937e-02 4.12217498e-01
  9.50466156e-01 9.15645838e-01 1.04921656e-02 2.60392297e-02]
 [3.22348159e-03 5.70822600e-03 1.15324697e-02 4.11718637e-01
  9.51965094e-01 9.10870910e-01 9.75013617e-03 1.99324638e-02]
 [4.95658396e-03 9.66569223e-03 2.37643830e-02 3.65356863e-01
  9.18314397e-01 8.41423690e-01 2.48818155e-02 1.19057074e-02]
 [4.43048310e-03 9.19225626e-03 1.86375976e-02 3.64446878e-01
  9.33771789e-01 8.77422094e-01 2.00447626e-02 1.74262468e-02]
 [1.06870299e-02 1.85843688e-02 3.54706980e-02 3.52920145e-01
  8.77482116e-01 8.04923713e-01 4.61972095e-02 2.47312840e-02]
 [1.49621321e-02 2.02212073e-02 4.25723009e-02 3.80202264e-01
  8.77352178e-01 8.24759543e-01 4.20934781e-02 4.01480980e-02]
 [9.80181713e-03 1.36754820e-02 2.86920723e-02 4.00556684e-01
  9.16176081e-01 8.80686998e-01 2.31010392e-02 3.94352302e-02]
 [6.86514020e-15 9.99773085e-01 5.87710381e-01 2.37847667e-06
  9.91750658e-01 1.49084808e-05 9.99998450e-01 4.96570416e-21]
 [1.38107688e-17 9.99880672e-01 2.63627189e-05 2.20404418e-05
  1.00000000e+00 2.54046940e-03 1.00000000e+00 3.03045020e-30]
 [1.47298081e-13 9.99940395e-01 1.62876603e-07 2.42460836e-02
  9.99997854e-01 1.03487051e-04 1.00000000e+00 2.50451967e-18]
 [7.87992871e-09 1.19527922e-05 6.15522658e-05 3.01924098e-04
  9.98838365e-01 5.85640252e-01 9.99997497e-01 7.24225367e-12]
 [8.27574606e-11 2.53748515e-11 4.74832724e-08 2.29497746e-04
  1.00000000e+00 1.00000000e+00 1.01805508e-09 9.32443440e-01]
 [3.00369649e-08 9.91139899e-08 3.31461274e-06 5.64107113e-03
  9.99999762e-01 9.99998093e-01 1.84369142e-07 8.29879940e-02]
 [2.92592867e-05 1.02523863e-07 8.88261828e-04 4.22972515e-02
  9.99985814e-01 9.99903917e-01 2.72253897e-06 2.24013595e-04]
 [2.04004991e-08 2.03784657e-06 1.26434161e-05 2.48460472e-01
  9.99928355e-01 9.99617219e-01 3.82373719e-06 3.50312366e-05]
 [1.76248118e-08 3.03749471e-06 3.85282729e-05 2.54588366e-01
  9.99741018e-01 9.99689817e-01 5.31569685e-06 1.14669519e-05]
 [3.71518126e-06 1.09291075e-04 8.60948232e-04 2.37228647e-01
  9.98211980e-01 9.96300161e-01 2.69113283e-04 1.01696627e-04]]
2022-12-18 23:52:16,124 INFO Evaluating teacher dev iter6 on 18 examples
2022-12-18 23:52:16,125 INFO teacher dev iter6 performance: 9.83
2022-12-18 23:52:16,125 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:16,125 INFO Predicting labels for 32 texts
2022-12-18 23:52:16,237 INFO There are 7/7 active rules
2022-12-18 23:52:16,237 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:16,238 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:16,260 INFO DONE, Getting attention scores...
2022-12-18 23:52:16,313 INFO the attention scores are
2022-12-18 23:52:16,313 INFO [[3.79319226e-06 1.30579504e-03 1.39425334e-04 2.06790119e-03
  9.99955535e-01 8.27509165e-01 9.99613106e-01 1.12402740e-05]
 [8.54726415e-03 2.90048280e-04 1.74424171e-01 6.40911469e-03
  9.98828351e-01 9.90756094e-01 3.07985395e-01 8.48433316e-01]
 [4.01395112e-02 1.20475059e-02 2.82013059e-01 5.91792315e-02
  9.79468942e-01 9.48434293e-01 7.32474327e-02 6.44669056e-01]
 [1.53565491e-02 1.09613398e-02 4.48250920e-02 3.38261455e-01
  9.22686934e-01 8.97257447e-01 2.87486762e-02 5.92262819e-02]
 [4.04571928e-03 6.48764521e-03 2.41141301e-02 4.00464177e-01
  9.40216124e-01 9.08446014e-01 1.42498342e-02 1.44705614e-02]
 [1.84903480e-03 6.89512445e-03 2.09303666e-02 3.79212320e-01
  9.49664831e-01 9.18540716e-01 1.22008547e-02 8.50654859e-03]
 [4.04434372e-03 1.60589945e-02 5.39748520e-02 3.45122039e-01
  8.95050168e-01 8.69100809e-01 3.25488709e-02 1.13403155e-02]
 [6.82799518e-03 2.11010538e-02 1.00700915e-01 3.30734700e-01
  8.75878215e-01 8.57425809e-01 5.17201461e-02 9.92576685e-03]
 [1.18160546e-02 2.53364556e-02 7.58401006e-02 3.59560490e-01
  8.97934556e-01 8.62915337e-01 4.42016423e-02 4.32831682e-02]
 [1.27473427e-02 1.06941666e-02 5.83455525e-02 3.71578842e-01
  9.20208037e-01 8.98598552e-01 2.38109324e-02 5.89743964e-02]
 [1.38842445e-02 8.26331321e-03 5.79142384e-02 3.84974480e-01
  9.24479604e-01 8.99391651e-01 2.12649014e-02 3.75284292e-02]
 [4.13704524e-03 6.06085313e-03 2.55620182e-02 3.76708299e-01
  9.50080335e-01 9.28379834e-01 1.21573713e-02 2.55234949e-02]
 [7.66810169e-03 1.68935880e-02 8.13634247e-02 3.48925889e-01
  8.76554191e-01 8.44109833e-01 3.99476737e-02 1.19328089e-02]
 [8.27079546e-03 2.05057301e-02 6.13454469e-02 3.54810655e-01
  8.93694580e-01 8.56179535e-01 3.73311639e-02 2.38814484e-02]
 [1.00462390e-02 1.93475224e-02 6.90955073e-02 3.74385744e-01
  8.97252202e-01 8.72832417e-01 3.43402885e-02 2.81213876e-02]
 [2.31697019e-02 2.98549104e-02 9.38383266e-02 3.80787402e-01
  8.58527958e-01 8.23708832e-01 5.37309200e-02 6.61933050e-02]
 [4.90349298e-03 6.39896886e-03 3.08871064e-02 3.87330323e-01
  9.52811837e-01 9.37324166e-01 1.22107957e-02 3.77817936e-02]
 [5.05487062e-03 5.05254790e-03 3.78740393e-02 3.68287683e-01
  9.50747073e-01 9.29224253e-01 1.36424871e-02 1.47443162e-02]
 [4.20430768e-03 9.84614156e-03 2.57749110e-02 3.75279307e-01
  9.49679673e-01 9.27607000e-01 1.48488889e-02 4.31662202e-02]
 [2.09233840e-03 3.38120176e-03 1.71925407e-02 3.96717012e-01
  9.69125390e-01 9.60818887e-01 6.45324308e-03 2.19264403e-02]
 [5.54179074e-03 6.22066157e-03 3.02432869e-02 3.88836592e-01
  9.41375256e-01 9.16735172e-01 1.44054173e-02 2.33514588e-02]
 [1.86172465e-03 4.43853950e-03 1.37135778e-02 3.90875578e-01
  9.61073637e-01 9.45124209e-01 7.03974906e-03 2.97040865e-02]
 [1.29423931e-03 2.48057256e-03 1.21098002e-02 3.88596863e-01
  9.68882740e-01 9.56507146e-01 5.03065437e-03 9.72733647e-03]
 [1.43462955e-03 5.15586277e-03 2.03757714e-02 3.58138889e-01
  9.56239164e-01 9.24148321e-01 1.03952978e-02 6.33170549e-03]
 [1.31394470e-03 5.99826267e-03 1.97053347e-02 3.46498370e-01
  9.53379929e-01 9.37206686e-01 1.06280604e-02 8.59006494e-03]
 [8.81876238e-03 2.09810138e-02 8.11677426e-02 3.36767852e-01
  8.57458830e-01 8.36739659e-01 4.74456213e-02 1.89433154e-02]
 [1.65451057e-02 2.83182729e-02 1.11496337e-01 3.45481128e-01
  8.42362106e-01 8.11085343e-01 6.36168867e-02 2.70642471e-02]
 [3.40839699e-02 4.66034114e-02 1.60336897e-01 3.47643137e-01
  7.75276482e-01 7.35114634e-01 1.04607336e-01 5.15827127e-02]
 [4.09379527e-02 4.06999476e-02 1.36823490e-01 3.68822873e-01
  7.86027074e-01 7.50630677e-01 9.09681916e-02 6.88981712e-02]
 [1.90790575e-02 2.03365721e-02 6.13191500e-02 3.95335943e-01
  8.88873696e-01 8.53060961e-01 3.95754017e-02 4.44441698e-02]
 [1.98755953e-02 2.56502610e-02 5.44955991e-02 4.01690006e-01
  8.76173437e-01 8.29397559e-01 4.45467718e-02 5.30506223e-02]
 [1.20501108e-02 1.62655693e-02 3.73126678e-02 4.01537359e-01
  9.07862008e-01 8.78885508e-01 2.76890323e-02 4.35037091e-02]]
2022-12-18 23:52:16,318 INFO Evaluating teacher test iter6 on 32 examples
2022-12-18 23:52:16,318 INFO teacher test iter6 performance: 1.44
2022-12-18 23:52:16,319 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:16,324 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9411381483078003
2022-12-18 23:52:16,324 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:17,098 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:17,898 INFO Predicting labels for 18 texts
2022-12-18 23:52:18,017 INFO Evaluating student dev iter6 on 18 examples
2022-12-18 23:52:18,018 INFO student dev iter6 performance: 13.66
2022-12-18 23:52:18,019 INFO Predicting labels for 32 texts
2022-12-18 23:52:18,128 INFO Evaluating student test iter6 on 32 examples
2022-12-18 23:52:18,129 INFO student test iter6 performance: 0.54
2022-12-18 23:52:18,129 INFO Student Dev performance on iter 6: 13.655488491399117
2022-12-18 23:52:18,129 INFO Student Test performance on iter 6: 0.539798271868872
2022-12-18 23:52:18,130 INFO 

	 *** Starting loop 7 ***
2022-12-18 23:52:18,130 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:18,130 INFO Getting rule predictions
2022-12-18 23:52:18,130 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:18,130 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:18,130 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:18,131 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:18,131 INFO Predicting labels for 247 texts
2022-12-18 23:52:19,265 INFO Predicting labels for 18 texts
2022-12-18 23:52:19,369 INFO Predicting labels for 444 texts
2022-12-18 23:52:19,481 INFO Training Rule Attention Network
2022-12-18 23:52:19,482 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:19,482 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:19,485 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:19,485 INFO 

		*** Training RAN ***
2022-12-18 23:52:20,724 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:20,725 INFO Predicting labels for 444 texts
2022-12-18 23:52:20,836 INFO There are 3/7 active rules
2022-12-18 23:52:20,836 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:20,841 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:20,913 INFO DONE, Getting attention scores...
2022-12-18 23:52:20,970 INFO the attention scores are
2022-12-18 23:52:20,970 INFO [[7.0865408e-10 9.9881977e-01 4.3112826e-02 ... 4.3112826e-02
  4.3112826e-02 4.3112826e-02]
 [8.5363017e-10 9.9877590e-01 4.9256254e-02 ... 4.9256254e-02
  4.9256254e-02 4.9256254e-02]
 [2.7879054e-05 3.0678231e-01 7.8799576e-02 ... 7.8799576e-02
  7.8799576e-02 7.8799576e-02]
 ...
 [2.4129039e-11 9.0602595e-01 4.1651241e-08 ... 5.2905969e-02
  5.2905969e-02 5.2905969e-02]
 [2.2379447e-10 7.8453317e-02 1.6931965e-09 ... 4.4421569e-01
  4.4421569e-01 4.4421569e-01]
 [1.0568183e-09 4.3073196e-02 1.5994366e-09 ... 4.6694875e-01
  4.6694875e-01 4.6694875e-01]]
2022-12-18 23:52:20,972 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:20,972 INFO Predicting labels for 18 texts
2022-12-18 23:52:22,103 INFO There are 7/7 active rules
2022-12-18 23:52:22,103 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:22,104 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:22,134 INFO DONE, Getting attention scores...
2022-12-18 23:52:22,187 INFO the attention scores are
2022-12-18 23:52:22,188 INFO [[3.90037103e-03 9.06976406e-03 8.72510299e-03 4.76319849e-01
  9.45729434e-01 9.08167124e-01 8.43784399e-03 6.23398572e-02]
 [1.83253468e-03 5.12828864e-03 4.64058621e-03 4.82211888e-01
  9.64823067e-01 9.34258521e-01 4.46799397e-03 4.65785861e-02]
 [1.24457595e-03 4.68823733e-03 4.79736133e-03 4.96816635e-01
  9.60373580e-01 9.30142760e-01 4.52026213e-03 2.95707844e-02]
 [1.97304063e-03 9.80992336e-03 1.11223226e-02 4.72380161e-01
  9.14463699e-01 8.43592942e-01 1.55284489e-02 1.51171628e-02]
 [2.10246933e-03 8.76736175e-03 9.43962485e-03 4.55436677e-01
  9.23753798e-01 8.69357407e-01 1.40758976e-02 2.32014302e-02]
 [5.19248797e-03 1.92000475e-02 1.87148955e-02 4.38526481e-01
  8.73963356e-01 7.67340541e-01 3.18545848e-02 3.08101457e-02]
 [8.17092415e-03 1.88758932e-02 1.84798930e-02 4.46187943e-01
  8.96705091e-01 8.21868658e-01 2.60050390e-02 5.49496077e-02]
 [5.21995500e-03 1.14502963e-02 1.06813153e-02 4.58232611e-01
  9.35134172e-01 9.00162578e-01 1.25103891e-02 5.95367365e-02]
 [6.26328507e-16 9.99998927e-01 4.75341082e-03 2.15802465e-05
  9.87383425e-01 7.81101392e-07 9.99999523e-01 7.40375823e-22]
 [5.23462267e-18 9.99942422e-01 7.35892698e-08 1.11082231e-03
  9.99997497e-01 1.76837028e-03 1.00000000e+00 2.61291847e-31]
 [2.81438935e-13 9.99982357e-01 8.33930078e-11 6.31217957e-01
  9.99783933e-01 7.26399085e-05 1.00000000e+00 2.84163238e-18]
 [1.75549619e-08 9.91349589e-06 3.32382092e-06 1.10685835e-02
  2.35122591e-01 2.03720078e-01 9.99999404e-01 2.65162241e-12]
 [2.09567363e-09 1.75937841e-11 1.16507051e-13 1.98162370e-03
  1.00000000e+00 1.00000000e+00 1.75673032e-10 9.40336585e-01]
 [1.99142818e-08 6.79244394e-09 6.47221332e-10 1.41035309e-02
  9.99999285e-01 9.99998450e-01 9.15542531e-10 2.97055155e-01]
 [2.60517913e-06 6.98994373e-09 6.11263943e-07 6.56170994e-02
  9.99995112e-01 9.99981999e-01 9.77761587e-08 3.67789529e-04]
 [8.78097595e-09 3.62348544e-07 3.01864098e-08 3.95591378e-01
  9.99932647e-01 9.99922752e-01 2.44149732e-07 1.74599918e-04]
 [3.51623974e-09 5.41578231e-07 2.88267501e-07 5.03295004e-01
  9.99518633e-01 9.99935985e-01 4.90373452e-07 4.48624014e-05]
 [4.54324027e-06 4.45975566e-05 3.68285328e-05 4.29598123e-01
  9.97959852e-01 9.97443795e-01 7.87402823e-05 9.85393999e-04]]
2022-12-18 23:52:22,191 INFO Evaluating teacher dev iter7 on 18 examples
2022-12-18 23:52:22,192 INFO teacher dev iter7 performance: 11.07
2022-12-18 23:52:22,192 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:22,192 INFO Predicting labels for 32 texts
2022-12-18 23:52:22,305 INFO There are 7/7 active rules
2022-12-18 23:52:22,305 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:22,305 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:22,329 INFO DONE, Getting attention scores...
2022-12-18 23:52:22,388 INFO the attention scores are
2022-12-18 23:52:22,388 INFO [[1.15980583e-05 6.19470433e-04 7.82992743e-07 3.02728936e-02
  9.83975172e-01 7.01374531e-01 9.99282777e-01 4.95884451e-05]
 [3.13069783e-02 8.38337583e-05 4.44305921e-03 1.35699473e-02
  9.56793427e-01 9.88005459e-01 8.00838172e-02 9.60211039e-01]
 [4.67741713e-02 5.32854442e-03 1.32185854e-02 7.23676011e-02
  9.57732797e-01 9.55714166e-01 1.84721146e-02 7.72160411e-01]
 [5.60817216e-03 7.22314604e-03 1.01988111e-02 3.67204845e-01
  9.45331395e-01 9.40207243e-01 9.80102085e-03 7.76495337e-02]
 [1.19293784e-03 3.72397946e-03 7.39100855e-03 4.61959004e-01
  9.55613554e-01 9.63955998e-01 5.03435545e-03 2.04851925e-02]
 [7.43285927e-04 3.48177925e-03 5.55291539e-03 4.57852900e-01
  9.46472108e-01 9.69197989e-01 5.31668169e-03 1.26369027e-02]
 [2.06678268e-03 8.85689817e-03 1.26817571e-02 4.27850366e-01
  8.86910319e-01 9.27199125e-01 1.45207448e-02 1.93632003e-02]
 [6.71130978e-03 1.20576248e-02 2.55809948e-02 4.05872285e-01
  8.68197799e-01 9.02416468e-01 2.56073643e-02 2.67583821e-02]
 [9.50396992e-03 1.42671056e-02 1.96588542e-02 4.08250779e-01
  9.06560540e-01 9.03647542e-01 2.17567254e-02 7.20159709e-02]
 [6.12863945e-03 6.01659436e-03 1.03499573e-02 4.18936402e-01
  9.34721231e-01 9.36017632e-01 8.75653140e-03 7.96546564e-02]
 [7.37372972e-03 3.96539923e-03 8.94953124e-03 4.10067022e-01
  9.36541080e-01 9.36033309e-01 6.82915375e-03 5.67586683e-02]
 [2.09107343e-03 3.11616226e-03 5.30771958e-03 4.23171580e-01
  9.62135017e-01 9.61180627e-01 4.19793231e-03 4.11494486e-02]
 [4.56768740e-03 1.06328903e-02 2.23135911e-02 4.36050832e-01
  8.86790693e-01 9.14592028e-01 1.98113695e-02 2.04684399e-02]
 [5.33148926e-03 1.24047678e-02 1.81672499e-02 4.16970432e-01
  8.98393869e-01 9.16597247e-01 1.93327088e-02 4.14114296e-02]
 [6.71739690e-03 1.14839710e-02 2.06678044e-02 4.19159830e-01
  8.99481654e-01 9.23216879e-01 1.83822960e-02 3.82155702e-02]
 [1.49141308e-02 1.78666357e-02 3.00160907e-02 4.16712105e-01
  8.82620692e-01 8.82860720e-01 2.66060662e-02 9.33353007e-02]
 [2.78380001e-03 3.26378015e-03 5.14610019e-03 4.25489843e-01
  9.59561765e-01 9.60329652e-01 4.02960833e-03 4.59343307e-02]
 [3.91853508e-03 2.41380534e-03 7.10824784e-03 3.91677588e-01
  9.57074881e-01 9.59954441e-01 5.64314984e-03 1.99354906e-02]
 [2.45696330e-03 5.77923795e-03 6.49993913e-03 4.23860937e-01
  9.56953585e-01 9.57443774e-01 6.12253416e-03 5.69196083e-02]
 [9.48105357e-04 1.66903483e-03 2.67664529e-03 4.48014438e-01
  9.76823568e-01 9.79606330e-01 1.89699582e-03 3.05934120e-02]
 [2.36380752e-03 3.21105076e-03 6.65539037e-03 4.32196528e-01
  9.55345094e-01 9.57673192e-01 4.85567050e-03 3.28232683e-02]
 [6.01261447e-04 2.35553435e-03 2.64225970e-03 4.52068925e-01
  9.74517107e-01 9.76665914e-01 1.99758331e-03 4.48941886e-02]
 [3.56323930e-04 1.24233402e-03 2.47115106e-03 4.60686326e-01
  9.78835642e-01 9.84581649e-01 1.44327886e-03 1.27304550e-02]
 [6.64369727e-04 2.66967015e-03 4.34276741e-03 4.47690636e-01
  9.60140765e-01 9.69756246e-01 4.03796649e-03 1.26057584e-02]
 [6.97876443e-04 3.15211806e-03 3.96171119e-03 4.33066219e-01
  9.48537409e-01 9.67804015e-01 4.39300807e-03 1.50184715e-02]
 [5.31541882e-03 1.37247201e-02 2.08154116e-02 4.18548733e-01
  8.68513048e-01 8.91503751e-01 2.44525392e-02 3.15129831e-02]
 [1.32955322e-02 2.02278811e-02 3.58489864e-02 4.10155624e-01
  8.61842334e-01 8.61864388e-01 3.64876054e-02 4.80237901e-02]
 [2.42443979e-02 3.52045186e-02 5.07090129e-02 4.04057145e-01
  8.14312637e-01 7.88839638e-01 6.09086640e-02 7.55320638e-02]
 [2.50445735e-02 3.17834839e-02 4.69103754e-02 4.16450769e-01
  8.34977150e-01 8.04175675e-01 5.20761907e-02 8.67767483e-02]
 [1.17375404e-02 1.67464390e-02 2.58360188e-02 4.32856202e-01
  9.10452783e-01 8.85309339e-01 2.25966517e-02 6.82838187e-02]
 [1.26696127e-02 2.17448790e-02 2.50806753e-02 4.42373902e-01
  8.96150231e-01 8.60891700e-01 2.77945865e-02 7.56968409e-02]
 [6.83351094e-03 1.32425912e-02 1.52656948e-02 4.46991622e-01
  9.25928950e-01 9.07197952e-01 1.50977513e-02 6.44102916e-02]]
2022-12-18 23:52:22,393 INFO Evaluating teacher test iter7 on 32 examples
2022-12-18 23:52:22,394 INFO teacher test iter7 performance: 1.56
2022-12-18 23:52:22,395 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:22,400 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.94098699092865
2022-12-18 23:52:22,400 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:23,185 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:24,994 INFO Predicting labels for 18 texts
2022-12-18 23:52:25,104 INFO Evaluating student dev iter7 on 18 examples
2022-12-18 23:52:25,105 INFO student dev iter7 performance: 13.86
2022-12-18 23:52:25,105 INFO Predicting labels for 32 texts
2022-12-18 23:52:25,209 INFO Evaluating student test iter7 on 32 examples
2022-12-18 23:52:25,210 INFO student test iter7 performance: 0.54
2022-12-18 23:52:25,210 INFO Student Dev performance on iter 7: 13.860118407698948
2022-12-18 23:52:25,210 INFO Student Test performance on iter 7: 0.5370303789857995
2022-12-18 23:52:25,210 INFO 

	 *** Starting loop 8 ***
2022-12-18 23:52:25,210 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:25,210 INFO Getting rule predictions
2022-12-18 23:52:25,210 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:25,211 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:25,211 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:25,211 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:25,212 INFO Predicting labels for 247 texts
2022-12-18 23:52:26,354 INFO Predicting labels for 18 texts
2022-12-18 23:52:26,461 INFO Predicting labels for 444 texts
2022-12-18 23:52:27,623 INFO Training Rule Attention Network
2022-12-18 23:52:27,625 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:27,625 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:27,631 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:27,631 INFO 

		*** Training RAN ***
2022-12-18 23:52:28,797 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:28,798 INFO Predicting labels for 444 texts
2022-12-18 23:52:28,908 INFO There are 3/7 active rules
2022-12-18 23:52:28,908 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:28,911 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:28,982 INFO DONE, Getting attention scores...
2022-12-18 23:52:29,041 INFO the attention scores are
2022-12-18 23:52:29,041 INFO [[1.9313523e-11 9.9928468e-01 2.3575755e-02 ... 2.3575755e-02
  2.3575755e-02 2.3575755e-02]
 [2.2302861e-11 9.9924028e-01 2.6211917e-02 ... 2.6211917e-02
  2.6211917e-02 2.6211917e-02]
 [3.3285280e-06 2.8327498e-01 7.3256738e-02 ... 7.3256738e-02
  7.3256738e-02 7.3256738e-02]
 ...
 [1.0700773e-13 9.7941577e-01 7.0883175e-07 ... 1.9770322e-02
  1.9770322e-02 1.9770322e-02]
 [5.9851503e-12 4.5676506e-01 4.3486397e-09 ... 4.4774345e-01
  4.4774345e-01 4.4774345e-01]
 [3.1490373e-11 4.1556200e-01 2.6351143e-09 ... 4.9765253e-01
  4.9765253e-01 4.9765253e-01]]
2022-12-18 23:52:29,042 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:29,043 INFO Predicting labels for 18 texts
2022-12-18 23:52:29,148 INFO There are 7/7 active rules
2022-12-18 23:52:29,148 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:29,148 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:29,172 INFO DONE, Getting attention scores...
2022-12-18 23:52:29,226 INFO the attention scores are
2022-12-18 23:52:29,226 INFO [[5.28322766e-03 7.25665037e-03 1.16581190e-02 4.28449869e-01
  9.38537300e-01 8.83035064e-01 1.23452600e-02 4.12912741e-02]
 [2.53222510e-03 4.13641287e-03 5.66388946e-03 4.35054868e-01
  9.61161613e-01 9.10106003e-01 6.65906677e-03 3.17096189e-02]
 [2.16783537e-03 4.25936095e-03 6.08502747e-03 4.43531275e-01
  9.58523333e-01 8.97767544e-01 7.46798469e-03 2.72523612e-02]
 [4.79653291e-03 9.77293309e-03 2.30706576e-02 4.13313776e-01
  9.04365122e-01 7.68380821e-01 3.00832614e-02 2.03406103e-02]
 [3.84485908e-03 8.56964663e-03 1.53678739e-02 4.10510540e-01
  9.25032496e-01 8.32228363e-01 2.22292412e-02 2.73451842e-02]
 [8.50813277e-03 2.06035748e-02 3.66556160e-02 3.88354123e-01
  8.61983061e-01 7.43110061e-01 5.61510064e-02 2.86470968e-02]
 [1.17269643e-02 1.76630281e-02 3.31028774e-02 3.93859476e-01
  8.79169226e-01 7.98639238e-01 4.22951393e-02 4.46590371e-02]
 [6.61418913e-03 9.31990985e-03 1.53979901e-02 4.06913728e-01
  9.25965965e-01 8.75311017e-01 1.76739525e-02 3.90742645e-02]
 [2.84330365e-17 9.99974728e-01 9.36807930e-01 6.90203115e-06
  4.33249146e-01 1.65318652e-05 1.00000000e+00 1.91828342e-25]
 [1.02731026e-21 9.99980688e-01 3.26155669e-06 8.38921333e-05
  9.99931335e-01 8.94526392e-02 1.00000000e+00 3.81545205e-35]
 [6.22583880e-16 9.99999881e-01 8.41074499e-09 5.94867468e-02
  9.97352839e-01 5.44423645e-04 1.00000000e+00 1.19652524e-20]
 [1.20649560e-10 2.62412232e-06 4.52666291e-06 1.67668203e-03
  3.94444726e-02 9.77581143e-01 9.99999642e-01 3.22233424e-13]
 [2.35746866e-10 3.54306883e-12 3.98265971e-16 3.01138149e-04
  1.00000000e+00 1.00000000e+00 1.14115419e-11 9.99971867e-01]
 [1.94814831e-08 2.38344899e-09 1.50242194e-10 5.32413367e-03
  1.00000000e+00 9.99999881e-01 3.52647556e-09 4.21365470e-01]
 [8.52684843e-06 1.21865218e-09 2.48496258e-06 1.07560501e-01
  9.99979854e-01 9.99969721e-01 4.27345519e-08 4.30125947e-04]
 [5.02590813e-09 1.16684845e-07 9.54798480e-08 3.72834057e-01
  9.99940634e-01 9.99664903e-01 5.83733993e-07 3.97699368e-05]
 [4.21297353e-09 4.71053568e-07 1.37982931e-06 4.02798772e-01
  9.99751031e-01 9.99675393e-01 1.42918122e-06 1.66592672e-05]
 [3.05868571e-06 2.99797048e-05 7.82923962e-05 3.12382400e-01
  9.98011827e-01 9.95077312e-01 1.46243328e-04 1.89782018e-04]]
2022-12-18 23:52:29,229 INFO Evaluating teacher dev iter8 on 18 examples
2022-12-18 23:52:29,230 INFO teacher dev iter8 performance: 11.40
2022-12-18 23:52:29,230 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:29,230 INFO Predicting labels for 32 texts
2022-12-18 23:52:29,341 INFO There are 7/7 active rules
2022-12-18 23:52:29,341 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:29,342 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:29,366 INFO DONE, Getting attention scores...
2022-12-18 23:52:29,418 INFO the attention scores are
2022-12-18 23:52:29,419 INFO [[4.07338666e-06 2.24360218e-03 5.43079750e-07 2.47044233e-03
  9.88455772e-01 9.85909402e-01 9.99759495e-01 1.02358594e-04]
 [4.82409336e-02 1.12221896e-04 1.27696467e-03 9.81545541e-03
  9.89788830e-01 9.98703361e-01 2.05457017e-01 9.86966014e-01]
 [7.63214529e-02 4.62917332e-03 1.25090340e-02 8.26403350e-02
  9.67276633e-01 9.75549281e-01 6.13527820e-02 8.56837749e-01]
 [9.03805438e-03 4.32762085e-03 1.42190037e-02 3.91701907e-01
  9.32772815e-01 9.15257156e-01 1.18545508e-02 5.89541793e-02]
 [1.97816384e-03 2.72709690e-03 9.57055297e-03 4.50322241e-01
  9.48994875e-01 9.20205772e-01 5.27423434e-03 1.71892233e-02]
 [1.28430140e-03 3.14286584e-03 9.66632180e-03 4.19218957e-01
  9.52942908e-01 9.21258330e-01 6.13363413e-03 1.16425045e-02]
 [3.73745593e-03 9.15650930e-03 3.08407936e-02 3.61252367e-01
  8.90649021e-01 8.61575305e-01 2.60041095e-02 1.86807830e-02]
 [7.46146310e-03 9.90259275e-03 5.94716184e-02 3.56395155e-01
  8.55504453e-01 8.34694684e-01 3.64065953e-02 1.77343804e-02]
 [9.18475911e-03 1.18508926e-02 3.24085429e-02 3.71400833e-01
  8.86799216e-01 8.62641573e-01 2.79179234e-02 4.45731021e-02]
 [6.41018059e-03 4.39810567e-03 1.57641731e-02 4.04038787e-01
  9.11944568e-01 9.24264908e-01 9.78222676e-03 4.33855429e-02]
 [9.21936519e-03 2.50400160e-03 1.67930461e-02 4.17115003e-01
  9.14822519e-01 9.01107788e-01 7.32497638e-03 3.49637792e-02]
 [2.45969137e-03 1.99549203e-03 6.94537302e-03 4.16446477e-01
  9.51561809e-01 9.33257997e-01 4.05921601e-03 2.75397599e-02]
 [7.33175082e-03 8.69286619e-03 5.13480864e-02 3.74870390e-01
  8.65938425e-01 8.30910504e-01 2.86067333e-02 1.76781826e-02]
 [7.61126680e-03 1.12584857e-02 3.27310190e-02 3.67460608e-01
  8.88181329e-01 8.48667920e-01 2.67621279e-02 3.51053998e-02]
 [7.42242951e-03 8.90592299e-03 3.57044004e-02 3.93703848e-01
  8.91951740e-01 8.76406491e-01 1.96361803e-02 2.90595796e-02]
 [1.71788018e-02 1.43848639e-02 4.57325652e-02 3.86713117e-01
  8.46472681e-01 8.34827244e-01 3.19446959e-02 6.09306917e-02]
 [2.69980333e-03 1.79331226e-03 6.10110583e-03 4.29629296e-01
  9.55812931e-01 9.55378771e-01 3.23739694e-03 3.08976211e-02]
 [4.07960825e-03 1.25976373e-03 1.04231127e-02 4.23873186e-01
  9.44303095e-01 9.29054141e-01 3.66976229e-03 1.48998890e-02]
 [2.35651061e-03 4.20892378e-03 7.29871402e-03 4.03551370e-01
  9.50156629e-01 9.33869720e-01 6.82694465e-03 3.98476571e-02]
 [8.35063169e-04 9.66211490e-04 3.05835740e-03 4.47865933e-01
  9.73851323e-01 9.74262118e-01 1.47202553e-03 1.70201380e-02]
 [3.32609471e-03 1.93400052e-03 9.26995277e-03 4.31995153e-01
  9.42768633e-01 9.21287179e-01 4.46619559e-03 2.57712230e-02]
 [8.85074202e-04 1.71615463e-03 3.15948343e-03 4.19519961e-01
  9.66874301e-01 9.58777070e-01 2.63155135e-03 2.57223267e-02]
 [5.44827781e-04 7.63392018e-04 3.42157530e-03 4.50163990e-01
  9.74207759e-01 9.64437723e-01 1.32332242e-03 8.88453797e-03]
 [1.02645601e-03 2.01047328e-03 8.12032539e-03 4.00073498e-01
  9.58089173e-01 9.24012423e-01 5.02231484e-03 9.29112080e-03]
 [1.07878435e-03 3.08478018e-03 7.46114878e-03 3.73717368e-01
  9.54026937e-01 9.34584200e-01 7.09466450e-03 1.28432494e-02]
 [9.21380892e-03 1.41116763e-02 5.03774323e-02 3.46560895e-01
  8.46608520e-01 8.26823235e-01 4.35810275e-02 2.56978534e-02]
 [1.83008537e-02 1.78752635e-02 6.96615055e-02 3.55502695e-01
  8.26268315e-01 7.94400811e-01 5.29795215e-02 3.73672061e-02]
 [3.47399563e-02 3.40834856e-02 1.08097412e-01 3.45187604e-01
  7.54124522e-01 7.25873828e-01 1.03293583e-01 5.33267744e-02]
 [3.60854939e-02 3.18261050e-02 9.19009969e-02 3.61355633e-01
  7.82781243e-01 7.64255822e-01 8.67872313e-02 6.05245940e-02]
 [1.51971392e-02 1.27941929e-02 3.25308107e-02 4.02604342e-01
  8.91195953e-01 8.51581872e-01 2.58561932e-02 4.58405949e-02]
 [1.63570605e-02 1.83314309e-02 3.31430249e-02 4.00927365e-01
  8.83722425e-01 8.23648512e-01 3.53885069e-02 5.62319160e-02]
 [8.37160181e-03 1.06287468e-02 1.84338354e-02 4.11335230e-01
  9.18531239e-01 8.81745160e-01 1.79971028e-02 4.30877134e-02]]
2022-12-18 23:52:29,423 INFO Evaluating teacher test iter8 on 32 examples
2022-12-18 23:52:29,424 INFO teacher test iter8 performance: 1.59
2022-12-18 23:52:29,424 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:29,429 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9354908466339111
2022-12-18 23:52:29,429 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:30,232 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:32,119 INFO Predicting labels for 18 texts
2022-12-18 23:52:32,232 INFO Evaluating student dev iter8 on 18 examples
2022-12-18 23:52:32,233 INFO student dev iter8 performance: 14.04
2022-12-18 23:52:32,233 INFO Predicting labels for 32 texts
2022-12-18 23:52:32,352 INFO Evaluating student test iter8 on 32 examples
2022-12-18 23:52:32,353 INFO student test iter8 performance: 0.55
2022-12-18 23:52:32,353 INFO Student Dev performance on iter 8: 14.041453665074716
2022-12-18 23:52:32,353 INFO Student Test performance on iter 8: 0.5465375766291339
2022-12-18 23:52:32,354 INFO 

	 *** Starting loop 9 ***
2022-12-18 23:52:32,354 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:32,354 INFO Getting rule predictions
2022-12-18 23:52:32,354 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:32,354 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:32,354 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:32,355 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:32,355 INFO Predicting labels for 247 texts
2022-12-18 23:52:32,472 INFO Predicting labels for 18 texts
2022-12-18 23:52:32,580 INFO Predicting labels for 444 texts
2022-12-18 23:52:32,689 INFO Training Rule Attention Network
2022-12-18 23:52:32,691 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:32,691 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:32,694 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:32,694 INFO 

		*** Training RAN ***
2022-12-18 23:52:33,842 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:33,843 INFO Predicting labels for 444 texts
2022-12-18 23:52:33,955 INFO There are 3/7 active rules
2022-12-18 23:52:33,956 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:33,958 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:34,031 INFO DONE, Getting attention scores...
2022-12-18 23:52:34,087 INFO the attention scores are
2022-12-18 23:52:34,087 INFO [[1.0661278e-12 9.9772078e-01 6.4930324e-03 ... 6.4930324e-03
  6.4930324e-03 6.4930324e-03]
 [1.3175244e-12 9.9748456e-01 7.2101839e-03 ... 7.2101839e-03
  7.2101839e-03 7.2101839e-03]
 [4.6210161e-07 8.3251446e-02 3.2755617e-02 ... 3.2755617e-02
  3.2755617e-02 3.2755617e-02]
 ...
 [7.7203631e-15 9.1580051e-01 1.2193513e-05 ... 1.5430165e-03
  1.5430165e-03 1.5430165e-03]
 [4.7195749e-13 2.1929121e-01 5.6821577e-08 ... 5.5253636e-02
  5.5253636e-02 5.5253636e-02]
 [3.3168331e-12 1.8269280e-01 3.0086046e-08 ... 7.3613778e-02
  7.3613778e-02 7.3613778e-02]]
2022-12-18 23:52:34,088 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:34,088 INFO Predicting labels for 18 texts
2022-12-18 23:52:34,203 INFO There are 7/7 active rules
2022-12-18 23:52:34,203 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:34,203 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:34,228 INFO DONE, Getting attention scores...
2022-12-18 23:52:34,284 INFO the attention scores are
2022-12-18 23:52:34,284 INFO [[5.2484870e-03 7.0009404e-03 2.3094369e-02 3.8899010e-01 9.1749048e-01
  8.8228118e-01 1.1164821e-02 3.3091273e-02]
 [2.4600050e-03 3.9491430e-03 1.2000372e-02 3.9225519e-01 9.4481903e-01
  9.0989238e-01 5.9116855e-03 2.4627419e-02]
 [1.7064031e-03 3.8022990e-03 1.1340449e-02 4.0130538e-01 9.4225746e-01
  9.0646505e-01 6.0558026e-03 1.7716913e-02]
 [3.0348834e-03 8.8271853e-03 3.0331697e-02 3.9170325e-01 8.7469333e-01
  8.1809092e-01 2.0337645e-02 1.3141873e-02]
 [2.5145307e-03 7.8881662e-03 2.1349179e-02 3.7866533e-01 8.9239818e-01
  8.5351020e-01 1.6970014e-02 1.9631358e-02]
 [5.9211170e-03 1.7864494e-02 6.1269157e-02 3.6824611e-01 8.0884421e-01
  7.7084893e-01 4.1391622e-02 2.5449922e-02]
 [1.0596058e-02 1.6661892e-02 6.1420768e-02 3.6310121e-01 8.3495253e-01
  8.0388904e-01 3.7029039e-02 3.9546657e-02]
 [6.8547963e-03 9.0370337e-03 3.1649597e-02 3.6949208e-01 8.9898008e-01
  8.6969775e-01 1.6262198e-02 3.5276964e-02]
 [9.0951572e-20 9.9999309e-01 9.9916339e-01 1.7564158e-06 9.7499895e-01
  1.1392311e-06 9.9999988e-01 1.2147614e-26]
 [3.6433519e-22 9.9999642e-01 5.8115728e-04 2.0666992e-05 9.9999964e-01
  1.0389255e-02 1.0000000e+00 1.1522672e-37]
 [1.4350029e-17 9.9999845e-01 1.0075276e-08 2.7576264e-02 9.9992037e-01
  1.7558578e-04 1.0000000e+00 3.6445475e-22]
 [2.4160663e-12 3.1286274e-07 2.7578900e-04 1.8155903e-03 9.8463929e-01
  9.8272634e-01 9.9999928e-01 1.8053931e-15]
 [2.0363558e-09 1.6038637e-12 8.7082912e-16 2.5698522e-03 1.0000000e+00
  1.0000000e+00 4.8225895e-11 9.9971610e-01]
 [9.5640935e-09 2.0880528e-09 5.3873317e-10 8.7567549e-03 1.0000000e+00
  9.9999976e-01 5.9381378e-10 5.0798970e-01]
 [1.5387754e-04 1.5939213e-09 1.1520639e-05 5.0119001e-02 9.9999392e-01
  9.9980313e-01 4.5339114e-08 1.4084787e-03]
 [8.7638385e-10 1.2186079e-07 8.3061178e-07 2.5529671e-01 9.9993587e-01
  9.9975115e-01 8.3541323e-07 5.2322816e-06]
 [6.2541128e-10 1.9888058e-07 5.7127982e-06 2.9376438e-01 9.9963236e-01
  9.9981540e-01 4.1960593e-07 1.9450167e-06]
 [1.2900575e-06 2.2632905e-05 5.3199090e-04 2.6921487e-01 9.9566048e-01
  9.9670106e-01 1.5250708e-04 8.1598817e-05]]
2022-12-18 23:52:34,287 INFO Evaluating teacher dev iter9 on 18 examples
2022-12-18 23:52:34,288 INFO teacher dev iter9 performance: 10.97
2022-12-18 23:52:34,288 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:34,288 INFO Predicting labels for 32 texts
2022-12-18 23:52:34,403 INFO There are 7/7 active rules
2022-12-18 23:52:34,403 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:34,403 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:34,427 INFO DONE, Getting attention scores...
2022-12-18 23:52:34,483 INFO the attention scores are
2022-12-18 23:52:34,483 INFO [[3.7642624e-07 1.0794922e-03 2.9338053e-06 6.4303228e-03 9.9991250e-01
  9.9550325e-01 9.9946588e-01 6.0679854e-06]
 [2.0490717e-02 1.3986247e-04 2.9643460e-03 2.9605715e-02 9.9957079e-01
  9.9936146e-01 9.9971890e-02 9.8917109e-01]
 [1.5880793e-01 8.1372764e-03 1.3599064e-02 9.3495719e-02 9.8663980e-01
  9.5865053e-01 4.2964391e-02 8.9979517e-01]
 [1.0274323e-02 3.8934445e-03 3.0143559e-02 3.2031640e-01 9.3912947e-01
  8.9075530e-01 1.1562541e-02 3.3066221e-02]
 [2.1451509e-03 2.4375650e-03 1.7773978e-02 4.0724051e-01 9.3928188e-01
  9.0944153e-01 4.7529414e-03 6.2592812e-03]
 [9.3733915e-04 2.6554642e-03 1.6784135e-02 3.9499933e-01 9.4659418e-01
  9.3675673e-01 4.9597807e-03 3.3446995e-03]
 [2.1653499e-03 8.2844459e-03 5.0820973e-02 3.4311923e-01 8.7208486e-01
  8.8157320e-01 2.1242624e-02 5.2851075e-03]
 [4.2175041e-03 9.1455616e-03 1.0855067e-01 3.3964363e-01 8.3700377e-01
  8.5724771e-01 3.3273313e-02 6.4133094e-03]
 [7.7270078e-03 1.2198528e-02 6.4306296e-02 3.4666237e-01 8.8501036e-01
  8.4663272e-01 2.5941133e-02 3.9598905e-02]
 [6.2398189e-03 5.7256981e-03 3.8709216e-02 3.7388805e-01 9.1962475e-01
  8.9701325e-01 9.0561882e-03 4.5973547e-02]
 [1.1546579e-02 3.0970634e-03 4.2400297e-02 3.7140763e-01 9.2837769e-01
  8.8621515e-01 7.0824586e-03 4.1303009e-02]
 [2.2729405e-03 2.2240556e-03 1.7264139e-02 3.8544834e-01 9.5301557e-01
  9.2208546e-01 3.7111260e-03 2.1362780e-02]
 [5.0666472e-03 8.5495478e-03 9.2064336e-02 3.5419941e-01 8.4748310e-01
  8.5253233e-01 2.5509560e-02 5.6803967e-03]
 [4.8507168e-03 1.1015083e-02 6.0552485e-02 3.5249883e-01 8.7775695e-01
  8.6531019e-01 2.4652608e-02 1.4017816e-02]
 [6.1226040e-03 8.4732408e-03 6.8561435e-02 3.7185898e-01 8.8964105e-01
  8.7775499e-01 1.7547809e-02 1.6875567e-02]
 [1.5839867e-02 1.6131941e-02 8.5954703e-02 3.6666471e-01 8.4782898e-01
  8.1243283e-01 3.0236097e-02 4.8626915e-02]
 [2.4693874e-03 2.0248196e-03 1.6388260e-02 3.9246330e-01 9.6469736e-01
  9.4151765e-01 2.7580892e-03 2.8729450e-02]
 [4.0640901e-03 1.3444454e-03 2.1448072e-02 3.8663709e-01 9.5331818e-01
  9.2265314e-01 3.9588204e-03 1.0212124e-02]
 [1.9552165e-03 4.0056431e-03 1.5022288e-02 3.7703833e-01 9.5376366e-01
  9.2817736e-01 5.3212754e-03 3.2188635e-02]
 [7.3955109e-04 9.3973521e-04 8.8270772e-03 4.0118870e-01 9.7749126e-01
  9.6592903e-01 1.0943302e-03 1.3995023e-02]
 [3.4771152e-03 2.1174066e-03 2.2648999e-02 3.9438388e-01 9.4446087e-01
  9.0804964e-01 4.3468005e-03 1.6489768e-02]
 [6.5276987e-04 1.6483174e-03 6.9924230e-03 3.8543603e-01 9.6948659e-01
  9.5578873e-01 1.8689388e-03 1.3709799e-02]
 [5.0920574e-04 6.9786143e-04 7.8548929e-03 4.0881613e-01 9.7552115e-01
  9.6214926e-01 1.0294322e-03 4.2049964e-03]
 [7.1016257e-04 1.8479800e-03 1.6109616e-02 3.7763214e-01 9.5254493e-01
  9.4009852e-01 4.3615890e-03 2.6726744e-03]
 [5.7668402e-04 2.5879203e-03 1.5596438e-02 3.4677276e-01 9.4239962e-01
  9.4608378e-01 5.4711993e-03 4.5338091e-03]
 [5.8577945e-03 1.4158742e-02 9.5251188e-02 3.2483336e-01 8.1529170e-01
  8.3859605e-01 3.6699839e-02 1.2296454e-02]
 [1.3407153e-02 1.8178379e-02 1.3638523e-01 3.3292159e-01 7.9702747e-01
  8.0633873e-01 4.9751759e-02 2.3634227e-02]
 [3.0686935e-02 3.7392516e-02 1.9970578e-01 3.2434076e-01 7.1147746e-01
  7.1579939e-01 9.5174968e-02 5.0296817e-02]
 [3.5267040e-02 3.4354053e-02 1.7419071e-01 3.3688664e-01 7.3797542e-01
  7.4513304e-01 8.1527539e-02 5.9386592e-02]
 [1.8244367e-02 1.3177884e-02 6.7011543e-02 3.7420934e-01 8.6862487e-01
  8.4318620e-01 2.4896542e-02 4.7246061e-02]
 [1.6184814e-02 1.7767446e-02 6.3250721e-02 3.7482938e-01 8.5203433e-01
  8.1458449e-01 3.1731427e-02 5.1199980e-02]
 [8.6577749e-03 1.0014861e-02 3.7553955e-02 3.8041523e-01 8.9793187e-01
  8.7415171e-01 1.5433296e-02 3.9356455e-02]]
2022-12-18 23:52:34,487 INFO Evaluating teacher test iter9 on 32 examples
2022-12-18 23:52:34,488 INFO teacher test iter9 performance: 1.47
2022-12-18 23:52:34,489 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:34,494 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9130440950393677
2022-12-18 23:52:34,494 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:35,290 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:36,143 INFO Predicting labels for 18 texts
2022-12-18 23:52:36,258 INFO Evaluating student dev iter9 on 18 examples
2022-12-18 23:52:36,259 INFO student dev iter9 performance: 14.20
2022-12-18 23:52:36,259 INFO Predicting labels for 32 texts
2022-12-18 23:52:36,465 INFO Evaluating student test iter9 on 32 examples
2022-12-18 23:52:36,466 INFO student test iter9 performance: 0.56
2022-12-18 23:52:36,466 INFO Student Dev performance on iter 9: 14.20288805983501
2022-12-18 23:52:36,466 INFO Student Test performance on iter 9: 0.563597424912806
2022-12-18 23:52:36,466 INFO 

	 *** Starting loop 10 ***
2022-12-18 23:52:36,466 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:36,466 INFO Getting rule predictions
2022-12-18 23:52:36,466 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:36,467 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:36,467 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:36,467 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:36,468 INFO Predicting labels for 247 texts
2022-12-18 23:52:36,576 INFO Predicting labels for 18 texts
2022-12-18 23:52:36,687 INFO Predicting labels for 444 texts
2022-12-18 23:52:37,866 INFO Training Rule Attention Network
2022-12-18 23:52:37,867 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:37,868 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:37,870 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:37,870 INFO 

		*** Training RAN ***
2022-12-18 23:52:39,014 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:39,015 INFO Predicting labels for 444 texts
2022-12-18 23:52:39,127 INFO There are 3/7 active rules
2022-12-18 23:52:39,127 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:39,133 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:39,205 INFO DONE, Getting attention scores...
2022-12-18 23:52:39,261 INFO the attention scores are
2022-12-18 23:52:39,261 INFO [[6.7699210e-14 9.9895835e-01 4.3816172e-02 ... 4.3816172e-02
  4.3816172e-02 4.3816172e-02]
 [8.3991977e-14 9.9886876e-01 4.5717634e-02 ... 4.5717634e-02
  4.5717634e-02 4.5717634e-02]
 [1.0022036e-07 8.6383559e-02 5.0604977e-02 ... 5.0604977e-02
  5.0604977e-02 5.0604977e-02]
 ...
 [1.5125700e-16 8.8827479e-01 2.1907137e-07 ... 6.4644697e-03
  6.4644697e-03 6.4644697e-03]
 [6.7359016e-15 1.4752294e-01 1.4383786e-10 ... 3.1196246e-01
  3.1196246e-01 3.1196246e-01]
 [5.2655461e-14 1.4582993e-01 7.8173752e-11 ... 3.6692059e-01
  3.6692059e-01 3.6692059e-01]]
2022-12-18 23:52:39,262 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:39,262 INFO Predicting labels for 18 texts
2022-12-18 23:52:39,367 INFO There are 7/7 active rules
2022-12-18 23:52:39,367 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:39,367 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:39,396 INFO DONE, Getting attention scores...
2022-12-18 23:52:39,450 INFO the attention scores are
2022-12-18 23:52:39,450 INFO [[1.03162229e-02 1.10008791e-02 3.50395329e-02 4.10330504e-01
  8.74475360e-01 8.21541548e-01 2.08634641e-02 5.19509092e-02]
 [4.91252402e-03 6.32602256e-03 2.01408621e-02 4.20820147e-01
  9.16687489e-01 8.57739270e-01 1.12241842e-02 4.35392968e-02]
 [4.29122010e-03 5.77105442e-03 2.23747920e-02 4.30447608e-01
  9.06390309e-01 8.44048262e-01 1.24819744e-02 3.80449146e-02]
 [9.09738336e-03 1.18207820e-02 6.42323941e-02 4.15687561e-01
  7.98282683e-01 7.22745776e-01 4.46221456e-02 3.27116773e-02]
 [6.64051482e-03 1.08194686e-02 4.95695956e-02 4.04374957e-01
  8.35083306e-01 7.60078311e-01 3.50889601e-02 3.96576114e-02]
 [1.45210382e-02 2.22545806e-02 1.09809883e-01 3.88818115e-01
  7.22797155e-01 6.63589954e-01 7.87833408e-02 4.64044027e-02]
 [2.06308905e-02 2.31428929e-02 8.36686119e-02 3.93871754e-01
  7.58593559e-01 7.05170274e-01 6.43495992e-02 5.53602539e-02]
 [1.19930254e-02 1.44560160e-02 4.28315662e-02 4.01118338e-01
  8.51764262e-01 8.06179047e-01 2.85768639e-02 5.16603664e-02]
 [2.12066309e-21 9.99873042e-01 9.83656287e-01 1.92005541e-06
  4.20992732e-01 3.60723220e-07 1.00000000e+00 3.21088768e-27]
 [2.57388895e-25 9.99999046e-01 2.55709892e-06 5.20079811e-05
  9.99999285e-01 4.83515626e-03 1.00000000e+00 0.00000000e+00]
 [1.85528094e-19 9.99999762e-01 2.85856117e-10 5.51782846e-01
  9.99949694e-01 3.85584717e-04 1.00000000e+00 1.18170980e-21]
 [3.29171667e-13 7.33241556e-09 1.30989196e-04 1.25907389e-02
  8.48695636e-02 9.88989294e-01 1.00000000e+00 6.65262768e-15]
 [2.59988781e-13 7.89563456e-13 3.67483722e-17 3.21283675e-04
  1.00000000e+00 1.00000000e+00 2.63183191e-11 9.99383330e-01]
 [8.25975954e-10 6.67916922e-09 2.79816739e-08 1.91693893e-03
  9.99999881e-01 1.00000000e+00 2.72171441e-09 3.94732952e-01]
 [4.87038997e-05 4.80088636e-10 8.17339969e-05 1.51348645e-02
  9.99988556e-01 9.99930739e-01 1.18794979e-07 9.09849710e-04]
 [7.31175676e-10 1.12260963e-07 1.11838074e-06 2.34904051e-01
  9.99941945e-01 9.99469221e-01 1.10576445e-06 7.89590922e-05]
 [2.35589215e-09 5.17552962e-07 8.90095544e-06 4.68168586e-01
  9.99444425e-01 9.99085665e-01 1.41103624e-06 1.74829838e-04]
 [2.08603137e-06 5.22513219e-05 4.12521156e-04 3.49152684e-01
  9.94599342e-01 9.91169691e-01 2.42114867e-04 5.10205165e-04]]
2022-12-18 23:52:39,453 INFO Evaluating teacher dev iter10 on 18 examples
2022-12-18 23:52:39,454 INFO teacher dev iter10 performance: 10.50
2022-12-18 23:52:39,454 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:39,455 INFO Predicting labels for 32 texts
2022-12-18 23:52:39,561 INFO There are 7/7 active rules
2022-12-18 23:52:39,561 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:39,562 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:39,585 INFO DONE, Getting attention scores...
2022-12-18 23:52:39,642 INFO the attention scores are
2022-12-18 23:52:39,642 INFO [[3.86047319e-08 3.19816463e-04 7.79863711e-08 4.29522758e-03
  9.97874141e-01 9.98833716e-01 9.99876380e-01 4.19067073e-05]
 [5.55164367e-03 2.42923616e-05 5.37178596e-04 3.55092273e-03
  9.92223442e-01 9.99817193e-01 2.15612322e-01 9.72121537e-01]
 [6.67681769e-02 7.82270264e-03 1.46760605e-02 2.51856782e-02
  9.63729382e-01 9.69697058e-01 6.23897910e-02 8.30565631e-01]
 [1.47529906e-02 3.70733044e-03 8.95391554e-02 2.63101906e-01
  9.08216357e-01 8.74372661e-01 1.95905119e-02 6.61758110e-02]
 [4.19521797e-03 2.91279866e-03 3.29070464e-02 3.89425248e-01
  9.20401573e-01 8.95192683e-01 7.75425648e-03 2.58510783e-02]
 [1.51399756e-03 3.84952221e-03 2.32510697e-02 4.41232175e-01
  9.20512438e-01 8.94429207e-01 8.89731571e-03 1.50441406e-02]
 [4.23504272e-03 1.15408171e-02 5.67103885e-02 3.96791756e-01
  7.95881629e-01 7.62392879e-01 3.85879911e-02 2.51116902e-02]
 [7.93853123e-03 1.09244445e-02 9.43294615e-02 3.90419811e-01
  7.70875573e-01 7.37488031e-01 4.93827537e-02 2.57501602e-02]
 [9.76398494e-03 1.36748385e-02 6.13286905e-02 3.80864918e-01
  8.51472974e-01 7.77011633e-01 3.85658219e-02 6.01162761e-02]
 [7.45029096e-03 6.88241795e-03 5.80885857e-02 3.43833685e-01
  8.68272126e-01 8.61048818e-01 1.47114908e-02 5.20840213e-02]
 [1.58630833e-02 2.94378377e-03 6.65762126e-02 3.26185524e-01
  8.80363226e-01 8.57250214e-01 1.23041132e-02 4.49669771e-02]
 [3.67888808e-03 2.28210050e-03 2.66434662e-02 3.67339075e-01
  9.33906436e-01 9.03258920e-01 5.92330610e-03 4.10531126e-02]
 [1.07071549e-02 1.03973178e-02 8.64345878e-02 3.93177569e-01
  7.59692013e-01 7.23271132e-01 4.01750579e-02 2.53942795e-02]
 [8.54239147e-03 1.39173502e-02 6.42347634e-02 3.98181856e-01
  8.12987864e-01 7.54306257e-01 3.74283418e-02 4.75892983e-02]
 [8.71926174e-03 9.05134156e-03 7.74547532e-02 3.99984658e-01
  8.50015283e-01 8.25308084e-01 2.60782763e-02 4.02495079e-02]
 [2.40407400e-02 1.70845166e-02 9.92947444e-02 3.74971002e-01
  7.86374927e-01 7.34948695e-01 4.41525541e-02 7.36632049e-02]
 [2.62542092e-03 2.30019796e-03 3.52529548e-02 3.50702643e-01
  9.47981119e-01 9.41164970e-01 4.71214624e-03 3.77980918e-02]
 [4.64025373e-03 1.23084185e-03 4.34765629e-02 3.37892205e-01
  9.39887285e-01 9.30309772e-01 6.57543121e-03 1.86676327e-02]
 [2.35868199e-03 4.65844292e-03 2.04253998e-02 3.99576306e-01
  9.41800237e-01 9.03372824e-01 8.26264545e-03 5.68495020e-02]
 [9.59321798e-04 1.11726939e-03 1.96449216e-02 3.71976346e-01
  9.70440149e-01 9.64458823e-01 2.02458166e-03 2.36182865e-02]
 [5.75654488e-03 2.08678632e-03 3.96425053e-02 3.55126172e-01
  9.20114577e-01 8.91539097e-01 7.10281543e-03 3.83745506e-02]
 [1.18838879e-03 2.15079659e-03 1.11813685e-02 4.12392050e-01
  9.57438409e-01 9.29044127e-01 3.19386111e-03 4.22570556e-02]
 [1.02188031e-03 8.08087119e-04 1.39267640e-02 3.98179293e-01
  9.65652287e-01 9.50290561e-01 1.80344016e-03 1.70369390e-02]
 [1.16704754e-03 2.42846040e-03 1.99379083e-02 4.16729033e-01
  9.27326262e-01 8.86366487e-01 7.23105203e-03 1.41310012e-02]
 [1.09055568e-03 3.98740824e-03 2.00284999e-02 4.09826815e-01
  9.12633538e-01 8.89016509e-01 9.64070670e-03 2.25695334e-02]
 [1.27407918e-02 1.84650905e-02 9.69341472e-02 3.67272824e-01
  7.09549069e-01 6.97713494e-01 6.35468215e-02 3.89348157e-02]
 [2.73961890e-02 2.28267778e-02 1.23516262e-01 3.67273599e-01
  6.94101751e-01 6.62826955e-01 7.47703537e-02 5.16347438e-02]
 [4.87222560e-02 4.32183892e-02 1.80708319e-01 3.60460877e-01
  5.96796811e-01 5.73777199e-01 1.40727624e-01 6.79166168e-02]
 [6.12138882e-02 4.44103032e-02 1.68953836e-01 3.64297688e-01
  6.24529779e-01 6.29479170e-01 1.28203258e-01 7.01469034e-02]
 [2.95114648e-02 1.61949843e-02 9.07505378e-02 3.60267431e-01
  8.13663960e-01 8.04914653e-01 3.94095108e-02 5.73736317e-02]
 [2.79675815e-02 2.51621921e-02 7.99476355e-02 3.94259155e-01
  7.84008265e-01 7.45981753e-01 5.28334528e-02 7.05579072e-02]
 [1.45223625e-02 1.46199772e-02 5.51121719e-02 3.91448408e-01
  8.53580713e-01 8.30468118e-01 2.61371806e-02 5.57009466e-02]]
2022-12-18 23:52:39,647 INFO Evaluating teacher test iter10 on 32 examples
2022-12-18 23:52:39,649 INFO teacher test iter10 performance: 1.36
2022-12-18 23:52:39,649 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:39,654 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9485108852386475
2022-12-18 23:52:39,654 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:41,488 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:42,294 INFO Predicting labels for 18 texts
2022-12-18 23:52:42,417 INFO Evaluating student dev iter10 on 18 examples
2022-12-18 23:52:42,418 INFO student dev iter10 performance: 14.34
2022-12-18 23:52:42,418 INFO Predicting labels for 32 texts
2022-12-18 23:52:42,523 INFO Evaluating student test iter10 on 32 examples
2022-12-18 23:52:42,524 INFO student test iter10 performance: 0.58
2022-12-18 23:52:42,524 INFO Student Dev performance on iter 10: 14.336710584591007
2022-12-18 23:52:42,524 INFO Student Test performance on iter 10: 0.584691081190684
2022-12-18 23:52:42,524 INFO 

	 *** Starting loop 11 ***
2022-12-18 23:52:42,524 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:42,524 INFO Getting rule predictions
2022-12-18 23:52:42,524 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:42,525 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:42,525 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:42,525 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:42,526 INFO Predicting labels for 247 texts
2022-12-18 23:52:42,636 INFO Predicting labels for 18 texts
2022-12-18 23:52:42,743 INFO Predicting labels for 444 texts
2022-12-18 23:52:42,853 INFO Training Rule Attention Network
2022-12-18 23:52:42,855 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:42,855 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:42,857 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:42,857 INFO 

		*** Training RAN ***
2022-12-18 23:52:44,046 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:44,047 INFO Predicting labels for 444 texts
2022-12-18 23:52:44,156 INFO There are 3/7 active rules
2022-12-18 23:52:44,157 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:44,159 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:44,332 INFO DONE, Getting attention scores...
2022-12-18 23:52:44,388 INFO the attention scores are
2022-12-18 23:52:44,388 INFO [[1.99603094e-14 9.96175289e-01 1.65609643e-02 ... 1.65609643e-02
  1.65609643e-02 1.65609643e-02]
 [2.65877560e-14 9.95721221e-01 1.79088898e-02 ... 1.79088898e-02
  1.79088898e-02 1.79088898e-02]
 [2.17000284e-08 8.01768452e-02 3.32531631e-02 ... 3.32531631e-02
  3.32531631e-02 3.32531631e-02]
 ...
 [4.24606987e-18 8.96234393e-01 1.24079676e-07 ... 2.25634500e-03
  2.25634500e-03 2.25634500e-03]
 [1.90699767e-16 2.35906214e-01 1.37541212e-09 ... 1.15919575e-01
  1.15919575e-01 1.15919575e-01]
 [1.45830327e-15 2.01738194e-01 9.84161530e-10 ... 1.70310438e-01
  1.70310438e-01 1.70310438e-01]]
2022-12-18 23:52:44,389 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:44,390 INFO Predicting labels for 18 texts
2022-12-18 23:52:44,500 INFO There are 7/7 active rules
2022-12-18 23:52:44,500 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:44,501 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:44,524 INFO DONE, Getting attention scores...
2022-12-18 23:52:44,583 INFO the attention scores are
2022-12-18 23:52:44,584 INFO [[2.77590193e-03 4.08719806e-03 1.06618125e-02 4.20973957e-01
  8.97033691e-01 8.67866755e-01 4.98052826e-03 3.99545208e-02]
 [1.15792744e-03 1.98259507e-03 5.35698654e-03 4.27040249e-01
  9.30620849e-01 8.96332204e-01 2.38233246e-03 2.87637096e-02]
 [9.34195006e-04 1.77974813e-03 5.30201336e-03 4.41546202e-01
  9.22975957e-01 8.87316048e-01 2.30958848e-03 2.08249968e-02]
 [2.14559003e-03 4.29479545e-03 1.42231686e-02 4.26249325e-01
  8.46707940e-01 8.10492992e-01 8.82772449e-03 1.27853053e-02]
 [1.88099663e-03 3.74452234e-03 1.47595359e-02 4.24938023e-01
  8.51435483e-01 8.34740043e-01 8.25374108e-03 2.11290792e-02]
 [5.15109301e-03 1.01063121e-02 3.13633829e-02 3.98600727e-01
  7.59328485e-01 7.50339925e-01 2.40615532e-02 2.43681800e-02]
 [7.41221057e-03 9.81071126e-03 3.13253775e-02 4.00746852e-01
  7.99996018e-01 7.97922075e-01 1.92298237e-02 4.19625863e-02]
 [3.71968676e-03 5.41031966e-03 1.59848947e-02 4.06928986e-01
  8.73385012e-01 8.65751266e-01 7.71391578e-03 4.13374901e-02]
 [1.33225518e-22 9.99937892e-01 3.23665552e-02 2.71431309e-05
  1.05060071e-01 9.59001454e-07 9.99999523e-01 2.11199193e-29]
 [1.83481420e-26 9.99973655e-01 2.01004968e-09 2.13725097e-03
  9.99974489e-01 8.52799416e-03 1.00000000e+00 0.00000000e+00]
 [2.10574087e-22 9.99999762e-01 4.58793246e-12 9.85694110e-01
  9.99952555e-01 4.58584000e-05 1.00000000e+00 2.18372328e-25]
 [1.48771959e-13 2.95005851e-08 9.04196058e-04 6.68587983e-01
  6.81363344e-02 9.55453992e-01 9.99999762e-01 1.66111922e-16]
 [9.11017604e-16 1.77999352e-13 4.40329052e-17 1.20865682e-03
  1.00000000e+00 1.00000000e+00 4.59692150e-15 9.94112551e-01]
 [7.16544619e-12 6.92304436e-09 2.61545317e-11 2.79815937e-03
  1.00000000e+00 1.00000000e+00 5.17991587e-11 4.86528635e-01]
 [3.25600922e-06 1.71585489e-11 2.26244552e-07 6.44743741e-02
  9.99997735e-01 9.99955416e-01 7.43014053e-11 1.91872256e-04]
 [1.54860014e-11 2.35484543e-09 7.51416565e-08 3.82975996e-01
  9.99950647e-01 9.99631047e-01 1.45393404e-08 1.24427843e-05]
 [7.79093942e-11 2.59741615e-08 2.83951550e-07 3.93366933e-01
  9.99407887e-01 9.99780118e-01 2.09352535e-08 7.80787195e-06]
 [2.54112933e-07 3.88781018e-06 6.29916540e-05 3.29973578e-01
  9.93288338e-01 9.97169197e-01 1.51100576e-05 1.08702276e-04]]
2022-12-18 23:52:44,586 INFO Evaluating teacher dev iter11 on 18 examples
2022-12-18 23:52:44,587 INFO teacher dev iter11 performance: 12.21
2022-12-18 23:52:44,587 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:44,588 INFO Predicting labels for 32 texts
2022-12-18 23:52:44,699 INFO There are 7/7 active rules
2022-12-18 23:52:44,699 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:44,699 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:44,724 INFO DONE, Getting attention scores...
2022-12-18 23:52:44,778 INFO the attention scores are
2022-12-18 23:52:44,779 INFO [[3.4768255e-09 1.2685227e-03 1.5389335e-06 1.0522773e-01 9.9812144e-01
  9.8901910e-01 9.9909067e-01 1.6264376e-06]
 [8.7153753e-03 8.5479500e-05 3.1259644e-03 2.2118868e-02 9.9621385e-01
  9.9980158e-01 1.2257199e-02 9.8778629e-01]
 [4.7426328e-02 5.4229093e-03 2.1063616e-03 5.9755724e-02 9.7865868e-01
  9.7959214e-01 5.7461369e-03 8.6074924e-01]
 [7.2131199e-03 1.9528870e-03 1.6366715e-02 3.8358349e-01 9.2590004e-01
  8.4504712e-01 3.3178600e-03 5.5131570e-02]
 [9.4024389e-04 8.5493963e-04 9.5856115e-03 4.5350170e-01 9.2582071e-01
  8.9387059e-01 1.2966476e-03 1.3422723e-02]
 [3.9491130e-04 9.1004570e-04 9.6801855e-03 4.5674893e-01 9.1822308e-01
  9.1567945e-01 1.2815422e-03 5.6873956e-03]
 [1.3733729e-03 3.3640296e-03 2.3889491e-02 4.0437493e-01 8.1001520e-01
  8.6549217e-01 8.4548444e-03 1.2579298e-02]
 [2.8237673e-03 3.8990909e-03 5.1999040e-02 3.9695609e-01 7.9712623e-01
  8.5852367e-01 1.2679191e-02 1.1115558e-02]
 [4.0703928e-03 6.2873992e-03 3.3516932e-02 3.8246253e-01 8.6651206e-01
  8.5515571e-01 1.4179463e-02 4.4292454e-02]
 [2.6824113e-03 3.4682553e-03 2.0413745e-02 3.9586133e-01 9.1130942e-01
  9.0372825e-01 4.3817312e-03 4.6108518e-02]
 [4.1079214e-03 1.3358574e-03 2.2385120e-02 3.9945340e-01 9.1009229e-01
  8.9448965e-01 2.4941224e-03 3.2210693e-02]
 [8.1509526e-04 8.6495018e-04 8.8819060e-03 4.1788164e-01 9.4161248e-01
  9.1720217e-01 1.3049962e-03 2.5185725e-02]
 [3.5597999e-03 3.3000156e-03 3.9294042e-02 4.1398042e-01 7.9821080e-01
  8.4283113e-01 7.8911595e-03 1.3046920e-02]
 [2.8943922e-03 4.9597574e-03 3.2922134e-02 4.0010646e-01 8.2620841e-01
  8.4794134e-01 1.1397237e-02 2.4948513e-02]
 [3.0634692e-03 3.9995466e-03 3.9512604e-02 4.1606671e-01 8.6386126e-01
  8.7278837e-01 7.6167788e-03 2.2391606e-02]
 [8.8009369e-03 8.7332027e-03 5.4853253e-02 3.9702666e-01 8.1229705e-01
  8.0786937e-01 1.6852275e-02 5.4749787e-02]
 [8.3061593e-04 1.0274310e-03 1.1707632e-02 4.1492161e-01 9.6044087e-01
  9.4488388e-01 1.2077269e-03 2.9242573e-02]
 [1.4902154e-03 4.4593748e-04 1.3652770e-02 4.1860509e-01 9.4838011e-01
  9.2978185e-01 1.0338697e-03 8.3923973e-03]
 [7.2187884e-04 1.8994315e-03 8.3477898e-03 4.0078279e-01 9.4425178e-01
  9.1882795e-01 2.7303721e-03 4.0379137e-02]
 [2.5921979e-04 4.3213888e-04 4.7572991e-03 4.3734944e-01 9.7713989e-01
  9.6559584e-01 3.8048386e-04 1.6405987e-02]
 [1.1870363e-03 8.3257916e-04 1.1887388e-02 4.3669927e-01 9.3362826e-01
  9.0264320e-01 1.3528115e-03 2.1078525e-02]
 [2.6032588e-04 7.1913574e-04 3.1029978e-03 4.1549525e-01 9.5771694e-01
  9.3885159e-01 7.2784681e-04 2.3010172e-02]
 [1.7308224e-04 2.1682461e-04 3.0313134e-03 4.5744085e-01 9.6943057e-01
  9.5583624e-01 2.3221674e-04 7.4714138e-03]
 [2.8338796e-04 5.1834248e-04 6.5223728e-03 4.3334419e-01 9.3376648e-01
  9.2798126e-01 1.0085175e-03 5.8357180e-03]
 [3.0285123e-04 1.0930394e-03 7.3639397e-03 3.9902309e-01 9.1355824e-01
  9.3712461e-01 2.0610148e-03 8.9756595e-03]
 [4.3686433e-03 6.7302273e-03 4.3801278e-02 3.7933677e-01 7.3321378e-01
  8.3560163e-01 1.7189287e-02 1.9672340e-02]
 [1.0461116e-02 9.7560724e-03 6.9788098e-02 3.7894332e-01 7.2954047e-01
  8.0866975e-01 2.4400031e-02 3.1917453e-02]
 [2.3385039e-02 2.2220511e-02 1.0762945e-01 3.6542070e-01 6.3827252e-01
  7.3682892e-01 5.8212489e-02 5.1275387e-02]
 [2.5225963e-02 2.1283776e-02 9.1726363e-02 3.7524030e-01 6.8202579e-01
  7.5731617e-01 4.6554714e-02 6.1645649e-02]
 [9.7989840e-03 7.6325247e-03 4.1838299e-02 4.0560177e-01 8.4119242e-01
  8.5027862e-01 1.2250527e-02 4.7046717e-02]
 [9.7613111e-03 1.1056049e-02 4.0099278e-02 4.0973297e-01 8.1584311e-01
  8.1067067e-01 1.8128926e-02 5.3696517e-02]
 [4.8634787e-03 6.0442812e-03 2.3053737e-02 4.1184670e-01 8.6866403e-01
  8.6824507e-01 8.1327939e-03 4.3356713e-02]]
2022-12-18 23:52:44,783 INFO Evaluating teacher test iter11 on 32 examples
2022-12-18 23:52:44,784 INFO teacher test iter11 performance: 1.39
2022-12-18 23:52:44,784 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:44,789 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9478386640548706
2022-12-18 23:52:44,789 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:45,588 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:47,491 INFO Predicting labels for 18 texts
2022-12-18 23:52:47,601 INFO Evaluating student dev iter11 on 18 examples
2022-12-18 23:52:47,602 INFO student dev iter11 performance: 14.43
2022-12-18 23:52:47,602 INFO Predicting labels for 32 texts
2022-12-18 23:52:47,710 INFO Evaluating student test iter11 on 32 examples
2022-12-18 23:52:47,711 INFO student test iter11 performance: 0.60
2022-12-18 23:52:47,711 INFO Student Dev performance on iter 11: 14.430762885398899
2022-12-18 23:52:47,712 INFO Student Test performance on iter 11: 0.6049954729962215
2022-12-18 23:52:47,712 INFO 

	 *** Starting loop 12 ***
2022-12-18 23:52:47,712 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:47,712 INFO Getting rule predictions
2022-12-18 23:52:47,712 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:47,712 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:47,712 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:47,713 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:47,713 INFO Predicting labels for 247 texts
2022-12-18 23:52:47,824 INFO Predicting labels for 18 texts
2022-12-18 23:52:47,931 INFO Predicting labels for 444 texts
2022-12-18 23:52:48,041 INFO Training Rule Attention Network
2022-12-18 23:52:48,043 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:48,043 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:48,046 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:48,046 INFO 

		*** Training RAN ***
2022-12-18 23:52:49,209 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:49,211 INFO Predicting labels for 444 texts
2022-12-18 23:52:49,321 INFO There are 3/7 active rules
2022-12-18 23:52:49,321 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:49,323 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:49,394 INFO DONE, Getting attention scores...
2022-12-18 23:52:49,452 INFO the attention scores are
2022-12-18 23:52:49,453 INFO [[6.4901214e-15 9.9869567e-01 2.8607860e-02 ... 2.8607860e-02
  2.8607860e-02 2.8607860e-02]
 [8.1993382e-15 9.9860591e-01 3.0113984e-02 ... 3.0113984e-02
  3.0113984e-02 3.0113984e-02]
 [4.9678114e-08 1.0495483e-02 4.0768698e-02 ... 4.0768698e-02
  4.0768698e-02 4.0768698e-02]
 ...
 [6.7706954e-18 3.1973928e-01 4.9427513e-07 ... 1.1468230e-02
  1.1468230e-02 1.1468230e-02]
 [2.8687116e-16 2.9862341e-03 6.0594740e-10 ... 4.8071030e-01
  4.8071030e-01 4.8071030e-01]
 [3.0685007e-15 2.9491377e-03 3.6153797e-10 ... 5.5779600e-01
  5.5779600e-01 5.5779600e-01]]
2022-12-18 23:52:49,454 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:49,454 INFO Predicting labels for 18 texts
2022-12-18 23:52:49,561 INFO There are 7/7 active rules
2022-12-18 23:52:49,562 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:49,562 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:49,586 INFO DONE, Getting attention scores...
2022-12-18 23:52:49,640 INFO the attention scores are
2022-12-18 23:52:49,640 INFO [[2.4329096e-03 9.7582974e-03 3.0413548e-02 4.0460005e-01 8.8486034e-01
  8.4720212e-01 1.3018621e-02 4.2926177e-02]
 [9.2279457e-04 5.4259780e-03 1.6387960e-02 4.0773502e-01 9.1725022e-01
  8.8258827e-01 7.3277364e-03 3.2656174e-02]
 [6.9764105e-04 5.2166646e-03 1.7295312e-02 4.1997722e-01 9.0537959e-01
  8.7843335e-01 7.7417367e-03 2.2547945e-02]
 [1.0971371e-03 1.2009234e-02 4.6846565e-02 4.1310585e-01 8.1217855e-01
  8.1182784e-01 2.5687223e-02 7.6426947e-03]
 [9.5030293e-04 9.1256462e-03 3.9143056e-02 4.0785849e-01 8.3666146e-01
  8.4302229e-01 2.0552961e-02 1.6875699e-02]
 [3.4094849e-03 2.2061896e-02 7.3381416e-02 3.8331231e-01 7.5579292e-01
  7.3533309e-01 4.3891758e-02 2.2850238e-02]
 [5.5708387e-03 2.2493059e-02 7.3428057e-02 3.8446507e-01 7.8195357e-01
  7.6816815e-01 3.6591563e-02 4.8222970e-02]
 [3.0159887e-03 1.1808969e-02 4.1198261e-02 3.9261362e-01 8.6395532e-01
  8.3989042e-01 1.7447766e-02 4.5425404e-02]
 [4.3248175e-24 9.9983382e-01 9.1187918e-01 1.5003628e-05 9.9975532e-01
  2.8725754e-06 1.0000000e+00 5.1644568e-30]
 [9.8249824e-28 9.9999940e-01 2.3192572e-06 5.1219738e-04 1.0000000e+00
  1.2763165e-02 1.0000000e+00 0.0000000e+00]
 [2.1335567e-21 9.9999928e-01 4.4865736e-11 8.8292366e-01 9.9999988e-01
  6.6456705e-06 1.0000000e+00 1.6423416e-25]
 [9.4817885e-14 1.5917717e-11 3.4896471e-04 1.0969382e-02 9.9996293e-01
  9.5087761e-01 1.0000000e+00 3.5028224e-18]
 [1.0815697e-18 8.4706903e-15 1.2698921e-18 9.5736184e-05 1.0000000e+00
  1.0000000e+00 3.4495082e-15 9.9965715e-01]
 [1.3852301e-12 1.8762938e-09 1.9058909e-10 4.1452907e-03 1.0000000e+00
  1.0000000e+00 1.3880713e-11 8.4072113e-01]
 [7.6972029e-08 1.2634251e-10 1.1272801e-05 1.3542318e-01 9.9999881e-01
  9.9988222e-01 1.8793094e-09 4.0216615e-05]
 [1.4425175e-12 4.1839073e-08 3.6740450e-06 4.1792002e-01 9.9996221e-01
  9.9952400e-01 8.6539308e-07 1.3300223e-06]
 [3.9544717e-12 7.3430050e-07 9.5016248e-06 4.3391931e-01 9.9991226e-01
  9.9989891e-01 3.5156117e-07 7.8039566e-06]
 [2.7636748e-08 3.3293287e-05 6.0360122e-04 3.5141838e-01 9.9623692e-01
  9.9803048e-01 1.1707085e-04 3.8393595e-05]]
2022-12-18 23:52:49,643 INFO Evaluating teacher dev iter12 on 18 examples
2022-12-18 23:52:49,643 INFO teacher dev iter12 performance: 12.26
2022-12-18 23:52:49,644 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:49,644 INFO Predicting labels for 32 texts
2022-12-18 23:52:49,755 INFO There are 7/7 active rules
2022-12-18 23:52:49,756 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:49,756 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:49,779 INFO DONE, Getting attention scores...
2022-12-18 23:52:49,832 INFO the attention scores are
2022-12-18 23:52:49,832 INFO [[4.15987422e-09 5.09899792e-06 1.15568646e-07 1.13599154e-03
  9.99999523e-01 9.94786739e-01 9.99856114e-01 5.17524313e-07]
 [1.79265253e-03 3.41504460e-06 5.97637729e-04 1.85846130e-03
  9.99953747e-01 9.99855757e-01 3.17851454e-02 9.74018395e-01]
 [1.26078064e-02 3.93414404e-03 5.12863835e-03 3.05836685e-02
  9.92560029e-01 9.72859979e-01 9.67299286e-03 9.15056765e-01]
 [3.66826146e-03 3.25624389e-03 5.52213602e-02 4.07571971e-01
  9.27844346e-01 8.31090748e-01 7.64389895e-03 4.89031002e-02]
 [4.51657746e-04 2.24959548e-03 2.92403493e-02 4.58008349e-01
  9.40932095e-01 8.92716527e-01 3.51445097e-03 8.38021189e-03]
 [9.75895018e-05 2.59505026e-03 2.83607952e-02 4.56923544e-01
  9.40629780e-01 9.35497940e-01 4.26565344e-03 2.26831133e-03]
 [5.65701455e-04 1.00277672e-02 6.97911382e-02 3.88784826e-01
  8.52358520e-01 8.76893222e-01 2.24339571e-02 7.53034791e-03]
 [1.18429691e-03 1.07604265e-02 1.15042292e-01 3.94311130e-01
  8.49020720e-01 8.74279499e-01 2.89288331e-02 6.96934061e-03]
 [2.26745056e-03 1.27399033e-02 7.69318268e-02 3.87227982e-01
  8.90926361e-01 8.43801498e-01 2.44376753e-02 3.86532396e-02]
 [1.96949556e-03 6.24590740e-03 4.16758731e-02 4.03475940e-01
  9.36807573e-01 8.94666016e-01 7.26628536e-03 5.31663820e-02]
 [2.50864355e-03 3.17153241e-03 4.93375212e-02 4.27849978e-01
  9.22413051e-01 8.62747848e-01 5.46508236e-03 2.97405366e-02]
 [4.01885220e-04 1.88644137e-03 2.22878642e-02 4.25564736e-01
  9.55246150e-01 9.10386801e-01 3.32499784e-03 1.89512763e-02]
 [1.40185270e-03 9.72335506e-03 1.07521795e-01 4.00505930e-01
  8.35705698e-01 8.56372416e-01 2.07459573e-02 6.22869050e-03]
 [1.26294151e-03 1.14616305e-02 7.45128691e-02 3.97066563e-01
  8.61542463e-01 8.56683791e-01 2.57297438e-02 1.56252161e-02]
 [1.49561046e-03 8.43531918e-03 7.37000629e-02 4.21621233e-01
  8.99855018e-01 8.79990518e-01 1.53953098e-02 2.08971798e-02]
 [7.71740219e-03 1.69793628e-02 1.05338112e-01 3.97105306e-01
  8.40509653e-01 7.69768059e-01 2.81208865e-02 6.43224791e-02]
 [4.57639049e-04 1.82037288e-03 1.78232454e-02 4.62879926e-01
  9.73835468e-01 9.45002854e-01 2.23323051e-03 3.11642606e-02]
 [2.92855024e-04 1.14580314e-03 3.01200133e-02 4.77803499e-01
  9.64684606e-01 9.40074801e-01 2.81016761e-03 3.99122993e-03]
 [4.45975369e-04 3.86234140e-03 2.25621015e-02 4.10475910e-01
  9.55796719e-01 9.03968692e-01 5.94005268e-03 3.80912572e-02]
 [1.17811760e-04 8.81187094e-04 8.85056704e-03 4.70555604e-01
  9.86013651e-01 9.68950987e-01 8.15084786e-04 1.81458928e-02]
 [5.79514250e-04 1.83124864e-03 3.01546194e-02 4.40616697e-01
  9.47580814e-01 8.97073448e-01 3.50011885e-03 1.54470969e-02]
 [2.03586096e-04 1.80101511e-03 1.06760859e-02 4.09044117e-01
  9.66336071e-01 9.16651011e-01 1.96004985e-03 3.09086069e-02]
 [8.32170335e-05 6.48782414e-04 9.49983671e-03 4.61925924e-01
  9.77505922e-01 9.49848831e-01 7.75176042e-04 7.26800552e-03]
 [6.76850614e-05 1.69767870e-03 2.19932608e-02 4.34549958e-01
  9.51831281e-01 9.40925717e-01 3.65103106e-03 2.28480459e-03]
 [8.32164806e-05 3.14268959e-03 2.21579038e-02 3.98212641e-01
  9.42483485e-01 9.47317123e-01 5.76007739e-03 5.33322478e-03]
 [2.45440635e-03 1.73442345e-02 1.12667136e-01 3.63782048e-01
  7.77751684e-01 8.22327256e-01 3.59305367e-02 1.49396108e-02]
 [6.04957202e-03 2.23883186e-02 1.47117078e-01 3.68294358e-01
  7.66989529e-01 8.03397477e-01 4.69970927e-02 2.08724402e-02]
 [1.95984356e-02 4.58267927e-02 2.09732592e-01 3.50656390e-01
  6.73185408e-01 6.88030779e-01 8.82721171e-02 4.93624434e-02]
 [2.35138107e-02 4.39777933e-02 1.82628766e-01 3.61652821e-01
  7.02242136e-01 6.94540799e-01 7.11537674e-02 6.88474849e-02]
 [6.83859363e-03 1.50792487e-02 8.00122991e-02 4.04796213e-01
  8.56074035e-01 8.38173270e-01 2.29315069e-02 3.96137424e-02]
 [8.20320379e-03 2.10368019e-02 8.48034546e-02 4.00788933e-01
  8.06871355e-01 7.83390343e-01 3.48729976e-02 5.58050610e-02]
 [3.80200474e-03 1.16538834e-02 4.99972254e-02 4.04397100e-01
  8.69855642e-01 8.49406838e-01 1.66058186e-02 4.39854041e-02]]
2022-12-18 23:52:49,837 INFO Evaluating teacher test iter12 on 32 examples
2022-12-18 23:52:49,838 INFO teacher test iter12 performance: 1.41
2022-12-18 23:52:49,838 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:49,842 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9484641551971436
2022-12-18 23:52:49,843 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:50,698 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:51,656 INFO Predicting labels for 18 texts
2022-12-18 23:52:51,773 INFO Evaluating student dev iter12 on 18 examples
2022-12-18 23:52:51,774 INFO student dev iter12 performance: 14.50
2022-12-18 23:52:51,774 INFO Predicting labels for 32 texts
2022-12-18 23:52:51,885 INFO Evaluating student test iter12 on 32 examples
2022-12-18 23:52:51,886 INFO student test iter12 performance: 0.62
2022-12-18 23:52:51,886 INFO Student Dev performance on iter 12: 14.50157818206178
2022-12-18 23:52:51,886 INFO Student Test performance on iter 12: 0.6219512721798007
2022-12-18 23:52:51,886 INFO 

	 *** Starting loop 13 ***
2022-12-18 23:52:51,886 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:51,886 INFO Getting rule predictions
2022-12-18 23:52:51,886 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:51,887 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:51,887 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:51,887 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:51,888 INFO Predicting labels for 247 texts
2022-12-18 23:52:51,996 INFO Predicting labels for 18 texts
2022-12-18 23:52:52,106 INFO Predicting labels for 444 texts
2022-12-18 23:52:52,213 INFO Training Rule Attention Network
2022-12-18 23:52:52,215 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:52,215 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:52,217 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:52,217 INFO 

		*** Training RAN ***
2022-12-18 23:52:53,367 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:53,368 INFO Predicting labels for 444 texts
2022-12-18 23:52:53,485 INFO There are 3/7 active rules
2022-12-18 23:52:53,485 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:53,487 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:53,562 INFO DONE, Getting attention scores...
2022-12-18 23:52:53,627 INFO the attention scores are
2022-12-18 23:52:53,627 INFO [[1.6163634e-15 9.9833751e-01 2.1243773e-02 ... 2.1243773e-02
  2.1243773e-02 2.1243773e-02]
 [2.1755194e-15 9.9813086e-01 2.2573257e-02 ... 2.2573257e-02
  2.2573257e-02 2.2573257e-02]
 [9.6958797e-09 2.4784051e-02 5.5699289e-02 ... 5.5699289e-02
  5.5699289e-02 5.5699289e-02]
 ...
 [5.1447606e-20 9.2051315e-01 2.9824720e-05 ... 1.4793808e-02
  1.4793808e-02 1.4793808e-02]
 [1.2959016e-19 1.0783487e-01 2.3173433e-08 ... 8.9867073e-01
  8.9867073e-01 8.9867073e-01]
 [1.6952440e-18 9.8862976e-02 1.0721905e-08 ... 9.2472607e-01
  9.2472607e-01 9.2472607e-01]]
2022-12-18 23:52:53,628 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:53,628 INFO Predicting labels for 18 texts
2022-12-18 23:52:53,754 INFO There are 7/7 active rules
2022-12-18 23:52:53,754 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:53,755 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:53,779 INFO DONE, Getting attention scores...
2022-12-18 23:52:53,835 INFO the attention scores are
2022-12-18 23:52:53,835 INFO [[2.84906407e-03 5.81686758e-03 1.84082072e-02 4.02414709e-01
  9.05776978e-01 8.87840211e-01 9.60285123e-03 2.98703145e-02]
 [1.14602747e-03 3.14532593e-03 8.76218732e-03 4.06854451e-01
  9.34463739e-01 9.15344417e-01 5.22656785e-03 2.16481909e-02]
 [8.32450169e-04 3.08697880e-03 8.85428209e-03 4.18886274e-01
  9.24245775e-01 9.12108123e-01 5.72282402e-03 1.48962773e-02]
 [2.33010785e-03 7.25026010e-03 3.38179432e-02 4.01973426e-01
  8.15810978e-01 8.52485716e-01 2.28521973e-02 7.54960254e-03]
 [1.71586068e-03 6.05893740e-03 2.47793142e-02 3.97378266e-01
  8.42858791e-01 8.64501655e-01 1.78043060e-02 1.41690755e-02]
 [5.74405305e-03 1.42753301e-02 6.84623718e-02 3.70962173e-01
  7.41598427e-01 7.99160302e-01 4.57648262e-02 1.65056605e-02]
 [7.60554569e-03 1.52584706e-02 5.37654646e-02 3.81629974e-01
  7.90633082e-01 8.23768139e-01 3.43272611e-02 3.24481390e-02]
 [3.87413776e-03 7.61035224e-03 2.57113110e-02 3.87115926e-01
  8.83679509e-01 8.80464017e-01 1.31159797e-02 3.27184089e-02]
 [8.05922118e-26 9.99963641e-01 9.99785602e-01 1.61268531e-07
  7.18261957e-01 1.07808614e-06 1.00000000e+00 1.19414864e-29]
 [7.78340814e-30 9.99999762e-01 8.39009706e-04 5.81139511e-06
  9.99999285e-01 1.93085838e-02 1.00000000e+00 0.00000000e+00]
 [3.88118240e-23 9.99999762e-01 6.71658451e-10 5.74452579e-01
  9.99972939e-01 1.71281918e-05 1.00000000e+00 1.71372506e-23]
 [1.10741437e-15 1.19208987e-09 6.93864096e-03 2.25433912e-02
  3.14687341e-01 9.79015589e-01 1.00000000e+00 1.85880296e-14]
 [1.70980878e-21 3.71983286e-15 6.63778127e-20 1.85003693e-04
  1.00000000e+00 1.00000000e+00 1.63241084e-13 9.99997854e-01]
 [2.78237676e-12 4.92849817e-10 2.21182864e-11 3.00764549e-03
  1.00000000e+00 1.00000000e+00 3.53611029e-11 7.38717735e-01]
 [9.66451125e-07 7.31624414e-11 7.48084688e-08 9.52296332e-02
  9.99999523e-01 9.99964595e-01 4.55941118e-10 1.30222621e-03]
 [1.98140658e-12 9.62026103e-09 1.31750442e-08 2.81661034e-01
  9.99978542e-01 9.99845147e-01 5.10112486e-08 5.08575476e-06]
 [1.59002082e-11 1.51814930e-07 6.79664538e-07 3.91820461e-01
  9.99944806e-01 9.99930143e-01 6.03292136e-08 1.76642061e-05]
 [9.19731704e-08 1.93141841e-05 1.04025188e-04 3.20621878e-01
  9.97617781e-01 9.98785436e-01 4.87630605e-05 7.92773280e-05]]
2022-12-18 23:52:53,838 INFO Evaluating teacher dev iter13 on 18 examples
2022-12-18 23:52:53,839 INFO teacher dev iter13 performance: 11.88
2022-12-18 23:52:53,840 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:53,840 INFO Predicting labels for 32 texts
2022-12-18 23:52:53,949 INFO There are 7/7 active rules
2022-12-18 23:52:53,950 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:53,950 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:53,978 INFO DONE, Getting attention scores...
2022-12-18 23:52:54,031 INFO the attention scores are
2022-12-18 23:52:54,031 INFO [[1.37594866e-11 9.01581370e-05 1.12488317e-06 2.88181519e-03
  9.99504447e-01 9.97839451e-01 9.99966741e-01 1.16650178e-03]
 [5.93769837e-05 7.73417105e-06 8.35034938e-04 3.65866278e-03
  9.99046385e-01 9.99948025e-01 7.18303323e-02 9.99834538e-01]
 [8.50556698e-03 1.84135919e-03 3.05102556e-03 2.65532918e-02
  9.91414845e-01 9.84401643e-01 1.51841929e-02 9.64015484e-01]
 [6.54647732e-03 2.74459505e-03 3.55757475e-02 3.84625942e-01
  9.46115375e-01 8.60555947e-01 6.40074257e-03 4.14796546e-02]
 [7.15460454e-04 1.30100944e-03 1.30427219e-02 4.37573195e-01
  9.47725236e-01 9.07751501e-01 2.11475627e-03 1.03194034e-02]
 [2.47662741e-04 1.52143906e-03 1.19783040e-02 4.31721598e-01
  9.42053735e-01 9.34562027e-01 2.21891142e-03 4.58898209e-03]
 [1.06318318e-03 5.83590614e-03 3.42799574e-02 3.64539951e-01
  8.58018637e-01 8.89445424e-01 1.09678088e-02 1.01287486e-02]
 [1.85803766e-03 6.04104251e-03 6.24630451e-02 3.70236069e-01
  8.50740552e-01 8.81898344e-01 1.59775838e-02 9.33601521e-03]
 [3.36889317e-03 7.50062102e-03 3.61811332e-02 3.78875375e-01
  9.09337580e-01 8.78662527e-01 1.36917634e-02 4.60697860e-02]
 [2.63469573e-03 3.42672039e-03 1.93375424e-02 4.00440246e-01
  9.44596767e-01 9.31059003e-01 4.13062843e-03 4.40897606e-02]
 [3.54934880e-03 1.94046821e-03 2.37615053e-02 4.10502613e-01
  9.31269050e-01 8.89020205e-01 3.39515344e-03 3.25728655e-02]
 [7.52040942e-04 1.07599166e-03 9.12566762e-03 4.08996105e-01
  9.60661530e-01 9.26974773e-01 1.76784501e-03 2.44390592e-02]
 [2.61351885e-03 5.50194830e-03 5.52381575e-02 3.83815199e-01
  8.39860380e-01 8.65779817e-01 1.14303436e-02 9.12123639e-03]
 [2.05584592e-03 7.13630253e-03 3.75723653e-02 3.76028121e-01
  8.73306334e-01 8.77229989e-01 1.36048151e-02 2.08795872e-02]
 [2.42132833e-03 5.21263340e-03 4.31563184e-02 4.04879391e-01
  9.06669259e-01 8.97829711e-01 8.63683410e-03 2.55642757e-02]
 [9.25887562e-03 1.03831533e-02 6.49602860e-02 3.84400934e-01
  8.54617834e-01 8.15348506e-01 1.77412257e-02 5.63227832e-02]
 [6.35077478e-04 1.01120991e-03 7.76723353e-03 4.46410984e-01
  9.79251623e-01 9.62953568e-01 1.30114402e-03 2.95383036e-02]
 [7.71916762e-04 6.10778574e-04 9.77833848e-03 4.30255204e-01
  9.63503599e-01 9.34048057e-01 1.60246796e-03 8.16876069e-03]
 [6.09935669e-04 2.26442120e-03 6.99659577e-03 3.92717689e-01
  9.70116138e-01 9.37284768e-01 2.86819763e-03 4.49813530e-02]
 [1.85929297e-04 4.52839828e-04 3.94543493e-03 4.62742686e-01
  9.90056157e-01 9.80593204e-01 4.61318821e-04 1.73122026e-02]
 [1.04687538e-03 1.05376251e-03 1.39326584e-02 4.27371860e-01
  9.53628480e-01 9.09544587e-01 2.08976329e-03 1.98512767e-02]
 [2.18539193e-04 9.40369442e-04 3.20883119e-03 3.97648633e-01
  9.78607535e-01 9.55949605e-01 8.62007088e-04 2.31842753e-02]
 [1.31454290e-04 3.14694684e-04 3.89338541e-03 4.43606466e-01
  9.80964601e-01 9.64576483e-01 3.98762582e-04 6.25047879e-03]
 [1.66779937e-04 9.04745015e-04 8.10831320e-03 4.11201239e-01
  9.52502966e-01 9.43774581e-01 1.80748862e-03 4.36208770e-03]
 [1.79886600e-04 1.92495657e-03 9.37741157e-03 3.75864595e-01
  9.48622167e-01 9.55632389e-01 2.78792111e-03 7.59550789e-03]
 [4.15039808e-03 1.17960665e-02 6.57768622e-02 3.40896517e-01
  7.86400318e-01 8.58787000e-01 2.25078054e-02 1.53310895e-02]
 [9.08226892e-03 1.43890353e-02 9.01558101e-02 3.57776254e-01
  7.81367898e-01 8.26780617e-01 3.10216993e-02 2.47550346e-02]
 [2.61788704e-02 3.21705677e-02 1.53598547e-01 3.42866004e-01
  6.71893954e-01 7.41985083e-01 7.29407296e-02 4.02352177e-02]
 [3.06557436e-02 3.08744684e-02 1.44133329e-01 3.57737899e-01
  7.04143465e-01 7.59043396e-01 6.24869354e-02 4.99571450e-02]
 [1.08808447e-02 1.07895378e-02 4.95615229e-02 3.87996197e-01
  8.65017533e-01 8.61221850e-01 1.69329289e-02 4.41579334e-02]
 [1.01547120e-02 1.47145037e-02 5.84462881e-02 3.90485883e-01
  8.29757035e-01 8.24645817e-01 2.69127544e-02 4.67688367e-02]
 [4.78049880e-03 7.99059868e-03 3.28224078e-02 3.94026458e-01
  8.92325938e-01 8.83651674e-01 1.22916596e-02 3.67005244e-02]]
2022-12-18 23:52:54,036 INFO Evaluating teacher test iter13 on 32 examples
2022-12-18 23:52:54,037 INFO teacher test iter13 performance: 1.49
2022-12-18 23:52:54,037 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:54,041 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.934989094734192
2022-12-18 23:52:54,042 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:54,836 INFO fine-tuning the student on clean labeled data
2022-12-18 23:52:55,634 INFO Predicting labels for 18 texts
2022-12-18 23:52:55,748 INFO Evaluating student dev iter13 on 18 examples
2022-12-18 23:52:55,749 INFO student dev iter13 performance: 14.55
2022-12-18 23:52:55,750 INFO Predicting labels for 32 texts
2022-12-18 23:52:55,854 INFO Evaluating student test iter13 on 32 examples
2022-12-18 23:52:55,855 INFO student test iter13 performance: 0.64
2022-12-18 23:52:55,855 INFO Student Dev performance on iter 13: 14.55343032912527
2022-12-18 23:52:55,855 INFO Student Test performance on iter 13: 0.636728897524222
2022-12-18 23:52:55,855 INFO 

	 *** Starting loop 14 ***
2022-12-18 23:52:55,855 INFO Adding Student as extra rule in Teacher
2022-12-18 23:52:55,855 INFO Getting rule predictions
2022-12-18 23:52:55,855 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:52:55,856 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:55,856 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:55,856 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:52:55,857 INFO Predicting labels for 247 texts
2022-12-18 23:52:55,970 INFO Predicting labels for 18 texts
2022-12-18 23:52:56,086 INFO Predicting labels for 444 texts
2022-12-18 23:52:56,197 INFO Training Rule Attention Network
2022-12-18 23:52:56,199 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:52:56,199 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:52:56,201 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:52:56,202 INFO 

		*** Training RAN ***
2022-12-18 23:52:57,537 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:52:57,539 INFO Predicting labels for 444 texts
2022-12-18 23:52:57,650 INFO There are 3/7 active rules
2022-12-18 23:52:57,651 INFO Coverage: 100.0% (444/444)
2022-12-18 23:52:57,654 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:52:57,731 INFO DONE, Getting attention scores...
2022-12-18 23:52:57,787 INFO the attention scores are
2022-12-18 23:52:57,787 INFO [[1.6997193e-17 9.9980360e-01 2.1091474e-02 ... 2.1091474e-02
  2.1091474e-02 2.1091474e-02]
 [2.4514737e-17 9.9977750e-01 2.2335654e-02 ... 2.2335654e-02
  2.2335654e-02 2.2335654e-02]
 [2.4151532e-09 7.3569166e-03 4.3379866e-02 ... 4.3379866e-02
  4.3379866e-02 4.3379866e-02]
 ...
 [2.2208520e-20 7.4114126e-01 5.5449718e-06 ... 7.3084668e-03
  7.3084668e-03 7.3084668e-03]
 [5.0818800e-18 1.2927104e-02 3.4405887e-09 ... 5.6096977e-01
  5.6096977e-01 5.6096977e-01]
 [1.2112093e-16 1.1690597e-02 1.5870200e-09 ... 6.3574380e-01
  6.3574380e-01 6.3574380e-01]]
2022-12-18 23:52:57,788 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:52:57,788 INFO Predicting labels for 18 texts
2022-12-18 23:52:57,894 INFO There are 7/7 active rules
2022-12-18 23:52:57,895 INFO Coverage: 100.0% (18/18)
2022-12-18 23:52:57,895 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:52:57,919 INFO DONE, Getting attention scores...
2022-12-18 23:52:57,978 INFO the attention scores are
2022-12-18 23:52:57,978 INFO [[1.87173672e-03 5.78324217e-03 2.40547862e-02 3.78355533e-01
  9.20133114e-01 8.82443905e-01 9.43718571e-03 3.13717052e-02]
 [6.80093362e-04 3.10019194e-03 1.14150830e-02 3.78300995e-01
  9.47313428e-01 9.12860572e-01 5.12122829e-03 2.23504398e-02]
 [4.49377752e-04 3.30869853e-03 1.09532997e-02 3.88877839e-01
  9.40249085e-01 9.12160575e-01 5.75857004e-03 1.47163030e-02]
 [1.02463388e-03 8.74998234e-03 4.50543538e-02 3.80183011e-01
  8.49941313e-01 8.70555162e-01 2.63140574e-02 4.74659633e-03]
 [7.30563595e-04 6.10661088e-03 2.91148219e-02 3.69771361e-01
  8.80539715e-01 8.84516895e-01 1.97754651e-02 8.97156354e-03]
 [2.98732333e-03 1.54633066e-02 8.64605457e-02 3.48257661e-01
  7.68745124e-01 7.90973365e-01 5.07399775e-02 1.32872593e-02]
 [5.31743793e-03 1.54711120e-02 6.87536076e-02 3.58902395e-01
  8.09374928e-01 8.15883577e-01 3.95566113e-02 2.74370350e-02]
 [2.57805432e-03 7.30102882e-03 3.37552577e-02 3.67810935e-01
  9.02164221e-01 8.74890566e-01 1.27860168e-02 3.45496386e-02]
 [1.83357288e-29 9.99997258e-01 9.99779522e-01 4.25376413e-07
  4.20088053e-01 8.44660190e-06 1.00000000e+00 1.06964667e-32]
 [1.25733609e-32 1.00000000e+00 2.79589579e-03 2.40194768e-05
  9.99999523e-01 5.74096322e-01 1.00000000e+00 0.00000000e+00]
 [6.44727538e-25 9.99999881e-01 3.67261499e-10 8.60115528e-01
  9.99990344e-01 5.27071301e-03 1.00000000e+00 9.47004245e-25]
 [8.19602378e-15 9.83543108e-12 1.77069404e-03 8.74504030e-01
  3.01611498e-02 9.99979496e-01 1.00000000e+00 1.35058848e-16]
 [8.77466538e-20 3.92970017e-18 3.02364292e-19 1.39724434e-05
  1.00000000e+00 1.00000000e+00 2.43621520e-15 9.99844313e-01]
 [4.99117241e-13 1.70502924e-12 2.63367470e-11 3.05386493e-04
  1.00000000e+00 1.00000000e+00 1.84248645e-12 9.47581351e-01]
 [1.83143856e-09 5.55604139e-11 5.10010295e-07 4.86329682e-02
  9.99999404e-01 9.99991179e-01 1.01752065e-10 2.17902518e-04]
 [9.31094191e-14 8.61251692e-09 1.25184812e-07 2.29882464e-01
  9.99991894e-01 9.99964833e-01 1.88777136e-07 1.54178906e-07]
 [8.82892175e-13 1.41931721e-07 7.35945264e-07 3.15259576e-01
  9.99984980e-01 9.99976397e-01 3.69953170e-08 1.97311556e-06]
 [5.99367045e-09 1.34205247e-05 1.63474993e-04 2.90107608e-01
  9.98952627e-01 9.99497294e-01 5.65260671e-05 6.87305055e-06]]
2022-12-18 23:52:57,981 INFO Evaluating teacher dev iter14 on 18 examples
2022-12-18 23:52:57,981 INFO teacher dev iter14 performance: 18.11
2022-12-18 23:52:57,982 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:52:57,982 INFO Predicting labels for 32 texts
2022-12-18 23:52:58,089 INFO There are 7/7 active rules
2022-12-18 23:52:58,089 INFO Coverage: 100.0% (32/32)
2022-12-18 23:52:58,090 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:52:58,113 INFO DONE, Getting attention scores...
2022-12-18 23:52:58,166 INFO the attention scores are
2022-12-18 23:52:58,166 INFO [[1.31017897e-09 2.00503632e-06 2.81176540e-07 3.87129262e-02
  9.97843862e-01 9.99995947e-01 9.99885201e-01 3.39950748e-05]
 [2.16658041e-03 2.68535757e-07 1.10082584e-03 1.09572979e-02
  9.93834496e-01 9.99996662e-01 1.58838741e-02 9.96236384e-01]
 [1.93598494e-02 9.30125010e-04 7.34756887e-03 1.80750936e-02
  9.86280680e-01 9.91562426e-01 7.12186331e-03 9.73461151e-01]
 [3.94966081e-03 2.60865223e-03 6.54285029e-02 3.67602021e-01
  9.37830925e-01 8.59579086e-01 6.11836929e-03 3.62716652e-02]
 [3.40974220e-04 1.83576311e-03 2.09991205e-02 4.10586894e-01
  9.55566943e-01 9.33171391e-01 2.40486907e-03 6.44340320e-03]
 [8.66884948e-05 2.17521982e-03 2.08501555e-02 4.02839690e-01
  9.58186567e-01 9.63551283e-01 2.37545301e-03 1.58669241e-03]
 [5.59379754e-04 8.61345045e-03 6.23324849e-02 3.52369487e-01
  8.77710581e-01 9.20502186e-01 1.35674458e-02 4.25328035e-03]
 [9.44804458e-04 8.48191790e-03 1.21961750e-01 3.56870919e-01
  8.62845123e-01 9.17868316e-01 1.90440658e-02 3.46070062e-03]
 [2.10569706e-03 8.39113165e-03 7.91853592e-02 3.58684093e-01
  8.97006929e-01 8.93320203e-01 1.67487003e-02 2.37951428e-02]
 [2.71081715e-03 3.25720035e-03 4.54688706e-02 3.68471146e-01
  9.36810017e-01 9.27101254e-01 4.48101852e-03 4.51285318e-02]
 [2.02934956e-03 2.14900565e-03 4.83224057e-02 4.02151793e-01
  9.29773390e-01 9.00466859e-01 3.76050337e-03 2.43800841e-02]
 [3.16835678e-04 1.27010641e-03 1.84001531e-02 3.87772858e-01
  9.63882983e-01 9.49315429e-01 2.07816809e-03 1.20346416e-02]
 [1.28219428e-03 8.61958507e-03 1.00427128e-01 3.73660892e-01
  8.59163284e-01 9.05282140e-01 1.47853876e-02 3.60025046e-03]
 [1.17464596e-03 9.10294242e-03 7.13275746e-02 3.56810123e-01
  8.80788088e-01 9.08377647e-01 1.74469240e-02 9.04814713e-03]
 [1.24556024e-03 6.26660883e-03 7.82553554e-02 3.87726486e-01
  9.13931608e-01 9.20232236e-01 9.14876442e-03 1.26356585e-02]
 [7.54419854e-03 1.20825237e-02 1.15131520e-01 3.72383088e-01
  8.34024787e-01 8.28731000e-01 2.07790602e-02 4.30011339e-02]
 [5.33486600e-04 9.92166926e-04 1.58025213e-02 4.15732533e-01
  9.76434350e-01 9.63893712e-01 1.15304813e-03 2.68615261e-02]
 [2.18723682e-04 7.06412306e-04 2.42107082e-02 4.07648772e-01
  9.71902490e-01 9.66117203e-01 1.58119597e-03 2.45787040e-03]
 [3.79574660e-04 2.26940820e-03 1.44188832e-02 3.73389930e-01
  9.64481890e-01 9.49493825e-01 3.26067465e-03 1.97521895e-02]
 [1.31512716e-04 4.31963883e-04 7.04670884e-03 4.20418471e-01
  9.90203738e-01 9.81520236e-01 3.60556005e-04 1.53435552e-02]
 [4.33425070e-04 1.29254290e-03 2.40992550e-02 4.02687848e-01
  9.57475662e-01 9.35231149e-01 2.24582804e-03 1.04557667e-02]
 [1.82894582e-04 1.19851262e-03 6.11662120e-03 3.75475109e-01
  9.75931644e-01 9.58449066e-01 9.84537299e-04 2.09878013e-02]
 [6.69465298e-05 4.60836483e-04 6.86823903e-03 4.17997003e-01
  9.84455705e-01 9.74719226e-01 3.58455436e-04 4.63501271e-03]
 [5.67901625e-05 1.39615440e-03 1.45380925e-02 3.89396489e-01
  9.66153204e-01 9.67299938e-01 2.29051732e-03 1.63656252e-03]
 [6.98750300e-05 2.36535771e-03 1.62965674e-02 3.58098924e-01
  9.61092234e-01 9.70205724e-01 3.11060506e-03 3.04983370e-03]
 [2.41760863e-03 1.51330596e-02 1.11301087e-01 3.35588634e-01
  8.08847249e-01 8.85705888e-01 2.74728313e-02 7.58202607e-03]
 [5.51070832e-03 1.87391341e-02 1.57212675e-01 3.43264580e-01
  7.90352046e-01 8.67573321e-01 4.20999378e-02 1.09241772e-02]
 [2.26124749e-02 3.88048440e-02 2.49282867e-01 3.34982276e-01
  6.53915942e-01 7.61747420e-01 9.52860266e-02 2.59924810e-02]
 [2.93150786e-02 3.42891291e-02 2.20696941e-01 3.49838555e-01
  6.87687397e-01 7.56564081e-01 7.56695941e-02 4.01062444e-02]
 [5.93768852e-03 9.66808479e-03 7.97284693e-02 3.76002163e-01
  8.80883157e-01 8.72632027e-01 1.81540288e-02 3.10485512e-02]
 [6.97808433e-03 1.39912926e-02 7.43632764e-02 3.76263201e-01
  8.47361863e-01 8.24552357e-01 2.75612790e-02 4.20347489e-02]
 [3.20122926e-03 7.43007148e-03 4.32124548e-02 3.77874792e-01
  9.08396959e-01 8.82302761e-01 1.13891335e-02 3.54618020e-02]]
2022-12-18 23:52:58,171 INFO Evaluating teacher test iter14 on 32 examples
2022-12-18 23:52:58,173 INFO teacher test iter14 performance: 1.43
2022-12-18 23:52:58,173 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:52:58,178 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9239182472229004
2022-12-18 23:52:58,178 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:52:59,979 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:00,775 INFO Predicting labels for 18 texts
2022-12-18 23:53:00,884 INFO Evaluating student dev iter14 on 18 examples
2022-12-18 23:53:00,885 INFO student dev iter14 performance: 14.59
2022-12-18 23:53:00,885 INFO Predicting labels for 32 texts
2022-12-18 23:53:00,992 INFO Evaluating student test iter14 on 32 examples
2022-12-18 23:53:00,993 INFO student test iter14 performance: 0.65
2022-12-18 23:53:00,993 INFO Student Dev performance on iter 14: 14.589040864969515
2022-12-18 23:53:00,993 INFO Student Test performance on iter 14: 0.6488766445929963
2022-12-18 23:53:00,993 INFO 

	 *** Starting loop 15 ***
2022-12-18 23:53:00,993 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:00,993 INFO Getting rule predictions
2022-12-18 23:53:00,994 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:00,994 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:00,994 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:00,994 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:00,995 INFO Predicting labels for 247 texts
2022-12-18 23:53:02,126 INFO Predicting labels for 18 texts
2022-12-18 23:53:02,242 INFO Predicting labels for 444 texts
2022-12-18 23:53:02,360 INFO Training Rule Attention Network
2022-12-18 23:53:02,362 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:02,362 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:02,368 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:02,368 INFO 

		*** Training RAN ***
2022-12-18 23:53:03,510 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:03,511 INFO Predicting labels for 444 texts
2022-12-18 23:53:03,621 INFO There are 3/7 active rules
2022-12-18 23:53:03,621 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:03,624 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:03,697 INFO DONE, Getting attention scores...
2022-12-18 23:53:03,757 INFO the attention scores are
2022-12-18 23:53:03,757 INFO [[9.34946861e-18 9.95723724e-01 5.48551418e-03 ... 5.48551418e-03
  5.48551418e-03 5.48551418e-03]
 [1.30814106e-17 9.94896472e-01 6.10803254e-03 ... 6.10803254e-03
  6.10803254e-03 6.10803254e-03]
 [3.17042304e-09 1.73412189e-02 1.79071706e-02 ... 1.79071706e-02
  1.79071706e-02 1.79071706e-02]
 ...
 [9.23637627e-20 8.57949376e-01 1.75337664e-06 ... 1.22852915e-03
  1.22852915e-03 1.22852915e-03]
 [3.62135735e-17 3.95309120e-01 2.45873255e-09 ... 3.14312838e-02
  3.14312838e-02 3.14312838e-02]
 [7.28788365e-16 3.31779093e-01 1.28425470e-09 ... 5.30840270e-02
  5.30840270e-02 5.30840270e-02]]
2022-12-18 23:53:03,759 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:03,759 INFO Predicting labels for 18 texts
2022-12-18 23:53:03,866 INFO There are 7/7 active rules
2022-12-18 23:53:03,866 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:03,866 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:03,891 INFO DONE, Getting attention scores...
2022-12-18 23:53:03,946 INFO the attention scores are
2022-12-18 23:53:03,946 INFO [[5.7835248e-03 2.7377557e-03 3.8553603e-02 3.4536576e-01 9.1950953e-01
  8.5222298e-01 8.9872163e-03 3.8002837e-02]
 [2.2613357e-03 1.2639072e-03 1.9423788e-02 3.4648773e-01 9.4735414e-01
  8.9033365e-01 4.6551698e-03 2.6846139e-02]
 [1.4321731e-03 1.1176479e-03 1.3950908e-02 3.5705400e-01 9.4826519e-01
  8.9007616e-01 4.4861650e-03 1.8345036e-02]
 [3.0758700e-03 3.1939794e-03 3.5139915e-02 3.5902509e-01 8.7635541e-01
  8.2690102e-01 1.9959545e-02 8.9986473e-03]
 [1.7051792e-03 2.2840470e-03 2.8046841e-02 3.5098237e-01 8.9745176e-01
  8.6393738e-01 1.6376227e-02 1.4674020e-02]
 [6.4404211e-03 7.3600090e-03 7.7085279e-02 3.2701367e-01 8.0153477e-01
  7.4685752e-01 3.8833998e-02 2.1159770e-02]
 [1.3558679e-02 7.9350621e-03 9.7403400e-02 3.3207789e-01 8.1471103e-01
  7.7708906e-01 3.7696443e-02 3.6889009e-02]
 [6.8971002e-03 3.5402051e-03 5.9489395e-02 3.3298472e-01 8.9774293e-01
  8.5325849e-01 1.3630186e-02 4.0547304e-02]
 [5.3104562e-30 9.9998319e-01 9.6386981e-01 1.4860976e-07 4.7034413e-01
  1.2123478e-06 1.0000000e+00 3.8082108e-35]
 [2.6793757e-31 9.9999881e-01 1.4094482e-05 6.7422047e-06 1.0000000e+00
  6.1418116e-01 1.0000000e+00 0.0000000e+00]
 [2.8860285e-26 9.9999952e-01 1.5606089e-11 5.7587069e-01 9.9999976e-01
  1.5043179e-04 1.0000000e+00 5.0600639e-24]
 [8.7233450e-14 3.1576397e-10 4.0872654e-04 2.5148371e-02 9.2853314e-01
  9.9774015e-01 1.0000000e+00 1.4663338e-14]
 [1.1634569e-19 8.0436247e-17 6.1934558e-24 4.2837983e-05 1.0000000e+00
  1.0000000e+00 1.0059879e-15 9.9999726e-01]
 [1.5578892e-13 2.6640248e-10 1.7054197e-12 1.7758488e-03 1.0000000e+00
  1.0000000e+00 5.8605278e-12 9.2741257e-01]
 [7.9215539e-08 1.7019761e-11 8.1637566e-08 2.4205543e-02 9.9999881e-01
  9.9996579e-01 1.8217419e-10 1.2837333e-03]
 [1.0500074e-12 3.8316178e-10 9.1577704e-07 2.7639684e-01 9.9998379e-01
  9.9989128e-01 3.1513528e-07 1.4492433e-06]
 [1.0183137e-12 3.1982157e-09 6.2040812e-07 2.0335105e-01 9.9999356e-01
  9.9996758e-01 7.6263852e-08 7.5536850e-06]
 [1.3872133e-08 1.2642481e-06 7.9954398e-04 2.2469747e-01 9.9910921e-01
  9.9949610e-01 1.2665415e-04 1.7323828e-05]]
2022-12-18 23:53:03,949 INFO Evaluating teacher dev iter15 on 18 examples
2022-12-18 23:53:03,950 INFO teacher dev iter15 performance: 18.54
2022-12-18 23:53:03,950 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:03,951 INFO Predicting labels for 32 texts
2022-12-18 23:53:04,060 INFO There are 7/7 active rules
2022-12-18 23:53:04,061 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:04,061 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:04,085 INFO DONE, Getting attention scores...
2022-12-18 23:53:04,140 INFO the attention scores are
2022-12-18 23:53:04,140 INFO [[6.5299960e-10 2.8960532e-04 1.8768196e-07 1.8012098e-03 9.9999607e-01
  9.9991918e-01 9.9990916e-01 9.9375931e-05]
 [5.5017346e-03 2.1826192e-05 8.2355204e-05 1.9555860e-03 9.9990106e-01
  9.9999261e-01 3.1105991e-02 9.9755549e-01]
 [3.5411242e-02 7.6382221e-03 1.1946424e-03 2.6146812e-02 9.9450582e-01
  9.8920035e-01 1.6107468e-02 9.5945233e-01]
 [1.0544209e-02 1.6035379e-03 5.3345721e-02 3.7495115e-01 9.2422295e-01
  8.2205510e-01 5.4161162e-03 3.1062899e-02]
 [1.2240199e-03 5.2645471e-04 2.0867705e-02 3.8433576e-01 9.6363360e-01
  9.2781484e-01 1.7361647e-03 7.8690154e-03]
 [1.4929575e-04 4.2441135e-04 1.8897649e-02 3.6285475e-01 9.7410494e-01
  9.6418321e-01 2.6428124e-03 1.8420262e-03]
 [7.6947594e-04 2.2005842e-03 5.8896270e-02 3.1547314e-01 9.1053224e-01
  9.1665983e-01 1.7355818e-02 4.1453303e-03]
 [1.0175814e-03 2.4396577e-03 1.5839680e-01 3.1635144e-01 8.9512134e-01
  9.1027665e-01 2.5292601e-02 4.5944043e-03]
 [2.5579627e-03 3.7543469e-03 1.1934384e-01 3.1981459e-01 8.9690632e-01
  8.7952292e-01 2.8965294e-02 3.1460419e-02]
 [2.6978473e-03 2.7209569e-03 7.9843581e-02 3.3581379e-01 9.1469324e-01
  9.2188239e-01 8.3464310e-03 4.3304712e-02]
 [4.7104578e-03 1.0967770e-03 8.4820986e-02 3.6017862e-01 9.2500812e-01
  8.8095284e-01 4.2647580e-03 2.9378565e-02]
 [7.1348011e-04 4.4004191e-04 3.0999370e-02 3.5175836e-01 9.6272701e-01
  9.3729872e-01 2.3995156e-03 1.9023895e-02]
 [2.2553038e-03 2.5424350e-03 1.1127411e-01 3.3025023e-01 8.8776726e-01
  8.9422667e-01 1.6312445e-02 4.1066539e-03]
 [1.4926298e-03 2.9359886e-03 9.3326218e-02 3.2717115e-01 8.9770895e-01
  9.0064019e-01 2.1490972e-02 1.3174974e-02]
 [1.5107041e-03 2.0523474e-03 9.5494010e-02 3.3738461e-01 9.2722279e-01
  9.1393924e-01 1.1943445e-02 1.7498167e-02]
 [1.1901819e-02 6.3105631e-03 1.6813669e-01 3.3818257e-01 8.2802683e-01
  8.0480176e-01 2.8854541e-02 5.6880821e-02]
 [4.8656974e-04 4.9584708e-04 2.2982253e-02 3.7494236e-01 9.7660738e-01
  9.6640778e-01 1.5409773e-03 2.7005786e-02]
 [2.8269526e-04 2.0795723e-04 4.0939432e-02 3.5175139e-01 9.7653824e-01
  9.6725202e-01 1.7608955e-03 5.0770133e-03]
 [5.8964675e-04 8.6425070e-04 2.7468361e-02 3.3360696e-01 9.6270192e-01
  9.3491572e-01 5.0069597e-03 3.6101326e-02]
 [1.3166906e-04 1.7531075e-04 9.1047231e-03 3.7257710e-01 9.9026978e-01
  9.8110479e-01 4.8532675e-04 1.6570473e-02]
 [1.1990733e-03 4.5373730e-04 3.6882598e-02 3.7046337e-01 9.5895672e-01
  9.2081821e-01 1.9383139e-03 1.8013155e-02]
 [4.0190859e-04 3.9290008e-04 1.1150237e-02 3.3879277e-01 9.7326851e-01
  9.4174957e-01 1.2575430e-03 2.5314521e-02]
 [1.4330454e-04 1.0163575e-04 6.8720100e-03 3.7121403e-01 9.8837858e-01
  9.6812135e-01 3.1470277e-04 7.9183867e-03]
 [1.0211331e-04 2.7327056e-04 1.9649675e-02 3.5031298e-01 9.7501206e-01
  9.6420270e-01 2.2529371e-03 2.1085609e-03]
 [9.6476491e-05 5.1518588e-04 1.9797638e-02 3.0669299e-01 9.7154981e-01
  9.6880990e-01 3.9684549e-03 4.6320590e-03]
 [3.9941939e-03 5.6543807e-03 1.3212934e-01 2.9425359e-01 8.3543515e-01
  8.7363279e-01 3.4155127e-02 9.7933281e-03]
 [9.5279021e-03 8.3008371e-03 2.3267396e-01 3.0513164e-01 8.0072165e-01
  8.5620749e-01 5.0425895e-02 1.4169782e-02]
 [4.9054738e-02 2.4274461e-02 3.6145446e-01 2.9738310e-01 6.3155651e-01
  7.2340208e-01 1.1811011e-01 3.3232950e-02]
 [6.4076252e-02 2.3819890e-02 3.2599720e-01 3.1449813e-01 6.6535366e-01
  7.1884549e-01 9.6234687e-02 4.8283409e-02]
 [1.3934138e-02 5.4059182e-03 1.3276319e-01 3.3711532e-01 8.7901038e-01
  8.6193132e-01 2.0047832e-02 4.0427797e-02]
 [1.5946487e-02 7.2439443e-03 1.1692226e-01 3.4547248e-01 8.4668946e-01
  8.0950117e-01 2.8630322e-02 5.0953660e-02]
 [7.3089167e-03 3.5687925e-03 6.9470689e-02 3.3863086e-01 9.0829134e-01
  8.7320697e-01 1.1803006e-02 4.0285666e-02]]
2022-12-18 23:53:04,145 INFO Evaluating teacher test iter15 on 32 examples
2022-12-18 23:53:04,146 INFO teacher test iter15 performance: 1.36
2022-12-18 23:53:04,147 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:04,152 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9197351932525635
2022-12-18 23:53:04,152 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:05,089 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:05,926 INFO Predicting labels for 18 texts
2022-12-18 23:53:06,041 INFO Evaluating student dev iter15 on 18 examples
2022-12-18 23:53:06,042 INFO student dev iter15 performance: 14.62
2022-12-18 23:53:06,042 INFO Predicting labels for 32 texts
2022-12-18 23:53:06,160 INFO Evaluating student test iter15 on 32 examples
2022-12-18 23:53:06,161 INFO student test iter15 performance: 0.66
2022-12-18 23:53:06,161 INFO Student Dev performance on iter 15: 14.615251422068834
2022-12-18 23:53:06,161 INFO Student Test performance on iter 15: 0.6595310002655571
2022-12-18 23:53:06,161 INFO 

	 *** Starting loop 16 ***
2022-12-18 23:53:06,161 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:06,161 INFO Getting rule predictions
2022-12-18 23:53:06,161 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:06,161 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:06,162 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:06,162 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:06,162 INFO Predicting labels for 247 texts
2022-12-18 23:53:06,280 INFO Predicting labels for 18 texts
2022-12-18 23:53:06,396 INFO Predicting labels for 444 texts
2022-12-18 23:53:06,512 INFO Training Rule Attention Network
2022-12-18 23:53:06,514 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:06,514 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:06,516 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:06,516 INFO 

		*** Training RAN ***
2022-12-18 23:53:07,708 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:07,709 INFO Predicting labels for 444 texts
2022-12-18 23:53:07,816 INFO There are 3/7 active rules
2022-12-18 23:53:07,816 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:07,819 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:07,892 INFO DONE, Getting attention scores...
2022-12-18 23:53:07,957 INFO the attention scores are
2022-12-18 23:53:07,957 INFO [[6.2365526e-18 9.9835312e-01 2.3388881e-03 ... 2.3388881e-03
  2.3388881e-03 2.3388881e-03]
 [8.8559181e-18 9.9802232e-01 2.6354264e-03 ... 2.6354264e-03
  2.6354264e-03 2.6354264e-03]
 [1.3992613e-09 6.4084530e-03 2.9486755e-02 ... 2.9486755e-02
  2.9486755e-02 2.9486755e-02]
 ...
 [8.1408151e-21 6.1207795e-01 9.8142889e-09 ... 4.2613149e-03
  4.2613149e-03 4.2613149e-03]
 [3.3794671e-19 4.4755254e-02 1.3514725e-12 ... 5.6980032e-01
  5.6980032e-01 5.6980032e-01]
 [9.2861992e-18 3.5523050e-02 7.7651329e-13 ... 6.9201815e-01
  6.9201815e-01 6.9201815e-01]]
2022-12-18 23:53:07,958 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:07,959 INFO Predicting labels for 18 texts
2022-12-18 23:53:08,081 INFO There are 7/7 active rules
2022-12-18 23:53:08,081 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:08,081 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:08,108 INFO DONE, Getting attention scores...
2022-12-18 23:53:08,162 INFO the attention scores are
2022-12-18 23:53:08,162 INFO [[3.7642086e-03 3.0364706e-03 3.6732379e-02 3.5446590e-01 8.6454922e-01
  9.2382580e-01 1.0709524e-02 1.9984910e-02]
 [1.3825353e-03 1.4896848e-03 1.6945634e-02 3.5634628e-01 9.0479296e-01
  9.4807315e-01 5.7136901e-03 1.3372519e-02]
 [9.0139528e-04 1.4748793e-03 1.5964305e-02 3.6554784e-01 8.9664692e-01
  9.4524926e-01 6.0183164e-03 9.0564024e-03]
 [1.7768566e-03 4.4232095e-03 4.1990694e-02 3.6270675e-01 7.9563642e-01
  9.0220714e-01 2.1255204e-02 6.8475702e-03]
 [1.1056303e-03 2.9419074e-03 3.0772958e-02 3.5084379e-01 8.2169181e-01
  9.1843784e-01 1.5951432e-02 1.0484475e-02]
 [4.4049346e-03 8.2801143e-03 8.6155251e-02 3.2795635e-01 7.0551723e-01
  8.5305589e-01 3.8819794e-02 1.4250866e-02]
 [8.0202594e-03 7.8942291e-03 9.6508913e-02 3.3304062e-01 7.3884976e-01
  8.6605752e-01 3.2425176e-02 2.6141230e-02]
 [4.5283092e-03 3.7232810e-03 5.1525090e-02 3.3955044e-01 8.4246874e-01
  9.1926402e-01 1.4354885e-02 2.2898689e-02]
 [6.6394877e-32 9.9998999e-01 8.1626272e-01 2.6857924e-08 1.4912017e-01
  1.7220860e-07 1.0000000e+00 1.5123765e-35]
 [5.7962109e-33 9.9999988e-01 1.1088808e-06 2.8558663e-08 1.0000000e+00
  7.5935766e-02 1.0000000e+00 0.0000000e+00]
 [1.6386048e-26 9.9999893e-01 2.3700394e-13 1.0952597e-02 1.0000000e+00
  1.1802549e-05 1.0000000e+00 1.8832977e-26]
 [9.1438138e-15 2.1235355e-11 2.1669377e-06 9.2540035e-04 1.4195816e-01
  3.7347671e-01 1.0000000e+00 2.8466355e-17]
 [3.0919989e-24 2.5502380e-17 1.7099609e-26 7.9021309e-05 1.0000000e+00
  1.0000000e+00 1.4583859e-16 9.9999583e-01]
 [7.7493376e-15 1.6324757e-10 7.0307611e-14 5.4865549e-03 1.0000000e+00
  1.0000000e+00 3.6830075e-12 6.8555290e-01]
 [8.6075245e-09 4.6607510e-12 3.3643527e-08 5.5442430e-02 9.9999893e-01
  9.9999774e-01 2.5000862e-10 5.6066667e-04]
 [1.4755398e-13 7.6285600e-10 1.0360722e-07 2.6922849e-01 9.9996960e-01
  9.9997222e-01 2.4029831e-07 1.3630738e-06]
 [3.2559928e-13 2.1009374e-08 3.2183260e-07 2.7713498e-01 9.9996293e-01
  9.9998939e-01 2.7478274e-08 2.7025915e-06]
 [8.2356326e-09 2.0905622e-06 1.4836875e-04 2.5024122e-01 9.9777406e-01
  9.9981278e-01 4.7214828e-05 1.9786987e-05]]
2022-12-18 23:53:08,165 INFO Evaluating teacher dev iter16 on 18 examples
2022-12-18 23:53:08,166 INFO teacher dev iter16 performance: 12.45
2022-12-18 23:53:08,166 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:08,166 INFO Predicting labels for 32 texts
2022-12-18 23:53:08,280 INFO There are 7/7 active rules
2022-12-18 23:53:08,280 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:08,280 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:08,304 INFO DONE, Getting attention scores...
2022-12-18 23:53:08,356 INFO the attention scores are
2022-12-18 23:53:08,356 INFO [[2.49983714e-11 2.44843322e-05 4.14548812e-10 3.89506022e-04
  9.99851465e-01 9.94740844e-01 9.99416828e-01 2.00576505e-06]
 [4.32900008e-04 4.00230329e-06 3.87989485e-06 5.31206187e-03
  9.97829139e-01 9.99908209e-01 2.50109355e-03 9.90027487e-01]
 [8.04421119e-03 2.63531599e-03 5.70050208e-04 4.09432314e-02
  9.82071102e-01 9.77373958e-01 5.69503987e-03 9.13091004e-01]
 [4.56220796e-03 1.65522285e-03 4.24783006e-02 3.91685098e-01
  7.94542015e-01 8.85337651e-01 7.82903843e-03 9.45274159e-03]
 [6.25759596e-04 8.52022087e-04 1.89190544e-02 3.96716326e-01
  9.02240396e-01 9.52905238e-01 2.54554208e-03 2.42053275e-03]
 [1.14527385e-04 8.29375349e-04 1.80047899e-02 3.76566768e-01
  9.36374068e-01 9.70033467e-01 2.48187082e-03 1.37230393e-03]
 [7.18352792e-04 3.49732116e-03 4.77354825e-02 3.18756819e-01
  8.43333662e-01 9.26742315e-01 1.41108530e-02 6.21667132e-03]
 [8.91174655e-04 2.98143248e-03 1.08758643e-01 3.28726888e-01
  8.40370595e-01 9.25922334e-01 1.75817665e-02 6.46197749e-03]
 [2.58628861e-03 3.62366997e-03 8.05594400e-02 3.22870404e-01
  8.67646873e-01 9.03711379e-01 1.69221777e-02 3.98433469e-02]
 [2.18583224e-03 1.96701428e-03 4.42661420e-02 3.55000675e-01
  9.26118672e-01 9.59593058e-01 5.11571625e-03 3.06983907e-02]
 [3.21541587e-03 1.02897326e-03 5.17723560e-02 3.80482972e-01
  8.92733216e-01 9.39375460e-01 3.92781431e-03 2.14726757e-02]
 [5.08855679e-04 5.30007645e-04 1.63973402e-02 3.67785633e-01
  9.44160342e-01 9.65191066e-01 1.98431220e-03 1.68534443e-02]
 [2.01144558e-03 3.43750115e-03 8.89087394e-02 3.35075438e-01
  8.12717259e-01 9.12645221e-01 1.30574685e-02 6.19235635e-03]
 [1.45202328e-03 3.86282592e-03 7.20342919e-02 3.29236388e-01
  8.38993192e-01 9.13308680e-01 1.75254699e-02 1.48438467e-02]
 [1.32714666e-03 2.65562185e-03 7.16881454e-02 3.53047788e-01
  8.85962069e-01 9.34158385e-01 9.32726823e-03 1.68897007e-02]
 [8.75863433e-03 6.23390265e-03 1.27060398e-01 3.36331218e-01
  7.94221103e-01 8.62401843e-01 2.22240966e-02 4.30576131e-02]
 [3.87964770e-04 5.12382190e-04 1.29808905e-02 4.23166275e-01
  9.74380910e-01 9.85632896e-01 1.29685388e-03 1.78625789e-02]
 [2.01793795e-04 2.51933903e-04 2.79662963e-02 3.99677992e-01
  9.61463034e-01 9.81518507e-01 1.57305598e-03 4.08568652e-03]
 [4.08945605e-04 1.01936783e-03 1.44775063e-02 3.41233253e-01
  9.50402617e-01 9.60989594e-01 3.59561620e-03 3.23569030e-02]
 [9.07336726e-05 2.21828654e-04 5.80803072e-03 4.19601589e-01
  9.86255288e-01 9.92515147e-01 4.13929607e-04 9.15406086e-03]
 [8.32344696e-04 5.80062682e-04 2.21395865e-02 3.89324486e-01
  9.32352781e-01 9.58881915e-01 2.01705191e-03 1.34537872e-02]
 [2.10184284e-04 5.79844636e-04 7.43042585e-03 3.43556732e-01
  9.62454736e-01 9.73639131e-01 1.10212550e-03 1.43723143e-02]
 [6.80021403e-05 1.70235464e-04 4.94897924e-03 3.93268645e-01
  9.76925611e-01 9.86386180e-01 3.33342643e-04 3.64466710e-03]
 [7.96755121e-05 4.38782969e-04 1.42605286e-02 3.62206489e-01
  9.44532454e-01 9.73057806e-01 2.02546641e-03 2.10710755e-03]
 [7.96043532e-05 8.22846428e-04 1.56966262e-02 3.22877407e-01
  9.40941274e-01 9.75229383e-01 2.99716857e-03 4.62652883e-03]
 [3.53441318e-03 6.59754872e-03 1.07817821e-01 2.96282828e-01
  7.46963143e-01 8.88199389e-01 2.42981147e-02 1.32975345e-02]
 [9.58211720e-03 9.23877303e-03 1.81543797e-01 3.07910562e-01
  7.21418798e-01 8.70526910e-01 3.66332345e-02 2.02827379e-02]
 [3.24891172e-02 2.12021917e-02 2.86349803e-01 2.95692027e-01
  5.86818933e-01 7.69112170e-01 8.15904737e-02 3.40516679e-02]
 [4.06396501e-02 1.96569748e-02 2.80253291e-01 3.07926983e-01
  6.06361985e-01 7.84469962e-01 7.03850389e-02 4.18408401e-02]
 [1.08658439e-02 5.49391797e-03 1.04636744e-01 3.48810852e-01
  8.29429507e-01 9.11437750e-01 1.91620961e-02 3.16249095e-02]
 [1.10644773e-02 7.67273689e-03 1.09046601e-01 3.46149474e-01
  7.77828753e-01 8.73031139e-01 2.90934313e-02 3.41623053e-02]
 [5.05952071e-03 3.95123893e-03 6.11500740e-02 3.49181443e-01
  8.56267095e-01 9.25821364e-01 1.27219241e-02 2.50949971e-02]]
2022-12-18 23:53:08,362 INFO Evaluating teacher test iter16 on 32 examples
2022-12-18 23:53:08,363 INFO teacher test iter16 performance: 1.32
2022-12-18 23:53:08,363 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:08,368 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9370384216308594
2022-12-18 23:53:08,369 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:09,148 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:10,996 INFO Predicting labels for 18 texts
2022-12-18 23:53:11,106 INFO Evaluating student dev iter16 on 18 examples
2022-12-18 23:53:11,107 INFO student dev iter16 performance: 14.63
2022-12-18 23:53:11,107 INFO Predicting labels for 32 texts
2022-12-18 23:53:11,325 INFO Evaluating student test iter16 on 32 examples
2022-12-18 23:53:11,326 INFO student test iter16 performance: 0.67
2022-12-18 23:53:11,326 INFO Student Dev performance on iter 16: 14.632777300789396
2022-12-18 23:53:11,326 INFO Student Test performance on iter 16: 0.6686337881977789
2022-12-18 23:53:11,327 INFO 

	 *** Starting loop 17 ***
2022-12-18 23:53:11,327 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:11,327 INFO Getting rule predictions
2022-12-18 23:53:11,327 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:11,327 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:11,327 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:11,328 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:11,328 INFO Predicting labels for 247 texts
2022-12-18 23:53:11,441 INFO Predicting labels for 18 texts
2022-12-18 23:53:12,580 INFO Predicting labels for 444 texts
2022-12-18 23:53:12,694 INFO Training Rule Attention Network
2022-12-18 23:53:12,696 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:12,696 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:12,699 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:12,699 INFO 

		*** Training RAN ***
2022-12-18 23:53:13,857 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:13,858 INFO Predicting labels for 444 texts
2022-12-18 23:53:14,991 INFO There are 3/7 active rules
2022-12-18 23:53:14,991 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:14,994 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:15,068 INFO DONE, Getting attention scores...
2022-12-18 23:53:15,123 INFO the attention scores are
2022-12-18 23:53:15,123 INFO [[1.2276935e-19 9.9967420e-01 4.2522564e-03 ... 4.2522564e-03
  4.2522564e-03 4.2522564e-03]
 [1.9061077e-19 9.9963427e-01 5.0116703e-03 ... 5.0116703e-03
  5.0116703e-03 5.0116703e-03]
 [1.0678485e-10 4.3994758e-02 1.8676296e-02 ... 1.8676296e-02
  1.8676296e-02 1.8676296e-02]
 ...
 [1.8275462e-22 9.9186170e-01 8.2183718e-09 ... 2.3794568e-03
  2.3794568e-03 2.3794568e-03]
 [4.7625542e-21 7.8400964e-01 3.9739319e-13 ... 3.6667088e-01
  3.6667088e-01 3.6667088e-01]
 [1.6412505e-19 6.7617130e-01 3.1736595e-13 ... 4.6501920e-01
  4.6501920e-01 4.6501920e-01]]
2022-12-18 23:53:15,124 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:15,125 INFO Predicting labels for 18 texts
2022-12-18 23:53:15,237 INFO There are 7/7 active rules
2022-12-18 23:53:15,237 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:15,238 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:15,261 INFO DONE, Getting attention scores...
2022-12-18 23:53:15,319 INFO the attention scores are
2022-12-18 23:53:15,319 INFO [[4.95126657e-03 2.70146388e-03 3.57333459e-02 3.66211653e-01
  8.89076293e-01 9.26976204e-01 6.82270713e-03 2.26209182e-02]
 [1.72476028e-03 1.27493148e-03 1.65496916e-02 3.69197607e-01
  9.27201271e-01 9.53488171e-01 3.47043318e-03 1.56128313e-02]
 [1.12474454e-03 1.23291044e-03 1.50241097e-02 3.77652168e-01
  9.19322789e-01 9.49878752e-01 3.68922134e-03 1.03731044e-02]
 [2.15056143e-03 4.04574210e-03 6.11059405e-02 3.63153696e-01
  7.76385784e-01 8.87813389e-01 2.28097606e-02 3.80781735e-03]
 [1.15809625e-03 2.49569025e-03 3.89674194e-02 3.61334205e-01
  8.32675457e-01 9.18976426e-01 1.53257707e-02 7.36061484e-03]
 [6.52233837e-03 8.05222429e-03 1.14408165e-01 3.33731323e-01
  6.92202985e-01 8.11938465e-01 4.02924940e-02 1.28716156e-02]
 [1.21428790e-02 7.82867521e-03 1.13913223e-01 3.41966063e-01
  7.33629286e-01 8.45210254e-01 3.25667150e-02 2.32607182e-02]
 [5.51004196e-03 3.43329716e-03 5.13632186e-02 3.56048912e-01
  8.63308847e-01 9.24972892e-01 9.94054228e-03 2.58741733e-02]
 [4.83979172e-34 9.99999762e-01 8.90192628e-01 1.38506977e-07
  1.48400515e-01 5.28034612e-08 1.00000000e+00 5.40036214e-38]
 [5.56973502e-35 1.00000000e+00 2.37985387e-06 4.02773549e-06
  9.99999881e-01 7.13519799e-03 1.00000000e+00 0.00000000e+00]
 [1.91233950e-29 1.00000000e+00 4.39953900e-13 5.63015938e-01
  9.99999642e-01 9.61114665e-07 1.00000000e+00 1.18609268e-25]
 [5.93953532e-16 1.73689074e-09 5.39139455e-06 3.95493396e-03
  9.70572114e-01 9.73724008e-01 1.00000000e+00 1.58972811e-13]
 [1.49989366e-25 8.65337420e-19 1.57973624e-27 3.71720461e-07
  1.00000000e+00 1.00000000e+00 1.40068602e-18 1.00000000e+00]
 [1.45913378e-13 1.15434311e-12 1.44910956e-14 4.87413694e-04
  1.00000000e+00 1.00000000e+00 6.78839478e-15 9.81065214e-01]
 [1.42812047e-08 9.48003937e-13 2.27075714e-09 3.02109290e-02
  9.99999881e-01 9.99999404e-01 3.93938736e-11 1.58288074e-03]
 [7.62090993e-14 6.35085540e-10 2.96886657e-08 3.20370972e-01
  9.99990225e-01 9.99994397e-01 7.92914179e-08 4.91100252e-07]
 [1.37546184e-13 2.40462370e-08 1.28858034e-07 3.27362210e-01
  9.99980569e-01 9.99998808e-01 6.17902529e-09 9.70324436e-07]
 [1.88663973e-09 2.22362223e-06 1.79528477e-04 2.79877871e-01
  9.98588622e-01 9.99928474e-01 2.82752208e-05 4.93400466e-06]]
2022-12-18 23:53:15,322 INFO Evaluating teacher dev iter17 on 18 examples
2022-12-18 23:53:15,322 INFO teacher dev iter17 performance: 13.30
2022-12-18 23:53:15,323 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:15,323 INFO Predicting labels for 32 texts
2022-12-18 23:53:15,430 INFO There are 7/7 active rules
2022-12-18 23:53:15,430 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:15,430 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:15,455 INFO DONE, Getting attention scores...
2022-12-18 23:53:15,512 INFO the attention scores are
2022-12-18 23:53:15,512 INFO [[9.72601448e-13 2.92393292e-04 9.57728202e-11 1.43477082e-04
  9.99999642e-01 9.99916792e-01 9.97968614e-01 1.66222057e-03]
 [5.56115046e-05 2.52139534e-06 2.08497750e-06 5.13731677e-04
  9.99994159e-01 9.99999046e-01 3.86149914e-04 9.99948263e-01]
 [6.53215637e-03 6.75272779e-04 2.26452074e-04 1.23273488e-02
  9.98820722e-01 9.97658372e-01 2.50783702e-03 9.94511843e-01]
 [1.02398610e-02 1.58226001e-03 2.65742950e-02 3.91955644e-01
  9.18552458e-01 9.15705740e-01 3.94938141e-03 3.07888426e-02]
 [9.50123707e-04 9.79478122e-04 2.04634741e-02 4.09654915e-01
  9.35347378e-01 9.69626606e-01 1.42085354e-03 4.17057332e-03]
 [9.37551013e-05 8.42432783e-04 1.82110909e-02 3.94250035e-01
  9.34677362e-01 9.80827093e-01 1.83686684e-03 9.60812729e-04]
 [5.79121639e-04 3.80565645e-03 6.30470812e-02 3.38826150e-01
  8.09522569e-01 9.41817999e-01 1.19109247e-02 3.15884803e-03]
 [6.40351151e-04 3.53276241e-03 1.26545832e-01 3.46067101e-01
  8.21067393e-01 9.46976125e-01 1.50975594e-02 2.95643089e-03]
 [1.91069243e-03 3.89749114e-03 7.86008462e-02 3.48857045e-01
  8.78518462e-01 9.33353186e-01 1.34949312e-02 2.52180491e-02]
 [3.45872948e-03 2.01659510e-03 4.22375090e-02 3.72141242e-01
  9.31295693e-01 9.67721641e-01 2.95400713e-03 3.77896652e-02]
 [4.00557276e-03 1.10968482e-03 4.86969203e-02 3.93288076e-01
  9.09409404e-01 9.52498555e-01 2.61247740e-03 2.20993329e-02]
 [5.47773670e-04 5.28267119e-04 1.55087374e-02 3.77574593e-01
  9.53220367e-01 9.77256656e-01 1.30309840e-03 1.15464646e-02]
 [1.72935019e-03 3.92544968e-03 1.22007258e-01 3.45400482e-01
  7.76932180e-01 9.30210650e-01 1.15414476e-02 2.77980254e-03]
 [1.16057601e-03 4.17576870e-03 7.94791803e-02 3.49047482e-01
  8.29479873e-01 9.34302509e-01 1.49424532e-02 8.82671494e-03]
 [1.14520185e-03 2.77192355e-03 6.84908852e-02 3.77067894e-01
  8.92781615e-01 9.57475424e-01 6.73083961e-03 1.23518016e-02]
 [1.17170541e-02 6.67761732e-03 1.26872703e-01 3.53868663e-01
  7.90912986e-01 8.78916383e-01 1.66030470e-02 4.63159196e-02]
 [5.99019229e-04 4.63593751e-04 9.88548249e-03 4.36023414e-01
  9.79816198e-01 9.90539908e-01 6.10100746e-04 2.15169135e-02]
 [2.20189220e-04 2.51998543e-04 1.64613575e-02 4.02785599e-01
  9.70891595e-01 9.88197744e-01 9.36161086e-04 2.88470648e-03]
 [4.52683831e-04 9.37276171e-04 1.06717711e-02 3.63062352e-01
  9.60330963e-01 9.74619806e-01 2.17736629e-03 2.94589605e-02]
 [1.58050694e-04 2.07878722e-04 4.55763238e-03 4.41811800e-01
  9.90002632e-01 9.95575190e-01 1.71336287e-04 1.17530320e-02]
 [9.41171602e-04 6.03664201e-04 2.22187042e-02 4.00348902e-01
  9.43789184e-01 9.71706808e-01 1.33237604e-03 1.00117326e-02]
 [3.66695778e-04 5.19948255e-04 4.28633951e-03 3.59780073e-01
  9.71569300e-01 9.83031511e-01 5.38008171e-04 1.70532279e-02]
 [1.33792404e-04 1.82933145e-04 4.57661832e-03 4.12325948e-01
  9.79862988e-01 9.91069317e-01 1.71318650e-04 4.05222410e-03]
 [6.12268268e-05 4.63949196e-04 1.58101171e-02 3.73199493e-01
  9.41527843e-01 9.81869400e-01 1.62860088e-03 1.22586160e-03]
 [5.06188335e-05 7.50031904e-04 1.41731650e-02 3.49980414e-01
  9.45891738e-01 9.85720456e-01 1.97221385e-03 2.56492035e-03]
 [3.07836989e-03 6.90014148e-03 1.35110497e-01 3.15504551e-01
  7.13828683e-01 9.05171990e-01 2.01238804e-02 6.47590915e-03]
 [6.98181940e-03 9.87039506e-03 2.12647960e-01 3.22678387e-01
  7.09315538e-01 8.95628214e-01 3.22529636e-02 9.72610991e-03]
 [3.57575715e-02 2.47750953e-02 3.35532993e-01 3.11232626e-01
  5.46221495e-01 7.65226007e-01 8.10687393e-02 2.53207255e-02]
 [5.58223091e-02 2.29208525e-02 3.13494295e-01 3.21276993e-01
  5.84276736e-01 7.67969787e-01 6.45104200e-02 3.88282128e-02]
 [1.00411950e-02 5.39510418e-03 1.10647954e-01 3.64981443e-01
  8.49605262e-01 9.26475585e-01 1.41358580e-02 2.66847126e-02]
 [1.27098849e-02 7.07990676e-03 1.14306770e-01 3.62272561e-01
  7.85456121e-01 8.75276148e-01 2.29168329e-02 3.52802649e-02]
 [5.98859554e-03 3.54636880e-03 5.91004081e-02 3.67712259e-01
  8.74440730e-01 9.35032666e-01 8.43841024e-03 2.76164953e-02]]
2022-12-18 23:53:15,517 INFO Evaluating teacher test iter17 on 32 examples
2022-12-18 23:53:15,518 INFO teacher test iter17 performance: 1.41
2022-12-18 23:53:15,518 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:15,523 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.906617283821106
2022-12-18 23:53:15,523 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:16,311 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:17,207 INFO Predicting labels for 18 texts
2022-12-18 23:53:17,320 INFO Evaluating student dev iter17 on 18 examples
2022-12-18 23:53:17,321 INFO student dev iter17 performance: 14.64
2022-12-18 23:53:17,322 INFO Predicting labels for 32 texts
2022-12-18 23:53:17,429 INFO Evaluating student test iter17 on 32 examples
2022-12-18 23:53:17,430 INFO student test iter17 performance: 0.68
2022-12-18 23:53:17,430 INFO Student Dev performance on iter 17: 14.64072645650085
2022-12-18 23:53:17,430 INFO Student Test performance on iter 17: 0.675702780662528
2022-12-18 23:53:17,430 INFO 

	 *** Starting loop 18 ***
2022-12-18 23:53:17,430 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:17,430 INFO Getting rule predictions
2022-12-18 23:53:17,430 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:17,431 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:17,431 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:17,432 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:17,432 INFO Predicting labels for 247 texts
2022-12-18 23:53:17,539 INFO Predicting labels for 18 texts
2022-12-18 23:53:17,642 INFO Predicting labels for 444 texts
2022-12-18 23:53:17,755 INFO Training Rule Attention Network
2022-12-18 23:53:17,756 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:17,757 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:17,759 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:17,759 INFO 

		*** Training RAN ***
2022-12-18 23:53:18,895 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:18,896 INFO Predicting labels for 444 texts
2022-12-18 23:53:19,007 INFO There are 3/7 active rules
2022-12-18 23:53:19,008 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:19,115 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:19,186 INFO DONE, Getting attention scores...
2022-12-18 23:53:19,241 INFO the attention scores are
2022-12-18 23:53:19,241 INFO [[3.04380073e-20 9.99823034e-01 2.28747446e-03 ... 2.28747446e-03
  2.28747446e-03 2.28747446e-03]
 [4.54829622e-20 9.99790609e-01 2.66021187e-03 ... 2.66021187e-03
  2.66021187e-03 2.66021187e-03]
 [4.10969897e-10 1.29731896e-03 1.50546720e-02 ... 1.50546720e-02
  1.50546720e-02 1.50546720e-02]
 ...
 [8.78282265e-23 3.37769151e-01 5.47846241e-07 ... 3.48753674e-04
  3.48753674e-04 3.48753674e-04]
 [1.49000884e-20 1.87628921e-05 4.56845109e-12 ... 2.01704577e-01
  2.01704577e-01 2.01704577e-01]
 [5.31145855e-19 1.12759735e-05 2.51126225e-12 ... 2.75136411e-01
  2.75136411e-01 2.75136411e-01]]
2022-12-18 23:53:19,243 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:19,243 INFO Predicting labels for 18 texts
2022-12-18 23:53:20,375 INFO There are 7/7 active rules
2022-12-18 23:53:20,375 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:20,375 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:20,399 INFO DONE, Getting attention scores...
2022-12-18 23:53:20,457 INFO the attention scores are
2022-12-18 23:53:20,457 INFO [[7.1190845e-04 1.6985864e-03 2.7851032e-02 3.6286730e-01 8.9067209e-01
  9.1738522e-01 4.6043792e-03 1.0407155e-02]
 [2.0616852e-04 6.8892015e-04 1.2099839e-02 3.7055349e-01 9.2513764e-01
  9.4603056e-01 2.2422823e-03 6.7372215e-03]
 [1.6028472e-04 6.5532367e-04 1.0753240e-02 3.7683800e-01 9.1394562e-01
  9.4036007e-01 2.4902439e-03 4.9641007e-03]
 [6.7257747e-04 2.3208440e-03 4.1311059e-02 3.7418312e-01 7.7009684e-01
  8.5794604e-01 1.6427908e-02 4.7259736e-03]
 [2.8814512e-04 1.2835340e-03 2.7041901e-02 3.7268478e-01 8.2634807e-01
  9.0088916e-01 1.0986704e-02 6.6212080e-03]
 [1.7521014e-03 5.0406456e-03 9.1237992e-02 3.4677517e-01 6.9584650e-01
  8.0347896e-01 3.3549532e-02 9.6774986e-03]
 [2.3202421e-03 5.1021851e-03 9.2391141e-02 3.4735909e-01 7.6077950e-01
  8.3844393e-01 2.4634138e-02 1.4807449e-02]
 [8.2877139e-04 2.1129970e-03 4.2567965e-02 3.5645178e-01 8.7089521e-01
  9.1701317e-01 6.9559980e-03 1.2066773e-02]
 [1.6908634e-35 9.9999988e-01 9.4897634e-01 4.9639420e-10 8.8944393e-01
  3.5336086e-06 1.0000000e+00 0.0000000e+00]
 [5.7039624e-38 1.0000000e+00 5.0427036e-05 1.0687445e-07 1.0000000e+00
  9.3975610e-01 1.0000000e+00 0.0000000e+00]
 [2.1200316e-29 9.9999928e-01 4.5504841e-12 5.3949788e-04 1.0000000e+00
  5.6925863e-03 1.0000000e+00 2.8506915e-30]
 [1.5992456e-15 7.8196862e-15 3.3991477e-05 6.1584710e-06 9.6614212e-01
  9.9576110e-01 1.0000000e+00 1.2266648e-17]
 [1.5530613e-29 3.5464515e-26 4.0178067e-29 1.2522912e-05 1.0000000e+00
  1.0000000e+00 7.6980306e-18 1.0000000e+00]
 [6.4102432e-18 4.3376134e-13 1.9053555e-15 8.7531627e-04 1.0000000e+00
  1.0000000e+00 8.5507171e-15 1.6431414e-01]
 [6.9152572e-13 1.4893046e-12 3.2070224e-10 5.6130879e-02 9.9999869e-01
  9.9999857e-01 2.3213022e-12 3.4624353e-04]
 [1.2688046e-15 3.7560656e-11 2.0692296e-08 4.6830010e-01 9.9999022e-01
  9.9999595e-01 8.3281675e-09 1.8110806e-07]
 [1.0218493e-15 6.1474852e-09 7.9959207e-08 2.9858291e-01 9.9997938e-01
  9.9999785e-01 1.2191963e-09 1.0545721e-07]
 [7.6142523e-11 2.9631505e-07 7.7384168e-05 3.0105659e-01 9.9804461e-01
  9.9991930e-01 9.7729071e-06 2.5244558e-06]]
2022-12-18 23:53:20,459 INFO Evaluating teacher dev iter18 on 18 examples
2022-12-18 23:53:20,460 INFO teacher dev iter18 performance: 20.53
2022-12-18 23:53:20,461 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:20,461 INFO Predicting labels for 32 texts
2022-12-18 23:53:21,611 INFO There are 7/7 active rules
2022-12-18 23:53:21,611 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:21,612 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:21,638 INFO DONE, Getting attention scores...
2022-12-18 23:53:21,706 INFO the attention scores are
2022-12-18 23:53:21,706 INFO [[4.72057679e-12 3.85173893e-10 1.99598171e-10 1.03716013e-06
  9.99999166e-01 9.99996305e-01 9.99970436e-01 5.48651587e-06]
 [1.30430941e-04 1.18294777e-10 6.87353577e-07 1.23911028e-04
  9.99814570e-01 9.99997735e-01 1.51203526e-03 9.99027014e-01]
 [6.75332616e-04 7.16886061e-05 2.00377865e-04 1.94746871e-02
  9.95808840e-01 9.95795965e-01 1.00244174e-03 9.72444177e-01]
 [9.81832040e-04 1.42816547e-03 1.43793151e-02 4.17984009e-01
  9.44807351e-01 9.21447694e-01 1.93666888e-03 1.66733414e-02]
 [1.80179122e-04 6.05242443e-04 1.18273292e-02 4.27890480e-01
  9.49136615e-01 9.67776239e-01 6.94204937e-04 2.87291454e-03]
 [2.54924526e-05 4.82203264e-04 1.32686915e-02 4.05784130e-01
  9.41436827e-01 9.79334354e-01 8.83520930e-04 6.36079931e-04]
 [2.14552594e-04 2.52043130e-03 5.97070679e-02 3.39123785e-01
  8.38987827e-01 9.37176406e-01 6.83241105e-03 2.69439607e-03]
 [2.22212213e-04 2.19900184e-03 1.24659337e-01 3.51391077e-01
  8.52011442e-01 9.49542403e-01 9.85081028e-03 2.94589368e-03]
 [5.91046060e-04 2.52070487e-03 1.04335181e-01 3.43543261e-01
  8.82515848e-01 9.30032730e-01 9.04168095e-03 1.64558291e-02]
 [4.98805894e-04 1.68975466e-03 4.01100628e-02 3.64648700e-01
  9.43616569e-01 9.70763385e-01 1.84279960e-03 1.79754570e-02]
 [5.06283774e-04 7.35107169e-04 3.42908576e-02 4.12535191e-01
  9.30229306e-01 9.52246845e-01 1.51030999e-03 1.28890453e-02]
 [1.10664769e-04 3.31990013e-04 1.27919884e-02 4.00227040e-01
  9.60721850e-01 9.74900484e-01 7.16873910e-04 9.26091801e-03]
 [6.06496993e-04 2.77816923e-03 1.02150530e-01 3.63663107e-01
  8.24287534e-01 9.24100280e-01 7.69158825e-03 3.17655480e-03]
 [4.92940366e-04 2.63167662e-03 7.72692114e-02 3.49641323e-01
  8.52577567e-01 9.33452487e-01 9.87415202e-03 7.17787724e-03]
 [3.64840758e-04 1.97586534e-03 7.15362951e-02 3.76513451e-01
  8.99258912e-01 9.51429367e-01 4.26739547e-03 8.66657495e-03]
 [3.35513987e-03 4.98595182e-03 1.25050321e-01 3.57270092e-01
  8.22136879e-01 8.84156942e-01 1.23252124e-02 2.61598099e-02]
 [5.26121730e-05 3.43294611e-04 9.19889472e-03 4.30804133e-01
  9.83123422e-01 9.91598129e-01 3.47407215e-04 9.13154241e-03]
 [2.98982504e-05 1.63836245e-04 2.01192722e-02 4.53319877e-01
  9.73144770e-01 9.88493145e-01 4.92357824e-04 2.15975125e-03]
 [9.41775070e-05 6.17318321e-04 1.39360121e-02 3.68195415e-01
  9.62705910e-01 9.73638773e-01 1.26221450e-03 1.59236658e-02]
 [1.06523094e-05 1.55293019e-04 3.44088417e-03 4.40881670e-01
  9.92452562e-01 9.95967388e-01 8.99101869e-05 4.10383474e-03]
 [1.83334050e-04 3.73284973e-04 1.44539578e-02 4.21249539e-01
  9.55492735e-01 9.68697667e-01 7.04070029e-04 8.76753498e-03]
 [5.82519788e-05 3.70741065e-04 5.67129813e-03 3.60903740e-01
  9.73766029e-01 9.81737792e-01 3.09713039e-04 7.28865340e-03]
 [1.66756072e-05 1.16565679e-04 3.18215531e-03 4.30417359e-01
  9.83251929e-01 9.90371525e-01 8.47591291e-05 1.77699607e-03]
 [1.70918374e-05 2.41872578e-04 1.14824828e-02 3.99709195e-01
  9.50639009e-01 9.80608761e-01 7.78043352e-04 8.21586233e-04]
 [1.35641467e-05 4.12833528e-04 1.40402336e-02 3.53179932e-01
  9.45138931e-01 9.82766747e-01 1.06147234e-03 1.38654443e-03]
 [1.21885026e-03 5.27060358e-03 1.32901207e-01 3.18906248e-01
  7.65238523e-01 8.98838997e-01 1.47299003e-02 6.59142947e-03]
 [2.36055092e-03 7.26551097e-03 2.04082385e-01 3.33960921e-01
  7.65815616e-01 8.96742940e-01 2.53601186e-02 9.69650503e-03]
 [1.37167135e-02 1.88628733e-02 3.39286745e-01 3.17252845e-01
  6.17511034e-01 7.68032610e-01 6.75648600e-02 2.05922294e-02]
 [1.64626781e-02 2.06417385e-02 3.07941645e-01 3.27464253e-01
  6.56599879e-01 7.81759083e-01 5.53499535e-02 2.55186725e-02]
 [2.10078643e-03 3.64067964e-03 8.80148783e-02 3.71061713e-01
  8.68919790e-01 9.21398580e-01 9.69741121e-03 1.85215659e-02]
 [2.73553678e-03 4.71934117e-03 9.09602568e-02 3.65000635e-01
  8.18874955e-01 8.78766119e-01 1.67465806e-02 2.03464348e-02]
 [9.94641334e-04 2.31338455e-03 4.78651077e-02 3.65857422e-01
  8.85863483e-01 9.30085361e-01 5.79963904e-03 1.43281454e-02]]
2022-12-18 23:53:21,711 INFO Evaluating teacher test iter18 on 32 examples
2022-12-18 23:53:21,712 INFO teacher test iter18 performance: 1.41
2022-12-18 23:53:21,712 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:21,718 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9430432319641113
2022-12-18 23:53:21,718 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:22,555 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:23,391 INFO Predicting labels for 18 texts
2022-12-18 23:53:23,499 INFO Evaluating student dev iter18 on 18 examples
2022-12-18 23:53:23,500 INFO student dev iter18 performance: 14.64
2022-12-18 23:53:23,500 INFO Predicting labels for 32 texts
2022-12-18 23:53:23,611 INFO Evaluating student test iter18 on 32 examples
2022-12-18 23:53:23,612 INFO student test iter18 performance: 0.68
2022-12-18 23:53:23,613 INFO Student Dev performance on iter 18: 14.63880607297699
2022-12-18 23:53:23,613 INFO Student Test performance on iter 18: 0.6794045657361922
2022-12-18 23:53:23,613 INFO 

	 *** Starting loop 19 ***
2022-12-18 23:53:23,613 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:23,613 INFO Getting rule predictions
2022-12-18 23:53:23,613 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:23,613 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:23,613 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:23,614 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:23,614 INFO Predicting labels for 247 texts
2022-12-18 23:53:23,723 INFO Predicting labels for 18 texts
2022-12-18 23:53:23,825 INFO Predicting labels for 444 texts
2022-12-18 23:53:23,938 INFO Training Rule Attention Network
2022-12-18 23:53:23,940 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:23,940 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:23,942 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:23,942 INFO 

		*** Training RAN ***
2022-12-18 23:53:25,139 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:25,140 INFO Predicting labels for 444 texts
2022-12-18 23:53:25,254 INFO There are 3/7 active rules
2022-12-18 23:53:25,254 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:25,256 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:25,331 INFO DONE, Getting attention scores...
2022-12-18 23:53:25,387 INFO the attention scores are
2022-12-18 23:53:25,387 INFO [[1.5118624e-21 9.9999690e-01 8.4801335e-03 ... 8.4801335e-03
  8.4801335e-03 8.4801335e-03]
 [2.6200281e-21 9.9999619e-01 9.6953418e-03 ... 9.6953418e-03
  9.6953418e-03 9.6953418e-03]
 [6.9158318e-11 9.2249399e-01 4.1208725e-02 ... 4.1208725e-02
  4.1208725e-02 4.1208725e-02]
 ...
 [3.5130887e-24 1.0000000e+00 1.3378881e-06 ... 1.0763126e-02
  1.0763126e-02 1.0763126e-02]
 [1.3597817e-21 9.9999976e-01 2.2687301e-10 ... 9.2287642e-01
  9.2287642e-01 9.2287642e-01]
 [6.0777781e-20 9.9999928e-01 1.6486248e-10 ... 9.3680668e-01
  9.3680668e-01 9.3680668e-01]]
2022-12-18 23:53:25,388 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:25,388 INFO Predicting labels for 18 texts
2022-12-18 23:53:25,496 INFO There are 7/7 active rules
2022-12-18 23:53:25,496 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:25,496 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:25,522 INFO DONE, Getting attention scores...
2022-12-18 23:53:25,574 INFO the attention scores are
2022-12-18 23:53:25,574 INFO [[1.64398144e-03 2.71153799e-03 2.01329924e-02 3.28052074e-01
  9.00565386e-01 9.15703535e-01 3.91944312e-03 4.07414548e-02]
 [5.17395500e-04 1.19018147e-03 8.32740683e-03 3.30425084e-01
  9.33575392e-01 9.46272671e-01 1.83445192e-03 3.12649906e-02]
 [3.76604847e-04 1.08448870e-03 8.09319410e-03 3.35893124e-01
  9.18148637e-01 9.40347075e-01 1.89198635e-03 2.18087211e-02]
 [7.84318021e-04 3.20248352e-03 3.68682034e-02 3.36409032e-01
  8.03177476e-01 9.01473045e-01 1.26649672e-02 7.13824900e-03]
 [3.57181852e-04 1.81638042e-03 2.31104940e-02 3.37782234e-01
  8.54331911e-01 9.30403292e-01 7.70645496e-03 1.23453531e-02]
 [3.43919871e-03 7.04754237e-03 6.94968179e-02 3.18367660e-01
  7.13472188e-01 8.21971118e-01 2.34687272e-02 2.84002759e-02]
 [4.75785695e-03 7.32156215e-03 7.46273026e-02 3.19506049e-01
  7.75443614e-01 8.46478999e-01 1.92073099e-02 4.38973121e-02]
 [1.89733808e-03 3.33649153e-03 3.01095117e-02 3.26274544e-01
  8.84775996e-01 9.17120934e-01 5.52366721e-03 4.31930795e-02]
 [6.41448654e-37 1.00000000e+00 9.99010086e-01 9.82000939e-11
  1.74432904e-01 2.37926328e-11 1.00000000e+00 0.00000000e+00]
 [0.00000000e+00 1.00000000e+00 2.09768259e-04 1.53790203e-09
  9.99998093e-01 4.25172164e-09 1.00000000e+00 0.00000000e+00]
 [5.45776333e-33 1.00000000e+00 6.19883160e-13 1.07529927e-02
  9.99999285e-01 7.20744471e-12 1.00000000e+00 6.75060471e-33]
 [4.28552127e-15 5.21025562e-04 2.16031657e-03 5.27856173e-06
  4.26971586e-03 1.38752910e-06 1.00000000e+00 2.86068602e-19]
 [1.82650500e-25 1.08412245e-18 1.52244810e-28 3.95977841e-05
  1.00000000e+00 1.00000000e+00 6.04423603e-18 1.00000000e+00]
 [4.93909782e-16 3.94796244e-11 1.38601822e-15 9.77000338e-04
  1.00000000e+00 1.00000000e+00 7.80842201e-14 9.84569490e-01]
 [1.45733647e-10 5.78549274e-12 2.05919466e-11 5.97494170e-02
  1.00000000e+00 9.99999166e-01 1.10785968e-12 1.51546451e-03]
 [1.82496806e-15 4.02010474e-11 1.23344126e-08 3.52013499e-01
  9.99995589e-01 9.99989510e-01 7.33388417e-09 3.59635038e-07]
 [9.61540155e-16 4.25935109e-09 2.88740942e-08 2.48361602e-01
  9.99994755e-01 9.99996543e-01 7.19218129e-10 7.23483936e-07]
 [1.33940248e-10 7.15218050e-07 4.71395142e-05 2.61888057e-01
  9.99386549e-01 9.99954820e-01 7.44717909e-06 1.15632265e-05]]
2022-12-18 23:53:25,577 INFO Evaluating teacher dev iter19 on 18 examples
2022-12-18 23:53:25,578 INFO teacher dev iter19 performance: 13.25
2022-12-18 23:53:25,579 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:25,579 INFO Predicting labels for 32 texts
2022-12-18 23:53:25,685 INFO There are 7/7 active rules
2022-12-18 23:53:25,686 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:25,686 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:25,710 INFO DONE, Getting attention scores...
2022-12-18 23:53:25,766 INFO the attention scores are
2022-12-18 23:53:25,766 INFO [[7.59006226e-12 8.15704525e-01 2.20731415e-08 3.37010897e-06
  9.99956608e-01 1.40603513e-01 9.99971271e-01 2.24401944e-07]
 [3.67637835e-02 3.14140721e-04 2.08416604e-05 1.55082147e-04
  9.99889851e-01 9.99934316e-01 8.50491866e-04 9.98289168e-01]
 [2.49955803e-02 5.46621205e-03 3.20886029e-04 1.67463757e-02
  9.99186575e-01 9.96100545e-01 1.31814112e-03 9.86832917e-01]
 [3.13652912e-03 1.65956002e-03 1.50430957e-02 4.01927590e-01
  9.20412898e-01 8.41584265e-01 2.29433109e-03 2.61070300e-02]
 [2.46234267e-04 6.14510034e-04 1.10634025e-02 3.92708093e-01
  9.32074606e-01 9.42585111e-01 6.43130334e-04 2.28581345e-03]
 [2.57089050e-05 5.24813426e-04 1.14180483e-02 3.79617840e-01
  9.51283038e-01 9.71538663e-01 8.67654337e-04 6.36841869e-04]
 [2.25779644e-04 2.72779469e-03 4.75005731e-02 3.19238991e-01
  8.64446878e-01 9.31826711e-01 6.97997538e-03 2.80960393e-03]
 [2.64282717e-04 2.37648631e-03 1.04081549e-01 3.26296628e-01
  8.79980505e-01 9.38170254e-01 9.46590398e-03 4.58147563e-03]
 [6.27387140e-04 3.04856105e-03 6.41074330e-02 3.38142782e-01
  9.28600788e-01 9.48926806e-01 9.25063808e-03 2.99158357e-02]
 [8.99813254e-04 2.07663793e-03 2.12479681e-02 3.59158933e-01
  9.69608784e-01 9.72019494e-01 2.07358575e-03 6.12389334e-02]
 [1.12864550e-03 8.92404292e-04 2.36301888e-02 3.74056131e-01
  9.48311269e-01 9.39023197e-01 1.28969667e-03 3.29139866e-02]
 [1.25124963e-04 3.88802640e-04 8.58328212e-03 3.69759291e-01
  9.72066343e-01 9.68844473e-01 6.57884637e-04 1.63088646e-02]
 [7.57958624e-04 2.77908472e-03 8.44081044e-02 3.30578953e-01
  8.56326342e-01 9.23814833e-01 7.33261881e-03 3.67702916e-03]
 [4.53380810e-04 3.01613635e-03 6.82539791e-02 3.31433564e-01
  8.75227392e-01 9.26904261e-01 8.90347827e-03 9.56775993e-03]
 [3.15863319e-04 2.15030950e-03 4.46511656e-02 3.74577582e-01
  9.34302628e-01 9.57178950e-01 3.62414704e-03 1.18228933e-02]
 [4.56848135e-03 6.14154572e-03 1.05139449e-01 3.38145494e-01
  8.49275827e-01 8.66470456e-01 1.21182511e-02 5.94454445e-02]
 [8.50531287e-05 4.42286575e-04 3.25408718e-03 4.54923928e-01
  9.90764022e-01 9.91161108e-01 3.15829908e-04 2.27768533e-02]
 [3.15848156e-05 1.61111995e-04 6.31753076e-03 4.53461409e-01
  9.87680793e-01 9.89434302e-01 3.69258894e-04 3.00768996e-03]
 [9.95170412e-05 7.41956464e-04 5.95437596e-03 3.72886360e-01
  9.77133393e-01 9.78021979e-01 1.10487547e-03 2.30183396e-02]
 [1.76624199e-05 1.88808801e-04 1.13773136e-03 4.54587966e-01
  9.95942533e-01 9.95760143e-01 7.94732914e-05 1.15865450e-02]
 [2.21841750e-04 4.29986569e-04 1.12201311e-02 3.87476414e-01
  9.65920627e-01 9.57158923e-01 5.62084373e-04 1.29774874e-02]
 [9.38107260e-05 4.61903604e-04 2.81474926e-03 3.37329537e-01
  9.76682723e-01 9.68982697e-01 3.03711160e-04 2.63340324e-02]
 [1.74569668e-05 1.25626233e-04 1.78176456e-03 3.98073524e-01
  9.87056255e-01 9.83406305e-01 6.40720391e-05 4.03357344e-03]
 [1.60089749e-05 2.57612643e-04 9.73858219e-03 3.67632180e-01
  9.61840272e-01 9.75784779e-01 7.08536478e-04 8.80642678e-04]
 [1.40287611e-05 6.05672656e-04 1.15417466e-02 3.32790464e-01
  9.59039390e-01 9.80975032e-01 9.45036765e-04 2.39108596e-03]
 [1.38012460e-03 6.66811271e-03 1.16744004e-01 2.89091080e-01
  7.96801627e-01 9.12215590e-01 1.44803496e-02 1.02257300e-02]
 [3.29237524e-03 8.56854487e-03 1.96481124e-01 3.02764326e-01
  7.90150642e-01 9.02542174e-01 2.25850791e-02 1.50281042e-02]
 [2.27273144e-02 2.69503612e-02 3.60682815e-01 2.87410140e-01
  6.20370328e-01 7.85247266e-01 7.17948750e-02 3.32241580e-02]
 [3.32035273e-02 2.76138019e-02 2.87027359e-01 2.97994763e-01
  6.57707930e-01 7.68627346e-01 5.25515452e-02 6.06049821e-02]
 [3.27686919e-03 5.06303832e-03 7.07082823e-02 3.38998884e-01
  8.89296532e-01 9.26300824e-01 8.37178715e-03 3.54993567e-02]
 [5.05091297e-03 6.75478810e-03 8.07996839e-02 3.35841477e-01
  8.25994432e-01 8.75517964e-01 1.40209664e-02 4.79756109e-02]
 [2.17732997e-03 3.57826869e-03 3.49090360e-02 3.36686105e-01
  8.97064507e-01 9.27256107e-01 4.73963423e-03 4.39820848e-02]]
2022-12-18 23:53:25,771 INFO Evaluating teacher test iter19 on 32 examples
2022-12-18 23:53:25,772 INFO teacher test iter19 performance: 1.32
2022-12-18 23:53:25,772 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:25,777 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.906428575515747
2022-12-18 23:53:25,777 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:27,600 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:29,524 INFO Predicting labels for 18 texts
2022-12-18 23:53:29,635 INFO Evaluating student dev iter19 on 18 examples
2022-12-18 23:53:29,636 INFO student dev iter19 performance: 14.63
2022-12-18 23:53:29,636 INFO Predicting labels for 32 texts
2022-12-18 23:53:29,744 INFO Evaluating student test iter19 on 32 examples
2022-12-18 23:53:29,745 INFO student test iter19 performance: 0.68
2022-12-18 23:53:29,746 INFO Student Dev performance on iter 19: 14.630733114251788
2022-12-18 23:53:29,746 INFO Student Test performance on iter 19: 0.6789703274398067
2022-12-18 23:53:29,746 INFO 

	 *** Starting loop 20 ***
2022-12-18 23:53:29,746 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:29,746 INFO Getting rule predictions
2022-12-18 23:53:29,746 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:29,746 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:29,746 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:29,747 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:29,747 INFO Predicting labels for 247 texts
2022-12-18 23:53:29,858 INFO Predicting labels for 18 texts
2022-12-18 23:53:29,968 INFO Predicting labels for 444 texts
2022-12-18 23:53:30,085 INFO Training Rule Attention Network
2022-12-18 23:53:30,087 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:30,087 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:30,089 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:30,090 INFO 

		*** Training RAN ***
2022-12-18 23:53:31,307 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:31,308 INFO Predicting labels for 444 texts
2022-12-18 23:53:31,417 INFO There are 3/7 active rules
2022-12-18 23:53:31,417 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:31,423 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:31,495 INFO DONE, Getting attention scores...
2022-12-18 23:53:31,550 INFO the attention scores are
2022-12-18 23:53:31,551 INFO [[2.67216976e-23 9.98054385e-01 4.67504142e-03 ... 4.67504142e-03
  4.67504142e-03 4.67504142e-03]
 [4.80805736e-23 9.98069704e-01 5.57638612e-03 ... 5.57638612e-03
  5.57638612e-03 5.57638612e-03]
 [1.28779045e-11 2.57402705e-03 9.94214788e-03 ... 9.94214788e-03
  9.94214788e-03 9.94214788e-03]
 ...
 [4.54705065e-26 9.47932899e-01 2.18436047e-10 ... 3.94202303e-04
  3.94202303e-04 3.94202303e-04]
 [5.19396985e-24 3.41348387e-02 3.84481130e-13 ... 1.20985873e-01
  1.20985873e-01 1.20985873e-01]
 [2.21558666e-22 2.57863626e-02 3.27525794e-13 ... 1.74727827e-01
  1.74727827e-01 1.74727827e-01]]
2022-12-18 23:53:31,552 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:31,552 INFO Predicting labels for 18 texts
2022-12-18 23:53:31,657 INFO There are 7/7 active rules
2022-12-18 23:53:31,657 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:31,657 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:31,687 INFO DONE, Getting attention scores...
2022-12-18 23:53:31,740 INFO the attention scores are
2022-12-18 23:53:31,740 INFO [[2.03421107e-03 2.12730118e-03 3.72749530e-02 3.30204457e-01
  8.44852686e-01 9.03171778e-01 4.79033170e-03 2.32275054e-02]
 [7.07462255e-04 9.49254609e-04 1.68471728e-02 3.23425859e-01
  8.98438394e-01 9.34935391e-01 2.25312775e-03 1.86521020e-02]
 [5.16701315e-04 7.96008273e-04 1.79566890e-02 3.36665511e-01
  8.90662074e-01 9.29244280e-01 2.28815828e-03 1.27334092e-02]
 [1.39471644e-03 2.19074124e-03 5.12777418e-02 3.50616276e-01
  7.33804762e-01 8.70690167e-01 1.01274336e-02 6.04262855e-03]
 [6.58987497e-04 1.36408524e-03 3.43232527e-02 3.27659190e-01
  7.98203826e-01 9.08359766e-01 6.67847134e-03 1.22354934e-02]
 [4.50913375e-03 4.57022479e-03 1.10374853e-01 3.22667927e-01
  6.37494683e-01 7.97967851e-01 2.01323144e-02 1.55369006e-02]
 [6.30707154e-03 5.38759679e-03 1.15469679e-01 3.24766099e-01
  6.72379613e-01 8.16000521e-01 1.99110880e-02 2.52732355e-02]
 [2.28812220e-03 2.67961156e-03 5.08601815e-02 3.18427891e-01
  8.16422105e-01 8.99662971e-01 6.33096462e-03 2.49675643e-02]
 [0.00000000e+00 9.99955416e-01 2.07307283e-03 4.90946395e-09
  6.50222739e-03 4.57769772e-07 1.00000000e+00 0.00000000e+00]
 [0.00000000e+00 1.00000000e+00 5.22590998e-12 4.04805223e-06
  1.00000000e+00 1.19554251e-02 1.00000000e+00 0.00000000e+00]
 [8.48966559e-33 1.00000000e+00 1.87812033e-16 5.64284384e-01
  1.00000000e+00 1.17905245e-07 1.00000000e+00 2.93343238e-35]
 [5.66825225e-18 2.61499644e-13 7.99330337e-06 1.16808355e-04
  9.87753272e-03 1.14530712e-01 1.00000000e+00 6.87445560e-19]
 [8.70089740e-36 4.72729031e-23 8.21249028e-29 7.67140534e-07
  1.00000000e+00 1.00000000e+00 6.15933108e-19 1.00000000e+00]
 [1.09778977e-17 2.59524173e-12 4.49437545e-15 3.31250834e-04
  1.00000000e+00 1.00000000e+00 4.24473197e-15 9.74848211e-01]
 [8.00838562e-13 1.36200740e-12 2.03426130e-11 4.93669845e-02
  1.00000000e+00 9.99997497e-01 5.68218758e-13 2.55694933e-04]
 [5.07948188e-16 4.34026634e-11 8.17547097e-09 3.38261276e-01
  9.99988794e-01 9.99970794e-01 1.17270931e-08 1.50169933e-06]
 [1.20450997e-16 1.88961424e-09 2.92485036e-09 2.29532227e-01
  9.99988675e-01 9.99996185e-01 3.43115036e-10 2.13611133e-06]
 [4.18766133e-11 4.64754265e-07 1.65967576e-05 2.18391553e-01
  9.98286068e-01 9.99894738e-01 5.80016649e-06 9.60448961e-06]]
2022-12-18 23:53:31,743 INFO Evaluating teacher dev iter20 on 18 examples
2022-12-18 23:53:31,744 INFO teacher dev iter20 performance: 14.58
2022-12-18 23:53:31,744 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:31,744 INFO Predicting labels for 32 texts
2022-12-18 23:53:31,855 INFO There are 7/7 active rules
2022-12-18 23:53:31,855 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:31,855 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:31,880 INFO DONE, Getting attention scores...
2022-12-18 23:53:31,936 INFO the attention scores are
2022-12-18 23:53:31,936 INFO [[5.92074268e-14 3.73966259e-07 2.19168994e-09 1.80350089e-05
  9.99987245e-01 9.99154806e-01 9.99928594e-01 8.80077152e-07]
 [1.16636566e-05 1.73154948e-08 1.34439297e-05 1.96051202e-04
  9.99920011e-01 9.99997258e-01 5.73072641e-04 9.99231935e-01]
 [4.69860010e-04 2.82989728e-04 2.39012734e-04 1.54986400e-02
  9.99167323e-01 9.98302341e-01 5.09491947e-04 9.90824103e-01]
 [1.51522213e-03 1.31310523e-03 2.39473730e-02 4.00106281e-01
  8.73594105e-01 8.28587890e-01 3.18402075e-03 2.17835587e-02]
 [1.78198898e-04 4.16205352e-04 1.68621391e-02 4.00519460e-01
  9.05626476e-01 9.31664228e-01 9.34751995e-04 3.18232947e-03]
 [1.89161274e-05 3.70046881e-04 1.21508781e-02 3.77779633e-01
  9.28822994e-01 9.66634154e-01 8.92422569e-04 1.62436068e-03]
 [1.93718253e-04 1.84101472e-03 4.45660129e-02 3.39608699e-01
  7.80637264e-01 8.95585358e-01 5.66842454e-03 4.64028632e-03]
 [1.40769087e-04 1.61965587e-03 8.62032101e-02 3.51835340e-01
  8.16026211e-01 9.12753463e-01 6.58581173e-03 3.94898187e-03]
 [5.31678670e-04 2.43948936e-03 5.83854392e-02 3.48618746e-01
  8.75077367e-01 9.14570391e-01 7.28900544e-03 3.11990473e-02]
 [5.66110364e-04 1.79231039e-03 2.78467219e-02 3.59058708e-01
  9.31171894e-01 9.65790510e-01 1.74215750e-03 3.15864272e-02]
 [7.72351283e-04 7.48449704e-04 2.96027418e-02 3.77069294e-01
  9.04137135e-01 9.22662020e-01 1.23748241e-03 2.32485570e-02]
 [1.14933588e-04 3.61536979e-04 1.29872579e-02 3.65095437e-01
  9.52733278e-01 9.60134983e-01 6.77550910e-04 1.74443964e-02]
 [5.85660222e-04 1.88654999e-03 8.89243335e-02 3.64945918e-01
  7.64022946e-01 8.74773562e-01 5.27811330e-03 3.92956659e-03]
 [4.41425829e-04 2.38045654e-03 7.31844157e-02 3.45859975e-01
  8.10517788e-01 8.92032802e-01 8.33097100e-03 1.18575338e-02]
 [2.35813859e-04 1.63371023e-03 4.96273339e-02 3.70110095e-01
  8.95445824e-01 9.41622615e-01 3.23159527e-03 1.43842623e-02]
 [3.84727237e-03 4.96484293e-03 1.30722806e-01 3.47270608e-01
  7.67563701e-01 8.31638992e-01 1.13848876e-02 3.88620310e-02]
 [4.43896424e-05 3.60665843e-04 5.90033596e-03 4.09308851e-01
  9.84927416e-01 9.90910470e-01 3.18331091e-04 2.44675167e-02]
 [1.17700547e-05 1.36568051e-04 9.65108350e-03 4.26290184e-01
  9.81491208e-01 9.88466382e-01 3.72695416e-04 4.56788717e-03]
 [8.14375089e-05 7.15239905e-04 1.10862451e-02 3.47757488e-01
  9.61705387e-01 9.68714654e-01 1.25104981e-03 2.92109754e-02]
 [7.51878451e-06 1.47371611e-04 2.53104023e-03 4.11214828e-01
  9.93899107e-01 9.95880842e-01 8.22239235e-05 1.25760762e-02]
 [1.88938284e-04 3.58981197e-04 1.78303160e-02 3.82118165e-01
  9.46262956e-01 9.48081374e-01 6.66206935e-04 1.38941966e-02]
 [6.99430966e-05 3.99366720e-04 8.63496400e-03 3.40230972e-01
  9.63339925e-01 9.67882752e-01 4.05276020e-04 1.41482437e-02]
 [1.28381589e-05 9.42763363e-05 3.29333777e-03 3.98507297e-01
  9.83280838e-01 9.84125495e-01 7.34686982e-05 3.96401854e-03]
 [1.32593295e-05 1.88033751e-04 1.13362838e-02 3.72989833e-01
  9.42458570e-01 9.64280427e-01 6.84216327e-04 2.09448906e-03]
 [1.25228407e-05 4.46846010e-04 1.15351826e-02 3.17613751e-01
  9.29612577e-01 9.74495113e-01 9.24553839e-04 3.92836658e-03]
 [1.67235511e-03 5.10060927e-03 1.25277296e-01 3.16281617e-01
  6.53607011e-01 8.54885280e-01 1.25457821e-02 8.57889280e-03]
 [3.63613362e-03 6.61371322e-03 2.04833239e-01 3.30714792e-01
  6.66184783e-01 8.43606949e-01 1.90701671e-02 1.33675123e-02]
 [2.57207621e-02 2.06478313e-02 3.83090168e-01 3.18157881e-01
  4.68911111e-01 6.92851841e-01 6.60081133e-02 2.44851820e-02]
 [3.24111916e-02 2.10113786e-02 3.43411267e-01 3.23848426e-01
  4.94465560e-01 7.26262629e-01 5.45861945e-02 3.06921378e-02]
 [3.83679289e-03 4.65658167e-03 8.65861252e-02 3.36546838e-01
  8.10559869e-01 9.03351426e-01 8.64712428e-03 3.16889323e-02]
 [6.18640520e-03 5.74966054e-03 1.18489496e-01 3.33141834e-01
  7.36099124e-01 8.45073879e-01 1.62264891e-02 3.56646068e-02]
 [2.19715387e-03 2.93930154e-03 5.89854047e-02 3.27409387e-01
  8.43710184e-01 9.17000234e-01 5.42988069e-03 2.77822316e-02]]
2022-12-18 23:53:31,941 INFO Evaluating teacher test iter20 on 32 examples
2022-12-18 23:53:31,942 INFO teacher test iter20 performance: 1.33
2022-12-18 23:53:31,942 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:31,947 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9540249109268188
2022-12-18 23:53:31,947 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:33,807 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:36,692 INFO Predicting labels for 18 texts
2022-12-18 23:53:36,801 INFO Evaluating student dev iter20 on 18 examples
2022-12-18 23:53:36,802 INFO student dev iter20 performance: 14.62
2022-12-18 23:53:36,803 INFO Predicting labels for 32 texts
2022-12-18 23:53:36,910 INFO Evaluating student test iter20 on 32 examples
2022-12-18 23:53:36,911 INFO student test iter20 performance: 0.68
2022-12-18 23:53:36,911 INFO Student Dev performance on iter 20: 14.617923133181149
2022-12-18 23:53:36,912 INFO Student Test performance on iter 20: 0.6768955826594882
2022-12-18 23:53:36,912 INFO 

	 *** Starting loop 21 ***
2022-12-18 23:53:36,912 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:36,912 INFO Getting rule predictions
2022-12-18 23:53:36,912 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:36,912 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:36,912 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:36,913 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:36,913 INFO Predicting labels for 247 texts
2022-12-18 23:53:37,027 INFO Predicting labels for 18 texts
2022-12-18 23:53:37,132 INFO Predicting labels for 444 texts
2022-12-18 23:53:37,245 INFO Training Rule Attention Network
2022-12-18 23:53:37,247 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:37,247 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:37,250 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:37,250 INFO 

		*** Training RAN ***
2022-12-18 23:53:38,507 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:38,508 INFO Predicting labels for 444 texts
2022-12-18 23:53:38,621 INFO There are 3/7 active rules
2022-12-18 23:53:38,621 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:38,627 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:38,702 INFO DONE, Getting attention scores...
2022-12-18 23:53:38,758 INFO the attention scores are
2022-12-18 23:53:38,758 INFO [[1.0132137e-21 9.9839669e-01 1.3098358e-03 ... 1.3098358e-03
  1.3098358e-03 1.3098358e-03]
 [1.8521040e-21 9.9831319e-01 1.4714417e-03 ... 1.4714417e-03
  1.4714417e-03 1.4714417e-03]
 [4.5815798e-10 4.6267742e-04 4.3067369e-03 ... 4.3067369e-03
  4.3067369e-03 4.3067369e-03]
 ...
 [4.9508891e-23 4.2087635e-01 4.6350920e-17 ... 8.7288812e-05
  8.7288812e-05 8.7288812e-05]
 [1.7219721e-19 2.7546289e-04 2.3685530e-20 ... 2.0511965e-01
  2.0511965e-01 2.0511965e-01]
 [8.0246189e-18 1.5237670e-04 2.5295485e-20 ... 2.4444194e-01
  2.4444194e-01 2.4444194e-01]]
2022-12-18 23:53:38,760 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:38,760 INFO Predicting labels for 18 texts
2022-12-18 23:53:38,866 INFO There are 7/7 active rules
2022-12-18 23:53:38,867 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:38,867 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:38,897 INFO DONE, Getting attention scores...
2022-12-18 23:53:38,949 INFO the attention scores are
2022-12-18 23:53:38,950 INFO [[4.44382476e-03 2.64356821e-03 7.83184767e-02 2.88661063e-01
  8.72132480e-01 9.15346086e-01 4.46581189e-03 2.86957119e-02]
 [1.31200638e-03 1.07947364e-03 3.99844944e-02 2.86278069e-01
  9.19274926e-01 9.48209107e-01 2.02596374e-03 1.93101447e-02]
 [9.59755213e-04 9.73143149e-04 3.39635238e-02 2.85093367e-01
  9.04346347e-01 9.43257749e-01 1.88922661e-03 1.17988065e-02]
 [2.38982262e-03 3.18307965e-03 7.66944736e-02 2.92205364e-01
  7.68822193e-01 8.92456949e-01 7.32489303e-03 7.21052196e-03]
 [9.96090355e-04 1.50414126e-03 4.99946363e-02 2.86179632e-01
  8.37589324e-01 9.30391908e-01 4.50417260e-03 1.02970153e-02]
 [6.69352943e-03 6.17705705e-03 1.25243783e-01 2.76814908e-01
  6.81291163e-01 8.47471535e-01 1.34605104e-02 1.83387212e-02]
 [1.11706126e-02 6.79524662e-03 1.59001037e-01 2.82780349e-01
  7.15629339e-01 8.50511014e-01 1.41954962e-02 3.13595310e-02]
 [4.32683621e-03 2.94188643e-03 9.60027277e-02 2.87319392e-01
  8.58116269e-01 9.21494246e-01 5.63965412e-03 3.15815061e-02]
 [1.04708014e-37 9.99997258e-01 6.00648946e-06 2.91314173e-09
  5.83167493e-01 4.60492338e-08 1.00000000e+00 0.00000000e+00]
 [0.00000000e+00 9.99999881e-01 4.10227003e-16 7.56782129e-07
  1.00000000e+00 2.41306520e-06 1.00000000e+00 0.00000000e+00]
 [1.35749955e-31 9.99999881e-01 1.21022080e-24 6.26859069e-01
  1.00000000e+00 5.74573333e-10 1.00000000e+00 1.49887287e-36]
 [3.41833723e-12 4.69289869e-16 3.35741782e-11 2.86016788e-04
  2.59785652e-01 2.91940778e-01 1.00000000e+00 5.04680391e-23]
 [9.20575706e-31 1.41170431e-25 1.22049331e-26 2.00900807e-08
  1.00000000e+00 1.00000000e+00 1.80827410e-15 1.00000000e+00]
 [3.14006866e-16 2.72302770e-13 6.44282197e-11 7.59428440e-05
  1.00000000e+00 1.00000000e+00 1.20147447e-12 9.98483121e-01]
 [2.90386493e-10 1.26742063e-12 1.69694143e-08 6.79670088e-03
  9.99999881e-01 9.99999642e-01 2.12814683e-10 3.61524522e-02]
 [7.33656147e-15 2.00121083e-11 7.63271373e-07 2.15645939e-01
  9.99998450e-01 9.99989748e-01 1.08806386e-08 3.41694943e-07]
 [3.92290604e-15 8.75830686e-10 8.43238581e-08 1.54148012e-01
  9.99997735e-01 9.99999404e-01 1.34361425e-10 5.42048201e-06]
 [3.38399753e-10 2.54477669e-07 2.09231905e-04 1.76901892e-01
  9.99383807e-01 9.99959707e-01 3.22382925e-06 1.23383743e-05]]
2022-12-18 23:53:38,953 INFO Evaluating teacher dev iter21 on 18 examples
2022-12-18 23:53:38,954 INFO teacher dev iter21 performance: 13.89
2022-12-18 23:53:38,954 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:38,954 INFO Predicting labels for 32 texts
2022-12-18 23:53:39,062 INFO There are 7/7 active rules
2022-12-18 23:53:39,062 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:39,062 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:39,086 INFO DONE, Getting attention scores...
2022-12-18 23:53:39,142 INFO the attention scores are
2022-12-18 23:53:39,142 INFO [[6.51956711e-10 7.65339792e-09 1.94133955e-14 8.42904319e-06
  1.00000000e+00 9.99903440e-01 9.99994993e-01 5.13517406e-08]
 [3.38268653e-02 2.01785522e-09 1.97976533e-06 2.44990933e-05
  9.99997497e-01 9.99999762e-01 3.19202133e-02 9.99329329e-01]
 [1.14918333e-02 4.26123763e-04 1.35752489e-03 5.73794823e-03
  9.99123275e-01 9.98787582e-01 9.69033409e-03 9.95861709e-01]
 [7.59740500e-03 2.12238240e-03 1.03343144e-01 3.43077153e-01
  8.50515783e-01 8.54124188e-01 6.24691322e-03 2.37520933e-02]
 [5.88886847e-04 4.74808097e-04 3.36055681e-02 3.33936930e-01
  9.13692415e-01 9.37041163e-01 9.55018739e-04 3.44962813e-03]
 [6.95024864e-05 3.44355794e-04 2.92336289e-02 3.08329970e-01
  9.48716164e-01 9.76013184e-01 7.70741841e-04 1.23480556e-03]
 [5.29030745e-04 1.85755233e-03 7.57201761e-02 2.69040346e-01
  8.51960897e-01 9.31949019e-01 4.31313133e-03 6.04398921e-03]
 [4.56351176e-04 1.34695228e-03 1.16046384e-01 2.98181444e-01
  8.72277021e-01 9.32548106e-01 5.20094344e-03 7.31176743e-03]
 [1.03162648e-03 1.80443714e-03 8.93625915e-02 2.99578607e-01
  9.10042822e-01 9.39005971e-01 5.60153322e-03 3.98186371e-02]
 [1.46641920e-03 1.88610458e-03 9.94349793e-02 2.94343024e-01
  9.32010412e-01 9.77900684e-01 1.78264175e-03 6.86562434e-02]
 [1.83474901e-03 9.58294084e-04 9.07091498e-02 3.24018300e-01
  9.03520644e-01 9.42580998e-01 1.77800213e-03 4.69963141e-02]
 [2.87107978e-04 2.80897861e-04 3.37003395e-02 3.12995374e-01
  9.64294255e-01 9.72671866e-01 6.18935796e-04 2.36993656e-02]
 [1.56157312e-03 2.18855776e-03 1.32893726e-01 3.03316116e-01
  8.27143013e-01 9.06777620e-01 5.35156205e-03 6.33861823e-03]
 [9.80555080e-04 2.08429247e-03 1.12575069e-01 2.84082949e-01
  8.65256011e-01 9.27688658e-01 6.19088020e-03 1.48904976e-02]
 [6.60770747e-04 1.39097706e-03 8.19856375e-02 3.08185220e-01
  9.24551368e-01 9.56395507e-01 2.60656350e-03 2.14953218e-02]
 [1.00058401e-02 5.00117615e-03 2.00981528e-01 3.07548374e-01
  8.00797701e-01 8.65704119e-01 9.62786283e-03 6.32591099e-02]
 [8.97939972e-05 4.19473916e-04 2.71658655e-02 3.47019434e-01
  9.82141256e-01 9.95400369e-01 3.80156416e-04 4.37668040e-02]
 [3.57269819e-05 1.23470963e-04 3.46775092e-02 3.26944888e-01
  9.77089703e-01 9.91642356e-01 4.72806423e-04 6.15529623e-03]
 [2.22438626e-04 5.23911265e-04 2.63895877e-02 3.07831377e-01
  9.73266721e-01 9.79763091e-01 8.91771866e-04 4.34023291e-02]
 [2.10228955e-05 1.39884083e-04 9.73062590e-03 3.39343548e-01
  9.93681550e-01 9.97885048e-01 7.91800921e-05 2.17919238e-02]
 [5.12584695e-04 3.21091065e-04 3.85327712e-02 3.29437017e-01
  9.59481895e-01 9.59016323e-01 6.82047685e-04 2.30629928e-02]
 [2.29297599e-04 4.13417001e-04 2.04046741e-02 2.79849708e-01
  9.72185791e-01 9.79835153e-01 2.84270121e-04 2.38748081e-02]
 [6.27561385e-05 9.19242666e-05 9.18252021e-03 3.14908624e-01
  9.84972715e-01 9.88502622e-01 6.54061660e-05 6.92408485e-03]
 [5.06307151e-05 1.76212372e-04 2.61145253e-02 2.98590809e-01
  9.62450624e-01 9.77166414e-01 6.16165926e-04 2.32059206e-03]
 [3.36302910e-05 3.58205725e-04 2.45654080e-02 2.61361599e-01
  9.59952354e-01 9.86432850e-01 6.12843374e-04 4.39011864e-03]
 [3.06889717e-03 5.47668152e-03 1.67620122e-01 2.61311680e-01
  7.41472125e-01 9.01993752e-01 9.03119333e-03 1.34869413e-02]
 [5.68988221e-03 6.56758063e-03 2.50986964e-01 2.87104577e-01
  7.40230143e-01 8.84372771e-01 1.62641201e-02 1.90996118e-02]
 [4.21919785e-02 2.42225993e-02 3.97013307e-01 2.85273015e-01
  5.24639606e-01 7.28073001e-01 5.32293916e-02 4.65865992e-02]
 [6.81305379e-02 2.76729707e-02 4.13726926e-01 2.88965374e-01
  5.48627794e-01 7.41882026e-01 4.78818305e-02 5.84801435e-02]
 [7.88340904e-03 4.52628266e-03 1.72602743e-01 3.04834098e-01
  8.60396802e-01 9.19099271e-01 8.60725529e-03 4.64080349e-02]
 [1.08235432e-02 6.09399471e-03 1.81480765e-01 2.99336314e-01
  7.92998970e-01 8.67459893e-01 1.37770167e-02 4.68860343e-02]
 [3.93303949e-03 2.93476204e-03 1.02993563e-01 2.97104478e-01
  8.84752631e-01 9.34677362e-01 4.71063424e-03 3.71177681e-02]]
2022-12-18 23:53:39,147 INFO Evaluating teacher test iter21 on 32 examples
2022-12-18 23:53:39,148 INFO teacher test iter21 performance: 1.31
2022-12-18 23:53:39,148 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:39,153 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9618955850601196
2022-12-18 23:53:39,153 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:42,019 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:43,921 INFO Predicting labels for 18 texts
2022-12-18 23:53:44,032 INFO Evaluating student dev iter21 on 18 examples
2022-12-18 23:53:44,033 INFO student dev iter21 performance: 14.60
2022-12-18 23:53:44,034 INFO Predicting labels for 32 texts
2022-12-18 23:53:44,146 INFO Evaluating student test iter21 on 32 examples
2022-12-18 23:53:44,147 INFO student test iter21 performance: 0.67
2022-12-18 23:53:44,147 INFO Student Dev performance on iter 21: 14.59733439430789
2022-12-18 23:53:44,147 INFO Student Test performance on iter 21: 0.6720604374714425
2022-12-18 23:53:44,147 INFO 

	 *** Starting loop 22 ***
2022-12-18 23:53:44,147 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:44,147 INFO Getting rule predictions
2022-12-18 23:53:44,147 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:44,148 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:44,148 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:44,148 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:44,149 INFO Predicting labels for 247 texts
2022-12-18 23:53:44,258 INFO Predicting labels for 18 texts
2022-12-18 23:53:44,365 INFO Predicting labels for 444 texts
2022-12-18 23:53:44,475 INFO Training Rule Attention Network
2022-12-18 23:53:44,477 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:44,477 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:44,479 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:44,479 INFO 

		*** Training RAN ***
2022-12-18 23:53:45,628 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:45,629 INFO Predicting labels for 444 texts
2022-12-18 23:53:45,744 INFO There are 3/7 active rules
2022-12-18 23:53:45,744 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:45,746 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:45,819 INFO DONE, Getting attention scores...
2022-12-18 23:53:45,874 INFO the attention scores are
2022-12-18 23:53:45,874 INFO [[3.1631644e-23 9.9978477e-01 3.9252932e-03 ... 3.9252932e-03
  3.9252932e-03 3.9252932e-03]
 [5.6038041e-23 9.9974984e-01 4.2282236e-03 ... 4.2282236e-03
  4.2282236e-03 4.2282236e-03]
 [6.9263493e-12 1.6564304e-02 4.7285040e-03 ... 4.7285040e-03
  4.7285040e-03 4.7285040e-03]
 ...
 [3.7804503e-27 9.9864429e-01 4.3086344e-11 ... 4.0265546e-05
  4.0265546e-05 4.0265546e-05]
 [4.8743669e-26 4.0653464e-01 1.2216786e-15 ... 4.8695266e-02
  4.8695266e-02 4.8695266e-02]
 [2.0498937e-24 3.6694518e-01 1.2379197e-15 ... 8.5542679e-02
  8.5542679e-02 8.5542679e-02]]
2022-12-18 23:53:45,875 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:45,875 INFO Predicting labels for 18 texts
2022-12-18 23:53:45,985 INFO There are 7/7 active rules
2022-12-18 23:53:45,986 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:45,986 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:46,010 INFO DONE, Getting attention scores...
2022-12-18 23:53:46,062 INFO the attention scores are
2022-12-18 23:53:46,062 INFO [[3.0413596e-03 1.2848557e-03 1.5744772e-02 3.4408942e-01 8.9331526e-01
  9.0172386e-01 4.1995607e-03 5.0065182e-02]
 [1.0526874e-03 4.7923051e-04 5.5477121e-03 3.4569502e-01 9.3245763e-01
  9.3405837e-01 1.9500692e-03 4.0167905e-02]
 [8.8459876e-04 4.1858194e-04 5.1041166e-03 3.5503295e-01 9.2069757e-01
  9.2695457e-01 2.0439578e-03 3.1153316e-02]
 [2.7915107e-03 1.4765897e-03 2.0094503e-02 3.5831517e-01 7.8777969e-01
  8.5244536e-01 1.0662777e-02 2.3533558e-02]
 [1.3072982e-03 7.8563788e-04 1.2235142e-02 3.3809236e-01 8.3666599e-01
  8.9228845e-01 6.6301464e-03 3.3041015e-02]
 [6.2690587e-03 3.3796111e-03 5.3463079e-02 3.3300635e-01 6.8735319e-01
  8.1116843e-01 2.0760382e-02 4.0425017e-02]
 [8.7106060e-03 3.8202077e-03 6.4911574e-02 3.2623532e-01 7.2754091e-01
  8.1662554e-01 1.9836869e-02 5.5285465e-02]
 [3.3883306e-03 1.5862747e-03 2.4022963e-02 3.3022028e-01 8.6563683e-01
  9.0095091e-01 5.6530694e-03 5.4219991e-02]
 [0.0000000e+00 9.9999011e-01 9.2854190e-01 4.4263956e-10 5.4493576e-04
  2.2232632e-07 1.0000000e+00 0.0000000e+00]
 [0.0000000e+00 1.0000000e+00 9.7301573e-08 2.1141023e-08 9.9999976e-01
  1.6319279e-03 1.0000000e+00 0.0000000e+00]
 [7.1869922e-34 1.0000000e+00 3.4125013e-19 5.0223764e-02 1.0000000e+00
  1.2851037e-07 1.0000000e+00 0.0000000e+00]
 [1.3868782e-18 1.3795665e-12 6.1526468e-09 4.0620566e-07 1.1422192e-01
  9.6468693e-01 1.0000000e+00 3.1989130e-23]
 [0.0000000e+00 1.1023757e-26 2.8834212e-33 3.2787604e-08 1.0000000e+00
  1.0000000e+00 5.3683075e-20 1.0000000e+00]
 [2.3073419e-18 3.7948011e-14 4.7873544e-17 1.2975957e-04 1.0000000e+00
  1.0000000e+00 4.5361960e-15 9.9829251e-01]
 [5.6598970e-12 1.9961680e-14 1.7106070e-11 2.8119909e-02 1.0000000e+00
  9.9999964e-01 1.4055638e-12 1.2423756e-02]
 [2.2384011e-14 9.8147001e-13 1.2020585e-09 4.2026302e-01 9.9999428e-01
  9.9994099e-01 1.6234479e-08 7.1894838e-06]
 [1.1402423e-15 1.6768274e-10 1.1588777e-10 3.3534852e-01 9.9999630e-01
  9.9999356e-01 1.5001282e-10 1.7348842e-05]
 [3.2678002e-10 4.8237741e-08 3.2176004e-06 2.9977962e-01 9.9910128e-01
  9.9989557e-01 5.4558723e-06 8.8264867e-05]]
2022-12-18 23:53:46,065 INFO Evaluating teacher dev iter22 on 18 examples
2022-12-18 23:53:46,066 INFO teacher dev iter22 performance: 13.56
2022-12-18 23:53:46,066 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:46,066 INFO Predicting labels for 32 texts
2022-12-18 23:53:46,176 INFO There are 7/7 active rules
2022-12-18 23:53:46,176 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:46,177 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:46,200 INFO DONE, Getting attention scores...
2022-12-18 23:53:46,257 INFO the attention scores are
2022-12-18 23:53:46,257 INFO [[2.79956539e-16 6.22674804e-07 3.32050278e-13 2.96868876e-07
  9.99998689e-01 9.99998212e-01 9.99487162e-01 1.15911590e-07]
 [1.21866847e-07 1.67559100e-09 4.53291705e-07 1.54627869e-05
  9.99927878e-01 9.99999881e-01 3.48393041e-05 9.99873638e-01]
 [4.20213182e-05 4.32916968e-05 6.44745945e-04 7.47594144e-03
  9.94705498e-01 9.99013901e-01 3.92136164e-04 9.99135196e-01]
 [6.38193497e-03 9.12902935e-04 1.88903697e-02 4.04995620e-01
  8.89023066e-01 8.17708850e-01 3.28112976e-03 3.79244462e-02]
 [5.91430697e-04 2.51358084e-04 6.78243674e-03 4.06212121e-01
  9.17253733e-01 9.14625525e-01 7.13700778e-04 7.54185347e-03]
 [5.57646599e-05 1.82623611e-04 4.11342643e-03 3.88100594e-01
  9.54951584e-01 9.50431824e-01 6.85074017e-04 4.03279206e-03]
 [4.61216841e-04 1.19897316e-03 2.34339684e-02 3.26716334e-01
  8.49472761e-01 8.85556579e-01 4.83524846e-03 1.33677647e-02]
 [4.03217040e-04 9.42466490e-04 5.01038022e-02 3.56171250e-01
  8.68383825e-01 9.16453004e-01 6.25906186e-03 1.66235119e-02]
 [1.03906204e-03 1.15538458e-03 3.51371020e-02 3.51565242e-01
  8.86505425e-01 9.23904538e-01 6.41634874e-03 7.58816525e-02]
 [1.20281498e-03 8.91321630e-04 1.67422146e-02 3.64616632e-01
  9.43816841e-01 9.73813534e-01 1.65656290e-03 7.07766265e-02]
 [2.01848266e-03 3.62779887e-04 2.22880524e-02 3.71897846e-01
  9.21803296e-01 9.37595010e-01 1.37150567e-03 5.69783449e-02]
 [3.16980411e-04 1.40773642e-04 5.52733010e-03 3.79867911e-01
  9.56075668e-01 9.61753547e-01 6.21706829e-04 4.57430817e-02]
 [1.86304806e-03 1.42795732e-03 5.42194955e-02 3.53162736e-01
  8.19729328e-01 8.82570624e-01 5.30483807e-03 1.46424081e-02]
 [9.28172143e-04 1.36987970e-03 3.63018811e-02 3.38807672e-01
  8.62340510e-01 8.92090619e-01 7.06201280e-03 3.44800912e-02]
 [4.95293934e-04 8.80809734e-04 2.50988342e-02 3.80091399e-01
  9.16507602e-01 9.42811310e-01 2.64823274e-03 3.78172621e-02]
 [7.26097682e-03 3.22251488e-03 9.01239812e-02 3.40988964e-01
  7.95143664e-01 8.44063282e-01 1.01334201e-02 9.34168845e-02]
 [9.38010708e-05 1.15985902e-04 2.64883111e-03 4.17800188e-01
  9.85971868e-01 9.92333889e-01 2.94371101e-04 3.95373106e-02]
 [4.24727441e-05 4.03965823e-05 5.60725480e-03 4.30802912e-01
  9.81961250e-01 9.89002466e-01 3.73432849e-04 1.03534693e-02]
 [1.84242861e-04 2.54070386e-04 4.85525560e-03 3.69584978e-01
  9.60716248e-01 9.63624299e-01 1.19914231e-03 6.25648648e-02]
 [1.82236672e-05 4.78771617e-05 5.94447658e-04 4.50633049e-01
  9.94178176e-01 9.96310651e-01 6.14832752e-05 2.26537809e-02]
 [5.38266962e-04 1.66901969e-04 7.63188908e-03 4.01145995e-01
  9.49286222e-01 9.46371734e-01 5.69216034e-04 3.50264609e-02]
 [2.35285406e-04 1.70880929e-04 2.30611907e-03 3.50294799e-01
  9.66040075e-01 9.64403689e-01 3.22366424e-04 4.09933664e-02]
 [4.65567718e-05 4.10168250e-05 9.83393635e-04 4.21150386e-01
  9.84470844e-01 9.82019722e-01 5.25144787e-05 1.09458575e-02]
 [4.25190628e-05 8.33719241e-05 3.70283145e-03 3.82371217e-01
  9.62562382e-01 9.57170725e-01 5.44450129e-04 5.70098311e-03]
 [2.82422079e-05 1.75969428e-04 3.73603962e-03 3.37534815e-01
  9.53264534e-01 9.69655633e-01 6.97087438e-04 1.18172737e-02]
 [3.26428283e-03 3.42311710e-03 7.58442283e-02 3.04493159e-01
  7.29706109e-01 8.58825147e-01 9.53152962e-03 3.27169932e-02]
 [6.81886030e-03 4.92191501e-03 1.38162404e-01 3.20735633e-01
  7.20697701e-01 8.60914946e-01 1.78195555e-02 4.03544493e-02]
 [4.21638750e-02 1.77968368e-02 2.92899042e-01 3.09524387e-01
  5.20197928e-01 6.87287927e-01 5.41108847e-02 7.34372735e-02]
 [4.81903628e-02 1.83772370e-02 2.81617224e-01 3.19625825e-01
  5.65197766e-01 7.24811137e-01 4.57438342e-02 7.65860528e-02]
 [5.75740449e-03 2.72937119e-03 6.06587492e-02 3.50936979e-01
  8.49144220e-01 9.07365143e-01 8.73990916e-03 6.87072724e-02]
 [9.11813322e-03 3.83393117e-03 6.79619983e-02 3.40465605e-01
  8.00450563e-01 8.45000803e-01 1.51126487e-02 7.50082508e-02]
 [3.32782115e-03 1.72562432e-03 2.85201427e-02 3.42544734e-01
  8.84615302e-01 9.18407142e-01 4.82329307e-03 6.15341067e-02]]
2022-12-18 23:53:46,263 INFO Evaluating teacher test iter22 on 32 examples
2022-12-18 23:53:46,264 INFO teacher test iter22 performance: 1.43
2022-12-18 23:53:46,265 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:46,269 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9440478086471558
2022-12-18 23:53:46,270 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:47,169 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:48,994 INFO Predicting labels for 18 texts
2022-12-18 23:53:49,102 INFO Evaluating student dev iter22 on 18 examples
2022-12-18 23:53:49,103 INFO student dev iter22 performance: 14.56
2022-12-18 23:53:49,103 INFO Predicting labels for 32 texts
2022-12-18 23:53:49,207 INFO Evaluating student test iter22 on 32 examples
2022-12-18 23:53:49,208 INFO student test iter22 performance: 0.66
2022-12-18 23:53:49,208 INFO Student Dev performance on iter 22: 14.562203776808307
2022-12-18 23:53:49,208 INFO Student Test performance on iter 22: 0.6639458671801337
2022-12-18 23:53:49,208 INFO 

	 *** Starting loop 23 ***
2022-12-18 23:53:49,208 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:49,208 INFO Getting rule predictions
2022-12-18 23:53:49,208 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:49,209 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:49,209 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:49,209 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:49,210 INFO Predicting labels for 247 texts
2022-12-18 23:53:49,321 INFO Predicting labels for 18 texts
2022-12-18 23:53:49,427 INFO Predicting labels for 444 texts
2022-12-18 23:53:49,540 INFO Training Rule Attention Network
2022-12-18 23:53:49,542 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:49,542 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:49,545 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:49,545 INFO 

		*** Training RAN ***
2022-12-18 23:53:50,681 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:50,682 INFO Predicting labels for 444 texts
2022-12-18 23:53:51,818 INFO There are 3/7 active rules
2022-12-18 23:53:51,818 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:51,824 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:51,896 INFO DONE, Getting attention scores...
2022-12-18 23:53:51,951 INFO the attention scores are
2022-12-18 23:53:51,952 INFO [[1.3285199e-22 9.9799347e-01 2.5227477e-04 ... 2.5227477e-04
  2.5227477e-04 2.5227477e-04]
 [2.1404929e-22 9.9794799e-01 2.9337927e-04 ... 2.9337927e-04
  2.9337927e-04 2.9337927e-04]
 [1.0178094e-11 1.3855842e-04 9.0716837e-04 ... 9.0716837e-04
  9.0716837e-04 9.0716837e-04]
 ...
 [9.9375027e-27 4.5806266e-02 4.7311887e-11 ... 2.1734902e-06
  2.1734902e-06 2.1734902e-06]
 [1.3483180e-24 1.1338230e-04 4.2334126e-15 ... 5.2502253e-03
  5.2502253e-03 5.2502253e-03]
 [6.6006024e-23 1.2085620e-04 3.0254488e-15 ... 8.1269071e-03
  8.1269071e-03 8.1269071e-03]]
2022-12-18 23:53:51,953 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:51,953 INFO Predicting labels for 18 texts
2022-12-18 23:53:52,057 INFO There are 7/7 active rules
2022-12-18 23:53:52,058 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:52,059 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:52,087 INFO DONE, Getting attention scores...
2022-12-18 23:53:52,140 INFO the attention scores are
2022-12-18 23:53:52,140 INFO [[1.8974980e-03 2.2617606e-03 2.2067275e-02 3.1654629e-01 8.7705165e-01
  8.9682275e-01 3.7908920e-03 2.2236990e-02]
 [6.0886034e-04 8.9486199e-04 8.5309101e-03 3.1583095e-01 9.1870421e-01
  9.2933089e-01 1.7594760e-03 1.5846439e-02]
 [5.1422947e-04 8.2115148e-04 8.0467761e-03 3.2790205e-01 9.0646142e-01
  9.1991550e-01 2.0082863e-03 1.0674631e-02]
 [2.0984176e-03 2.9676671e-03 4.0710788e-02 3.4166190e-01 7.2902960e-01
  8.1563246e-01 1.4868530e-02 5.4524750e-03]
 [7.2249927e-04 1.3473243e-03 2.1961400e-02 3.3054647e-01 8.1215024e-01
  8.7907559e-01 8.2635321e-03 1.1188360e-02]
 [5.8281985e-03 5.7659270e-03 8.7965958e-02 3.1893596e-01 6.3767713e-01
  7.7266067e-01 2.5903678e-02 1.4065901e-02]
 [7.4535422e-03 6.3208570e-03 9.0830341e-02 3.1087592e-01 6.9643247e-01
  7.9996949e-01 2.0819610e-02 2.6414223e-02]
 [2.1336237e-03 2.5717730e-03 3.3194426e-02 3.0692127e-01 8.4914112e-01
  8.9624828e-01 4.9923500e-03 2.6190402e-02]
 [0.0000000e+00 9.9999762e-01 7.3726559e-01 7.2056956e-09 9.3124002e-01
  1.9690967e-06 1.0000000e+00 0.0000000e+00]
 [0.0000000e+00 9.9999988e-01 4.0100154e-09 1.2602534e-05 1.0000000e+00
  5.0867772e-01 1.0000000e+00 0.0000000e+00]
 [3.3766800e-36 1.0000000e+00 3.1918023e-18 7.9010725e-01 1.0000000e+00
  2.5584454e-06 1.0000000e+00 0.0000000e+00]
 [2.0790244e-16 7.5775559e-18 1.1328574e-06 3.0182607e-03 9.9947125e-01
  9.8016500e-01 1.0000000e+00 3.9014238e-26]
 [4.4166874e-37 2.3920084e-26 8.5218620e-31 2.0810127e-08 1.0000000e+00
  1.0000000e+00 3.1504732e-22 1.0000000e+00]
 [2.7660271e-19 1.7439812e-13 5.5676222e-16 2.8207352e-05 1.0000000e+00
  1.0000000e+00 1.0598222e-16 9.6117085e-01]
 [1.3552464e-12 3.0287818e-14 1.8038444e-11 2.0297661e-02 1.0000000e+00
  9.9999738e-01 3.3299654e-13 4.8096201e-04]
 [1.8041812e-15 3.6327193e-12 7.2997346e-09 4.1165668e-01 9.9999845e-01
  9.9997747e-01 5.1066125e-09 1.4155232e-06]
 [1.9438303e-17 5.6093907e-10 5.6468769e-10 2.8454170e-01 9.9999928e-01
  9.9999893e-01 5.4488792e-11 1.1052152e-06]
 [6.2852369e-11 1.6804525e-07 1.4646406e-05 2.8370550e-01 9.9903154e-01
  9.9996185e-01 3.4931807e-06 1.1763411e-05]]
2022-12-18 23:53:52,143 INFO Evaluating teacher dev iter23 on 18 examples
2022-12-18 23:53:52,144 INFO teacher dev iter23 performance: 17.33
2022-12-18 23:53:52,144 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:52,145 INFO Predicting labels for 32 texts
2022-12-18 23:53:52,253 INFO There are 7/7 active rules
2022-12-18 23:53:52,253 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:52,254 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:52,280 INFO DONE, Getting attention scores...
2022-12-18 23:53:52,340 INFO the attention scores are
2022-12-18 23:53:52,340 INFO [[1.89978241e-14 1.00079163e-08 2.96813754e-11 3.78816621e-05
  1.00000000e+00 9.99998212e-01 9.96397197e-01 2.86020846e-10]
 [1.50644235e-04 3.51861429e-09 1.24175822e-05 4.87282887e-05
  9.99998689e-01 9.99999762e-01 2.91329889e-05 9.98123825e-01]
 [6.79585093e-04 3.03765322e-04 1.06228562e-03 5.15518012e-03
  9.97821927e-01 9.97172415e-01 6.70747366e-04 9.96753752e-01]
 [2.46778107e-03 1.04059407e-03 1.78054236e-02 3.56445163e-01
  9.22794878e-01 8.38394165e-01 1.86553330e-03 3.89248244e-02]
 [1.84492135e-04 4.20897646e-04 6.36653835e-03 3.75935704e-01
  9.64688361e-01 9.33155537e-01 3.92971269e-04 5.51523361e-03]
 [1.14546010e-05 2.30380174e-04 5.29069873e-03 3.75111729e-01
  9.70525622e-01 9.63905215e-01 4.53920686e-04 1.27735443e-03]
 [1.74633562e-04 1.58573024e-03 2.94083040e-02 3.24146509e-01
  8.92509162e-01 8.97796094e-01 3.59020312e-03 6.38956204e-03]
 [1.41411612e-04 1.18913106e-03 5.87200746e-02 3.43252152e-01
  9.02619123e-01 9.29642439e-01 4.63828724e-03 6.39017066e-03]
 [5.60442568e-04 1.40120729e-03 3.54233868e-02 3.30481827e-01
  9.16219175e-01 9.38996196e-01 4.16337652e-03 4.95956950e-02]
 [4.78897418e-04 1.11196260e-03 1.55745428e-02 3.02969992e-01
  9.66487288e-01 9.84147549e-01 8.80680978e-04 3.95260341e-02]
 [8.43923131e-04 4.44942387e-04 2.32699029e-02 3.16668272e-01
  9.47633624e-01 9.43205953e-01 8.35874467e-04 3.12104132e-02]
 [1.34527349e-04 1.71249223e-04 5.99859562e-03 3.35134149e-01
  9.71236885e-01 9.66280758e-01 3.68407142e-04 2.43059546e-02]
 [7.40532763e-04 1.90359983e-03 6.83965012e-02 3.42051059e-01
  8.57334495e-01 8.87955964e-01 4.14753146e-03 4.88757575e-03]
 [4.19094198e-04 1.71791529e-03 4.30215634e-02 3.28855872e-01
  8.87301028e-01 9.02596474e-01 5.42962551e-03 1.55682489e-02]
 [1.64690806e-04 9.94391623e-04 2.43248604e-02 3.64163101e-01
  9.43876505e-01 9.60717738e-01 1.79674185e-03 1.76402740e-02]
 [4.14250651e-03 4.03267518e-03 8.18705037e-02 3.22033197e-01
  8.50223780e-01 8.63798916e-01 7.10419053e-03 5.67710400e-02]
 [2.62729936e-05 1.29467764e-04 2.57301843e-03 3.43228281e-01
  9.92908955e-01 9.96444762e-01 1.42996054e-04 2.34560035e-02]
 [1.04559149e-05 3.96912037e-05 6.76345639e-03 3.74081671e-01
  9.90290701e-01 9.93914187e-01 1.92252788e-04 4.34734719e-03]
 [6.64132895e-05 3.10019677e-04 5.01392270e-03 3.38898420e-01
  9.78415549e-01 9.78768170e-01 6.82308106e-04 4.11914811e-02]
 [4.12163399e-06 5.78944528e-05 6.57812867e-04 3.71742189e-01
  9.97649133e-01 9.98443425e-01 2.94831934e-05 1.20646078e-02]
 [2.11680599e-04 1.98622336e-04 7.88370799e-03 3.52543473e-01
  9.66954410e-01 9.49223399e-01 3.61862127e-04 1.92490704e-02]
 [8.07975666e-05 2.72168370e-04 2.56569986e-03 3.10579896e-01
  9.80767429e-01 9.69093859e-01 1.79633615e-04 1.84220430e-02]
 [1.10314932e-05 5.94400990e-05 1.01391249e-03 3.69644344e-01
  9.91346538e-01 9.83132660e-01 3.03272445e-05 3.84323578e-03]
 [1.19314045e-05 1.10831519e-04 4.92220232e-03 3.67905825e-01
  9.73942876e-01 9.66810226e-01 4.03286394e-04 1.66717905e-03]
 [8.00921316e-06 2.65272538e-04 4.98864427e-03 3.18741560e-01
  9.64867115e-01 9.77629900e-01 5.39655797e-04 3.77580430e-03]
 [1.87350053e-03 5.87681308e-03 9.96402949e-02 2.94110268e-01
  7.46302187e-01 8.63543391e-01 8.80300440e-03 1.25943916e-02]
 [4.19244822e-03 6.75103627e-03 1.60230309e-01 3.10546637e-01
  7.39232123e-01 8.62638831e-01 1.42022567e-02 2.00527869e-02]
 [4.34875004e-02 2.77840868e-02 3.44095349e-01 2.94774890e-01
  5.14781177e-01 6.87403798e-01 5.22666164e-02 3.89839858e-02]
 [4.65395637e-02 3.00433915e-02 3.20752650e-01 3.01976889e-01
  5.56306124e-01 7.27790296e-01 4.43624072e-02 4.25693765e-02]
 [3.33472551e-03 3.92996427e-03 6.91560432e-02 3.26107860e-01
  8.53662193e-01 9.19349909e-01 6.77170698e-03 3.68049480e-02]
 [5.93056343e-03 5.65295946e-03 8.30311701e-02 3.21885198e-01
  7.90206313e-01 8.46301734e-01 1.35401906e-02 3.98785956e-02]
 [1.76479993e-03 2.54397583e-03 3.45944501e-02 3.19437027e-01
  8.80270183e-01 9.24702823e-01 3.91271198e-03 2.93078627e-02]]
2022-12-18 23:53:52,345 INFO Evaluating teacher test iter23 on 32 examples
2022-12-18 23:53:52,346 INFO teacher test iter23 performance: 1.36
2022-12-18 23:53:52,346 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:52,352 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.9506192207336426
2022-12-18 23:53:52,352 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:53,161 INFO fine-tuning the student on clean labeled data
2022-12-18 23:53:55,009 INFO Predicting labels for 18 texts
2022-12-18 23:53:55,120 INFO Evaluating student dev iter23 on 18 examples
2022-12-18 23:53:55,121 INFO student dev iter23 performance: 14.53
2022-12-18 23:53:55,122 INFO Predicting labels for 32 texts
2022-12-18 23:53:55,226 INFO Evaluating student test iter23 on 32 examples
2022-12-18 23:53:55,227 INFO student test iter23 performance: 0.66
2022-12-18 23:53:55,227 INFO Student Dev performance on iter 23: 14.532489542450556
2022-12-18 23:53:55,227 INFO Student Test performance on iter 23: 0.6562866988422067
2022-12-18 23:53:55,227 INFO 

	 *** Starting loop 24 ***
2022-12-18 23:53:55,227 INFO Adding Student as extra rule in Teacher
2022-12-18 23:53:55,227 INFO Getting rule predictions
2022-12-18 23:53:55,227 INFO Applying Teacher with 7 LF(s) on 247 data
2022-12-18 23:53:55,228 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:55,228 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:55,228 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:53:55,229 INFO Predicting labels for 247 texts
2022-12-18 23:53:55,450 INFO Predicting labels for 18 texts
2022-12-18 23:53:55,560 INFO Predicting labels for 444 texts
2022-12-18 23:53:55,675 INFO Training Rule Attention Network
2022-12-18 23:53:55,677 INFO X Train Shape (247, 7) (247, 8) (247,)
2022-12-18 23:53:55,677 INFO X Dev Shape (18, 7) (18, 8) (18,)
2022-12-18 23:53:55,679 INFO X Unsup Shape (444, 7) (444, 8)
2022-12-18 23:53:55,679 INFO 

		*** Training RAN ***
2022-12-18 23:53:56,815 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:53:56,816 INFO Predicting labels for 444 texts
2022-12-18 23:53:56,928 INFO There are 3/7 active rules
2022-12-18 23:53:56,928 INFO Coverage: 100.0% (444/444)
2022-12-18 23:53:56,931 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:53:57,005 INFO DONE, Getting attention scores...
2022-12-18 23:53:57,061 INFO the attention scores are
2022-12-18 23:53:57,061 INFO [[1.8425878e-24 9.9884713e-01 2.6939559e-05 ... 2.6939559e-05
  2.6939559e-05 2.6939559e-05]
 [3.1847143e-24 9.9883074e-01 3.1575779e-05 ... 3.1575779e-05
  3.1575779e-05 3.1575779e-05]
 [2.1915099e-13 9.5176641e-05 1.0919475e-03 ... 1.0919475e-03
  1.0919475e-03 1.0919475e-03]
 ...
 [2.9430453e-30 8.3117448e-03 9.9357935e-09 ... 2.4439275e-06
  2.4439275e-06 2.4439275e-06]
 [9.8370910e-29 7.9014380e-06 8.4183955e-14 ... 1.0919520e-02
  1.0919520e-02 1.0919520e-02]
 [6.9136648e-27 7.5099838e-06 3.5629011e-14 ... 1.8007990e-02
  1.8007990e-02 1.8007990e-02]]
2022-12-18 23:53:57,062 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:53:57,062 INFO Predicting labels for 18 texts
2022-12-18 23:53:57,175 INFO There are 7/7 active rules
2022-12-18 23:53:57,175 INFO Coverage: 100.0% (18/18)
2022-12-18 23:53:57,176 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:53:57,198 INFO DONE, Getting attention scores...
2022-12-18 23:53:57,255 INFO the attention scores are
2022-12-18 23:53:57,256 INFO [[6.8857195e-04 1.7882201e-03 8.6165126e-03 3.1338662e-01 9.3028617e-01
  9.4123507e-01 1.6064248e-03 1.1437393e-02]
 [1.5386932e-04 6.8856019e-04 2.9010547e-03 3.1778693e-01 9.5982605e-01
  9.6657825e-01 6.6069234e-04 6.9043608e-03]
 [1.0017074e-04 6.8868842e-04 2.4811185e-03 3.2761216e-01 9.5594525e-01
  9.6269518e-01 6.8893225e-04 3.8614080e-03]
 [3.5367420e-04 2.6170337e-03 1.5116453e-02 3.4249383e-01 8.5254484e-01
  9.0096486e-01 5.0505796e-03 3.2209102e-03]
 [1.2084826e-04 1.1872698e-03 7.5550131e-03 3.2153904e-01 8.9800715e-01
  9.3964231e-01 3.1382742e-03 4.6443716e-03]
 [1.1901758e-03 5.4115122e-03 3.9975680e-02 3.0990422e-01 7.7260232e-01
  8.6058015e-01 1.1150763e-02 8.8448301e-03]
 [2.2458620e-03 5.3483169e-03 4.0789932e-02 3.0233040e-01 8.0466878e-01
  8.7839592e-01 9.5257778e-03 1.5868042e-02]
 [6.6553388e-04 2.0562136e-03 1.3404473e-02 3.0503485e-01 9.1158265e-01
  9.4463319e-01 2.3593060e-03 1.3962254e-02]
 [0.0000000e+00 9.9999666e-01 9.9998772e-01 2.8810444e-08 6.5445310e-01
  4.7441176e-08 1.0000000e+00 0.0000000e+00]
 [0.0000000e+00 9.9999988e-01 6.6744933e-06 1.3644260e-05 1.0000000e+00
  1.4874978e-02 1.0000000e+00 0.0000000e+00]
 [0.0000000e+00 1.0000000e+00 1.1076842e-16 8.2192987e-01 1.0000000e+00
  5.7649453e-05 1.0000000e+00 0.0000000e+00]
 [2.2179228e-20 4.5398743e-19 1.6338176e-05 1.8699230e-03 8.7595505e-01
  9.9357879e-01 1.0000000e+00 2.9469371e-27]
 [0.0000000e+00 1.8466432e-29 5.3395163e-33 3.2820889e-08 1.0000000e+00
  1.0000000e+00 1.0095461e-18 1.0000000e+00]
 [1.7824384e-18 4.0283938e-15 2.4550779e-16 4.6000659e-05 1.0000000e+00
  1.0000000e+00 7.1686029e-16 9.9621767e-01]
 [1.6242644e-13 3.0429496e-15 1.9351319e-11 5.5582128e-02 1.0000000e+00
  9.9999738e-01 2.9845519e-13 6.0099610e-05]
 [2.0690466e-17 3.8006992e-13 6.6607671e-11 4.5450935e-01 9.9999988e-01
  9.9999499e-01 7.2259615e-11 2.1297821e-07]
 [3.5252874e-19 2.3302755e-09 3.4994091e-11 4.0032893e-01 9.9999988e-01
  9.9999976e-01 4.7032673e-12 2.5770092e-07]
 [4.5760817e-12 2.8825153e-07 2.0775303e-06 2.7024618e-01 9.9982387e-01
  9.9998844e-01 9.2609133e-07 5.8046376e-06]]
2022-12-18 23:53:57,259 INFO Evaluating teacher dev iter24 on 18 examples
2022-12-18 23:53:57,260 INFO teacher dev iter24 performance: 13.15
2022-12-18 23:53:57,260 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:53:57,260 INFO Predicting labels for 32 texts
2022-12-18 23:53:57,370 INFO There are 7/7 active rules
2022-12-18 23:53:57,370 INFO Coverage: 100.0% (32/32)
2022-12-18 23:53:57,370 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:53:57,395 INFO DONE, Getting attention scores...
2022-12-18 23:53:57,448 INFO the attention scores are
2022-12-18 23:53:57,449 INFO [[1.01444951e-17 4.84584595e-10 6.16181273e-11 1.94378590e-05
  1.00000000e+00 9.99999881e-01 9.99989629e-01 1.30673483e-09]
 [8.72697171e-07 1.35643483e-10 6.14810779e-06 4.15945979e-05
  9.99997973e-01 1.00000000e+00 4.97434346e-04 9.99835610e-01]
 [7.69062899e-05 1.47883875e-05 4.01240017e-04 7.50737172e-03
  9.98498917e-01 9.97021854e-01 8.45690491e-04 9.96543705e-01]
 [1.47218187e-03 7.20886746e-04 6.88644452e-03 4.05974060e-01
  9.61490095e-01 8.87261331e-01 7.93161686e-04 1.38575602e-02]
 [3.65063097e-05 2.65321607e-04 2.16115243e-03 4.03365254e-01
  9.79082108e-01 9.60853577e-01 1.22553698e-04 1.42159523e-03]
 [2.23881534e-06 2.15671840e-04 1.49654434e-03 3.83536458e-01
  9.82192755e-01 9.80206490e-01 1.33996044e-04 3.98728589e-04]
 [3.84455489e-05 1.29460718e-03 9.09975544e-03 3.46260726e-01
  9.24495101e-01 9.35321033e-01 1.28382142e-03 2.05498119e-03]
 [3.98193479e-05 7.57164904e-04 1.92426667e-02 3.63887876e-01
  9.36254501e-01 9.49997067e-01 1.91464589e-03 3.36052710e-03]
 [2.24115953e-04 1.08390523e-03 1.72675774e-02 3.41255426e-01
  9.35855687e-01 9.32052314e-01 2.32097739e-03 3.37479562e-02]
 [3.09269875e-04 7.39342824e-04 8.91199894e-03 3.37502211e-01
  9.69526827e-01 9.79101181e-01 5.73387602e-04 2.64689140e-02]
 [3.24735389e-04 2.24519303e-04 8.97720736e-03 3.63953292e-01
  9.65328038e-01 9.57283139e-01 4.31056251e-04 1.35019151e-02]
 [2.59346652e-05 9.60692487e-05 2.01792549e-03 3.56897920e-01
  9.84615982e-01 9.80614483e-01 1.24993298e-04 8.15098919e-03]
 [2.19534326e-04 1.12234813e-03 2.22222786e-02 3.68400604e-01
  9.08627987e-01 9.25078511e-01 1.60657160e-03 2.26478535e-03]
 [1.13257061e-04 1.37868815e-03 1.57620572e-02 3.42350125e-01
  9.26623464e-01 9.31321561e-01 2.12761899e-03 8.01759679e-03]
 [5.38787717e-05 9.44214989e-04 1.11963609e-02 3.67827505e-01
  9.53924954e-01 9.58768427e-01 9.02027998e-04 8.79795849e-03]
 [1.65260735e-03 2.50233803e-03 4.17504460e-02 3.36089820e-01
  8.80931079e-01 8.91034067e-01 3.89773212e-03 2.97876764e-02]
 [1.07241585e-05 9.37551886e-05 1.32687122e-03 3.70122463e-01
  9.95084107e-01 9.95675862e-01 7.18920710e-05 1.08477073e-02]
 [2.66691063e-06 2.81418997e-05 2.29133246e-03 3.85027707e-01
  9.93279159e-01 9.92867470e-01 8.70349759e-05 1.82415009e-03]
 [1.77867259e-05 2.17409426e-04 2.33632606e-03 3.42338443e-01
  9.84551728e-01 9.77531910e-01 2.65296811e-04 1.81052182e-02]
 [1.16289857e-06 5.17531917e-05 2.71481316e-04 4.13194627e-01
  9.98417497e-01 9.98256862e-01 1.23101900e-05 4.01015254e-03]
 [4.12874142e-05 1.09229710e-04 2.59125046e-03 3.87926221e-01
  9.81601238e-01 9.68877554e-01 1.21083343e-04 5.24016097e-03]
 [1.64805806e-05 1.65029094e-04 8.74446880e-04 3.33276957e-01
  9.90034401e-01 9.85721111e-01 4.86246354e-05 5.49394405e-03]
 [1.79499432e-06 3.98832708e-05 3.06532864e-04 4.09186780e-01
  9.95636046e-01 9.92558002e-01 8.15262774e-06 7.99850735e-04]
 [1.94713789e-06 8.04502924e-05 1.25663530e-03 3.78053308e-01
  9.86842453e-01 9.80747402e-01 9.76824304e-05 5.79198939e-04]
 [1.28227850e-06 2.76039180e-04 1.26073125e-03 3.29951495e-01
  9.80377138e-01 9.88223791e-01 1.55327230e-04 1.50961545e-03]
 [5.57180494e-04 3.93083040e-03 3.42298821e-02 3.15640956e-01
  8.29593718e-01 9.13406551e-01 3.64381890e-03 7.67839607e-03]
 [1.51989330e-03 4.35898500e-03 6.84642717e-02 3.26556563e-01
  8.10943663e-01 9.01451468e-01 6.85684197e-03 1.20356446e-02]
 [1.54602574e-02 1.58065408e-02 1.86317354e-01 3.15265656e-01
  6.19016588e-01 7.64185190e-01 2.58136746e-02 2.65872143e-02]
 [2.34714095e-02 2.21170839e-02 1.89364776e-01 3.12187999e-01
  6.27515256e-01 7.98445165e-01 2.69654784e-02 2.98262443e-02]
 [1.41416129e-03 3.08212987e-03 3.30999605e-02 3.22718412e-01
  8.93261015e-01 9.42970693e-01 4.15285816e-03 2.14907713e-02]
 [2.04519648e-03 4.41546598e-03 3.92994024e-02 3.14027011e-01
  8.59826982e-01 9.04928863e-01 7.31672579e-03 2.29671933e-02]
 [6.17169193e-04 2.12472654e-03 1.52987521e-02 3.12986612e-01
  9.25013721e-01 9.53232944e-01 2.02330947e-03 1.61183756e-02]]
2022-12-18 23:53:57,468 INFO Evaluating teacher test iter24 on 32 examples
2022-12-18 23:53:57,471 INFO teacher test iter24 performance: 1.46
2022-12-18 23:53:57,472 INFO Saving attention scores at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_dump
2022-12-18 23:53:57,476 INFO PSEUDO-DATASET:
444 examples
 with mean PSEUDO-LABELS:
1.939495325088501
2022-12-18 23:53:57,476 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:53:59,327 INFO fine-tuning the student on clean labeled data
2022-12-18 23:54:01,130 INFO Predicting labels for 18 texts
2022-12-18 23:54:01,229 INFO Evaluating student dev iter24 on 18 examples
2022-12-18 23:54:01,230 INFO student dev iter24 performance: 14.49
2022-12-18 23:54:01,230 INFO Predicting labels for 32 texts
2022-12-18 23:54:01,356 INFO Evaluating student test iter24 on 32 examples
2022-12-18 23:54:01,357 INFO student test iter24 performance: 0.65
2022-12-18 23:54:01,357 INFO Student Dev performance on iter 24: 14.489120040208576
2022-12-18 23:54:01,357 INFO Student Test performance on iter 24: 0.6455880296048703
2022-12-18 23:54:01,357 INFO Final Results
2022-12-18 23:54:01,357 INFO TEACHER PERFORMANCES:
0:	10.07	0.29
1:	25.70	1.97
2:	13.87	1.56
3:	13.08	1.30
4:	13.81	1.50
5:	13.39	1.61
6:	14.61	1.51
7:	9.83	1.44
8:	11.07	1.56
9:	11.40	1.59
10:	10.97	1.47
11:	10.50	1.36
12:	12.21	1.39
13:	12.26	1.41
14:	11.88	1.49
15:	18.11	1.43
16:	18.54	1.36
17:	12.45	1.32
18:	13.30	1.41
19:	20.53	1.41
20:	13.25	1.32
21:	14.58	1.33
22:	13.89	1.31
23:	13.56	1.43
24:	17.33	1.36
25:	13.15	1.46
2022-12-18 23:54:01,358 INFO STUDENT PERFORMANCES:
0:	12.72	1.67
1:	12.71	1.32
2:	12.78	1.06
3:	12.89	0.87
4:	13.05	0.72
5:	13.24	0.62
6:	13.44	0.57
7:	13.66	0.54
8:	13.86	0.54
9:	14.04	0.55
10:	14.20	0.56
11:	14.34	0.58
12:	14.43	0.60
13:	14.50	0.62
14:	14.55	0.64
15:	14.59	0.65
16:	14.62	0.66
17:	14.63	0.67
18:	14.64	0.68
19:	14.64	0.68
20:	14.63	0.68
21:	14.62	0.68
22:	14.60	0.67
23:	14.56	0.66
24:	14.53	0.66
25:	14.49	0.65
2022-12-18 23:54:01,358 INFO BEST DEV mse = 12.711 for epoch 1
2022-12-18 23:54:01,358 INFO FINAL TEST mse = 1.322 for epoch 1 (min=0.54 for epoch 8)
2022-12-18 23:54:01,358 INFO Saving student_last to ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/student_last
2022-12-18 23:54:01,358 INFO Saving model at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/student_last/final_model.h5
2022-12-18 23:54:01,366 INFO Saving teacher at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_last
2022-12-18 23:54:01,366 INFO Saving rule attention network at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/teacher_last/rule_attention_network.h5
2022-12-18 23:54:01,374 INFO 	*** Final Results ***
2022-12-18 23:54:01,374 INFO 
student_train:	{'dev_loss': 12.724145889282227}
2022-12-18 23:54:01,374 INFO 
supervised_student_dev:	{'mse': 12.724145315072679, 'r2': 16.943265386491813, 'var_explained': 17.69760274046067, 'ignored': 0, 'total': 18, 'perf': 12.724145315072679}
2022-12-18 23:54:01,374 INFO 
supervised_student_test:	{'mse': 1.6734363736602704, 'r2': -303.04758755788885, 'var_explained': -6.639555480424364, 'ignored': 0, 'total': 32, 'perf': 1.6734363736602704}
2022-12-18 23:54:01,374 INFO 
teacher_train:	{'mse': 1.964282890845551, 'r2': 73.43854672719033, 'var_explained': 74.21887383947193, 'ignored': 0, 'total': 247, 'perf': 1.964282890845551}
2022-12-18 23:54:01,374 INFO 
teacher_dev:	{'mse': 25.696180391832982, 'r2': -67.73156723203569, 'var_explained': -67.72010688657268, 'ignored': 0, 'total': 18, 'perf': 25.696180391832982}
2022-12-18 23:54:01,374 INFO 
teacher_test:	{'mse': 1.9670350395943883, 'r2': -373.7609029115708, 'var_explained': 28.360787720456415, 'ignored': 0, 'total': 32, 'perf': 1.9670350395943883}
2022-12-18 23:54:01,374 INFO 
teacher_train_iter:	[{'mse': 1.964282890845551, 'r2': 73.43854672719033, 'var_explained': 74.21887383947193, 'ignored': 0, 'total': 247, 'perf': 1.964282890845551}]
2022-12-18 23:54:01,374 INFO 
teacher_dev_iter:	[{'mse': 10.06782251954834, 'r2': 34.28238656222455, 'var_explained': 35.437258352947275, 'ignored': 0, 'total': 18, 'perf': 10.06782251954834}, {'mse': 25.696180391832982, 'r2': -67.73156723203569, 'var_explained': -67.72010688657268, 'ignored': 0, 'total': 18, 'perf': 25.696180391832982}, {'mse': 13.868156667384628, 'r2': 9.47574242671717, 'var_explained': 9.591168874152112, 'ignored': 0, 'total': 18, 'perf': 13.868156667384628}, {'mse': 13.077510046379178, 'r2': 14.636680544590408, 'var_explained': 15.002200137881495, 'ignored': 0, 'total': 18, 'perf': 13.077510046379178}, {'mse': 13.810206858713975, 'r2': 9.854009238395312, 'var_explained': 10.611899446957384, 'ignored': 0, 'total': 18, 'perf': 13.810206858713975}, {'mse': 13.3938829063353, 'r2': 12.571559782635145, 'var_explained': 12.615403640484946, 'ignored': 0, 'total': 18, 'perf': 13.3938829063353}, {'mse': 14.607772623031833, 'r2': 4.647906479941422, 'var_explained': 4.654861583581715, 'ignored': 0, 'total': 18, 'perf': 14.607772623031833}, {'mse': 9.827251569286538, 'r2': 35.85271109694557, 'var_explained': 35.86691019792671, 'ignored': 0, 'total': 18, 'perf': 9.827251569286538}, {'mse': 11.067118139318485, 'r2': 27.75949413711427, 'var_explained': 28.33659643130507, 'ignored': 0, 'total': 18, 'perf': 11.067118139318485}, {'mse': 11.395732272169504, 'r2': 25.61446858556513, 'var_explained': 25.787166151429574, 'ignored': 0, 'total': 18, 'perf': 11.395732272169504}, {'mse': 10.97107733666431, 'r2': 28.386399541021202, 'var_explained': 28.415808163677212, 'ignored': 0, 'total': 18, 'perf': 10.97107733666431}, {'mse': 10.497013710017718, 'r2': 31.480845246671983, 'var_explained': 31.5204216177596, 'ignored': 0, 'total': 18, 'perf': 10.497013710017718}, {'mse': 12.205800688723135, 'r2': 20.326754886415543, 'var_explained': 20.987002046845582, 'ignored': 0, 'total': 18, 'perf': 12.205800688723135}, {'mse': 12.261443054020056, 'r2': 19.963549888885403, 'var_explained': 20.126865252907066, 'ignored': 0, 'total': 18, 'perf': 12.261443054020056}, {'mse': 11.878222653953365, 'r2': 22.46501731783073, 'var_explained': 22.607626638857635, 'ignored': 0, 'total': 18, 'perf': 11.878222653953365}, {'mse': 18.106255265480513, 'r2': -18.18840489412159, 'var_explained': -18.167462787521238, 'ignored': 0, 'total': 18, 'perf': 18.106255265480513}, {'mse': 18.535171878463885, 'r2': -20.988153907808595, 'var_explained': -20.937584716118952, 'ignored': 0, 'total': 18, 'perf': 18.535171878463885}, {'mse': 12.45358042240641, 'r2': 18.70937508812297, 'var_explained': 18.951231063633767, 'ignored': 0, 'total': 18, 'perf': 12.45358042240641}, {'mse': 13.304866472241692, 'r2': 13.152613689178938, 'var_explained': 13.729007343438104, 'ignored': 0, 'total': 18, 'perf': 13.304866472241692}, {'mse': 20.53462650785688, 'r2': -34.03957452688344, 'var_explained': -32.662427955473625, 'ignored': 0, 'total': 18, 'perf': 20.53462650785688}, {'mse': 13.247499654298256, 'r2': 13.527075034563385, 'var_explained': 14.044839975067724, 'ignored': 0, 'total': 18, 'perf': 13.247499654298256}, {'mse': 14.580766013225976, 'r2': 4.824191862410188, 'var_explained': 5.866637472829228, 'ignored': 0, 'total': 18, 'perf': 14.580766013225976}, {'mse': 13.89261952288887, 'r2': 9.316061375676554, 'var_explained': 9.98564397215369, 'ignored': 0, 'total': 18, 'perf': 13.89261952288887}, {'mse': 13.556286895744476, 'r2': 11.511469323549106, 'var_explained': 12.279605260321603, 'ignored': 0, 'total': 18, 'perf': 13.556286895744476}, {'mse': 17.3296447330993, 'r2': -13.119087208034363, 'var_explained': -13.084723839920676, 'ignored': 0, 'total': 18, 'perf': 17.3296447330993}, {'mse': 13.151882265820346, 'r2': 14.151216606558714, 'var_explained': 14.475102936054473, 'ignored': 0, 'total': 18, 'perf': 13.151882265820346}]
2022-12-18 23:54:01,375 INFO 
teacher_test_iter:	[{'mse': 0.29446293547838565, 'r2': 29.078525100906084, 'var_explained': 29.35653434829424, 'ignored': 0, 'total': 32, 'perf': 0.29446293547838565}, {'mse': 1.9670350395943883, 'r2': -373.7609029115708, 'var_explained': 28.360787720456415, 'ignored': 0, 'total': 32, 'perf': 1.9670350395943883}, {'mse': 1.5555130532341124, 'r2': -274.64572504152653, 'var_explained': 0.8090433049057988, 'ignored': 0, 'total': 32, 'perf': 1.5555130532341124}, {'mse': 1.299522734708109, 'r2': -212.99038998124814, 'var_explained': 26.232236628472847, 'ignored': 0, 'total': 32, 'perf': 1.299522734708109}, {'mse': 1.5010559206553575, 'r2': -261.52971044027873, 'var_explained': 8.018530266433165, 'ignored': 0, 'total': 32, 'perf': 1.5010559206553575}, {'mse': 1.6078045443547366, 'r2': -287.2401443320989, 'var_explained': -9.523424896900657, 'ignored': 0, 'total': 32, 'perf': 1.6078045443547366}, {'mse': 1.5087540906578227, 'r2': -263.38381669549153, 'var_explained': -13.159626708103156, 'ignored': 0, 'total': 32, 'perf': 1.5087540906578227}, {'mse': 1.437355526424867, 'r2': -246.18745385664246, 'var_explained': -11.148450413757338, 'ignored': 0, 'total': 32, 'perf': 1.437355526424867}, {'mse': 1.5611499054287576, 'r2': -276.00336236448186, 'var_explained': 9.081065378689201, 'ignored': 0, 'total': 32, 'perf': 1.5611499054287576}, {'mse': 1.5873782140179418, 'r2': -282.3204573368304, 'var_explained': -24.02009251434576, 'ignored': 0, 'total': 32, 'perf': 1.5873782140179418}, {'mse': 1.4690796156027144, 'r2': -253.82820901880945, 'var_explained': -28.840621106141118, 'ignored': 0, 'total': 32, 'perf': 1.4690796156027144}, {'mse': 1.3632022279923461, 'r2': -228.32761256652168, 'var_explained': -26.78021077061077, 'ignored': 0, 'total': 32, 'perf': 1.3632022279923461}, {'mse': 1.3946868971527877, 'r2': -235.91070335497997, 'var_explained': -14.3511923269376, 'ignored': 0, 'total': 32, 'perf': 1.3946868971527877}, {'mse': 1.4083267045460128, 'r2': -239.1958545272167, 'var_explained': -15.778878333135538, 'ignored': 0, 'total': 32, 'perf': 1.4083267045460128}, {'mse': 1.4888940034701932, 'r2': -258.60050951055496, 'var_explained': -19.28812896518506, 'ignored': 0, 'total': 32, 'perf': 1.4888940034701932}, {'mse': 1.4292082053031845, 'r2': -244.22516943708544, 'var_explained': -19.65194776590011, 'ignored': 0, 'total': 32, 'perf': 1.4292082053031845}, {'mse': 1.3566877105209794, 'r2': -226.75858933249512, 'var_explained': -26.12768048403855, 'ignored': 0, 'total': 32, 'perf': 1.3566877105209794}, {'mse': 1.3227924592629354, 'r2': -218.5949092163866, 'var_explained': -18.258628509816212, 'ignored': 0, 'total': 32, 'perf': 1.3227924592629354}, {'mse': 1.4112776518150227, 'r2': -239.9065909474987, 'var_explained': -23.114285636639686, 'ignored': 0, 'total': 32, 'perf': 1.4112776518150227}, {'mse': 1.4134737244729298, 'r2': -240.43551562058641, 'var_explained': -20.790252134138054, 'ignored': 0, 'total': 32, 'perf': 1.4134737244729298}, {'mse': 1.3243413519009124, 'r2': -218.96796041268476, 'var_explained': -7.851274108497197, 'ignored': 0, 'total': 32, 'perf': 1.3243413519009124}, {'mse': 1.3269077181720894, 'r2': -219.58607039921824, 'var_explained': -27.408667617421667, 'ignored': 0, 'total': 32, 'perf': 1.3269077181720894}, {'mse': 1.3145794959391872, 'r2': -216.6168148553218, 'var_explained': -28.597515067369738, 'ignored': 0, 'total': 32, 'perf': 1.3145794959391872}, {'mse': 1.4262775954802192, 'r2': -243.5193312959937, 'var_explained': -19.380064376451433, 'ignored': 0, 'total': 32, 'perf': 1.4262775954802192}, {'mse': 1.3597863615531294, 'r2': -227.5049002426973, 'var_explained': -20.488531730758996, 'ignored': 0, 'total': 32, 'perf': 1.3597863615531294}, {'mse': 1.456938934989482, 'r2': -250.90412292298066, 'var_explained': -15.474993526540937, 'ignored': 0, 'total': 32, 'perf': 1.456938934989482}]
2022-12-18 23:54:01,375 INFO 
student_train_iter:	[{'dev_loss': 12.724145889282227}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]
2022-12-18 23:54:01,376 INFO 
student_dev_iter:	[{'mse': 12.724145315072679, 'r2': 16.943265386491813, 'var_explained': 17.69760274046067, 'ignored': 0, 'total': 18, 'perf': 12.724145315072679}, {'mse': 12.710674436239168, 'r2': 17.031196416873883, 'var_explained': 17.180007676159892, 'ignored': 0, 'total': 18, 'perf': 12.710674436239168}, {'mse': 12.779571103368271, 'r2': 16.581474093228422, 'var_explained': 16.582505483596634, 'ignored': 0, 'total': 18, 'perf': 12.779571103368271}, {'mse': 12.893538571084346, 'r2': 15.83755255773207, 'var_explained': 16.000138488870398, 'ignored': 0, 'total': 18, 'perf': 12.893538571084346}, {'mse': 13.054550715548805, 'r2': 14.786547352966384, 'var_explained': 15.32341233541591, 'ignored': 0, 'total': 18, 'perf': 13.054550715548805}, {'mse': 13.242729618634646, 'r2': 13.5582113958984, 'var_explained': 14.623627458655497, 'ignored': 0, 'total': 18, 'perf': 13.242729618634646}, {'mse': 13.444849123420921, 'r2': 12.238878297009514, 'var_explained': 13.930617405862279, 'ignored': 0, 'total': 18, 'perf': 13.444849123420921}, {'mse': 13.655488491399117, 'r2': 10.863931874117128, 'var_explained': 13.231123613443796, 'ignored': 0, 'total': 18, 'perf': 13.655488491399117}, {'mse': 13.860118407698948, 'r2': 9.528212088524413, 'var_explained': 12.544960977084695, 'ignored': 0, 'total': 18, 'perf': 13.860118407698948}, {'mse': 14.041453665074716, 'r2': 8.344547962173198, 'var_explained': 11.951514440173739, 'ignored': 0, 'total': 18, 'perf': 14.041453665074716}, {'mse': 14.20288805983501, 'r2': 7.290786522714077, 'var_explained': 11.419910930275034, 'ignored': 0, 'total': 18, 'perf': 14.20288805983501}, {'mse': 14.336710584591007, 'r2': 6.417261295773913, 'var_explained': 11.00602558672289, 'ignored': 0, 'total': 18, 'perf': 14.336710584591007}, {'mse': 14.430762885398899, 'r2': 5.803335818300981, 'var_explained': 10.74176670300977, 'ignored': 0, 'total': 18, 'perf': 14.430762885398899}, {'mse': 14.50157818206178, 'r2': 5.341089659060849, 'var_explained': 10.554485213497244, 'ignored': 0, 'total': 18, 'perf': 14.50157818206178}, {'mse': 14.55343032912527, 'r2': 5.002625274133454, 'var_explained': 10.434752007567837, 'ignored': 0, 'total': 18, 'perf': 14.55343032912527}, {'mse': 14.589040864969515, 'r2': 4.770177848249624, 'var_explained': 10.369996847593676, 'ignored': 0, 'total': 18, 'perf': 14.589040864969515}, {'mse': 14.615251422068834, 'r2': 4.599088692069408, 'var_explained': 10.340319565505474, 'ignored': 0, 'total': 18, 'perf': 14.615251422068834}, {'mse': 14.632777300789396, 'r2': 4.48468868941948, 'var_explained': 10.339254446311209, 'ignored': 0, 'total': 18, 'perf': 14.632777300789396}, {'mse': 14.64072645650085, 'r2': 4.432800652936153, 'var_explained': 10.37046640880861, 'ignored': 0, 'total': 18, 'perf': 14.64072645650085}, {'mse': 14.63880607297699, 'r2': 4.445335937684003, 'var_explained': 10.43623127811516, 'ignored': 0, 'total': 18, 'perf': 14.63880607297699}, {'mse': 14.630733114251788, 'r2': 4.498032097133764, 'var_explained': 10.49561350058541, 'ignored': 0, 'total': 18, 'perf': 14.630733114251788}, {'mse': 14.617923133181149, 'r2': 4.581649123805698, 'var_explained': 10.557774590300806, 'ignored': 0, 'total': 18, 'perf': 14.617923133181149}, {'mse': 14.59733439430789, 'r2': 4.716041916270708, 'var_explained': 10.627915719458647, 'ignored': 0, 'total': 18, 'perf': 14.59733439430789}, {'mse': 14.562203776808307, 'r2': 4.945356679834056, 'var_explained': 10.738106443643602, 'ignored': 0, 'total': 18, 'perf': 14.562203776808307}, {'mse': 14.532489542450556, 'r2': 5.139316055193577, 'var_explained': 10.831928772852994, 'ignored': 0, 'total': 18, 'perf': 14.532489542450556}, {'mse': 14.489120040208576, 'r2': 5.422410058667825, 'var_explained': 10.972281545883556, 'ignored': 0, 'total': 18, 'perf': 14.489120040208576}]
2022-12-18 23:54:01,376 INFO 
student_test_iter:	[{'mse': 1.6734363736602704, 'r2': -303.04758755788885, 'var_explained': -6.639555480424364, 'ignored': 0, 'total': 32, 'perf': 1.6734363736602704}, {'mse': 1.3221550267137934, 'r2': -218.4413834204816, 'var_explained': -8.469440899897783, 'ignored': 0, 'total': 32, 'perf': 1.3221550267137934}, {'mse': 1.062718319254087, 'r2': -155.95598468561192, 'var_explained': -10.75268910218188, 'ignored': 0, 'total': 32, 'perf': 1.062718319254087}, {'mse': 0.8666216385974859, 'r2': -108.72604794539482, 'var_explained': -13.462228473271033, 'ignored': 0, 'total': 32, 'perf': 0.8666216385974859}, {'mse': 0.7239477152635393, 'r2': -74.3629962559014, 'var_explained': -16.28726205867075, 'ignored': 0, 'total': 32, 'perf': 0.7239477152635393}, {'mse': 0.6245617363022478, 'r2': -50.4258572717575, 'var_explained': -19.448703814874936, 'ignored': 0, 'total': 32, 'perf': 0.6245617363022478}, {'mse': 0.565933929536388, 'r2': -36.305334703513736, 'var_explained': -22.87619270415775, 'ignored': 0, 'total': 32, 'perf': 0.565933929536388}, {'mse': 0.539798271868872, 'r2': -30.010554729841598, 'var_explained': -26.316986881097826, 'ignored': 0, 'total': 32, 'perf': 0.539798271868872}, {'mse': 0.5370303789857995, 'r2': -29.343907006211168, 'var_explained': -29.151860912104866, 'ignored': 0, 'total': 32, 'perf': 0.5370303789857995}, {'mse': 0.5465375766291339, 'r2': -31.633718041094227, 'var_explained': -30.957789383809796, 'ignored': 0, 'total': 32, 'perf': 0.5465375766291339}, {'mse': 0.563597424912806, 'r2': -35.74258695482413, 'var_explained': -32.18228435443442, 'ignored': 0, 'total': 32, 'perf': 0.563597424912806}, {'mse': 0.584691081190684, 'r2': -40.822999577252304, 'var_explained': -32.98764618804935, 'ignored': 0, 'total': 32, 'perf': 0.584691081190684}, {'mse': 0.6049954729962215, 'r2': -45.713317645427296, 'var_explained': -33.46587668249399, 'ignored': 0, 'total': 32, 'perf': 0.6049954729962215}, {'mse': 0.6219512721798007, 'r2': -49.79712630623092, 'var_explained': -33.458759023605246, 'ignored': 0, 'total': 32, 'perf': 0.6219512721798007}, {'mse': 0.636728897524222, 'r2': -53.35632122911629, 'var_explained': -33.29680337349068, 'ignored': 0, 'total': 32, 'perf': 0.636728897524222}, {'mse': 0.6488766445929963, 'r2': -56.28210928260751, 'var_explained': -32.98584460470195, 'ignored': 0, 'total': 32, 'perf': 0.6488766445929963}, {'mse': 0.6595310002655571, 'r2': -58.8482136283716, 'var_explained': -32.619432999488154, 'ignored': 0, 'total': 32, 'perf': 0.6595310002655571}, {'mse': 0.6686337881977789, 'r2': -61.04062247873514, 'var_explained': -32.227921556604585, 'ignored': 0, 'total': 32, 'perf': 0.6686337881977789}, {'mse': 0.675702780662528, 'r2': -62.743191159700395, 'var_explained': -31.863606316154346, 'ignored': 0, 'total': 32, 'perf': 0.675702780662528}, {'mse': 0.6794045657361922, 'r2': -63.6347670612895, 'var_explained': -31.369765388228355, 'ignored': 0, 'total': 32, 'perf': 0.6794045657361922}, {'mse': 0.6789703274398067, 'r2': -63.53018065421827, 'var_explained': -30.700628998450764, 'ignored': 0, 'total': 32, 'perf': 0.6789703274398067}, {'mse': 0.6768955826594882, 'r2': -63.03047783212852, 'var_explained': -30.048411927332296, 'ignored': 0, 'total': 32, 'perf': 0.6768955826594882}, {'mse': 0.6720604374714425, 'r2': -61.86593185105163, 'var_explained': -29.392393726820742, 'ignored': 0, 'total': 32, 'perf': 0.6720604374714425}, {'mse': 0.6639458671801337, 'r2': -59.91153547754189, 'var_explained': -28.683841505178776, 'ignored': 0, 'total': 32, 'perf': 0.6639458671801337}, {'mse': 0.6562866988422067, 'r2': -58.0668227834171, 'var_explained': -27.96470830826532, 'ignored': 0, 'total': 32, 'perf': 0.6562866988422067}, {'mse': 0.6455880296048703, 'r2': -55.49004550400578, 'var_explained': -27.18561599668261, 'ignored': 0, 'total': 32, 'perf': 0.6455880296048703}]
2022-12-18 23:54:01,377 INFO 
student_dev:	{'mse': 12.710674436239168, 'r2': 17.031196416873883, 'var_explained': 17.180007676159892, 'ignored': 0, 'total': 18, 'perf': 12.710674436239168}
2022-12-18 23:54:01,377 INFO 
student_test:	{'mse': 1.3221550267137934, 'r2': -218.4413834204816, 'var_explained': -8.469440899897783, 'ignored': 0, 'total': 32, 'perf': 1.3221550267137934}
2022-12-18 23:54:01,377 INFO Saving results at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/results.pkl
2022-12-18 23:54:01,389 INFO Dataset: econ_reg_ffill
2022-12-18 23:54:01,389 INFO Weak Sources: ['econ_reg_ffillrules']
2022-12-18 23:54:01,390 INFO Model: bert

2022-12-18 23:54:01,390 INFO Teacher Train mse: 2.0
2022-12-18 23:54:01,390 INFO Teacher Dev mse: 25.7
2022-12-18 23:54:01,390 INFO Teacher Test mse: 2.0

2022-12-18 23:54:01,390 INFO Student Dev mse: 12.7
2022-12-18 23:54:01,390 INFO Student Test mse: 1.3
2022-12-18 23:54:01,390 INFO Saved report at ../experiments/econ_reg_ffill/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_51_stBERT/results.txt
