2022-12-18 23:41:53,681 INFO 

		 *** NEW EXPERIMENT ***
args=Namespace(adam_epsilon=1e-08, convert_abstain_to_random=False, datapath='../data', dataset='econ_0', debug=False, device=device(type='cuda'), downsample=1.0, eval_batch_size=16, experiment_folder='../experiments/econ_0', finetuning_rate=0.0001, fp16=False, hard_student_rule=False, learning_rate=0.0001, logdir='../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT', logging_steps=500, loss_weights=False, lower_case=False, max_grad_norm=1.0, max_rule_seq_length=10, max_seq_length=64, max_size=1000, metric='weighted_acc', n_gpu=1, no_cuda=False, num_epochs=15, num_iter=25, num_labels=2, num_supervised_trials=5, num_unsup_epochs=25, oversample=3, overwrite=False, sample_size=16384, seed=0, soft_labels=False, student_name='bert', teacher_name='ran', tokenizer_method='clean', train_batch_size=16, unsup_batch_size=128, warmup_steps=0, weak_sources=None, weight_decay=0.0)
2022-12-18 23:41:53,681 INFO building student: bert
2022-12-18 23:41:53,681 INFO building teacher
2022-12-18 23:41:53,681 INFO No weak sources specified for Teacher. Using default: ['econ_0rules']
2022-12-18 23:41:53,681 INFO loading data
2022-12-18 23:41:53,685 INFO Pre-processing train data for student...
2022-12-18 23:41:53,688 INFO train DATASET: 247 examples
2022-12-18 23:41:53,691 INFO train LABELS:
1    217
0     30
Name: label, dtype: int64
2022-12-18 23:41:53,691 INFO Oversampling train data 3 times
2022-12-18 23:41:53,694 INFO train DATASET: 741 examples
2022-12-18 23:41:53,695 INFO train LABELS:
1    651
0     90
Name: label, dtype: int64
2022-12-18 23:41:53,697 INFO Pre-processing dev data for student...
2022-12-18 23:41:53,700 INFO dev DATASET: 18 examples
2022-12-18 23:41:53,701 INFO dev LABELS:
1    15
0     3
Name: label, dtype: int64
2022-12-18 23:41:53,702 INFO Pre-processing test data for student...
2022-12-18 23:41:53,704 INFO test DATASET: 32 examples
2022-12-18 23:41:53,705 INFO test LABELS:
1    32
Name: label, dtype: int64
2022-12-18 23:41:53,706 INFO Pre-processing unlabeled data for student...
2022-12-18 23:41:53,708 INFO unlabeled DATASET: 444 examples
2022-12-18 23:41:53,710 INFO unlabeled LABELS:
Series([], Name: label, dtype: int64)
2022-12-18 23:41:53,710 INFO creating pseudo-dataset
2022-12-18 23:41:53,710 INFO copying data from unlabeled dataset
2022-12-18 23:41:53,719 INFO done
2022-12-18 23:41:53,720 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:41:53,720 INFO Downsampling 444 data
2022-12-18 23:41:53,720 INFO copying data from train dataset
2022-12-18 23:41:53,730 INFO done
2022-12-18 23:41:53,731 INFO Balancing Pseudo Dataset to keep 1302 items...
2022-12-18 23:41:53,735 INFO PSEUDO-DATASET:
1302 examples
PSEUDO-LABELS:
1    651
0    651
Name: label, dtype: int64
2022-12-18 23:41:53,735 INFO Class labels: 2
2022-12-18 23:41:53,737 INFO X Train Shape (1302, 7) (1302,)
2022-12-18 23:41:53,737 INFO X Dev Shape (18, 7) (18,)
2022-12-18 23:42:06,993 INFO Saving supervised_student to ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/supervised_student
2022-12-18 23:42:06,993 INFO Saving model at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/supervised_student/final_model.h5
2022-12-18 23:42:07,001 INFO 

	*** Evaluating on dev data ***
2022-12-18 23:42:07,001 INFO Predicting labels for 18 texts
2022-12-18 23:42:08,125 INFO Evaluating student dev on 18 examples
2022-12-18 23:42:08,129 INFO student dev performance: 16.67
2022-12-18 23:42:08,129 INFO student dev confusion matrix:
[[ 2  1]
 [14  1]]
2022-12-18 23:42:08,130 INFO student dev report:
              precision    recall  f1-score   support

           0       0.12      0.67      0.21         3
           1       0.50      0.07      0.12        15

    accuracy                           0.17        18
   macro avg       0.31      0.37      0.16        18
weighted avg       0.44      0.17      0.13        18

2022-12-18 23:42:08,130 INFO 

	*** Evaluating on test data ***
2022-12-18 23:42:08,130 INFO Predicting labels for 32 texts
2022-12-18 23:42:09,256 INFO Evaluating student test on 32 examples
2022-12-18 23:42:09,266 INFO student test performance: 15.62
2022-12-18 23:42:09,266 INFO student test confusion matrix:
[[ 0  0]
 [27  5]]
2022-12-18 23:42:09,266 INFO student test report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.16      0.27        32

    accuracy                           0.16        32
   macro avg       0.50      0.08      0.14        32
weighted avg       1.00      0.16      0.27        32

2022-12-18 23:42:09,266 INFO initializing teacher on unlabeled data with majority voting
2022-12-18 23:42:09,266 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:09,267 INFO There are 3/7 active rules
2022-12-18 23:42:09,267 INFO Coverage: 100.0% (444/444)
2022-12-18 23:42:09,277 INFO evaluating majority voting
2022-12-18 23:42:09,277 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:42:09,278 INFO There are 7/7 active rules
2022-12-18 23:42:09,278 INFO Coverage: 100.0% (741/741)
2022-12-18 23:42:09,299 INFO Evaluating teacher train on 741 examples
2022-12-18 23:42:09,314 INFO teacher train performance: 93.12
2022-12-18 23:42:09,314 INFO teacher train confusion matrix:
[[ 51  39]
 [ 12 639]]
2022-12-18 23:42:09,314 INFO teacher train report:
              precision    recall  f1-score   support

           0       0.81      0.57      0.67        90
           1       0.94      0.98      0.96       651

    accuracy                           0.93       741
   macro avg       0.88      0.77      0.81       741
weighted avg       0.93      0.93      0.93       741

2022-12-18 23:42:09,314 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:09,314 INFO There are 7/7 active rules
2022-12-18 23:42:09,314 INFO Coverage: 100.0% (18/18)
2022-12-18 23:42:09,315 INFO Evaluating teacher dev on 18 examples
2022-12-18 23:42:09,319 INFO teacher dev performance: 83.33
2022-12-18 23:42:09,320 INFO teacher dev confusion matrix:
[[ 1  2]
 [ 1 14]]
2022-12-18 23:42:09,320 INFO teacher dev report:
              precision    recall  f1-score   support

           0       0.50      0.33      0.40         3
           1       0.88      0.93      0.90        15

    accuracy                           0.83        18
   macro avg       0.69      0.63      0.65        18
weighted avg       0.81      0.83      0.82        18

2022-12-18 23:42:09,320 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:42:09,320 INFO There are 7/7 active rules
2022-12-18 23:42:09,320 INFO Coverage: 100.0% (32/32)
2022-12-18 23:42:09,322 INFO Evaluating teacher test on 32 examples
2022-12-18 23:42:09,327 INFO teacher test performance: 100.00
2022-12-18 23:42:09,327 INFO teacher test confusion matrix:
[[32]]
2022-12-18 23:42:09,327 INFO teacher test report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:42:09,327 INFO 

	 *** Starting loop 0 ***
2022-12-18 23:42:09,327 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:42:09,327 INFO Downsampling 444 data
2022-12-18 23:42:09,328 INFO Adding Student as extra rule in Teacher
2022-12-18 23:42:09,328 INFO Getting rule predictions
2022-12-18 23:42:09,328 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:42:09,329 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:09,329 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:09,335 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:42:09,336 INFO Predicting labels for 741 texts
2022-12-18 23:42:09,450 INFO Predicting labels for 18 texts
2022-12-18 23:42:09,549 INFO Predicting labels for 444 texts
2022-12-18 23:42:09,651 INFO Training Rule Attention Network
2022-12-18 23:42:09,659 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:42:09,660 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:42:09,665 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:42:09,737 INFO 

		*** Training RAN ***
2022-12-18 23:42:12,544 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:12,546 INFO Predicting labels for 444 texts
2022-12-18 23:42:12,656 INFO There are 3/7 active rules
2022-12-18 23:42:12,656 INFO Coverage: 100.0% (444/444)
2022-12-18 23:42:12,660 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:42:12,742 INFO DONE, Getting attention scores...
2022-12-18 23:42:12,800 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:12,800 INFO Predicting labels for 18 texts
2022-12-18 23:42:12,905 INFO There are 7/7 active rules
2022-12-18 23:42:12,906 INFO Coverage: 100.0% (18/18)
2022-12-18 23:42:12,906 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:42:12,930 INFO DONE, Getting attention scores...
2022-12-18 23:42:12,985 INFO Evaluating teacher dev iter0 on 18 examples
2022-12-18 23:42:12,989 INFO teacher dev iter0 performance: 88.89
2022-12-18 23:42:12,990 INFO teacher dev iter0 confusion matrix:
[[ 1  2]
 [ 0 15]]
2022-12-18 23:42:12,990 INFO teacher dev iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50         3
           1       0.88      1.00      0.94        15

    accuracy                           0.89        18
   macro avg       0.94      0.67      0.72        18
weighted avg       0.90      0.89      0.86        18

2022-12-18 23:42:12,990 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:42:12,990 INFO Predicting labels for 32 texts
2022-12-18 23:42:13,091 INFO There are 7/7 active rules
2022-12-18 23:42:13,092 INFO Coverage: 100.0% (32/32)
2022-12-18 23:42:13,093 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:42:13,117 INFO DONE, Getting attention scores...
2022-12-18 23:42:13,177 INFO Evaluating teacher test iter0 on 32 examples
2022-12-18 23:42:13,181 INFO teacher test iter0 performance: 100.00
2022-12-18 23:42:13,181 INFO teacher test iter0 confusion matrix:
[[32]]
2022-12-18 23:42:13,182 INFO teacher test iter0 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:42:13,182 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:42:13,185 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:42:13,187 INFO Balancing Pseudo Dataset to keep 824 items...
2022-12-18 23:42:13,191 INFO PSEUDO-DATASET:
824 examples
PSEUDO-LABELS:
1    412
0    412
Name: label, dtype: int64
2022-12-18 23:42:13,191 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:42:15,132 INFO fine-tuning the student on clean labeled data
2022-12-18 23:42:18,353 INFO Predicting labels for 18 texts
2022-12-18 23:42:18,459 INFO Evaluating student dev iter0 on 18 examples
2022-12-18 23:42:18,463 INFO student dev iter0 performance: 94.44
2022-12-18 23:42:18,463 INFO student dev iter0 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:42:18,463 INFO student dev iter0 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:42:18,464 INFO Predicting labels for 32 texts
2022-12-18 23:42:18,565 INFO Evaluating student test iter0 on 32 examples
2022-12-18 23:42:18,570 INFO student test iter0 performance: 90.62
2022-12-18 23:42:18,571 INFO student test iter0 confusion matrix:
[[ 0  0]
 [ 3 29]]
2022-12-18 23:42:18,571 INFO student test iter0 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.91      0.95        32

    accuracy                           0.91        32
   macro avg       0.50      0.45      0.48        32
weighted avg       1.00      0.91      0.95        32

2022-12-18 23:42:18,571 INFO Student Dev performance on iter 0: 94.44444444444444
2022-12-18 23:42:18,571 INFO Student Test performance on iter 0: 90.625
2022-12-18 23:42:18,571 INFO Improved dev performance from 16.67 to 94.44
2022-12-18 23:42:18,571 INFO Saving student_best to ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/student_best
2022-12-18 23:42:18,572 INFO Saving model at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/student_best/final_model.h5
2022-12-18 23:42:18,580 INFO Saving teacher at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_best
2022-12-18 23:42:18,580 INFO Saving rule attention network at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_best/rule_attention_network.h5
2022-12-18 23:42:18,589 INFO 

	 *** Starting loop 1 ***
2022-12-18 23:42:18,589 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:42:18,589 INFO Downsampling 444 data
2022-12-18 23:42:18,590 INFO Adding Student as extra rule in Teacher
2022-12-18 23:42:18,590 INFO Getting rule predictions
2022-12-18 23:42:18,590 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:42:18,591 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:18,591 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:18,592 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:42:18,592 INFO Predicting labels for 741 texts
2022-12-18 23:42:18,698 INFO Predicting labels for 18 texts
2022-12-18 23:42:18,800 INFO Predicting labels for 444 texts
2022-12-18 23:42:18,902 INFO Training Rule Attention Network
2022-12-18 23:42:18,909 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:42:18,910 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:42:18,917 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:42:18,917 INFO 

		*** Training RAN ***
2022-12-18 23:42:21,764 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:21,765 INFO Predicting labels for 444 texts
2022-12-18 23:42:21,868 INFO There are 3/7 active rules
2022-12-18 23:42:21,868 INFO Coverage: 100.0% (444/444)
2022-12-18 23:42:21,873 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:42:21,961 INFO DONE, Getting attention scores...
2022-12-18 23:42:22,017 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:22,018 INFO Predicting labels for 18 texts
2022-12-18 23:42:22,118 INFO There are 7/7 active rules
2022-12-18 23:42:22,118 INFO Coverage: 100.0% (18/18)
2022-12-18 23:42:22,119 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:42:22,143 INFO DONE, Getting attention scores...
2022-12-18 23:42:22,202 INFO Evaluating teacher dev iter1 on 18 examples
2022-12-18 23:42:22,206 INFO teacher dev iter1 performance: 94.44
2022-12-18 23:42:22,207 INFO teacher dev iter1 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:42:22,207 INFO teacher dev iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:42:22,207 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:42:22,207 INFO Predicting labels for 32 texts
2022-12-18 23:42:22,317 INFO There are 7/7 active rules
2022-12-18 23:42:22,318 INFO Coverage: 100.0% (32/32)
2022-12-18 23:42:22,319 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:42:22,346 INFO DONE, Getting attention scores...
2022-12-18 23:42:22,405 INFO Evaluating teacher test iter1 on 32 examples
2022-12-18 23:42:22,409 INFO teacher test iter1 performance: 100.00
2022-12-18 23:42:22,410 INFO teacher test iter1 confusion matrix:
[[32]]
2022-12-18 23:42:22,410 INFO teacher test iter1 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:42:22,410 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:42:22,413 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:42:22,414 INFO Balancing Pseudo Dataset to keep 824 items...
2022-12-18 23:42:22,418 INFO PSEUDO-DATASET:
824 examples
PSEUDO-LABELS:
1    412
0    412
Name: label, dtype: int64
2022-12-18 23:42:22,418 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:42:25,225 INFO fine-tuning the student on clean labeled data
2022-12-18 23:42:29,511 INFO Predicting labels for 18 texts
2022-12-18 23:42:29,615 INFO Evaluating student dev iter1 on 18 examples
2022-12-18 23:42:29,619 INFO student dev iter1 performance: 94.44
2022-12-18 23:42:29,620 INFO student dev iter1 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:42:29,620 INFO student dev iter1 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:42:29,621 INFO Predicting labels for 32 texts
2022-12-18 23:42:29,724 INFO Evaluating student test iter1 on 32 examples
2022-12-18 23:42:29,730 INFO student test iter1 performance: 96.88
2022-12-18 23:42:29,731 INFO student test iter1 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:42:29,731 INFO student test iter1 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:42:29,731 INFO Student Dev performance on iter 1: 94.44444444444444
2022-12-18 23:42:29,731 INFO Student Test performance on iter 1: 96.875
2022-12-18 23:42:29,731 INFO 

	 *** Starting loop 2 ***
2022-12-18 23:42:29,731 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:42:29,732 INFO Downsampling 444 data
2022-12-18 23:42:29,733 INFO Adding Student as extra rule in Teacher
2022-12-18 23:42:29,733 INFO Getting rule predictions
2022-12-18 23:42:29,734 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:42:29,735 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:29,735 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:29,735 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:42:29,736 INFO Predicting labels for 741 texts
2022-12-18 23:42:29,845 INFO Predicting labels for 18 texts
2022-12-18 23:42:29,950 INFO Predicting labels for 444 texts
2022-12-18 23:42:30,054 INFO Training Rule Attention Network
2022-12-18 23:42:30,061 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:42:30,062 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:42:30,066 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:42:30,066 INFO 

		*** Training RAN ***
2022-12-18 23:42:32,795 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:32,796 INFO Predicting labels for 444 texts
2022-12-18 23:42:32,901 INFO There are 3/7 active rules
2022-12-18 23:42:32,901 INFO Coverage: 100.0% (444/444)
2022-12-18 23:42:32,906 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:42:32,995 INFO DONE, Getting attention scores...
2022-12-18 23:42:33,054 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:33,054 INFO Predicting labels for 18 texts
2022-12-18 23:42:33,157 INFO There are 7/7 active rules
2022-12-18 23:42:33,157 INFO Coverage: 100.0% (18/18)
2022-12-18 23:42:33,158 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:42:33,181 INFO DONE, Getting attention scores...
2022-12-18 23:42:33,240 INFO Evaluating teacher dev iter2 on 18 examples
2022-12-18 23:42:33,244 INFO teacher dev iter2 performance: 94.44
2022-12-18 23:42:33,244 INFO teacher dev iter2 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:42:33,245 INFO teacher dev iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:42:33,245 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:42:33,245 INFO Predicting labels for 32 texts
2022-12-18 23:42:34,369 INFO There are 7/7 active rules
2022-12-18 23:42:34,369 INFO Coverage: 100.0% (32/32)
2022-12-18 23:42:34,370 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:42:34,394 INFO DONE, Getting attention scores...
2022-12-18 23:42:34,447 INFO Evaluating teacher test iter2 on 32 examples
2022-12-18 23:42:34,452 INFO teacher test iter2 performance: 100.00
2022-12-18 23:42:34,452 INFO teacher test iter2 confusion matrix:
[[32]]
2022-12-18 23:42:34,452 INFO teacher test iter2 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:42:34,452 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:42:34,456 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:42:34,457 INFO Balancing Pseudo Dataset to keep 790 items...
2022-12-18 23:42:34,461 INFO PSEUDO-DATASET:
790 examples
PSEUDO-LABELS:
1    395
0    395
Name: label, dtype: int64
2022-12-18 23:42:34,462 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:42:37,322 INFO fine-tuning the student on clean labeled data
2022-12-18 23:42:40,566 INFO Predicting labels for 18 texts
2022-12-18 23:42:41,695 INFO Evaluating student dev iter2 on 18 examples
2022-12-18 23:42:41,700 INFO student dev iter2 performance: 94.44
2022-12-18 23:42:41,700 INFO student dev iter2 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:42:41,700 INFO student dev iter2 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:42:41,700 INFO Predicting labels for 32 texts
2022-12-18 23:42:41,801 INFO Evaluating student test iter2 on 32 examples
2022-12-18 23:42:41,807 INFO student test iter2 performance: 96.88
2022-12-18 23:42:41,807 INFO student test iter2 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:42:41,807 INFO student test iter2 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:42:41,807 INFO Student Dev performance on iter 2: 94.44444444444444
2022-12-18 23:42:41,807 INFO Student Test performance on iter 2: 96.875
2022-12-18 23:42:41,808 INFO 

	 *** Starting loop 3 ***
2022-12-18 23:42:41,808 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:42:41,808 INFO Downsampling 444 data
2022-12-18 23:42:41,808 INFO Adding Student as extra rule in Teacher
2022-12-18 23:42:41,808 INFO Getting rule predictions
2022-12-18 23:42:41,808 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:42:41,809 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:41,809 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:41,810 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:42:41,811 INFO Predicting labels for 741 texts
2022-12-18 23:42:41,911 INFO Predicting labels for 18 texts
2022-12-18 23:42:42,015 INFO Predicting labels for 444 texts
2022-12-18 23:42:42,117 INFO Training Rule Attention Network
2022-12-18 23:42:42,124 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:42:42,125 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:42:42,129 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:42:42,129 INFO 

		*** Training RAN ***
2022-12-18 23:42:45,008 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:45,010 INFO Predicting labels for 444 texts
2022-12-18 23:42:45,116 INFO There are 3/7 active rules
2022-12-18 23:42:45,116 INFO Coverage: 100.0% (444/444)
2022-12-18 23:42:45,120 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:42:45,210 INFO DONE, Getting attention scores...
2022-12-18 23:42:45,267 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:45,267 INFO Predicting labels for 18 texts
2022-12-18 23:42:45,367 INFO There are 7/7 active rules
2022-12-18 23:42:45,367 INFO Coverage: 100.0% (18/18)
2022-12-18 23:42:45,368 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:42:45,392 INFO DONE, Getting attention scores...
2022-12-18 23:42:45,450 INFO Evaluating teacher dev iter3 on 18 examples
2022-12-18 23:42:45,454 INFO teacher dev iter3 performance: 94.44
2022-12-18 23:42:45,455 INFO teacher dev iter3 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:42:45,455 INFO teacher dev iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:42:45,455 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:42:45,455 INFO Predicting labels for 32 texts
2022-12-18 23:42:45,557 INFO There are 7/7 active rules
2022-12-18 23:42:45,557 INFO Coverage: 100.0% (32/32)
2022-12-18 23:42:45,558 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:42:45,582 INFO DONE, Getting attention scores...
2022-12-18 23:42:45,636 INFO Evaluating teacher test iter3 on 32 examples
2022-12-18 23:42:45,640 INFO teacher test iter3 performance: 100.00
2022-12-18 23:42:45,641 INFO teacher test iter3 confusion matrix:
[[32]]
2022-12-18 23:42:45,641 INFO teacher test iter3 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:42:45,641 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:42:45,644 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:42:45,646 INFO Balancing Pseudo Dataset to keep 768 items...
2022-12-18 23:42:45,650 INFO PSEUDO-DATASET:
768 examples
PSEUDO-LABELS:
1    384
0    384
Name: label, dtype: int64
2022-12-18 23:42:45,651 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:42:48,358 INFO fine-tuning the student on clean labeled data
2022-12-18 23:42:51,548 INFO Predicting labels for 18 texts
2022-12-18 23:42:51,650 INFO Evaluating student dev iter3 on 18 examples
2022-12-18 23:42:51,654 INFO student dev iter3 performance: 94.44
2022-12-18 23:42:51,654 INFO student dev iter3 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:42:51,654 INFO student dev iter3 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:42:51,655 INFO Predicting labels for 32 texts
2022-12-18 23:42:51,760 INFO Evaluating student test iter3 on 32 examples
2022-12-18 23:42:51,766 INFO student test iter3 performance: 96.88
2022-12-18 23:42:51,766 INFO student test iter3 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:42:51,766 INFO student test iter3 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:42:51,766 INFO Student Dev performance on iter 3: 94.44444444444444
2022-12-18 23:42:51,766 INFO Student Test performance on iter 3: 96.875
2022-12-18 23:42:51,767 INFO 

	 *** Starting loop 4 ***
2022-12-18 23:42:51,767 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:42:51,767 INFO Downsampling 444 data
2022-12-18 23:42:51,767 INFO Adding Student as extra rule in Teacher
2022-12-18 23:42:51,767 INFO Getting rule predictions
2022-12-18 23:42:51,768 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:42:51,768 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:51,769 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:51,769 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:42:51,770 INFO Predicting labels for 741 texts
2022-12-18 23:42:51,874 INFO Predicting labels for 18 texts
2022-12-18 23:42:51,976 INFO Predicting labels for 444 texts
2022-12-18 23:42:52,077 INFO Training Rule Attention Network
2022-12-18 23:42:52,084 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:42:52,085 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:42:52,089 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:42:52,090 INFO 

		*** Training RAN ***
2022-12-18 23:42:54,921 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:42:54,923 INFO Predicting labels for 444 texts
2022-12-18 23:42:55,025 INFO There are 3/7 active rules
2022-12-18 23:42:55,026 INFO Coverage: 100.0% (444/444)
2022-12-18 23:42:55,030 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:42:55,115 INFO DONE, Getting attention scores...
2022-12-18 23:42:55,173 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:42:55,174 INFO Predicting labels for 18 texts
2022-12-18 23:42:55,274 INFO There are 7/7 active rules
2022-12-18 23:42:55,274 INFO Coverage: 100.0% (18/18)
2022-12-18 23:42:55,275 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:42:55,299 INFO DONE, Getting attention scores...
2022-12-18 23:42:55,352 INFO Evaluating teacher dev iter4 on 18 examples
2022-12-18 23:42:55,356 INFO teacher dev iter4 performance: 94.44
2022-12-18 23:42:55,356 INFO teacher dev iter4 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:42:55,356 INFO teacher dev iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:42:55,357 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:42:55,357 INFO Predicting labels for 32 texts
2022-12-18 23:42:55,464 INFO There are 7/7 active rules
2022-12-18 23:42:55,464 INFO Coverage: 100.0% (32/32)
2022-12-18 23:42:55,465 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:42:55,489 INFO DONE, Getting attention scores...
2022-12-18 23:42:55,544 INFO Evaluating teacher test iter4 on 32 examples
2022-12-18 23:42:55,548 INFO teacher test iter4 performance: 100.00
2022-12-18 23:42:55,548 INFO teacher test iter4 confusion matrix:
[[32]]
2022-12-18 23:42:55,549 INFO teacher test iter4 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:42:55,549 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:42:55,552 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:42:55,554 INFO Balancing Pseudo Dataset to keep 742 items...
2022-12-18 23:42:55,558 INFO PSEUDO-DATASET:
742 examples
PSEUDO-LABELS:
1    371
0    371
Name: label, dtype: int64
2022-12-18 23:42:55,558 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:42:58,286 INFO fine-tuning the student on clean labeled data
2022-12-18 23:43:02,660 INFO Predicting labels for 18 texts
2022-12-18 23:43:02,762 INFO Evaluating student dev iter4 on 18 examples
2022-12-18 23:43:02,766 INFO student dev iter4 performance: 94.44
2022-12-18 23:43:02,766 INFO student dev iter4 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:43:02,767 INFO student dev iter4 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:43:02,767 INFO Predicting labels for 32 texts
2022-12-18 23:43:02,872 INFO Evaluating student test iter4 on 32 examples
2022-12-18 23:43:02,877 INFO student test iter4 performance: 96.88
2022-12-18 23:43:02,878 INFO student test iter4 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:43:02,878 INFO student test iter4 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:43:02,878 INFO Student Dev performance on iter 4: 94.44444444444444
2022-12-18 23:43:02,878 INFO Student Test performance on iter 4: 96.875
2022-12-18 23:43:02,878 INFO 

	 *** Starting loop 5 ***
2022-12-18 23:43:02,878 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:43:02,878 INFO Downsampling 444 data
2022-12-18 23:43:02,879 INFO Adding Student as extra rule in Teacher
2022-12-18 23:43:02,879 INFO Getting rule predictions
2022-12-18 23:43:02,879 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:43:02,880 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:02,880 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:02,881 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:43:02,882 INFO Predicting labels for 741 texts
2022-12-18 23:43:02,985 INFO Predicting labels for 18 texts
2022-12-18 23:43:03,090 INFO Predicting labels for 444 texts
2022-12-18 23:43:03,193 INFO Training Rule Attention Network
2022-12-18 23:43:03,200 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:43:03,201 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:43:03,205 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:43:03,205 INFO 

		*** Training RAN ***
2022-12-18 23:43:06,026 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:06,027 INFO Predicting labels for 444 texts
2022-12-18 23:43:07,162 INFO There are 3/7 active rules
2022-12-18 23:43:07,162 INFO Coverage: 100.0% (444/444)
2022-12-18 23:43:07,166 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:43:07,259 INFO DONE, Getting attention scores...
2022-12-18 23:43:07,315 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:07,315 INFO Predicting labels for 18 texts
2022-12-18 23:43:07,441 INFO There are 7/7 active rules
2022-12-18 23:43:07,441 INFO Coverage: 100.0% (18/18)
2022-12-18 23:43:07,442 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:43:07,471 INFO DONE, Getting attention scores...
2022-12-18 23:43:07,547 INFO Evaluating teacher dev iter5 on 18 examples
2022-12-18 23:43:07,552 INFO teacher dev iter5 performance: 94.44
2022-12-18 23:43:07,552 INFO teacher dev iter5 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:43:07,552 INFO teacher dev iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:43:07,552 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:43:07,552 INFO Predicting labels for 32 texts
2022-12-18 23:43:08,666 INFO There are 7/7 active rules
2022-12-18 23:43:08,666 INFO Coverage: 100.0% (32/32)
2022-12-18 23:43:08,667 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:43:08,693 INFO DONE, Getting attention scores...
2022-12-18 23:43:08,747 INFO Evaluating teacher test iter5 on 32 examples
2022-12-18 23:43:08,751 INFO teacher test iter5 performance: 100.00
2022-12-18 23:43:08,752 INFO teacher test iter5 confusion matrix:
[[32]]
2022-12-18 23:43:08,752 INFO teacher test iter5 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:43:08,752 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:43:08,755 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:43:08,757 INFO Balancing Pseudo Dataset to keep 784 items...
2022-12-18 23:43:08,761 INFO PSEUDO-DATASET:
784 examples
PSEUDO-LABELS:
1    392
0    392
Name: label, dtype: int64
2022-12-18 23:43:08,761 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:43:11,478 INFO fine-tuning the student on clean labeled data
2022-12-18 23:43:14,896 INFO Predicting labels for 18 texts
2022-12-18 23:43:15,000 INFO Evaluating student dev iter5 on 18 examples
2022-12-18 23:43:15,004 INFO student dev iter5 performance: 94.44
2022-12-18 23:43:15,005 INFO student dev iter5 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:43:15,005 INFO student dev iter5 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:43:15,005 INFO Predicting labels for 32 texts
2022-12-18 23:43:15,106 INFO Evaluating student test iter5 on 32 examples
2022-12-18 23:43:15,112 INFO student test iter5 performance: 96.88
2022-12-18 23:43:15,113 INFO student test iter5 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:43:15,113 INFO student test iter5 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:43:15,113 INFO Student Dev performance on iter 5: 94.44444444444444
2022-12-18 23:43:15,113 INFO Student Test performance on iter 5: 96.875
2022-12-18 23:43:15,113 INFO 

	 *** Starting loop 6 ***
2022-12-18 23:43:15,113 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:43:15,113 INFO Downsampling 444 data
2022-12-18 23:43:15,114 INFO Adding Student as extra rule in Teacher
2022-12-18 23:43:15,114 INFO Getting rule predictions
2022-12-18 23:43:15,114 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:43:15,115 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:15,115 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:15,116 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:43:15,117 INFO Predicting labels for 741 texts
2022-12-18 23:43:15,313 INFO Predicting labels for 18 texts
2022-12-18 23:43:15,417 INFO Predicting labels for 444 texts
2022-12-18 23:43:15,524 INFO Training Rule Attention Network
2022-12-18 23:43:15,532 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:43:15,532 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:43:15,536 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:43:15,536 INFO 

		*** Training RAN ***
2022-12-18 23:43:18,311 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:18,312 INFO Predicting labels for 444 texts
2022-12-18 23:43:18,416 INFO There are 3/7 active rules
2022-12-18 23:43:18,417 INFO Coverage: 100.0% (444/444)
2022-12-18 23:43:18,421 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:43:18,506 INFO DONE, Getting attention scores...
2022-12-18 23:43:18,566 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:18,566 INFO Predicting labels for 18 texts
2022-12-18 23:43:18,667 INFO There are 7/7 active rules
2022-12-18 23:43:18,667 INFO Coverage: 100.0% (18/18)
2022-12-18 23:43:18,668 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:43:18,692 INFO DONE, Getting attention scores...
2022-12-18 23:43:18,749 INFO Evaluating teacher dev iter6 on 18 examples
2022-12-18 23:43:18,753 INFO teacher dev iter6 performance: 94.44
2022-12-18 23:43:18,753 INFO teacher dev iter6 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:43:18,754 INFO teacher dev iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:43:18,754 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:43:18,754 INFO Predicting labels for 32 texts
2022-12-18 23:43:18,868 INFO There are 7/7 active rules
2022-12-18 23:43:18,868 INFO Coverage: 100.0% (32/32)
2022-12-18 23:43:18,869 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:43:18,895 INFO DONE, Getting attention scores...
2022-12-18 23:43:18,950 INFO Evaluating teacher test iter6 on 32 examples
2022-12-18 23:43:18,954 INFO teacher test iter6 performance: 100.00
2022-12-18 23:43:18,954 INFO teacher test iter6 confusion matrix:
[[32]]
2022-12-18 23:43:18,954 INFO teacher test iter6 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:43:18,955 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:43:18,957 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:43:18,959 INFO Balancing Pseudo Dataset to keep 720 items...
2022-12-18 23:43:18,963 INFO PSEUDO-DATASET:
720 examples
PSEUDO-LABELS:
1    360
0    360
Name: label, dtype: int64
2022-12-18 23:43:18,963 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:43:20,665 INFO fine-tuning the student on clean labeled data
2022-12-18 23:43:23,177 INFO Predicting labels for 18 texts
2022-12-18 23:43:23,280 INFO Evaluating student dev iter6 on 18 examples
2022-12-18 23:43:23,284 INFO student dev iter6 performance: 94.44
2022-12-18 23:43:23,285 INFO student dev iter6 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:43:23,285 INFO student dev iter6 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:43:23,285 INFO Predicting labels for 32 texts
2022-12-18 23:43:23,391 INFO Evaluating student test iter6 on 32 examples
2022-12-18 23:43:23,396 INFO student test iter6 performance: 96.88
2022-12-18 23:43:23,397 INFO student test iter6 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:43:23,397 INFO student test iter6 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:43:23,397 INFO Student Dev performance on iter 6: 94.44444444444444
2022-12-18 23:43:23,397 INFO Student Test performance on iter 6: 96.875
2022-12-18 23:43:23,397 INFO 

	 *** Starting loop 7 ***
2022-12-18 23:43:23,397 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:43:23,397 INFO Downsampling 444 data
2022-12-18 23:43:23,398 INFO Adding Student as extra rule in Teacher
2022-12-18 23:43:23,398 INFO Getting rule predictions
2022-12-18 23:43:23,398 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:43:23,399 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:23,399 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:23,399 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:43:23,400 INFO Predicting labels for 741 texts
2022-12-18 23:43:23,506 INFO Predicting labels for 18 texts
2022-12-18 23:43:23,606 INFO Predicting labels for 444 texts
2022-12-18 23:43:23,711 INFO Training Rule Attention Network
2022-12-18 23:43:23,718 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:43:23,719 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:43:23,723 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:43:23,723 INFO 

		*** Training RAN ***
2022-12-18 23:43:26,638 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:26,639 INFO Predicting labels for 444 texts
2022-12-18 23:43:26,744 INFO There are 3/7 active rules
2022-12-18 23:43:26,744 INFO Coverage: 100.0% (444/444)
2022-12-18 23:43:26,748 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:43:26,832 INFO DONE, Getting attention scores...
2022-12-18 23:43:26,893 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:26,893 INFO Predicting labels for 18 texts
2022-12-18 23:43:26,994 INFO There are 7/7 active rules
2022-12-18 23:43:26,995 INFO Coverage: 100.0% (18/18)
2022-12-18 23:43:26,995 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:43:27,018 INFO DONE, Getting attention scores...
2022-12-18 23:43:27,071 INFO Evaluating teacher dev iter7 on 18 examples
2022-12-18 23:43:27,075 INFO teacher dev iter7 performance: 94.44
2022-12-18 23:43:27,075 INFO teacher dev iter7 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:43:27,075 INFO teacher dev iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:43:27,075 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:43:27,075 INFO Predicting labels for 32 texts
2022-12-18 23:43:27,183 INFO There are 7/7 active rules
2022-12-18 23:43:27,184 INFO Coverage: 100.0% (32/32)
2022-12-18 23:43:27,185 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:43:27,210 INFO DONE, Getting attention scores...
2022-12-18 23:43:27,264 INFO Evaluating teacher test iter7 on 32 examples
2022-12-18 23:43:27,268 INFO teacher test iter7 performance: 100.00
2022-12-18 23:43:27,268 INFO teacher test iter7 confusion matrix:
[[32]]
2022-12-18 23:43:27,269 INFO teacher test iter7 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:43:27,269 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:43:27,272 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:43:27,274 INFO Balancing Pseudo Dataset to keep 732 items...
2022-12-18 23:43:27,278 INFO PSEUDO-DATASET:
732 examples
PSEUDO-LABELS:
1    366
0    366
Name: label, dtype: int64
2022-12-18 23:43:27,278 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:43:28,975 INFO fine-tuning the student on clean labeled data
2022-12-18 23:43:30,235 INFO Predicting labels for 18 texts
2022-12-18 23:43:30,337 INFO Evaluating student dev iter7 on 18 examples
2022-12-18 23:43:30,341 INFO student dev iter7 performance: 94.44
2022-12-18 23:43:30,342 INFO student dev iter7 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:43:30,342 INFO student dev iter7 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:43:30,342 INFO Predicting labels for 32 texts
2022-12-18 23:43:30,445 INFO Evaluating student test iter7 on 32 examples
2022-12-18 23:43:30,450 INFO student test iter7 performance: 96.88
2022-12-18 23:43:30,450 INFO student test iter7 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:43:30,451 INFO student test iter7 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:43:30,451 INFO Student Dev performance on iter 7: 94.44444444444444
2022-12-18 23:43:30,451 INFO Student Test performance on iter 7: 96.875
2022-12-18 23:43:30,451 INFO 

	 *** Starting loop 8 ***
2022-12-18 23:43:30,451 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:43:30,451 INFO Downsampling 444 data
2022-12-18 23:43:30,452 INFO Adding Student as extra rule in Teacher
2022-12-18 23:43:30,452 INFO Getting rule predictions
2022-12-18 23:43:30,452 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:43:30,453 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:30,453 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:30,453 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:43:30,454 INFO Predicting labels for 741 texts
2022-12-18 23:43:30,559 INFO Predicting labels for 18 texts
2022-12-18 23:43:30,660 INFO Predicting labels for 444 texts
2022-12-18 23:43:30,762 INFO Training Rule Attention Network
2022-12-18 23:43:30,769 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:43:30,770 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:43:30,774 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:43:30,774 INFO 

		*** Training RAN ***
2022-12-18 23:43:33,654 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:33,655 INFO Predicting labels for 444 texts
2022-12-18 23:43:33,762 INFO There are 3/7 active rules
2022-12-18 23:43:33,762 INFO Coverage: 100.0% (444/444)
2022-12-18 23:43:33,767 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:43:33,853 INFO DONE, Getting attention scores...
2022-12-18 23:43:33,912 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:33,913 INFO Predicting labels for 18 texts
2022-12-18 23:43:34,014 INFO There are 7/7 active rules
2022-12-18 23:43:34,014 INFO Coverage: 100.0% (18/18)
2022-12-18 23:43:34,015 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:43:34,038 INFO DONE, Getting attention scores...
2022-12-18 23:43:34,092 INFO Evaluating teacher dev iter8 on 18 examples
2022-12-18 23:43:34,096 INFO teacher dev iter8 performance: 94.44
2022-12-18 23:43:34,096 INFO teacher dev iter8 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:43:34,097 INFO teacher dev iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:43:34,097 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:43:34,097 INFO Predicting labels for 32 texts
2022-12-18 23:43:34,205 INFO There are 7/7 active rules
2022-12-18 23:43:34,205 INFO Coverage: 100.0% (32/32)
2022-12-18 23:43:34,206 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:43:34,232 INFO DONE, Getting attention scores...
2022-12-18 23:43:34,285 INFO Evaluating teacher test iter8 on 32 examples
2022-12-18 23:43:34,289 INFO teacher test iter8 performance: 100.00
2022-12-18 23:43:34,289 INFO teacher test iter8 confusion matrix:
[[32]]
2022-12-18 23:43:34,289 INFO teacher test iter8 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:43:34,290 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:43:34,293 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:43:34,295 INFO Balancing Pseudo Dataset to keep 760 items...
2022-12-18 23:43:34,299 INFO PSEUDO-DATASET:
760 examples
PSEUDO-LABELS:
1    380
0    380
Name: label, dtype: int64
2022-12-18 23:43:34,299 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:43:36,065 INFO fine-tuning the student on clean labeled data
2022-12-18 23:43:38,326 INFO Predicting labels for 18 texts
2022-12-18 23:43:38,429 INFO Evaluating student dev iter8 on 18 examples
2022-12-18 23:43:38,433 INFO student dev iter8 performance: 94.44
2022-12-18 23:43:38,433 INFO student dev iter8 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:43:38,434 INFO student dev iter8 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:43:38,434 INFO Predicting labels for 32 texts
2022-12-18 23:43:38,539 INFO Evaluating student test iter8 on 32 examples
2022-12-18 23:43:38,544 INFO student test iter8 performance: 96.88
2022-12-18 23:43:38,545 INFO student test iter8 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:43:38,545 INFO student test iter8 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:43:38,545 INFO Student Dev performance on iter 8: 94.44444444444444
2022-12-18 23:43:38,545 INFO Student Test performance on iter 8: 96.875
2022-12-18 23:43:38,545 INFO 

	 *** Starting loop 9 ***
2022-12-18 23:43:38,545 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:43:38,545 INFO Downsampling 444 data
2022-12-18 23:43:38,546 INFO Adding Student as extra rule in Teacher
2022-12-18 23:43:38,546 INFO Getting rule predictions
2022-12-18 23:43:38,546 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:43:38,547 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:38,547 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:38,548 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:43:38,549 INFO Predicting labels for 741 texts
2022-12-18 23:43:38,652 INFO Predicting labels for 18 texts
2022-12-18 23:43:38,751 INFO Predicting labels for 444 texts
2022-12-18 23:43:38,852 INFO Training Rule Attention Network
2022-12-18 23:43:38,859 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:43:38,860 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:43:38,864 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:43:38,864 INFO 

		*** Training RAN ***
2022-12-18 23:43:41,826 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:41,827 INFO Predicting labels for 444 texts
2022-12-18 23:43:41,935 INFO There are 3/7 active rules
2022-12-18 23:43:41,935 INFO Coverage: 100.0% (444/444)
2022-12-18 23:43:41,940 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:43:42,026 INFO DONE, Getting attention scores...
2022-12-18 23:43:42,083 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:42,083 INFO Predicting labels for 18 texts
2022-12-18 23:43:42,185 INFO There are 7/7 active rules
2022-12-18 23:43:42,185 INFO Coverage: 100.0% (18/18)
2022-12-18 23:43:42,186 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:43:42,209 INFO DONE, Getting attention scores...
2022-12-18 23:43:42,268 INFO Evaluating teacher dev iter9 on 18 examples
2022-12-18 23:43:42,272 INFO teacher dev iter9 performance: 94.44
2022-12-18 23:43:42,272 INFO teacher dev iter9 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:43:42,273 INFO teacher dev iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:43:42,273 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:43:42,273 INFO Predicting labels for 32 texts
2022-12-18 23:43:42,389 INFO There are 7/7 active rules
2022-12-18 23:43:42,389 INFO Coverage: 100.0% (32/32)
2022-12-18 23:43:42,390 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:43:42,416 INFO DONE, Getting attention scores...
2022-12-18 23:43:42,471 INFO Evaluating teacher test iter9 on 32 examples
2022-12-18 23:43:42,475 INFO teacher test iter9 performance: 100.00
2022-12-18 23:43:42,476 INFO teacher test iter9 confusion matrix:
[[32]]
2022-12-18 23:43:42,476 INFO teacher test iter9 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:43:42,476 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:43:42,480 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:43:42,482 INFO Balancing Pseudo Dataset to keep 808 items...
2022-12-18 23:43:42,486 INFO PSEUDO-DATASET:
808 examples
PSEUDO-LABELS:
1    404
0    404
Name: label, dtype: int64
2022-12-18 23:43:42,486 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:43:44,265 INFO fine-tuning the student on clean labeled data
2022-12-18 23:43:45,474 INFO Predicting labels for 18 texts
2022-12-18 23:43:45,577 INFO Evaluating student dev iter9 on 18 examples
2022-12-18 23:43:45,581 INFO student dev iter9 performance: 94.44
2022-12-18 23:43:45,582 INFO student dev iter9 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:43:45,582 INFO student dev iter9 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:43:45,582 INFO Predicting labels for 32 texts
2022-12-18 23:43:45,687 INFO Evaluating student test iter9 on 32 examples
2022-12-18 23:43:45,693 INFO student test iter9 performance: 96.88
2022-12-18 23:43:45,693 INFO student test iter9 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:43:45,693 INFO student test iter9 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:43:45,693 INFO Student Dev performance on iter 9: 94.44444444444444
2022-12-18 23:43:45,693 INFO Student Test performance on iter 9: 96.875
2022-12-18 23:43:45,693 INFO 

	 *** Starting loop 10 ***
2022-12-18 23:43:45,693 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:43:45,694 INFO Downsampling 444 data
2022-12-18 23:43:45,694 INFO Adding Student as extra rule in Teacher
2022-12-18 23:43:45,694 INFO Getting rule predictions
2022-12-18 23:43:45,694 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:43:45,695 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:45,695 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:45,696 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:43:45,697 INFO Predicting labels for 741 texts
2022-12-18 23:43:45,802 INFO Predicting labels for 18 texts
2022-12-18 23:43:45,903 INFO Predicting labels for 444 texts
2022-12-18 23:43:46,004 INFO Training Rule Attention Network
2022-12-18 23:43:46,011 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:43:46,011 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:43:46,016 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:43:46,016 INFO 

		*** Training RAN ***
2022-12-18 23:43:48,944 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:48,945 INFO Predicting labels for 444 texts
2022-12-18 23:43:49,054 INFO There are 3/7 active rules
2022-12-18 23:43:49,054 INFO Coverage: 100.0% (444/444)
2022-12-18 23:43:49,058 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:43:49,144 INFO DONE, Getting attention scores...
2022-12-18 23:43:49,201 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:49,201 INFO Predicting labels for 18 texts
2022-12-18 23:43:49,304 INFO There are 7/7 active rules
2022-12-18 23:43:49,304 INFO Coverage: 100.0% (18/18)
2022-12-18 23:43:49,305 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:43:49,329 INFO DONE, Getting attention scores...
2022-12-18 23:43:49,383 INFO Evaluating teacher dev iter10 on 18 examples
2022-12-18 23:43:49,387 INFO teacher dev iter10 performance: 94.44
2022-12-18 23:43:49,387 INFO teacher dev iter10 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:43:49,387 INFO teacher dev iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:43:49,387 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:43:49,387 INFO Predicting labels for 32 texts
2022-12-18 23:43:49,489 INFO There are 7/7 active rules
2022-12-18 23:43:49,489 INFO Coverage: 100.0% (32/32)
2022-12-18 23:43:49,490 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:43:49,513 INFO DONE, Getting attention scores...
2022-12-18 23:43:49,575 INFO Evaluating teacher test iter10 on 32 examples
2022-12-18 23:43:49,579 INFO teacher test iter10 performance: 100.00
2022-12-18 23:43:49,579 INFO teacher test iter10 confusion matrix:
[[32]]
2022-12-18 23:43:49,580 INFO teacher test iter10 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:43:49,580 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:43:49,584 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:43:49,585 INFO Balancing Pseudo Dataset to keep 770 items...
2022-12-18 23:43:49,589 INFO PSEUDO-DATASET:
770 examples
PSEUDO-LABELS:
1    385
0    385
Name: label, dtype: int64
2022-12-18 23:43:49,589 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:43:51,459 INFO fine-tuning the student on clean labeled data
2022-12-18 23:43:52,694 INFO Predicting labels for 18 texts
2022-12-18 23:43:52,800 INFO Evaluating student dev iter10 on 18 examples
2022-12-18 23:43:52,805 INFO student dev iter10 performance: 94.44
2022-12-18 23:43:52,805 INFO student dev iter10 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:43:52,805 INFO student dev iter10 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:43:52,805 INFO Predicting labels for 32 texts
2022-12-18 23:43:52,908 INFO Evaluating student test iter10 on 32 examples
2022-12-18 23:43:52,913 INFO student test iter10 performance: 96.88
2022-12-18 23:43:52,913 INFO student test iter10 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:43:52,914 INFO student test iter10 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:43:52,914 INFO Student Dev performance on iter 10: 94.44444444444444
2022-12-18 23:43:52,914 INFO Student Test performance on iter 10: 96.875
2022-12-18 23:43:52,914 INFO 

	 *** Starting loop 11 ***
2022-12-18 23:43:52,914 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:43:52,914 INFO Downsampling 444 data
2022-12-18 23:43:52,915 INFO Adding Student as extra rule in Teacher
2022-12-18 23:43:52,915 INFO Getting rule predictions
2022-12-18 23:43:52,915 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:43:52,916 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:52,916 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:52,916 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:43:52,917 INFO Predicting labels for 741 texts
2022-12-18 23:43:53,024 INFO Predicting labels for 18 texts
2022-12-18 23:43:53,125 INFO Predicting labels for 444 texts
2022-12-18 23:43:53,229 INFO Training Rule Attention Network
2022-12-18 23:43:53,240 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:43:53,241 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:43:53,245 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:43:53,245 INFO 

		*** Training RAN ***
2022-12-18 23:43:56,056 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:43:56,057 INFO Predicting labels for 444 texts
2022-12-18 23:43:56,263 INFO There are 3/7 active rules
2022-12-18 23:43:56,263 INFO Coverage: 100.0% (444/444)
2022-12-18 23:43:56,267 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:43:56,354 INFO DONE, Getting attention scores...
2022-12-18 23:43:56,411 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:43:56,411 INFO Predicting labels for 18 texts
2022-12-18 23:43:56,520 INFO There are 7/7 active rules
2022-12-18 23:43:56,521 INFO Coverage: 100.0% (18/18)
2022-12-18 23:43:56,521 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:43:56,547 INFO DONE, Getting attention scores...
2022-12-18 23:43:56,603 INFO Evaluating teacher dev iter11 on 18 examples
2022-12-18 23:43:56,607 INFO teacher dev iter11 performance: 94.44
2022-12-18 23:43:56,607 INFO teacher dev iter11 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:43:56,608 INFO teacher dev iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:43:56,608 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:43:56,608 INFO Predicting labels for 32 texts
2022-12-18 23:43:56,713 INFO There are 7/7 active rules
2022-12-18 23:43:56,713 INFO Coverage: 100.0% (32/32)
2022-12-18 23:43:56,714 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:43:56,745 INFO DONE, Getting attention scores...
2022-12-18 23:43:56,801 INFO Evaluating teacher test iter11 on 32 examples
2022-12-18 23:43:56,805 INFO teacher test iter11 performance: 100.00
2022-12-18 23:43:56,806 INFO teacher test iter11 confusion matrix:
[[32]]
2022-12-18 23:43:56,806 INFO teacher test iter11 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:43:56,806 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:43:56,810 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:43:56,812 INFO Balancing Pseudo Dataset to keep 808 items...
2022-12-18 23:43:56,816 INFO PSEUDO-DATASET:
808 examples
PSEUDO-LABELS:
1    404
0    404
Name: label, dtype: int64
2022-12-18 23:43:56,816 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:44:00,660 INFO fine-tuning the student on clean labeled data
2022-12-18 23:44:01,898 INFO Predicting labels for 18 texts
2022-12-18 23:44:02,000 INFO Evaluating student dev iter11 on 18 examples
2022-12-18 23:44:02,004 INFO student dev iter11 performance: 94.44
2022-12-18 23:44:02,005 INFO student dev iter11 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:44:02,005 INFO student dev iter11 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:44:02,005 INFO Predicting labels for 32 texts
2022-12-18 23:44:02,109 INFO Evaluating student test iter11 on 32 examples
2022-12-18 23:44:02,115 INFO student test iter11 performance: 96.88
2022-12-18 23:44:02,115 INFO student test iter11 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:44:02,116 INFO student test iter11 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:44:02,116 INFO Student Dev performance on iter 11: 94.44444444444444
2022-12-18 23:44:02,116 INFO Student Test performance on iter 11: 96.875
2022-12-18 23:44:02,116 INFO 

	 *** Starting loop 12 ***
2022-12-18 23:44:02,116 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:44:02,117 INFO Downsampling 444 data
2022-12-18 23:44:02,118 INFO Adding Student as extra rule in Teacher
2022-12-18 23:44:02,118 INFO Getting rule predictions
2022-12-18 23:44:02,118 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:44:02,119 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:02,119 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:02,120 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:44:02,121 INFO Predicting labels for 741 texts
2022-12-18 23:44:02,236 INFO Predicting labels for 18 texts
2022-12-18 23:44:02,350 INFO Predicting labels for 444 texts
2022-12-18 23:44:02,460 INFO Training Rule Attention Network
2022-12-18 23:44:02,467 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:44:02,468 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:44:02,472 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:44:02,472 INFO 

		*** Training RAN ***
2022-12-18 23:44:05,292 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:05,293 INFO Predicting labels for 444 texts
2022-12-18 23:44:05,400 INFO There are 3/7 active rules
2022-12-18 23:44:05,400 INFO Coverage: 100.0% (444/444)
2022-12-18 23:44:05,404 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:44:05,490 INFO DONE, Getting attention scores...
2022-12-18 23:44:05,550 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:05,550 INFO Predicting labels for 18 texts
2022-12-18 23:44:05,657 INFO There are 7/7 active rules
2022-12-18 23:44:05,657 INFO Coverage: 100.0% (18/18)
2022-12-18 23:44:05,658 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:44:05,683 INFO DONE, Getting attention scores...
2022-12-18 23:44:05,736 INFO Evaluating teacher dev iter12 on 18 examples
2022-12-18 23:44:05,741 INFO teacher dev iter12 performance: 94.44
2022-12-18 23:44:05,741 INFO teacher dev iter12 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:44:05,741 INFO teacher dev iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:44:05,741 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:44:05,741 INFO Predicting labels for 32 texts
2022-12-18 23:44:05,946 INFO There are 7/7 active rules
2022-12-18 23:44:05,946 INFO Coverage: 100.0% (32/32)
2022-12-18 23:44:05,947 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:44:05,971 INFO DONE, Getting attention scores...
2022-12-18 23:44:06,027 INFO Evaluating teacher test iter12 on 32 examples
2022-12-18 23:44:06,031 INFO teacher test iter12 performance: 100.00
2022-12-18 23:44:06,032 INFO teacher test iter12 confusion matrix:
[[32]]
2022-12-18 23:44:06,032 INFO teacher test iter12 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:44:06,032 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:44:06,036 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:44:06,037 INFO Balancing Pseudo Dataset to keep 808 items...
2022-12-18 23:44:06,042 INFO PSEUDO-DATASET:
808 examples
PSEUDO-LABELS:
1    404
0    404
Name: label, dtype: int64
2022-12-18 23:44:06,042 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:44:07,920 INFO fine-tuning the student on clean labeled data
2022-12-18 23:44:09,172 INFO Predicting labels for 18 texts
2022-12-18 23:44:09,275 INFO Evaluating student dev iter12 on 18 examples
2022-12-18 23:44:09,279 INFO student dev iter12 performance: 94.44
2022-12-18 23:44:09,279 INFO student dev iter12 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:44:09,279 INFO student dev iter12 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:44:09,280 INFO Predicting labels for 32 texts
2022-12-18 23:44:09,386 INFO Evaluating student test iter12 on 32 examples
2022-12-18 23:44:09,391 INFO student test iter12 performance: 96.88
2022-12-18 23:44:09,392 INFO student test iter12 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:44:09,392 INFO student test iter12 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:44:09,392 INFO Student Dev performance on iter 12: 94.44444444444444
2022-12-18 23:44:09,392 INFO Student Test performance on iter 12: 96.875
2022-12-18 23:44:09,392 INFO 

	 *** Starting loop 13 ***
2022-12-18 23:44:09,392 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:44:09,392 INFO Downsampling 444 data
2022-12-18 23:44:09,393 INFO Adding Student as extra rule in Teacher
2022-12-18 23:44:09,393 INFO Getting rule predictions
2022-12-18 23:44:09,393 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:44:09,394 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:09,394 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:09,395 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:44:09,396 INFO Predicting labels for 741 texts
2022-12-18 23:44:09,500 INFO Predicting labels for 18 texts
2022-12-18 23:44:09,600 INFO Predicting labels for 444 texts
2022-12-18 23:44:09,704 INFO Training Rule Attention Network
2022-12-18 23:44:09,711 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:44:09,712 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:44:09,716 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:44:09,716 INFO 

		*** Training RAN ***
2022-12-18 23:44:12,662 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:12,664 INFO Predicting labels for 444 texts
2022-12-18 23:44:12,771 INFO There are 3/7 active rules
2022-12-18 23:44:12,772 INFO Coverage: 100.0% (444/444)
2022-12-18 23:44:12,776 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:44:12,864 INFO DONE, Getting attention scores...
2022-12-18 23:44:12,923 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:12,923 INFO Predicting labels for 18 texts
2022-12-18 23:44:13,023 INFO There are 7/7 active rules
2022-12-18 23:44:13,023 INFO Coverage: 100.0% (18/18)
2022-12-18 23:44:13,023 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:44:13,048 INFO DONE, Getting attention scores...
2022-12-18 23:44:13,106 INFO Evaluating teacher dev iter13 on 18 examples
2022-12-18 23:44:13,110 INFO teacher dev iter13 performance: 94.44
2022-12-18 23:44:13,111 INFO teacher dev iter13 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:44:13,111 INFO teacher dev iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:44:13,111 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:44:13,111 INFO Predicting labels for 32 texts
2022-12-18 23:44:13,219 INFO There are 7/7 active rules
2022-12-18 23:44:13,219 INFO Coverage: 100.0% (32/32)
2022-12-18 23:44:13,220 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:44:13,243 INFO DONE, Getting attention scores...
2022-12-18 23:44:13,297 INFO Evaluating teacher test iter13 on 32 examples
2022-12-18 23:44:13,301 INFO teacher test iter13 performance: 100.00
2022-12-18 23:44:13,301 INFO teacher test iter13 confusion matrix:
[[32]]
2022-12-18 23:44:13,301 INFO teacher test iter13 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:44:13,301 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:44:13,304 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:44:13,306 INFO Balancing Pseudo Dataset to keep 760 items...
2022-12-18 23:44:13,309 INFO PSEUDO-DATASET:
760 examples
PSEUDO-LABELS:
1    380
0    380
Name: label, dtype: int64
2022-12-18 23:44:13,309 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:44:15,103 INFO fine-tuning the student on clean labeled data
2022-12-18 23:44:18,359 INFO Predicting labels for 18 texts
2022-12-18 23:44:18,463 INFO Evaluating student dev iter13 on 18 examples
2022-12-18 23:44:18,467 INFO student dev iter13 performance: 94.44
2022-12-18 23:44:18,467 INFO student dev iter13 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:44:18,467 INFO student dev iter13 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:44:18,467 INFO Predicting labels for 32 texts
2022-12-18 23:44:18,573 INFO Evaluating student test iter13 on 32 examples
2022-12-18 23:44:18,578 INFO student test iter13 performance: 96.88
2022-12-18 23:44:18,578 INFO student test iter13 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:44:18,579 INFO student test iter13 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:44:18,579 INFO Student Dev performance on iter 13: 94.44444444444444
2022-12-18 23:44:18,579 INFO Student Test performance on iter 13: 96.875
2022-12-18 23:44:18,579 INFO 

	 *** Starting loop 14 ***
2022-12-18 23:44:18,579 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:44:18,579 INFO Downsampling 444 data
2022-12-18 23:44:18,580 INFO Adding Student as extra rule in Teacher
2022-12-18 23:44:18,580 INFO Getting rule predictions
2022-12-18 23:44:18,580 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:44:18,581 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:18,581 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:18,582 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:44:18,583 INFO Predicting labels for 741 texts
2022-12-18 23:44:18,688 INFO Predicting labels for 18 texts
2022-12-18 23:44:18,789 INFO Predicting labels for 444 texts
2022-12-18 23:44:18,892 INFO Training Rule Attention Network
2022-12-18 23:44:18,902 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:44:18,902 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:44:18,906 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:44:18,907 INFO 

		*** Training RAN ***
2022-12-18 23:44:21,845 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:21,847 INFO Predicting labels for 444 texts
2022-12-18 23:44:21,952 INFO There are 3/7 active rules
2022-12-18 23:44:21,952 INFO Coverage: 100.0% (444/444)
2022-12-18 23:44:21,957 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:44:22,045 INFO DONE, Getting attention scores...
2022-12-18 23:44:22,103 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:22,103 INFO Predicting labels for 18 texts
2022-12-18 23:44:22,202 INFO There are 7/7 active rules
2022-12-18 23:44:22,202 INFO Coverage: 100.0% (18/18)
2022-12-18 23:44:22,203 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:44:22,227 INFO DONE, Getting attention scores...
2022-12-18 23:44:22,287 INFO Evaluating teacher dev iter14 on 18 examples
2022-12-18 23:44:22,291 INFO teacher dev iter14 performance: 94.44
2022-12-18 23:44:22,291 INFO teacher dev iter14 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:44:22,291 INFO teacher dev iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:44:22,292 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:44:22,292 INFO Predicting labels for 32 texts
2022-12-18 23:44:22,412 INFO There are 7/7 active rules
2022-12-18 23:44:22,412 INFO Coverage: 100.0% (32/32)
2022-12-18 23:44:22,413 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:44:22,438 INFO DONE, Getting attention scores...
2022-12-18 23:44:22,491 INFO Evaluating teacher test iter14 on 32 examples
2022-12-18 23:44:22,495 INFO teacher test iter14 performance: 100.00
2022-12-18 23:44:22,495 INFO teacher test iter14 confusion matrix:
[[32]]
2022-12-18 23:44:22,496 INFO teacher test iter14 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:44:22,496 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:44:22,500 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:44:22,501 INFO Balancing Pseudo Dataset to keep 824 items...
2022-12-18 23:44:22,505 INFO PSEUDO-DATASET:
824 examples
PSEUDO-LABELS:
1    412
0    412
Name: label, dtype: int64
2022-12-18 23:44:22,505 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:44:24,292 INFO fine-tuning the student on clean labeled data
2022-12-18 23:44:26,683 INFO Predicting labels for 18 texts
2022-12-18 23:44:26,794 INFO Evaluating student dev iter14 on 18 examples
2022-12-18 23:44:26,798 INFO student dev iter14 performance: 94.44
2022-12-18 23:44:26,798 INFO student dev iter14 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:44:26,798 INFO student dev iter14 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:44:26,799 INFO Predicting labels for 32 texts
2022-12-18 23:44:27,932 INFO Evaluating student test iter14 on 32 examples
2022-12-18 23:44:27,938 INFO student test iter14 performance: 96.88
2022-12-18 23:44:27,938 INFO student test iter14 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:44:27,938 INFO student test iter14 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:44:27,938 INFO Student Dev performance on iter 14: 94.44444444444444
2022-12-18 23:44:27,938 INFO Student Test performance on iter 14: 96.875
2022-12-18 23:44:27,938 INFO 

	 *** Starting loop 15 ***
2022-12-18 23:44:27,939 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:44:27,939 INFO Downsampling 444 data
2022-12-18 23:44:27,939 INFO Adding Student as extra rule in Teacher
2022-12-18 23:44:27,939 INFO Getting rule predictions
2022-12-18 23:44:27,939 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:44:27,940 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:27,940 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:27,941 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:44:27,942 INFO Predicting labels for 741 texts
2022-12-18 23:44:28,052 INFO Predicting labels for 18 texts
2022-12-18 23:44:28,153 INFO Predicting labels for 444 texts
2022-12-18 23:44:28,262 INFO Training Rule Attention Network
2022-12-18 23:44:28,270 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:44:28,270 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:44:28,274 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:44:28,274 INFO 

		*** Training RAN ***
2022-12-18 23:44:31,160 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:31,161 INFO Predicting labels for 444 texts
2022-12-18 23:44:31,272 INFO There are 3/7 active rules
2022-12-18 23:44:31,272 INFO Coverage: 100.0% (444/444)
2022-12-18 23:44:31,277 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:44:31,377 INFO DONE, Getting attention scores...
2022-12-18 23:44:31,438 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:31,438 INFO Predicting labels for 18 texts
2022-12-18 23:44:31,546 INFO There are 7/7 active rules
2022-12-18 23:44:31,546 INFO Coverage: 100.0% (18/18)
2022-12-18 23:44:31,546 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:44:31,571 INFO DONE, Getting attention scores...
2022-12-18 23:44:31,630 INFO Evaluating teacher dev iter15 on 18 examples
2022-12-18 23:44:31,634 INFO teacher dev iter15 performance: 94.44
2022-12-18 23:44:31,634 INFO teacher dev iter15 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:44:31,634 INFO teacher dev iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:44:31,634 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:44:31,635 INFO Predicting labels for 32 texts
2022-12-18 23:44:31,737 INFO There are 7/7 active rules
2022-12-18 23:44:31,737 INFO Coverage: 100.0% (32/32)
2022-12-18 23:44:31,738 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:44:31,763 INFO DONE, Getting attention scores...
2022-12-18 23:44:31,819 INFO Evaluating teacher test iter15 on 32 examples
2022-12-18 23:44:31,823 INFO teacher test iter15 performance: 100.00
2022-12-18 23:44:31,824 INFO teacher test iter15 confusion matrix:
[[32]]
2022-12-18 23:44:31,825 INFO teacher test iter15 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:44:31,825 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:44:31,828 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:44:31,830 INFO Balancing Pseudo Dataset to keep 814 items...
2022-12-18 23:44:31,835 INFO PSEUDO-DATASET:
814 examples
PSEUDO-LABELS:
1    407
0    407
Name: label, dtype: int64
2022-12-18 23:44:31,835 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:44:33,580 INFO fine-tuning the student on clean labeled data
2022-12-18 23:44:35,907 INFO Predicting labels for 18 texts
2022-12-18 23:44:36,011 INFO Evaluating student dev iter15 on 18 examples
2022-12-18 23:44:36,016 INFO student dev iter15 performance: 94.44
2022-12-18 23:44:36,016 INFO student dev iter15 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:44:36,016 INFO student dev iter15 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:44:36,016 INFO Predicting labels for 32 texts
2022-12-18 23:44:36,118 INFO Evaluating student test iter15 on 32 examples
2022-12-18 23:44:36,124 INFO student test iter15 performance: 96.88
2022-12-18 23:44:36,124 INFO student test iter15 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:44:36,124 INFO student test iter15 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:44:36,124 INFO Student Dev performance on iter 15: 94.44444444444444
2022-12-18 23:44:36,125 INFO Student Test performance on iter 15: 96.875
2022-12-18 23:44:36,125 INFO 

	 *** Starting loop 16 ***
2022-12-18 23:44:36,125 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:44:36,125 INFO Downsampling 444 data
2022-12-18 23:44:36,125 INFO Adding Student as extra rule in Teacher
2022-12-18 23:44:36,125 INFO Getting rule predictions
2022-12-18 23:44:36,126 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:44:36,126 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:36,127 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:36,127 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:44:36,128 INFO Predicting labels for 741 texts
2022-12-18 23:44:36,233 INFO Predicting labels for 18 texts
2022-12-18 23:44:36,340 INFO Predicting labels for 444 texts
2022-12-18 23:44:36,444 INFO Training Rule Attention Network
2022-12-18 23:44:36,451 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:44:36,452 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:44:36,455 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:44:36,455 INFO 

		*** Training RAN ***
2022-12-18 23:44:39,353 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:39,354 INFO Predicting labels for 444 texts
2022-12-18 23:44:39,462 INFO There are 3/7 active rules
2022-12-18 23:44:39,462 INFO Coverage: 100.0% (444/444)
2022-12-18 23:44:39,466 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:44:39,548 INFO DONE, Getting attention scores...
2022-12-18 23:44:39,605 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:39,605 INFO Predicting labels for 18 texts
2022-12-18 23:44:39,714 INFO There are 7/7 active rules
2022-12-18 23:44:39,714 INFO Coverage: 100.0% (18/18)
2022-12-18 23:44:39,715 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:44:39,739 INFO DONE, Getting attention scores...
2022-12-18 23:44:39,793 INFO Evaluating teacher dev iter16 on 18 examples
2022-12-18 23:44:39,797 INFO teacher dev iter16 performance: 94.44
2022-12-18 23:44:39,797 INFO teacher dev iter16 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:44:39,798 INFO teacher dev iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:44:39,798 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:44:39,798 INFO Predicting labels for 32 texts
2022-12-18 23:44:39,911 INFO There are 7/7 active rules
2022-12-18 23:44:39,911 INFO Coverage: 100.0% (32/32)
2022-12-18 23:44:39,912 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:44:39,937 INFO DONE, Getting attention scores...
2022-12-18 23:44:39,992 INFO Evaluating teacher test iter16 on 32 examples
2022-12-18 23:44:39,996 INFO teacher test iter16 performance: 100.00
2022-12-18 23:44:39,996 INFO teacher test iter16 confusion matrix:
[[32]]
2022-12-18 23:44:39,996 INFO teacher test iter16 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:44:39,996 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:44:39,999 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:44:40,000 INFO Balancing Pseudo Dataset to keep 808 items...
2022-12-18 23:44:40,004 INFO PSEUDO-DATASET:
808 examples
PSEUDO-LABELS:
1    404
0    404
Name: label, dtype: int64
2022-12-18 23:44:40,004 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:44:41,876 INFO fine-tuning the student on clean labeled data
2022-12-18 23:44:43,102 INFO Predicting labels for 18 texts
2022-12-18 23:44:43,208 INFO Evaluating student dev iter16 on 18 examples
2022-12-18 23:44:43,213 INFO student dev iter16 performance: 94.44
2022-12-18 23:44:43,213 INFO student dev iter16 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:44:43,213 INFO student dev iter16 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:44:43,213 INFO Predicting labels for 32 texts
2022-12-18 23:44:43,317 INFO Evaluating student test iter16 on 32 examples
2022-12-18 23:44:43,322 INFO student test iter16 performance: 96.88
2022-12-18 23:44:43,323 INFO student test iter16 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:44:43,323 INFO student test iter16 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:44:43,323 INFO Student Dev performance on iter 16: 94.44444444444444
2022-12-18 23:44:43,323 INFO Student Test performance on iter 16: 96.875
2022-12-18 23:44:43,323 INFO 

	 *** Starting loop 17 ***
2022-12-18 23:44:43,323 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:44:43,323 INFO Downsampling 444 data
2022-12-18 23:44:43,324 INFO Adding Student as extra rule in Teacher
2022-12-18 23:44:43,324 INFO Getting rule predictions
2022-12-18 23:44:43,324 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:44:43,325 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:43,325 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:43,325 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:44:43,326 INFO Predicting labels for 741 texts
2022-12-18 23:44:43,433 INFO Predicting labels for 18 texts
2022-12-18 23:44:43,534 INFO Predicting labels for 444 texts
2022-12-18 23:44:43,637 INFO Training Rule Attention Network
2022-12-18 23:44:43,644 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:44:43,645 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:44:43,649 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:44:43,649 INFO 

		*** Training RAN ***
2022-12-18 23:44:46,557 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:46,558 INFO Predicting labels for 444 texts
2022-12-18 23:44:46,663 INFO There are 3/7 active rules
2022-12-18 23:44:46,663 INFO Coverage: 100.0% (444/444)
2022-12-18 23:44:46,667 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:44:46,756 INFO DONE, Getting attention scores...
2022-12-18 23:44:46,813 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:46,814 INFO Predicting labels for 18 texts
2022-12-18 23:44:46,914 INFO There are 7/7 active rules
2022-12-18 23:44:46,914 INFO Coverage: 100.0% (18/18)
2022-12-18 23:44:46,915 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:44:46,941 INFO DONE, Getting attention scores...
2022-12-18 23:44:46,999 INFO Evaluating teacher dev iter17 on 18 examples
2022-12-18 23:44:47,003 INFO teacher dev iter17 performance: 94.44
2022-12-18 23:44:47,003 INFO teacher dev iter17 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:44:47,004 INFO teacher dev iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:44:47,004 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:44:47,004 INFO Predicting labels for 32 texts
2022-12-18 23:44:47,105 INFO There are 7/7 active rules
2022-12-18 23:44:47,106 INFO Coverage: 100.0% (32/32)
2022-12-18 23:44:47,107 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:44:47,131 INFO DONE, Getting attention scores...
2022-12-18 23:44:47,185 INFO Evaluating teacher test iter17 on 32 examples
2022-12-18 23:44:47,189 INFO teacher test iter17 performance: 100.00
2022-12-18 23:44:47,190 INFO teacher test iter17 confusion matrix:
[[32]]
2022-12-18 23:44:47,190 INFO teacher test iter17 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:44:47,190 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:44:47,193 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:44:47,195 INFO Balancing Pseudo Dataset to keep 808 items...
2022-12-18 23:44:47,199 INFO PSEUDO-DATASET:
808 examples
PSEUDO-LABELS:
1    404
0    404
Name: label, dtype: int64
2022-12-18 23:44:47,199 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:44:48,986 INFO fine-tuning the student on clean labeled data
2022-12-18 23:44:50,194 INFO Predicting labels for 18 texts
2022-12-18 23:44:50,301 INFO Evaluating student dev iter17 on 18 examples
2022-12-18 23:44:50,305 INFO student dev iter17 performance: 94.44
2022-12-18 23:44:50,305 INFO student dev iter17 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:44:50,306 INFO student dev iter17 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:44:50,306 INFO Predicting labels for 32 texts
2022-12-18 23:44:50,408 INFO Evaluating student test iter17 on 32 examples
2022-12-18 23:44:50,413 INFO student test iter17 performance: 96.88
2022-12-18 23:44:50,413 INFO student test iter17 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:44:50,413 INFO student test iter17 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:44:50,413 INFO Student Dev performance on iter 17: 94.44444444444444
2022-12-18 23:44:50,414 INFO Student Test performance on iter 17: 96.875
2022-12-18 23:44:50,414 INFO 

	 *** Starting loop 18 ***
2022-12-18 23:44:50,414 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:44:50,414 INFO Downsampling 444 data
2022-12-18 23:44:50,415 INFO Adding Student as extra rule in Teacher
2022-12-18 23:44:50,415 INFO Getting rule predictions
2022-12-18 23:44:50,415 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:44:50,416 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:50,416 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:50,416 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:44:50,417 INFO Predicting labels for 741 texts
2022-12-18 23:44:50,518 INFO Predicting labels for 18 texts
2022-12-18 23:44:50,621 INFO Predicting labels for 444 texts
2022-12-18 23:44:50,723 INFO Training Rule Attention Network
2022-12-18 23:44:50,730 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:44:50,730 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:44:50,734 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:44:50,734 INFO 

		*** Training RAN ***
2022-12-18 23:44:53,738 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:53,739 INFO Predicting labels for 444 texts
2022-12-18 23:44:53,850 INFO There are 3/7 active rules
2022-12-18 23:44:53,851 INFO Coverage: 100.0% (444/444)
2022-12-18 23:44:53,855 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:44:53,944 INFO DONE, Getting attention scores...
2022-12-18 23:44:54,000 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:54,001 INFO Predicting labels for 18 texts
2022-12-18 23:44:54,108 INFO There are 7/7 active rules
2022-12-18 23:44:54,108 INFO Coverage: 100.0% (18/18)
2022-12-18 23:44:54,109 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:44:54,130 INFO DONE, Getting attention scores...
2022-12-18 23:44:54,185 INFO Evaluating teacher dev iter18 on 18 examples
2022-12-18 23:44:54,189 INFO teacher dev iter18 performance: 94.44
2022-12-18 23:44:54,189 INFO teacher dev iter18 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:44:54,189 INFO teacher dev iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:44:54,190 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:44:54,190 INFO Predicting labels for 32 texts
2022-12-18 23:44:54,303 INFO There are 7/7 active rules
2022-12-18 23:44:54,304 INFO Coverage: 100.0% (32/32)
2022-12-18 23:44:54,304 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:44:54,328 INFO DONE, Getting attention scores...
2022-12-18 23:44:54,382 INFO Evaluating teacher test iter18 on 32 examples
2022-12-18 23:44:54,386 INFO teacher test iter18 performance: 100.00
2022-12-18 23:44:54,387 INFO teacher test iter18 confusion matrix:
[[32]]
2022-12-18 23:44:54,387 INFO teacher test iter18 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:44:54,387 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:44:54,391 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:44:54,393 INFO Balancing Pseudo Dataset to keep 816 items...
2022-12-18 23:44:54,397 INFO PSEUDO-DATASET:
816 examples
PSEUDO-LABELS:
1    408
0    408
Name: label, dtype: int64
2022-12-18 23:44:54,397 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:44:56,226 INFO fine-tuning the student on clean labeled data
2022-12-18 23:44:58,426 INFO Predicting labels for 18 texts
2022-12-18 23:44:58,533 INFO Evaluating student dev iter18 on 18 examples
2022-12-18 23:44:58,537 INFO student dev iter18 performance: 94.44
2022-12-18 23:44:58,537 INFO student dev iter18 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:44:58,537 INFO student dev iter18 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:44:58,538 INFO Predicting labels for 32 texts
2022-12-18 23:44:58,642 INFO Evaluating student test iter18 on 32 examples
2022-12-18 23:44:58,648 INFO student test iter18 performance: 96.88
2022-12-18 23:44:58,648 INFO student test iter18 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:44:58,648 INFO student test iter18 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:44:58,649 INFO Student Dev performance on iter 18: 94.44444444444444
2022-12-18 23:44:58,649 INFO Student Test performance on iter 18: 96.875
2022-12-18 23:44:58,649 INFO 

	 *** Starting loop 19 ***
2022-12-18 23:44:58,649 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:44:58,649 INFO Downsampling 444 data
2022-12-18 23:44:58,650 INFO Adding Student as extra rule in Teacher
2022-12-18 23:44:58,650 INFO Getting rule predictions
2022-12-18 23:44:58,650 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:44:58,651 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:44:58,651 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:44:58,651 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:44:58,652 INFO Predicting labels for 741 texts
2022-12-18 23:44:58,757 INFO Predicting labels for 18 texts
2022-12-18 23:44:59,887 INFO Predicting labels for 444 texts
2022-12-18 23:44:59,993 INFO Training Rule Attention Network
2022-12-18 23:45:00,000 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:45:00,001 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:45:00,005 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:45:00,005 INFO 

		*** Training RAN ***
2022-12-18 23:45:02,949 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:02,950 INFO Predicting labels for 444 texts
2022-12-18 23:45:03,162 INFO There are 3/7 active rules
2022-12-18 23:45:03,162 INFO Coverage: 100.0% (444/444)
2022-12-18 23:45:03,166 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:45:03,256 INFO DONE, Getting attention scores...
2022-12-18 23:45:03,315 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:03,315 INFO Predicting labels for 18 texts
2022-12-18 23:45:03,426 INFO There are 7/7 active rules
2022-12-18 23:45:03,427 INFO Coverage: 100.0% (18/18)
2022-12-18 23:45:03,427 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:45:03,453 INFO DONE, Getting attention scores...
2022-12-18 23:45:03,509 INFO Evaluating teacher dev iter19 on 18 examples
2022-12-18 23:45:03,513 INFO teacher dev iter19 performance: 94.44
2022-12-18 23:45:03,513 INFO teacher dev iter19 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:45:03,513 INFO teacher dev iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:45:03,513 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:45:03,513 INFO Predicting labels for 32 texts
2022-12-18 23:45:03,617 INFO There are 7/7 active rules
2022-12-18 23:45:03,618 INFO Coverage: 100.0% (32/32)
2022-12-18 23:45:03,619 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:45:03,642 INFO DONE, Getting attention scores...
2022-12-18 23:45:03,702 INFO Evaluating teacher test iter19 on 32 examples
2022-12-18 23:45:03,706 INFO teacher test iter19 performance: 100.00
2022-12-18 23:45:03,706 INFO teacher test iter19 confusion matrix:
[[32]]
2022-12-18 23:45:03,706 INFO teacher test iter19 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:45:03,706 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:45:03,709 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:45:03,711 INFO Balancing Pseudo Dataset to keep 814 items...
2022-12-18 23:45:03,715 INFO PSEUDO-DATASET:
814 examples
PSEUDO-LABELS:
1    407
0    407
Name: label, dtype: int64
2022-12-18 23:45:03,715 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:45:05,528 INFO fine-tuning the student on clean labeled data
2022-12-18 23:45:07,763 INFO Predicting labels for 18 texts
2022-12-18 23:45:07,865 INFO Evaluating student dev iter19 on 18 examples
2022-12-18 23:45:07,869 INFO student dev iter19 performance: 94.44
2022-12-18 23:45:07,870 INFO student dev iter19 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:45:07,870 INFO student dev iter19 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:45:07,870 INFO Predicting labels for 32 texts
2022-12-18 23:45:07,976 INFO Evaluating student test iter19 on 32 examples
2022-12-18 23:45:07,981 INFO student test iter19 performance: 96.88
2022-12-18 23:45:07,981 INFO student test iter19 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:45:07,981 INFO student test iter19 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:45:07,981 INFO Student Dev performance on iter 19: 94.44444444444444
2022-12-18 23:45:07,982 INFO Student Test performance on iter 19: 96.875
2022-12-18 23:45:07,982 INFO 

	 *** Starting loop 20 ***
2022-12-18 23:45:07,982 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:45:07,982 INFO Downsampling 444 data
2022-12-18 23:45:07,982 INFO Adding Student as extra rule in Teacher
2022-12-18 23:45:07,983 INFO Getting rule predictions
2022-12-18 23:45:07,983 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:45:07,984 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:07,984 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:07,984 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:45:07,985 INFO Predicting labels for 741 texts
2022-12-18 23:45:08,090 INFO Predicting labels for 18 texts
2022-12-18 23:45:08,190 INFO Predicting labels for 444 texts
2022-12-18 23:45:08,297 INFO Training Rule Attention Network
2022-12-18 23:45:08,305 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:45:08,305 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:45:08,309 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:45:08,309 INFO 

		*** Training RAN ***
2022-12-18 23:45:11,121 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:11,122 INFO Predicting labels for 444 texts
2022-12-18 23:45:11,229 INFO There are 3/7 active rules
2022-12-18 23:45:11,230 INFO Coverage: 100.0% (444/444)
2022-12-18 23:45:11,234 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:45:11,321 INFO DONE, Getting attention scores...
2022-12-18 23:45:11,376 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:11,377 INFO Predicting labels for 18 texts
2022-12-18 23:45:11,477 INFO There are 7/7 active rules
2022-12-18 23:45:11,478 INFO Coverage: 100.0% (18/18)
2022-12-18 23:45:11,478 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:45:11,502 INFO DONE, Getting attention scores...
2022-12-18 23:45:11,558 INFO Evaluating teacher dev iter20 on 18 examples
2022-12-18 23:45:11,562 INFO teacher dev iter20 performance: 94.44
2022-12-18 23:45:11,562 INFO teacher dev iter20 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:45:11,562 INFO teacher dev iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:45:11,562 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:45:11,562 INFO Predicting labels for 32 texts
2022-12-18 23:45:11,663 INFO There are 7/7 active rules
2022-12-18 23:45:11,663 INFO Coverage: 100.0% (32/32)
2022-12-18 23:45:11,664 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:45:11,688 INFO DONE, Getting attention scores...
2022-12-18 23:45:11,740 INFO Evaluating teacher test iter20 on 32 examples
2022-12-18 23:45:11,744 INFO teacher test iter20 performance: 100.00
2022-12-18 23:45:11,744 INFO teacher test iter20 confusion matrix:
[[32]]
2022-12-18 23:45:11,744 INFO teacher test iter20 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:45:11,745 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:45:11,748 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:45:11,749 INFO Balancing Pseudo Dataset to keep 814 items...
2022-12-18 23:45:11,753 INFO PSEUDO-DATASET:
814 examples
PSEUDO-LABELS:
1    407
0    407
Name: label, dtype: int64
2022-12-18 23:45:11,753 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:45:13,789 INFO fine-tuning the student on clean labeled data
2022-12-18 23:45:14,987 INFO Predicting labels for 18 texts
2022-12-18 23:45:15,097 INFO Evaluating student dev iter20 on 18 examples
2022-12-18 23:45:15,102 INFO student dev iter20 performance: 94.44
2022-12-18 23:45:15,102 INFO student dev iter20 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:45:15,103 INFO student dev iter20 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:45:15,103 INFO Predicting labels for 32 texts
2022-12-18 23:45:15,207 INFO Evaluating student test iter20 on 32 examples
2022-12-18 23:45:15,212 INFO student test iter20 performance: 96.88
2022-12-18 23:45:15,212 INFO student test iter20 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:45:15,213 INFO student test iter20 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:45:15,213 INFO Student Dev performance on iter 20: 94.44444444444444
2022-12-18 23:45:15,213 INFO Student Test performance on iter 20: 96.875
2022-12-18 23:45:15,213 INFO 

	 *** Starting loop 21 ***
2022-12-18 23:45:15,213 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:45:15,213 INFO Downsampling 444 data
2022-12-18 23:45:15,214 INFO Adding Student as extra rule in Teacher
2022-12-18 23:45:15,214 INFO Getting rule predictions
2022-12-18 23:45:15,214 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:45:15,215 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:15,215 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:15,216 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:45:15,216 INFO Predicting labels for 741 texts
2022-12-18 23:45:15,327 INFO Predicting labels for 18 texts
2022-12-18 23:45:15,432 INFO Predicting labels for 444 texts
2022-12-18 23:45:15,534 INFO Training Rule Attention Network
2022-12-18 23:45:15,542 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:45:15,542 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:45:15,546 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:45:15,546 INFO 

		*** Training RAN ***
2022-12-18 23:45:18,371 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:18,372 INFO Predicting labels for 444 texts
2022-12-18 23:45:18,477 INFO There are 3/7 active rules
2022-12-18 23:45:18,477 INFO Coverage: 100.0% (444/444)
2022-12-18 23:45:18,481 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:45:18,567 INFO DONE, Getting attention scores...
2022-12-18 23:45:18,626 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:18,626 INFO Predicting labels for 18 texts
2022-12-18 23:45:18,727 INFO There are 7/7 active rules
2022-12-18 23:45:18,728 INFO Coverage: 100.0% (18/18)
2022-12-18 23:45:18,728 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:45:18,752 INFO DONE, Getting attention scores...
2022-12-18 23:45:18,810 INFO Evaluating teacher dev iter21 on 18 examples
2022-12-18 23:45:18,815 INFO teacher dev iter21 performance: 94.44
2022-12-18 23:45:18,815 INFO teacher dev iter21 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:45:18,815 INFO teacher dev iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:45:18,815 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:45:18,816 INFO Predicting labels for 32 texts
2022-12-18 23:45:18,917 INFO There are 7/7 active rules
2022-12-18 23:45:18,917 INFO Coverage: 100.0% (32/32)
2022-12-18 23:45:18,918 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:45:18,943 INFO DONE, Getting attention scores...
2022-12-18 23:45:18,997 INFO Evaluating teacher test iter21 on 32 examples
2022-12-18 23:45:19,001 INFO teacher test iter21 performance: 100.00
2022-12-18 23:45:19,001 INFO teacher test iter21 confusion matrix:
[[32]]
2022-12-18 23:45:19,001 INFO teacher test iter21 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:45:19,002 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:45:19,005 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:45:19,007 INFO Balancing Pseudo Dataset to keep 816 items...
2022-12-18 23:45:19,011 INFO PSEUDO-DATASET:
816 examples
PSEUDO-LABELS:
1    408
0    408
Name: label, dtype: int64
2022-12-18 23:45:19,011 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:45:20,833 INFO fine-tuning the student on clean labeled data
2022-12-18 23:45:24,253 INFO Predicting labels for 18 texts
2022-12-18 23:45:24,367 INFO Evaluating student dev iter21 on 18 examples
2022-12-18 23:45:24,372 INFO student dev iter21 performance: 94.44
2022-12-18 23:45:24,372 INFO student dev iter21 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:45:24,372 INFO student dev iter21 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:45:24,372 INFO Predicting labels for 32 texts
2022-12-18 23:45:24,477 INFO Evaluating student test iter21 on 32 examples
2022-12-18 23:45:24,483 INFO student test iter21 performance: 96.88
2022-12-18 23:45:24,483 INFO student test iter21 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:45:24,484 INFO student test iter21 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:45:24,484 INFO Student Dev performance on iter 21: 94.44444444444444
2022-12-18 23:45:24,484 INFO Student Test performance on iter 21: 96.875
2022-12-18 23:45:24,484 INFO 

	 *** Starting loop 22 ***
2022-12-18 23:45:24,484 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:45:24,484 INFO Downsampling 444 data
2022-12-18 23:45:24,485 INFO Adding Student as extra rule in Teacher
2022-12-18 23:45:24,485 INFO Getting rule predictions
2022-12-18 23:45:24,485 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:45:24,486 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:24,486 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:24,487 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:45:24,488 INFO Predicting labels for 741 texts
2022-12-18 23:45:24,598 INFO Predicting labels for 18 texts
2022-12-18 23:45:24,703 INFO Predicting labels for 444 texts
2022-12-18 23:45:24,805 INFO Training Rule Attention Network
2022-12-18 23:45:24,816 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:45:24,816 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:45:24,820 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:45:24,821 INFO 

		*** Training RAN ***
2022-12-18 23:45:27,740 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:27,741 INFO Predicting labels for 444 texts
2022-12-18 23:45:27,848 INFO There are 3/7 active rules
2022-12-18 23:45:27,849 INFO Coverage: 100.0% (444/444)
2022-12-18 23:45:27,853 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:45:27,945 INFO DONE, Getting attention scores...
2022-12-18 23:45:28,002 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:28,003 INFO Predicting labels for 18 texts
2022-12-18 23:45:29,124 INFO There are 7/7 active rules
2022-12-18 23:45:29,124 INFO Coverage: 100.0% (18/18)
2022-12-18 23:45:29,125 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:45:29,147 INFO DONE, Getting attention scores...
2022-12-18 23:45:29,205 INFO Evaluating teacher dev iter22 on 18 examples
2022-12-18 23:45:29,209 INFO teacher dev iter22 performance: 94.44
2022-12-18 23:45:29,209 INFO teacher dev iter22 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:45:29,209 INFO teacher dev iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:45:29,209 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:45:29,209 INFO Predicting labels for 32 texts
2022-12-18 23:45:30,338 INFO There are 7/7 active rules
2022-12-18 23:45:30,338 INFO Coverage: 100.0% (32/32)
2022-12-18 23:45:30,339 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:45:30,363 INFO DONE, Getting attention scores...
2022-12-18 23:45:30,417 INFO Evaluating teacher test iter22 on 32 examples
2022-12-18 23:45:30,421 INFO teacher test iter22 performance: 100.00
2022-12-18 23:45:30,421 INFO teacher test iter22 confusion matrix:
[[32]]
2022-12-18 23:45:30,421 INFO teacher test iter22 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:45:30,421 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:45:30,424 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:45:30,426 INFO Balancing Pseudo Dataset to keep 782 items...
2022-12-18 23:45:30,429 INFO PSEUDO-DATASET:
782 examples
PSEUDO-LABELS:
1    391
0    391
Name: label, dtype: int64
2022-12-18 23:45:30,429 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:45:31,650 INFO fine-tuning the student on clean labeled data
2022-12-18 23:45:33,182 INFO Predicting labels for 18 texts
2022-12-18 23:45:33,293 INFO Evaluating student dev iter22 on 18 examples
2022-12-18 23:45:33,297 INFO student dev iter22 performance: 94.44
2022-12-18 23:45:33,297 INFO student dev iter22 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:45:33,297 INFO student dev iter22 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:45:33,298 INFO Predicting labels for 32 texts
2022-12-18 23:45:33,404 INFO Evaluating student test iter22 on 32 examples
2022-12-18 23:45:33,409 INFO student test iter22 performance: 96.88
2022-12-18 23:45:33,410 INFO student test iter22 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:45:33,410 INFO student test iter22 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:45:33,410 INFO Student Dev performance on iter 22: 94.44444444444444
2022-12-18 23:45:33,410 INFO Student Test performance on iter 22: 96.875
2022-12-18 23:45:33,410 INFO 

	 *** Starting loop 23 ***
2022-12-18 23:45:33,410 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:45:33,410 INFO Downsampling 444 data
2022-12-18 23:45:33,411 INFO Adding Student as extra rule in Teacher
2022-12-18 23:45:33,411 INFO Getting rule predictions
2022-12-18 23:45:33,411 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:45:33,412 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:33,412 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:33,413 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:45:33,414 INFO Predicting labels for 741 texts
2022-12-18 23:45:33,522 INFO Predicting labels for 18 texts
2022-12-18 23:45:33,640 INFO Predicting labels for 444 texts
2022-12-18 23:45:33,751 INFO Training Rule Attention Network
2022-12-18 23:45:33,759 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:45:33,760 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:45:33,767 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:45:33,767 INFO 

		*** Training RAN ***
2022-12-18 23:45:36,812 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:36,814 INFO Predicting labels for 444 texts
2022-12-18 23:45:37,947 INFO There are 3/7 active rules
2022-12-18 23:45:37,948 INFO Coverage: 100.0% (444/444)
2022-12-18 23:45:37,952 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:45:38,036 INFO DONE, Getting attention scores...
2022-12-18 23:45:38,096 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:38,096 INFO Predicting labels for 18 texts
2022-12-18 23:45:38,197 INFO There are 7/7 active rules
2022-12-18 23:45:38,198 INFO Coverage: 100.0% (18/18)
2022-12-18 23:45:38,198 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:45:38,222 INFO DONE, Getting attention scores...
2022-12-18 23:45:38,275 INFO Evaluating teacher dev iter23 on 18 examples
2022-12-18 23:45:38,279 INFO teacher dev iter23 performance: 94.44
2022-12-18 23:45:38,279 INFO teacher dev iter23 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:45:38,279 INFO teacher dev iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:45:38,279 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:45:38,279 INFO Predicting labels for 32 texts
2022-12-18 23:45:38,385 INFO There are 7/7 active rules
2022-12-18 23:45:38,385 INFO Coverage: 100.0% (32/32)
2022-12-18 23:45:38,386 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:45:38,411 INFO DONE, Getting attention scores...
2022-12-18 23:45:38,466 INFO Evaluating teacher test iter23 on 32 examples
2022-12-18 23:45:38,471 INFO teacher test iter23 performance: 100.00
2022-12-18 23:45:38,471 INFO teacher test iter23 confusion matrix:
[[32]]
2022-12-18 23:45:38,471 INFO teacher test iter23 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:45:38,471 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:45:38,474 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:45:38,476 INFO Balancing Pseudo Dataset to keep 812 items...
2022-12-18 23:45:38,480 INFO PSEUDO-DATASET:
812 examples
PSEUDO-LABELS:
1    406
0    406
Name: label, dtype: int64
2022-12-18 23:45:38,481 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:45:41,352 INFO fine-tuning the student on clean labeled data
2022-12-18 23:45:43,602 INFO Predicting labels for 18 texts
2022-12-18 23:45:43,708 INFO Evaluating student dev iter23 on 18 examples
2022-12-18 23:45:43,712 INFO student dev iter23 performance: 94.44
2022-12-18 23:45:43,712 INFO student dev iter23 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:45:43,712 INFO student dev iter23 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:45:43,712 INFO Predicting labels for 32 texts
2022-12-18 23:45:43,820 INFO Evaluating student test iter23 on 32 examples
2022-12-18 23:45:43,825 INFO student test iter23 performance: 96.88
2022-12-18 23:45:43,826 INFO student test iter23 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:45:43,826 INFO student test iter23 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:45:43,826 INFO Student Dev performance on iter 23: 94.44444444444444
2022-12-18 23:45:43,826 INFO Student Test performance on iter 23: 96.875
2022-12-18 23:45:43,826 INFO 

	 *** Starting loop 24 ***
2022-12-18 23:45:43,826 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:45:43,826 INFO Downsampling 444 data
2022-12-18 23:45:43,827 INFO Adding Student as extra rule in Teacher
2022-12-18 23:45:43,827 INFO Getting rule predictions
2022-12-18 23:45:43,827 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:45:43,828 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:43,828 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:43,829 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:45:43,830 INFO Predicting labels for 741 texts
2022-12-18 23:45:43,940 INFO Predicting labels for 18 texts
2022-12-18 23:45:44,050 INFO Predicting labels for 444 texts
2022-12-18 23:45:44,159 INFO Training Rule Attention Network
2022-12-18 23:45:44,167 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:45:44,167 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:45:44,172 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:45:44,172 INFO 

		*** Training RAN ***
2022-12-18 23:45:47,170 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:45:47,171 INFO Predicting labels for 444 texts
2022-12-18 23:45:47,280 INFO There are 3/7 active rules
2022-12-18 23:45:47,280 INFO Coverage: 100.0% (444/444)
2022-12-18 23:45:47,284 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:45:47,369 INFO DONE, Getting attention scores...
2022-12-18 23:45:47,426 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:45:47,426 INFO Predicting labels for 18 texts
2022-12-18 23:45:47,532 INFO There are 7/7 active rules
2022-12-18 23:45:47,532 INFO Coverage: 100.0% (18/18)
2022-12-18 23:45:47,533 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:45:47,557 INFO DONE, Getting attention scores...
2022-12-18 23:45:47,610 INFO Evaluating teacher dev iter24 on 18 examples
2022-12-18 23:45:47,614 INFO teacher dev iter24 performance: 94.44
2022-12-18 23:45:47,614 INFO teacher dev iter24 confusion matrix:
[[ 2  1]
 [ 0 15]]
2022-12-18 23:45:47,614 INFO teacher dev iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80         3
           1       0.94      1.00      0.97        15

    accuracy                           0.94        18
   macro avg       0.97      0.83      0.88        18
weighted avg       0.95      0.94      0.94        18

2022-12-18 23:45:47,614 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:45:47,614 INFO Predicting labels for 32 texts
2022-12-18 23:45:47,720 INFO There are 7/7 active rules
2022-12-18 23:45:47,720 INFO Coverage: 100.0% (32/32)
2022-12-18 23:45:47,721 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:45:47,745 INFO DONE, Getting attention scores...
2022-12-18 23:45:47,799 INFO Evaluating teacher test iter24 on 32 examples
2022-12-18 23:45:47,803 INFO teacher test iter24 performance: 100.00
2022-12-18 23:45:47,803 INFO teacher test iter24 confusion matrix:
[[32]]
2022-12-18 23:45:47,803 INFO teacher test iter24 report:
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        32

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

2022-12-18 23:45:47,804 INFO Saving attention scores at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_dump
2022-12-18 23:45:47,807 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:45:47,809 INFO Balancing Pseudo Dataset to keep 786 items...
2022-12-18 23:45:47,814 INFO PSEUDO-DATASET:
786 examples
PSEUDO-LABELS:
1    393
0    393
Name: label, dtype: int64
2022-12-18 23:45:47,814 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:45:49,635 INFO fine-tuning the student on clean labeled data
2022-12-18 23:45:52,941 INFO Predicting labels for 18 texts
2022-12-18 23:45:53,043 INFO Evaluating student dev iter24 on 18 examples
2022-12-18 23:45:53,047 INFO student dev iter24 performance: 94.44
2022-12-18 23:45:53,047 INFO student dev iter24 confusion matrix:
[[ 3  0]
 [ 1 14]]
2022-12-18 23:45:53,047 INFO student dev iter24 report:
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         3
           1       1.00      0.93      0.97        15

    accuracy                           0.94        18
   macro avg       0.88      0.97      0.91        18
weighted avg       0.96      0.94      0.95        18

2022-12-18 23:45:53,048 INFO Predicting labels for 32 texts
2022-12-18 23:45:54,184 INFO Evaluating student test iter24 on 32 examples
2022-12-18 23:45:54,190 INFO student test iter24 performance: 96.88
2022-12-18 23:45:54,190 INFO student test iter24 confusion matrix:
[[ 0  0]
 [ 1 31]]
2022-12-18 23:45:54,190 INFO student test iter24 report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         0
           1       1.00      0.97      0.98        32

    accuracy                           0.97        32
   macro avg       0.50      0.48      0.49        32
weighted avg       1.00      0.97      0.98        32

2022-12-18 23:45:54,190 INFO Student Dev performance on iter 24: 94.44444444444444
2022-12-18 23:45:54,190 INFO Student Test performance on iter 24: 96.875
2022-12-18 23:45:54,191 INFO Final Results
2022-12-18 23:45:54,191 INFO TEACHER PERFORMANCES:
0:	83.33	100.00
1:	88.89	100.00
2:	94.44	100.00
3:	94.44	100.00
4:	94.44	100.00
5:	94.44	100.00
6:	94.44	100.00
7:	94.44	100.00
8:	94.44	100.00
9:	94.44	100.00
10:	94.44	100.00
11:	94.44	100.00
12:	94.44	100.00
13:	94.44	100.00
14:	94.44	100.00
15:	94.44	100.00
16:	94.44	100.00
17:	94.44	100.00
18:	94.44	100.00
19:	94.44	100.00
20:	94.44	100.00
21:	94.44	100.00
22:	94.44	100.00
23:	94.44	100.00
24:	94.44	100.00
25:	94.44	100.00
2022-12-18 23:45:54,191 INFO STUDENT PERFORMANCES:
0:	16.67	15.62
1:	94.44	90.62
2:	94.44	96.88
3:	94.44	96.88
4:	94.44	96.88
5:	94.44	96.88
6:	94.44	96.88
7:	94.44	96.88
8:	94.44	96.88
9:	94.44	96.88
10:	94.44	96.88
11:	94.44	96.88
12:	94.44	96.88
13:	94.44	96.88
14:	94.44	96.88
15:	94.44	96.88
16:	94.44	96.88
17:	94.44	96.88
18:	94.44	96.88
19:	94.44	96.88
20:	94.44	96.88
21:	94.44	96.88
22:	94.44	96.88
23:	94.44	96.88
24:	94.44	96.88
25:	94.44	96.88
2022-12-18 23:45:54,191 INFO BEST DEV weighted_acc = 94.444 for epoch 25
2022-12-18 23:45:54,191 INFO FINAL TEST weighted_acc = 96.875 for epoch 25 (max=96.88 for epoch 25)
2022-12-18 23:45:54,191 INFO Saving student_last to ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/student_last
2022-12-18 23:45:54,191 INFO Saving model at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/student_last/final_model.h5
2022-12-18 23:45:54,199 INFO Saving teacher at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_last
2022-12-18 23:45:54,199 INFO Saving rule attention network at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/teacher_last/rule_attention_network.h5
2022-12-18 23:45:54,207 INFO 	*** Final Results ***
2022-12-18 23:45:54,207 INFO 
student_train:	{'dev_loss': 1.1564583778381348}
2022-12-18 23:45:54,207 INFO 
supervised_student_dev:	{'acc': 16.666666666666664, 'weighted_acc': 16.666666666666664, 'prec': 31.25, 'rec': 36.666666666666664, 'f1': 16.408668730650156, 'weighted_f1': 16.408668730650156, 'ignored': 0, 'total': 18, 'perf': 16.666666666666664}
2022-12-18 23:45:54,207 INFO 
supervised_student_test:	{'acc': 15.625, 'weighted_acc': 15.625, 'prec': 50.0, 'rec': 7.8125, 'f1': 13.513513513513514, 'weighted_f1': 13.513513513513514, 'ignored': 0, 'total': 32, 'perf': 15.625}
2022-12-18 23:45:54,208 INFO 
teacher_train:	{'acc': 93.11740890688259, 'weighted_acc': 93.11740890688259, 'prec': 87.60008428150022, 'rec': 77.41167434715821, 'f1': 81.41459744168547, 'weighted_f1': 81.41459744168547, 'ignored': 0, 'total': 741, 'perf': 93.11740890688259}
2022-12-18 23:45:54,208 INFO 
teacher_dev:	{'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}
2022-12-18 23:45:54,208 INFO 
teacher_test:	{'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}
2022-12-18 23:45:54,208 INFO 
teacher_train_iter:	[{'acc': 93.11740890688259, 'weighted_acc': 93.11740890688259, 'prec': 87.60008428150022, 'rec': 77.41167434715821, 'f1': 81.41459744168547, 'weighted_f1': 81.41459744168547, 'ignored': 0, 'total': 741, 'perf': 93.11740890688259}]
2022-12-18 23:45:54,208 INFO 
teacher_dev_iter:	[{'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 68.75, 'rec': 63.33333333333333, 'f1': 65.16129032258064, 'weighted_f1': 65.16129032258064, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 88.88888888888889, 'weighted_acc': 88.88888888888889, 'prec': 94.11764705882352, 'rec': 66.66666666666666, 'f1': 71.875, 'weighted_f1': 71.875, 'ignored': 0, 'total': 18, 'perf': 88.88888888888889}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 96.875, 'rec': 83.33333333333333, 'f1': 88.38709677419355, 'weighted_f1': 88.38709677419355, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}]
2022-12-18 23:45:54,208 INFO 
teacher_test_iter:	[{'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}, {'acc': 100.0, 'weighted_acc': 100.0, 'prec': 100.0, 'rec': 100.0, 'f1': 100.0, 'weighted_f1': 100.0, 'ignored': 0, 'total': 32, 'perf': 100.0}]
2022-12-18 23:45:54,209 INFO 
student_train_iter:	[{'dev_loss': 1.1564583778381348}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]
2022-12-18 23:45:54,209 INFO 
student_dev_iter:	[{'acc': 16.666666666666664, 'weighted_acc': 16.666666666666664, 'prec': 31.25, 'rec': 36.666666666666664, 'f1': 16.408668730650156, 'weighted_f1': 16.408668730650156, 'ignored': 0, 'total': 18, 'perf': 16.666666666666664}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}]
2022-12-18 23:45:54,210 INFO 
student_test_iter:	[{'acc': 15.625, 'weighted_acc': 15.625, 'prec': 50.0, 'rec': 7.8125, 'f1': 13.513513513513514, 'weighted_f1': 13.513513513513514, 'ignored': 0, 'total': 32, 'perf': 15.625}, {'acc': 90.625, 'weighted_acc': 90.625, 'prec': 50.0, 'rec': 45.3125, 'f1': 47.540983606557376, 'weighted_f1': 47.540983606557376, 'ignored': 0, 'total': 32, 'perf': 90.625}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}, {'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}]
2022-12-18 23:45:54,211 INFO 
student_dev:	{'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 87.5, 'rec': 96.66666666666667, 'f1': 91.13300492610837, 'weighted_f1': 91.13300492610837, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}
2022-12-18 23:45:54,211 INFO 
student_test:	{'acc': 96.875, 'weighted_acc': 96.875, 'prec': 50.0, 'rec': 48.4375, 'f1': 49.2063492063492, 'weighted_f1': 49.2063492063492, 'ignored': 0, 'total': 32, 'perf': 96.875}
2022-12-18 23:45:54,211 INFO Saving results at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/results.pkl
2022-12-18 23:45:54,230 INFO Dataset: econ_0
2022-12-18 23:45:54,231 INFO Weak Sources: ['econ_0rules']
2022-12-18 23:45:54,231 INFO Model: bert

2022-12-18 23:45:54,231 INFO Teacher Train weighted_acc: 93.1
2022-12-18 23:45:54,231 INFO Teacher Dev weighted_acc: 94.4
2022-12-18 23:45:54,231 INFO Teacher Test weighted_acc: 100.0

2022-12-18 23:45:54,231 INFO Student Dev weighted_acc: 94.4
2022-12-18 23:45:54,231 INFO Student Test weighted_acc: 96.9
2022-12-18 23:45:54,232 INFO Saved report at ../experiments/econ_0/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_41_stBERT/results.txt
