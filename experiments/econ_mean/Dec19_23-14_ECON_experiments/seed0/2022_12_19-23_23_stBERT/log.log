2022-12-19 23:23:53,939 INFO 

		 *** NEW EXPERIMENT ***
args=Namespace(adam_epsilon=1e-08, convert_abstain_to_random=False, datapath='../data', dataset='econ_mean', debug=False, device=device(type='cuda'), downsample=1.0, eval_batch_size=16, experiment_folder='../experiments/econ_mean', finetuning_rate=0.0001, fp16=False, hard_student_rule=False, learning_rate=0.0001, logdir='../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT', logging_steps=500, loss_weights=False, lower_case=False, max_grad_norm=1.0, max_rule_seq_length=10, max_seq_length=64, max_size=1000, metric='weighted_acc', n_gpu=1, no_cuda=False, num_epochs=15, num_iter=25, num_labels=2, num_supervised_trials=5, num_unsup_epochs=25, oversample=3, overwrite=False, sample_size=16384, seed=0, soft_labels=False, student_name='bert', teacher_name='ran', tokenizer_method='clean', train_batch_size=16, unsup_batch_size=128, warmup_steps=0, weak_sources=None, weight_decay=0.0)
2022-12-19 23:23:53,939 INFO building student: bert
2022-12-19 23:23:53,939 INFO building teacher
2022-12-19 23:23:53,940 INFO No weak sources specified for Teacher. Using default: ['econ_meanrules']
2022-12-19 23:23:53,940 INFO loading data
2022-12-19 23:23:53,948 INFO Pre-processing train data for student...
2022-12-19 23:23:53,952 INFO train DATASET: 247 examples
2022-12-19 23:23:53,954 INFO train LABELS:
1    136
0    111
Name: label, dtype: int64
2022-12-19 23:23:53,954 INFO Oversampling train data 3 times
2022-12-19 23:23:53,957 INFO train DATASET: 741 examples
2022-12-19 23:23:53,958 INFO train LABELS:
1    408
0    333
Name: label, dtype: int64
2022-12-19 23:23:53,961 INFO Pre-processing dev data for student...
2022-12-19 23:23:53,963 INFO dev DATASET: 32 examples
2022-12-19 23:23:53,964 INFO dev LABELS:
0    30
1     2
Name: label, dtype: int64
2022-12-19 23:23:53,966 INFO Pre-processing test data for student...
2022-12-19 23:23:53,969 INFO test DATASET: 19 examples
2022-12-19 23:23:53,970 INFO test LABELS:
0    13
1     6
Name: label, dtype: int64
2022-12-19 23:23:53,974 INFO Pre-processing unlabeled data for student...
2022-12-19 23:23:53,977 INFO unlabeled DATASET: 444 examples
2022-12-19 23:23:53,978 INFO unlabeled LABELS:
Series([], Name: label, dtype: int64)
2022-12-19 23:23:53,978 INFO creating pseudo-dataset
2022-12-19 23:23:53,978 INFO copying data from unlabeled dataset
2022-12-19 23:23:53,987 INFO done
2022-12-19 23:23:53,987 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:23:53,988 INFO Downsampling 444 data
2022-12-19 23:23:53,988 INFO copying data from train dataset
2022-12-19 23:23:53,997 INFO done
2022-12-19 23:23:53,998 INFO Balancing Pseudo Dataset to keep 816 items...
2022-12-19 23:23:54,003 INFO PSEUDO-DATASET:
816 examples
PSEUDO-LABELS:
1    408
0    408
Name: label, dtype: int64
2022-12-19 23:23:54,003 INFO Class labels: 2
2022-12-19 23:23:54,005 INFO X Train Shape (816, 7) (816,)
2022-12-19 23:23:54,005 INFO X Dev Shape (32, 7) (32,)
2022-12-19 23:24:03,166 INFO Saving supervised_student to ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/supervised_student
2022-12-19 23:24:03,166 INFO Saving model at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/supervised_student/final_model.h5
2022-12-19 23:24:03,172 INFO 

	*** Evaluating on dev data ***
2022-12-19 23:24:03,173 INFO Predicting labels for 32 texts
2022-12-19 23:24:03,291 INFO Evaluating student dev on 32 examples
2022-12-19 23:24:03,296 INFO student dev performance: 87.50
2022-12-19 23:24:03,297 INFO student dev confusion matrix:
[[28  2]
 [ 2  0]]
2022-12-19 23:24:03,297 INFO student dev report:
              precision    recall  f1-score   support

           0       0.93      0.93      0.93        30
           1       0.00      0.00      0.00         2

    accuracy                           0.88        32
   macro avg       0.47      0.47      0.47        32
weighted avg       0.88      0.88      0.88        32

2022-12-19 23:24:03,297 INFO 

	*** Evaluating on test data ***
2022-12-19 23:24:03,297 INFO Predicting labels for 19 texts
2022-12-19 23:24:03,415 INFO Evaluating student test on 19 examples
2022-12-19 23:24:03,420 INFO student test performance: 63.16
2022-12-19 23:24:03,421 INFO student test confusion matrix:
[[10  3]
 [ 4  2]]
2022-12-19 23:24:03,421 INFO student test report:
              precision    recall  f1-score   support

           0       0.71      0.77      0.74        13
           1       0.40      0.33      0.36         6

    accuracy                           0.63        19
   macro avg       0.56      0.55      0.55        19
weighted avg       0.62      0.63      0.62        19

2022-12-19 23:24:03,421 INFO initializing teacher on unlabeled data with majority voting
2022-12-19 23:24:03,421 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:03,422 INFO There are 3/7 active rules
2022-12-19 23:24:03,422 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:03,435 INFO evaluating majority voting
2022-12-19 23:24:03,435 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:03,436 INFO There are 7/7 active rules
2022-12-19 23:24:03,436 INFO Coverage: 100.0% (741/741)
2022-12-19 23:24:03,458 INFO Evaluating teacher train on 741 examples
2022-12-19 23:24:03,467 INFO teacher train performance: 88.66
2022-12-19 23:24:03,468 INFO teacher train confusion matrix:
[[285  48]
 [ 36 372]]
2022-12-19 23:24:03,468 INFO teacher train report:
              precision    recall  f1-score   support

           0       0.89      0.86      0.87       333
           1       0.89      0.91      0.90       408

    accuracy                           0.89       741
   macro avg       0.89      0.88      0.89       741
weighted avg       0.89      0.89      0.89       741

2022-12-19 23:24:03,468 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:03,468 INFO There are 7/7 active rules
2022-12-19 23:24:03,468 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:03,469 INFO Evaluating teacher dev on 32 examples
2022-12-19 23:24:03,473 INFO teacher dev performance: 81.25
2022-12-19 23:24:03,474 INFO teacher dev confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:24:03,474 INFO teacher dev report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:24:03,474 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:03,474 INFO There are 7/7 active rules
2022-12-19 23:24:03,474 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:03,475 INFO Evaluating teacher test on 19 examples
2022-12-19 23:24:03,480 INFO teacher test performance: 89.47
2022-12-19 23:24:03,481 INFO teacher test confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:03,481 INFO teacher test report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:03,481 INFO 

	 *** Starting loop 0 ***
2022-12-19 23:24:03,481 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:03,481 INFO Downsampling 444 data
2022-12-19 23:24:03,481 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:03,481 INFO Getting rule predictions
2022-12-19 23:24:03,481 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:03,482 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:03,483 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:03,483 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:03,484 INFO Predicting labels for 741 texts
2022-12-19 23:24:03,591 INFO Predicting labels for 32 texts
2022-12-19 23:24:03,694 INFO Predicting labels for 444 texts
2022-12-19 23:24:03,796 INFO Training Rule Attention Network
2022-12-19 23:24:03,945 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:24:03,946 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:24:03,950 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:24:04,023 INFO 

		*** Training RAN ***
2022-12-19 23:24:06,944 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:06,945 INFO Predicting labels for 444 texts
2022-12-19 23:24:07,057 INFO There are 3/7 active rules
2022-12-19 23:24:07,058 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:07,062 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:24:07,151 INFO DONE, Getting attention scores...
2022-12-19 23:24:07,206 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:07,206 INFO Predicting labels for 32 texts
2022-12-19 23:24:07,311 INFO There are 7/7 active rules
2022-12-19 23:24:07,311 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:07,312 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:24:07,336 INFO DONE, Getting attention scores...
2022-12-19 23:24:07,391 INFO Evaluating teacher dev iter0 on 32 examples
2022-12-19 23:24:07,396 INFO teacher dev iter0 performance: 81.25
2022-12-19 23:24:07,396 INFO teacher dev iter0 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:24:07,396 INFO teacher dev iter0 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:24:07,396 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:07,396 INFO Predicting labels for 19 texts
2022-12-19 23:24:07,498 INFO There are 7/7 active rules
2022-12-19 23:24:07,499 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:07,499 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:24:07,525 INFO DONE, Getting attention scores...
2022-12-19 23:24:07,586 INFO Evaluating teacher test iter0 on 19 examples
2022-12-19 23:24:07,590 INFO teacher test iter0 performance: 89.47
2022-12-19 23:24:07,590 INFO teacher test iter0 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:07,590 INFO teacher test iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:07,591 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:24:07,593 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:24:07,595 INFO Balancing Pseudo Dataset to keep 520 items...
2022-12-19 23:24:07,598 INFO PSEUDO-DATASET:
520 examples
PSEUDO-LABELS:
1    260
0    260
Name: label, dtype: int64
2022-12-19 23:24:07,599 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:24:09,896 INFO fine-tuning the student on clean labeled data
2022-12-19 23:24:11,788 INFO Predicting labels for 32 texts
2022-12-19 23:24:11,893 INFO Evaluating student dev iter0 on 32 examples
2022-12-19 23:24:11,897 INFO student dev iter0 performance: 87.50
2022-12-19 23:24:11,898 INFO student dev iter0 confusion matrix:
[[28  2]
 [ 2  0]]
2022-12-19 23:24:11,898 INFO student dev iter0 report:
              precision    recall  f1-score   support

           0       0.93      0.93      0.93        30
           1       0.00      0.00      0.00         2

    accuracy                           0.88        32
   macro avg       0.47      0.47      0.47        32
weighted avg       0.88      0.88      0.88        32

2022-12-19 23:24:11,898 INFO Predicting labels for 19 texts
2022-12-19 23:24:11,999 INFO Evaluating student test iter0 on 19 examples
2022-12-19 23:24:12,003 INFO student test iter0 performance: 68.42
2022-12-19 23:24:12,003 INFO student test iter0 confusion matrix:
[[11  2]
 [ 4  2]]
2022-12-19 23:24:12,003 INFO student test iter0 report:
              precision    recall  f1-score   support

           0       0.73      0.85      0.79        13
           1       0.50      0.33      0.40         6

    accuracy                           0.68        19
   macro avg       0.62      0.59      0.59        19
weighted avg       0.66      0.68      0.66        19

2022-12-19 23:24:12,003 INFO Student Dev performance on iter 0: 87.5
2022-12-19 23:24:12,003 INFO Student Test performance on iter 0: 68.42105263157895
2022-12-19 23:24:12,004 INFO 

	 *** Starting loop 1 ***
2022-12-19 23:24:12,004 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:12,004 INFO Downsampling 444 data
2022-12-19 23:24:12,004 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:12,005 INFO Getting rule predictions
2022-12-19 23:24:12,005 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:12,006 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:12,006 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:12,007 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:12,008 INFO Predicting labels for 741 texts
2022-12-19 23:24:12,196 INFO Predicting labels for 32 texts
2022-12-19 23:24:12,299 INFO Predicting labels for 444 texts
2022-12-19 23:24:12,406 INFO Training Rule Attention Network
2022-12-19 23:24:12,413 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:24:12,414 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:24:12,418 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:24:12,419 INFO 

		*** Training RAN ***
2022-12-19 23:24:15,450 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:15,452 INFO Predicting labels for 444 texts
2022-12-19 23:24:15,557 INFO There are 3/7 active rules
2022-12-19 23:24:15,557 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:15,561 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:24:15,651 INFO DONE, Getting attention scores...
2022-12-19 23:24:15,707 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:15,708 INFO Predicting labels for 32 texts
2022-12-19 23:24:15,810 INFO There are 7/7 active rules
2022-12-19 23:24:15,811 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:15,812 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:24:15,835 INFO DONE, Getting attention scores...
2022-12-19 23:24:15,893 INFO Evaluating teacher dev iter1 on 32 examples
2022-12-19 23:24:15,897 INFO teacher dev iter1 performance: 81.25
2022-12-19 23:24:15,898 INFO teacher dev iter1 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:24:15,898 INFO teacher dev iter1 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:24:15,898 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:15,898 INFO Predicting labels for 19 texts
2022-12-19 23:24:16,001 INFO There are 7/7 active rules
2022-12-19 23:24:16,001 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:16,002 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:24:16,026 INFO DONE, Getting attention scores...
2022-12-19 23:24:16,082 INFO Evaluating teacher test iter1 on 19 examples
2022-12-19 23:24:16,087 INFO teacher test iter1 performance: 89.47
2022-12-19 23:24:16,087 INFO teacher test iter1 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:16,087 INFO teacher test iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:16,088 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:24:16,091 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:24:16,092 INFO Balancing Pseudo Dataset to keep 520 items...
2022-12-19 23:24:16,096 INFO PSEUDO-DATASET:
520 examples
PSEUDO-LABELS:
1    260
0    260
Name: label, dtype: int64
2022-12-19 23:24:16,096 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:24:16,925 INFO fine-tuning the student on clean labeled data
2022-12-19 23:24:17,841 INFO Predicting labels for 32 texts
2022-12-19 23:24:17,955 INFO Evaluating student dev iter1 on 32 examples
2022-12-19 23:24:17,961 INFO student dev iter1 performance: 87.50
2022-12-19 23:24:17,961 INFO student dev iter1 confusion matrix:
[[28  2]
 [ 2  0]]
2022-12-19 23:24:17,961 INFO student dev iter1 report:
              precision    recall  f1-score   support

           0       0.93      0.93      0.93        30
           1       0.00      0.00      0.00         2

    accuracy                           0.88        32
   macro avg       0.47      0.47      0.47        32
weighted avg       0.88      0.88      0.88        32

2022-12-19 23:24:17,961 INFO Predicting labels for 19 texts
2022-12-19 23:24:18,077 INFO Evaluating student test iter1 on 19 examples
2022-12-19 23:24:18,081 INFO student test iter1 performance: 73.68
2022-12-19 23:24:18,082 INFO student test iter1 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:24:18,082 INFO student test iter1 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:24:18,082 INFO Student Dev performance on iter 1: 87.5
2022-12-19 23:24:18,082 INFO Student Test performance on iter 1: 73.68421052631578
2022-12-19 23:24:18,082 INFO 

	 *** Starting loop 2 ***
2022-12-19 23:24:18,082 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:18,082 INFO Downsampling 444 data
2022-12-19 23:24:18,083 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:18,083 INFO Getting rule predictions
2022-12-19 23:24:18,083 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:18,084 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:18,084 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:18,085 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:18,086 INFO Predicting labels for 741 texts
2022-12-19 23:24:18,193 INFO Predicting labels for 32 texts
2022-12-19 23:24:18,296 INFO Predicting labels for 444 texts
2022-12-19 23:24:18,400 INFO Training Rule Attention Network
2022-12-19 23:24:18,408 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:24:18,408 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:24:18,412 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:24:18,413 INFO 

		*** Training RAN ***
2022-12-19 23:24:21,410 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:21,411 INFO Predicting labels for 444 texts
2022-12-19 23:24:21,516 INFO There are 3/7 active rules
2022-12-19 23:24:21,517 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:21,521 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:24:21,606 INFO DONE, Getting attention scores...
2022-12-19 23:24:21,663 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:21,663 INFO Predicting labels for 32 texts
2022-12-19 23:24:21,770 INFO There are 7/7 active rules
2022-12-19 23:24:21,770 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:21,771 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:24:21,795 INFO DONE, Getting attention scores...
2022-12-19 23:24:21,851 INFO Evaluating teacher dev iter2 on 32 examples
2022-12-19 23:24:21,855 INFO teacher dev iter2 performance: 78.12
2022-12-19 23:24:21,856 INFO teacher dev iter2 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-19 23:24:21,856 INFO teacher dev iter2 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-19 23:24:21,856 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:21,856 INFO Predicting labels for 19 texts
2022-12-19 23:24:21,958 INFO There are 7/7 active rules
2022-12-19 23:24:21,959 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:21,959 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:24:21,988 INFO DONE, Getting attention scores...
2022-12-19 23:24:22,046 INFO Evaluating teacher test iter2 on 19 examples
2022-12-19 23:24:22,051 INFO teacher test iter2 performance: 89.47
2022-12-19 23:24:22,051 INFO teacher test iter2 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:22,051 INFO teacher test iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:22,051 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:24:22,054 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:24:22,055 INFO Balancing Pseudo Dataset to keep 520 items...
2022-12-19 23:24:22,060 INFO PSEUDO-DATASET:
520 examples
PSEUDO-LABELS:
1    260
0    260
Name: label, dtype: int64
2022-12-19 23:24:22,060 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:24:22,805 INFO fine-tuning the student on clean labeled data
2022-12-19 23:24:23,794 INFO Predicting labels for 32 texts
2022-12-19 23:24:24,926 INFO Evaluating student dev iter2 on 32 examples
2022-12-19 23:24:24,930 INFO student dev iter2 performance: 90.62
2022-12-19 23:24:24,931 INFO student dev iter2 confusion matrix:
[[29  1]
 [ 2  0]]
2022-12-19 23:24:24,931 INFO student dev iter2 report:
              precision    recall  f1-score   support

           0       0.94      0.97      0.95        30
           1       0.00      0.00      0.00         2

    accuracy                           0.91        32
   macro avg       0.47      0.48      0.48        32
weighted avg       0.88      0.91      0.89        32

2022-12-19 23:24:24,931 INFO Predicting labels for 19 texts
2022-12-19 23:24:25,035 INFO Evaluating student test iter2 on 19 examples
2022-12-19 23:24:25,039 INFO student test iter2 performance: 73.68
2022-12-19 23:24:25,040 INFO student test iter2 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:24:25,040 INFO student test iter2 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:24:25,040 INFO Student Dev performance on iter 2: 90.625
2022-12-19 23:24:25,040 INFO Student Test performance on iter 2: 73.68421052631578
2022-12-19 23:24:25,040 INFO Improved dev performance from 87.50 to 90.62
2022-12-19 23:24:25,040 INFO Saving student_best to ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/student_best
2022-12-19 23:24:25,040 INFO Saving model at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/student_best/final_model.h5
2022-12-19 23:24:25,049 INFO Saving teacher at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_best
2022-12-19 23:24:25,049 INFO Saving rule attention network at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_best/rule_attention_network.h5
2022-12-19 23:24:25,058 INFO 

	 *** Starting loop 3 ***
2022-12-19 23:24:25,058 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:25,058 INFO Downsampling 444 data
2022-12-19 23:24:25,059 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:25,059 INFO Getting rule predictions
2022-12-19 23:24:25,059 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:25,060 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:25,060 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:25,061 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:25,062 INFO Predicting labels for 741 texts
2022-12-19 23:24:25,258 INFO Predicting labels for 32 texts
2022-12-19 23:24:25,361 INFO Predicting labels for 444 texts
2022-12-19 23:24:25,469 INFO Training Rule Attention Network
2022-12-19 23:24:25,476 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:24:25,477 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:24:25,481 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:24:25,481 INFO 

		*** Training RAN ***
2022-12-19 23:24:28,441 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:28,442 INFO Predicting labels for 444 texts
2022-12-19 23:24:28,547 INFO There are 3/7 active rules
2022-12-19 23:24:28,548 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:28,552 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:24:28,641 INFO DONE, Getting attention scores...
2022-12-19 23:24:28,698 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:28,698 INFO Predicting labels for 32 texts
2022-12-19 23:24:28,801 INFO There are 7/7 active rules
2022-12-19 23:24:28,801 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:28,802 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:24:28,827 INFO DONE, Getting attention scores...
2022-12-19 23:24:28,886 INFO Evaluating teacher dev iter3 on 32 examples
2022-12-19 23:24:28,890 INFO teacher dev iter3 performance: 81.25
2022-12-19 23:24:28,890 INFO teacher dev iter3 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:24:28,890 INFO teacher dev iter3 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:24:28,890 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:28,891 INFO Predicting labels for 19 texts
2022-12-19 23:24:28,993 INFO There are 7/7 active rules
2022-12-19 23:24:28,993 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:28,994 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:24:29,018 INFO DONE, Getting attention scores...
2022-12-19 23:24:29,073 INFO Evaluating teacher test iter3 on 19 examples
2022-12-19 23:24:29,078 INFO teacher test iter3 performance: 89.47
2022-12-19 23:24:29,078 INFO teacher test iter3 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:29,078 INFO teacher test iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:29,078 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:24:29,081 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:24:29,083 INFO Balancing Pseudo Dataset to keep 518 items...
2022-12-19 23:24:29,087 INFO PSEUDO-DATASET:
518 examples
PSEUDO-LABELS:
1    259
0    259
Name: label, dtype: int64
2022-12-19 23:24:29,087 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:24:29,821 INFO fine-tuning the student on clean labeled data
2022-12-19 23:24:30,715 INFO Predicting labels for 32 texts
2022-12-19 23:24:30,822 INFO Evaluating student dev iter3 on 32 examples
2022-12-19 23:24:30,826 INFO student dev iter3 performance: 87.50
2022-12-19 23:24:30,826 INFO student dev iter3 confusion matrix:
[[28  2]
 [ 2  0]]
2022-12-19 23:24:30,827 INFO student dev iter3 report:
              precision    recall  f1-score   support

           0       0.93      0.93      0.93        30
           1       0.00      0.00      0.00         2

    accuracy                           0.88        32
   macro avg       0.47      0.47      0.47        32
weighted avg       0.88      0.88      0.88        32

2022-12-19 23:24:30,827 INFO Predicting labels for 19 texts
2022-12-19 23:24:30,928 INFO Evaluating student test iter3 on 19 examples
2022-12-19 23:24:30,933 INFO student test iter3 performance: 73.68
2022-12-19 23:24:30,933 INFO student test iter3 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:24:30,933 INFO student test iter3 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:24:30,933 INFO Student Dev performance on iter 3: 87.5
2022-12-19 23:24:30,933 INFO Student Test performance on iter 3: 73.68421052631578
2022-12-19 23:24:30,934 INFO 

	 *** Starting loop 4 ***
2022-12-19 23:24:30,934 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:30,934 INFO Downsampling 444 data
2022-12-19 23:24:30,934 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:30,935 INFO Getting rule predictions
2022-12-19 23:24:30,935 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:30,936 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:30,936 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:30,937 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:30,937 INFO Predicting labels for 741 texts
2022-12-19 23:24:31,042 INFO Predicting labels for 32 texts
2022-12-19 23:24:31,146 INFO Predicting labels for 444 texts
2022-12-19 23:24:31,249 INFO Training Rule Attention Network
2022-12-19 23:24:31,256 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:24:31,257 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:24:31,261 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:24:31,261 INFO 

		*** Training RAN ***
2022-12-19 23:24:34,409 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:34,411 INFO Predicting labels for 444 texts
2022-12-19 23:24:34,518 INFO There are 3/7 active rules
2022-12-19 23:24:34,518 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:34,523 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:24:34,611 INFO DONE, Getting attention scores...
2022-12-19 23:24:34,669 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:34,669 INFO Predicting labels for 32 texts
2022-12-19 23:24:34,775 INFO There are 7/7 active rules
2022-12-19 23:24:34,776 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:34,777 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:24:34,802 INFO DONE, Getting attention scores...
2022-12-19 23:24:34,859 INFO Evaluating teacher dev iter4 on 32 examples
2022-12-19 23:24:34,864 INFO teacher dev iter4 performance: 81.25
2022-12-19 23:24:34,864 INFO teacher dev iter4 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:24:34,864 INFO teacher dev iter4 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:24:34,864 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:34,865 INFO Predicting labels for 19 texts
2022-12-19 23:24:34,967 INFO There are 7/7 active rules
2022-12-19 23:24:34,967 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:34,968 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:24:34,996 INFO DONE, Getting attention scores...
2022-12-19 23:24:35,052 INFO Evaluating teacher test iter4 on 19 examples
2022-12-19 23:24:35,056 INFO teacher test iter4 performance: 89.47
2022-12-19 23:24:35,057 INFO teacher test iter4 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:35,057 INFO teacher test iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:35,057 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:24:35,060 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:24:35,062 INFO Balancing Pseudo Dataset to keep 516 items...
2022-12-19 23:24:35,066 INFO PSEUDO-DATASET:
516 examples
PSEUDO-LABELS:
1    258
0    258
Name: label, dtype: int64
2022-12-19 23:24:35,066 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:24:36,824 INFO fine-tuning the student on clean labeled data
2022-12-19 23:24:37,745 INFO Predicting labels for 32 texts
2022-12-19 23:24:37,847 INFO Evaluating student dev iter4 on 32 examples
2022-12-19 23:24:37,852 INFO student dev iter4 performance: 87.50
2022-12-19 23:24:37,853 INFO student dev iter4 confusion matrix:
[[28  2]
 [ 2  0]]
2022-12-19 23:24:37,853 INFO student dev iter4 report:
              precision    recall  f1-score   support

           0       0.93      0.93      0.93        30
           1       0.00      0.00      0.00         2

    accuracy                           0.88        32
   macro avg       0.47      0.47      0.47        32
weighted avg       0.88      0.88      0.88        32

2022-12-19 23:24:37,853 INFO Predicting labels for 19 texts
2022-12-19 23:24:37,960 INFO Evaluating student test iter4 on 19 examples
2022-12-19 23:24:37,964 INFO student test iter4 performance: 73.68
2022-12-19 23:24:37,965 INFO student test iter4 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:24:37,965 INFO student test iter4 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:24:37,965 INFO Student Dev performance on iter 4: 87.5
2022-12-19 23:24:37,965 INFO Student Test performance on iter 4: 73.68421052631578
2022-12-19 23:24:37,965 INFO 

	 *** Starting loop 5 ***
2022-12-19 23:24:37,965 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:37,965 INFO Downsampling 444 data
2022-12-19 23:24:37,966 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:37,966 INFO Getting rule predictions
2022-12-19 23:24:37,966 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:37,967 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:37,967 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:37,968 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:37,969 INFO Predicting labels for 741 texts
2022-12-19 23:24:38,077 INFO Predicting labels for 32 texts
2022-12-19 23:24:38,179 INFO Predicting labels for 444 texts
2022-12-19 23:24:38,286 INFO Training Rule Attention Network
2022-12-19 23:24:38,293 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:24:38,294 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:24:38,298 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:24:38,298 INFO 

		*** Training RAN ***
2022-12-19 23:24:41,239 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:41,241 INFO Predicting labels for 444 texts
2022-12-19 23:24:41,348 INFO There are 3/7 active rules
2022-12-19 23:24:41,348 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:41,353 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:24:41,440 INFO DONE, Getting attention scores...
2022-12-19 23:24:41,498 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:41,498 INFO Predicting labels for 32 texts
2022-12-19 23:24:41,599 INFO There are 7/7 active rules
2022-12-19 23:24:41,600 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:41,600 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:24:41,625 INFO DONE, Getting attention scores...
2022-12-19 23:24:41,683 INFO Evaluating teacher dev iter5 on 32 examples
2022-12-19 23:24:41,687 INFO teacher dev iter5 performance: 81.25
2022-12-19 23:24:41,688 INFO teacher dev iter5 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:24:41,688 INFO teacher dev iter5 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:24:41,688 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:41,688 INFO Predicting labels for 19 texts
2022-12-19 23:24:41,794 INFO There are 7/7 active rules
2022-12-19 23:24:41,795 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:41,795 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:24:41,820 INFO DONE, Getting attention scores...
2022-12-19 23:24:41,875 INFO Evaluating teacher test iter5 on 19 examples
2022-12-19 23:24:41,879 INFO teacher test iter5 performance: 89.47
2022-12-19 23:24:41,879 INFO teacher test iter5 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:41,879 INFO teacher test iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:41,879 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:24:41,882 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:24:41,883 INFO Balancing Pseudo Dataset to keep 518 items...
2022-12-19 23:24:41,887 INFO PSEUDO-DATASET:
518 examples
PSEUDO-LABELS:
1    259
0    259
Name: label, dtype: int64
2022-12-19 23:24:41,887 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:24:44,705 INFO fine-tuning the student on clean labeled data
2022-12-19 23:24:45,649 INFO Predicting labels for 32 texts
2022-12-19 23:24:45,756 INFO Evaluating student dev iter5 on 32 examples
2022-12-19 23:24:45,760 INFO student dev iter5 performance: 87.50
2022-12-19 23:24:45,761 INFO student dev iter5 confusion matrix:
[[28  2]
 [ 2  0]]
2022-12-19 23:24:45,761 INFO student dev iter5 report:
              precision    recall  f1-score   support

           0       0.93      0.93      0.93        30
           1       0.00      0.00      0.00         2

    accuracy                           0.88        32
   macro avg       0.47      0.47      0.47        32
weighted avg       0.88      0.88      0.88        32

2022-12-19 23:24:45,761 INFO Predicting labels for 19 texts
2022-12-19 23:24:45,868 INFO Evaluating student test iter5 on 19 examples
2022-12-19 23:24:45,873 INFO student test iter5 performance: 73.68
2022-12-19 23:24:45,873 INFO student test iter5 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:24:45,873 INFO student test iter5 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:24:45,873 INFO Student Dev performance on iter 5: 87.5
2022-12-19 23:24:45,874 INFO Student Test performance on iter 5: 73.68421052631578
2022-12-19 23:24:45,874 INFO 

	 *** Starting loop 6 ***
2022-12-19 23:24:45,874 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:45,874 INFO Downsampling 444 data
2022-12-19 23:24:45,874 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:45,875 INFO Getting rule predictions
2022-12-19 23:24:45,875 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:45,876 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:45,876 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:45,876 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:45,877 INFO Predicting labels for 741 texts
2022-12-19 23:24:45,984 INFO Predicting labels for 32 texts
2022-12-19 23:24:46,088 INFO Predicting labels for 444 texts
2022-12-19 23:24:46,192 INFO Training Rule Attention Network
2022-12-19 23:24:46,199 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:24:46,200 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:24:46,206 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:24:46,207 INFO 

		*** Training RAN ***
2022-12-19 23:24:49,174 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:49,175 INFO Predicting labels for 444 texts
2022-12-19 23:24:49,285 INFO There are 3/7 active rules
2022-12-19 23:24:49,285 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:49,290 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:24:49,374 INFO DONE, Getting attention scores...
2022-12-19 23:24:49,431 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:49,431 INFO Predicting labels for 32 texts
2022-12-19 23:24:49,537 INFO There are 7/7 active rules
2022-12-19 23:24:49,538 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:49,538 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:24:49,563 INFO DONE, Getting attention scores...
2022-12-19 23:24:49,617 INFO Evaluating teacher dev iter6 on 32 examples
2022-12-19 23:24:49,622 INFO teacher dev iter6 performance: 81.25
2022-12-19 23:24:49,623 INFO teacher dev iter6 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:24:49,623 INFO teacher dev iter6 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:24:49,623 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:49,623 INFO Predicting labels for 19 texts
2022-12-19 23:24:49,731 INFO There are 7/7 active rules
2022-12-19 23:24:49,731 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:49,732 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:24:49,757 INFO DONE, Getting attention scores...
2022-12-19 23:24:49,811 INFO Evaluating teacher test iter6 on 19 examples
2022-12-19 23:24:49,815 INFO teacher test iter6 performance: 89.47
2022-12-19 23:24:49,815 INFO teacher test iter6 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:49,815 INFO teacher test iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:49,815 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:24:49,818 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:24:49,819 INFO Balancing Pseudo Dataset to keep 508 items...
2022-12-19 23:24:49,823 INFO PSEUDO-DATASET:
508 examples
PSEUDO-LABELS:
1    254
0    254
Name: label, dtype: int64
2022-12-19 23:24:49,823 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:24:50,531 INFO fine-tuning the student on clean labeled data
2022-12-19 23:24:52,459 INFO Predicting labels for 32 texts
2022-12-19 23:24:52,564 INFO Evaluating student dev iter6 on 32 examples
2022-12-19 23:24:52,568 INFO student dev iter6 performance: 90.62
2022-12-19 23:24:52,569 INFO student dev iter6 confusion matrix:
[[29  1]
 [ 2  0]]
2022-12-19 23:24:52,569 INFO student dev iter6 report:
              precision    recall  f1-score   support

           0       0.94      0.97      0.95        30
           1       0.00      0.00      0.00         2

    accuracy                           0.91        32
   macro avg       0.47      0.48      0.48        32
weighted avg       0.88      0.91      0.89        32

2022-12-19 23:24:52,569 INFO Predicting labels for 19 texts
2022-12-19 23:24:52,675 INFO Evaluating student test iter6 on 19 examples
2022-12-19 23:24:52,679 INFO student test iter6 performance: 73.68
2022-12-19 23:24:52,679 INFO student test iter6 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:24:52,680 INFO student test iter6 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:24:52,680 INFO Student Dev performance on iter 6: 90.625
2022-12-19 23:24:52,680 INFO Student Test performance on iter 6: 73.68421052631578
2022-12-19 23:24:52,680 INFO 

	 *** Starting loop 7 ***
2022-12-19 23:24:52,680 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:52,680 INFO Downsampling 444 data
2022-12-19 23:24:52,681 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:52,681 INFO Getting rule predictions
2022-12-19 23:24:52,681 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:52,682 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:52,682 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:52,683 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:52,684 INFO Predicting labels for 741 texts
2022-12-19 23:24:52,790 INFO Predicting labels for 32 texts
2022-12-19 23:24:52,895 INFO Predicting labels for 444 texts
2022-12-19 23:24:53,002 INFO Training Rule Attention Network
2022-12-19 23:24:53,009 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:24:53,010 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:24:53,015 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:24:53,015 INFO 

		*** Training RAN ***
2022-12-19 23:24:56,158 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:56,159 INFO Predicting labels for 444 texts
2022-12-19 23:24:56,269 INFO There are 3/7 active rules
2022-12-19 23:24:56,270 INFO Coverage: 100.0% (444/444)
2022-12-19 23:24:56,370 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:24:56,455 INFO DONE, Getting attention scores...
2022-12-19 23:24:56,512 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:56,513 INFO Predicting labels for 32 texts
2022-12-19 23:24:56,622 INFO There are 7/7 active rules
2022-12-19 23:24:56,622 INFO Coverage: 100.0% (32/32)
2022-12-19 23:24:56,623 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:24:56,648 INFO DONE, Getting attention scores...
2022-12-19 23:24:56,703 INFO Evaluating teacher dev iter7 on 32 examples
2022-12-19 23:24:56,708 INFO teacher dev iter7 performance: 81.25
2022-12-19 23:24:56,708 INFO teacher dev iter7 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:24:56,708 INFO teacher dev iter7 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:24:56,708 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:24:56,708 INFO Predicting labels for 19 texts
2022-12-19 23:24:56,812 INFO There are 7/7 active rules
2022-12-19 23:24:56,813 INFO Coverage: 100.0% (19/19)
2022-12-19 23:24:56,813 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:24:56,837 INFO DONE, Getting attention scores...
2022-12-19 23:24:56,899 INFO Evaluating teacher test iter7 on 19 examples
2022-12-19 23:24:56,904 INFO teacher test iter7 performance: 89.47
2022-12-19 23:24:56,904 INFO teacher test iter7 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:24:56,904 INFO teacher test iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:24:56,904 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:24:56,908 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:24:56,909 INFO Balancing Pseudo Dataset to keep 506 items...
2022-12-19 23:24:56,913 INFO PSEUDO-DATASET:
506 examples
PSEUDO-LABELS:
1    253
0    253
Name: label, dtype: int64
2022-12-19 23:24:56,913 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:24:57,657 INFO fine-tuning the student on clean labeled data
2022-12-19 23:24:59,587 INFO Predicting labels for 32 texts
2022-12-19 23:24:59,693 INFO Evaluating student dev iter7 on 32 examples
2022-12-19 23:24:59,697 INFO student dev iter7 performance: 90.62
2022-12-19 23:24:59,698 INFO student dev iter7 confusion matrix:
[[29  1]
 [ 2  0]]
2022-12-19 23:24:59,698 INFO student dev iter7 report:
              precision    recall  f1-score   support

           0       0.94      0.97      0.95        30
           1       0.00      0.00      0.00         2

    accuracy                           0.91        32
   macro avg       0.47      0.48      0.48        32
weighted avg       0.88      0.91      0.89        32

2022-12-19 23:24:59,698 INFO Predicting labels for 19 texts
2022-12-19 23:24:59,808 INFO Evaluating student test iter7 on 19 examples
2022-12-19 23:24:59,812 INFO student test iter7 performance: 73.68
2022-12-19 23:24:59,812 INFO student test iter7 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:24:59,812 INFO student test iter7 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:24:59,813 INFO Student Dev performance on iter 7: 90.625
2022-12-19 23:24:59,813 INFO Student Test performance on iter 7: 73.68421052631578
2022-12-19 23:24:59,813 INFO 

	 *** Starting loop 8 ***
2022-12-19 23:24:59,813 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:24:59,813 INFO Downsampling 444 data
2022-12-19 23:24:59,814 INFO Adding Student as extra rule in Teacher
2022-12-19 23:24:59,814 INFO Getting rule predictions
2022-12-19 23:24:59,814 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:24:59,815 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:24:59,815 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:24:59,816 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:24:59,817 INFO Predicting labels for 741 texts
2022-12-19 23:24:59,924 INFO Predicting labels for 32 texts
2022-12-19 23:25:00,026 INFO Predicting labels for 444 texts
2022-12-19 23:25:00,133 INFO Training Rule Attention Network
2022-12-19 23:25:00,140 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:25:00,141 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:25:00,145 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:25:00,145 INFO 

		*** Training RAN ***
2022-12-19 23:25:03,112 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:03,113 INFO Predicting labels for 444 texts
2022-12-19 23:25:03,217 INFO There are 3/7 active rules
2022-12-19 23:25:03,217 INFO Coverage: 100.0% (444/444)
2022-12-19 23:25:03,222 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:25:03,316 INFO DONE, Getting attention scores...
2022-12-19 23:25:03,374 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:03,374 INFO Predicting labels for 32 texts
2022-12-19 23:25:03,478 INFO There are 7/7 active rules
2022-12-19 23:25:03,479 INFO Coverage: 100.0% (32/32)
2022-12-19 23:25:03,480 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:25:03,506 INFO DONE, Getting attention scores...
2022-12-19 23:25:03,657 INFO Evaluating teacher dev iter8 on 32 examples
2022-12-19 23:25:03,662 INFO teacher dev iter8 performance: 81.25
2022-12-19 23:25:03,662 INFO teacher dev iter8 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:25:03,662 INFO teacher dev iter8 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:25:03,662 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:25:03,662 INFO Predicting labels for 19 texts
2022-12-19 23:25:03,769 INFO There are 7/7 active rules
2022-12-19 23:25:03,770 INFO Coverage: 100.0% (19/19)
2022-12-19 23:25:03,771 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:25:03,797 INFO DONE, Getting attention scores...
2022-12-19 23:25:03,853 INFO Evaluating teacher test iter8 on 19 examples
2022-12-19 23:25:03,857 INFO teacher test iter8 performance: 89.47
2022-12-19 23:25:03,858 INFO teacher test iter8 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:25:03,858 INFO teacher test iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:25:03,858 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:25:03,861 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:25:03,862 INFO Balancing Pseudo Dataset to keep 516 items...
2022-12-19 23:25:03,866 INFO PSEUDO-DATASET:
516 examples
PSEUDO-LABELS:
1    258
0    258
Name: label, dtype: int64
2022-12-19 23:25:03,867 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:25:04,608 INFO fine-tuning the student on clean labeled data
2022-12-19 23:25:06,590 INFO Predicting labels for 32 texts
2022-12-19 23:25:06,701 INFO Evaluating student dev iter8 on 32 examples
2022-12-19 23:25:06,705 INFO student dev iter8 performance: 90.62
2022-12-19 23:25:06,706 INFO student dev iter8 confusion matrix:
[[29  1]
 [ 2  0]]
2022-12-19 23:25:06,706 INFO student dev iter8 report:
              precision    recall  f1-score   support

           0       0.94      0.97      0.95        30
           1       0.00      0.00      0.00         2

    accuracy                           0.91        32
   macro avg       0.47      0.48      0.48        32
weighted avg       0.88      0.91      0.89        32

2022-12-19 23:25:06,706 INFO Predicting labels for 19 texts
2022-12-19 23:25:06,812 INFO Evaluating student test iter8 on 19 examples
2022-12-19 23:25:06,816 INFO student test iter8 performance: 73.68
2022-12-19 23:25:06,817 INFO student test iter8 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:25:06,817 INFO student test iter8 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:25:06,817 INFO Student Dev performance on iter 8: 90.625
2022-12-19 23:25:06,817 INFO Student Test performance on iter 8: 73.68421052631578
2022-12-19 23:25:06,817 INFO 

	 *** Starting loop 9 ***
2022-12-19 23:25:06,817 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:25:06,818 INFO Downsampling 444 data
2022-12-19 23:25:06,818 INFO Adding Student as extra rule in Teacher
2022-12-19 23:25:06,818 INFO Getting rule predictions
2022-12-19 23:25:06,818 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:25:06,819 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:06,820 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:06,820 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:25:06,821 INFO Predicting labels for 741 texts
2022-12-19 23:25:06,932 INFO Predicting labels for 32 texts
2022-12-19 23:25:07,032 INFO Predicting labels for 444 texts
2022-12-19 23:25:07,141 INFO Training Rule Attention Network
2022-12-19 23:25:07,151 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:25:07,152 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:25:07,156 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:25:07,156 INFO 

		*** Training RAN ***
2022-12-19 23:25:10,059 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:10,060 INFO Predicting labels for 444 texts
2022-12-19 23:25:10,166 INFO There are 3/7 active rules
2022-12-19 23:25:10,166 INFO Coverage: 100.0% (444/444)
2022-12-19 23:25:10,170 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:25:10,256 INFO DONE, Getting attention scores...
2022-12-19 23:25:10,314 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:10,314 INFO Predicting labels for 32 texts
2022-12-19 23:25:10,416 INFO There are 7/7 active rules
2022-12-19 23:25:10,417 INFO Coverage: 100.0% (32/32)
2022-12-19 23:25:10,417 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:25:10,442 INFO DONE, Getting attention scores...
2022-12-19 23:25:10,495 INFO Evaluating teacher dev iter9 on 32 examples
2022-12-19 23:25:10,500 INFO teacher dev iter9 performance: 81.25
2022-12-19 23:25:10,501 INFO teacher dev iter9 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:25:10,501 INFO teacher dev iter9 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:25:10,501 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:25:10,501 INFO Predicting labels for 19 texts
2022-12-19 23:25:10,608 INFO There are 7/7 active rules
2022-12-19 23:25:10,608 INFO Coverage: 100.0% (19/19)
2022-12-19 23:25:10,609 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:25:10,633 INFO DONE, Getting attention scores...
2022-12-19 23:25:10,687 INFO Evaluating teacher test iter9 on 19 examples
2022-12-19 23:25:10,692 INFO teacher test iter9 performance: 89.47
2022-12-19 23:25:10,692 INFO teacher test iter9 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:25:10,692 INFO teacher test iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:25:10,693 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:25:10,696 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:25:10,698 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-19 23:25:10,702 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-19 23:25:10,702 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:25:12,379 INFO fine-tuning the student on clean labeled data
2022-12-19 23:25:15,466 INFO Predicting labels for 32 texts
2022-12-19 23:25:15,581 INFO Evaluating student dev iter9 on 32 examples
2022-12-19 23:25:15,586 INFO student dev iter9 performance: 90.62
2022-12-19 23:25:15,587 INFO student dev iter9 confusion matrix:
[[29  1]
 [ 2  0]]
2022-12-19 23:25:15,587 INFO student dev iter9 report:
              precision    recall  f1-score   support

           0       0.94      0.97      0.95        30
           1       0.00      0.00      0.00         2

    accuracy                           0.91        32
   macro avg       0.47      0.48      0.48        32
weighted avg       0.88      0.91      0.89        32

2022-12-19 23:25:15,587 INFO Predicting labels for 19 texts
2022-12-19 23:25:15,702 INFO Evaluating student test iter9 on 19 examples
2022-12-19 23:25:15,707 INFO student test iter9 performance: 73.68
2022-12-19 23:25:15,707 INFO student test iter9 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:25:15,708 INFO student test iter9 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:25:15,708 INFO Student Dev performance on iter 9: 90.625
2022-12-19 23:25:15,708 INFO Student Test performance on iter 9: 73.68421052631578
2022-12-19 23:25:15,708 INFO 

	 *** Starting loop 10 ***
2022-12-19 23:25:15,708 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:25:15,708 INFO Downsampling 444 data
2022-12-19 23:25:15,708 INFO Adding Student as extra rule in Teacher
2022-12-19 23:25:15,709 INFO Getting rule predictions
2022-12-19 23:25:15,709 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:25:15,709 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:15,710 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:15,710 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:25:15,711 INFO Predicting labels for 741 texts
2022-12-19 23:25:15,822 INFO Predicting labels for 32 texts
2022-12-19 23:25:16,968 INFO Predicting labels for 444 texts
2022-12-19 23:25:17,076 INFO Training Rule Attention Network
2022-12-19 23:25:17,084 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:25:17,084 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:25:17,089 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:25:17,089 INFO 

		*** Training RAN ***
2022-12-19 23:25:20,312 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:20,313 INFO Predicting labels for 444 texts
2022-12-19 23:25:20,423 INFO There are 3/7 active rules
2022-12-19 23:25:20,424 INFO Coverage: 100.0% (444/444)
2022-12-19 23:25:20,428 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:25:20,512 INFO DONE, Getting attention scores...
2022-12-19 23:25:20,570 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:20,571 INFO Predicting labels for 32 texts
2022-12-19 23:25:20,675 INFO There are 7/7 active rules
2022-12-19 23:25:20,676 INFO Coverage: 100.0% (32/32)
2022-12-19 23:25:20,677 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:25:20,701 INFO DONE, Getting attention scores...
2022-12-19 23:25:20,756 INFO Evaluating teacher dev iter10 on 32 examples
2022-12-19 23:25:20,760 INFO teacher dev iter10 performance: 81.25
2022-12-19 23:25:20,760 INFO teacher dev iter10 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:25:20,760 INFO teacher dev iter10 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:25:20,761 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:25:20,761 INFO Predicting labels for 19 texts
2022-12-19 23:25:20,870 INFO There are 7/7 active rules
2022-12-19 23:25:20,870 INFO Coverage: 100.0% (19/19)
2022-12-19 23:25:20,871 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:25:20,895 INFO DONE, Getting attention scores...
2022-12-19 23:25:20,954 INFO Evaluating teacher test iter10 on 19 examples
2022-12-19 23:25:20,958 INFO teacher test iter10 performance: 89.47
2022-12-19 23:25:20,959 INFO teacher test iter10 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:25:20,959 INFO teacher test iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:25:20,959 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:25:20,963 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:25:20,964 INFO Balancing Pseudo Dataset to keep 516 items...
2022-12-19 23:25:20,968 INFO PSEUDO-DATASET:
516 examples
PSEUDO-LABELS:
1    258
0    258
Name: label, dtype: int64
2022-12-19 23:25:20,968 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:25:22,764 INFO fine-tuning the student on clean labeled data
2022-12-19 23:25:26,850 INFO Predicting labels for 32 texts
2022-12-19 23:25:26,961 INFO Evaluating student dev iter10 on 32 examples
2022-12-19 23:25:26,965 INFO student dev iter10 performance: 90.62
2022-12-19 23:25:26,966 INFO student dev iter10 confusion matrix:
[[28  2]
 [ 1  1]]
2022-12-19 23:25:26,966 INFO student dev iter10 report:
              precision    recall  f1-score   support

           0       0.97      0.93      0.95        30
           1       0.33      0.50      0.40         2

    accuracy                           0.91        32
   macro avg       0.65      0.72      0.67        32
weighted avg       0.93      0.91      0.91        32

2022-12-19 23:25:26,966 INFO Predicting labels for 19 texts
2022-12-19 23:25:28,095 INFO Evaluating student test iter10 on 19 examples
2022-12-19 23:25:28,099 INFO student test iter10 performance: 73.68
2022-12-19 23:25:28,100 INFO student test iter10 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:25:28,100 INFO student test iter10 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:25:28,100 INFO Student Dev performance on iter 10: 90.625
2022-12-19 23:25:28,100 INFO Student Test performance on iter 10: 73.68421052631578
2022-12-19 23:25:28,100 INFO 

	 *** Starting loop 11 ***
2022-12-19 23:25:28,100 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:25:28,100 INFO Downsampling 444 data
2022-12-19 23:25:28,101 INFO Adding Student as extra rule in Teacher
2022-12-19 23:25:28,101 INFO Getting rule predictions
2022-12-19 23:25:28,102 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:25:28,102 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:28,103 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:28,103 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:25:28,104 INFO Predicting labels for 741 texts
2022-12-19 23:25:28,218 INFO Predicting labels for 32 texts
2022-12-19 23:25:28,323 INFO Predicting labels for 444 texts
2022-12-19 23:25:28,433 INFO Training Rule Attention Network
2022-12-19 23:25:28,440 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:25:28,440 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:25:28,444 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:25:28,445 INFO 

		*** Training RAN ***
2022-12-19 23:25:31,375 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:31,376 INFO Predicting labels for 444 texts
2022-12-19 23:25:32,506 INFO There are 3/7 active rules
2022-12-19 23:25:32,507 INFO Coverage: 100.0% (444/444)
2022-12-19 23:25:32,514 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:25:32,599 INFO DONE, Getting attention scores...
2022-12-19 23:25:32,654 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:32,654 INFO Predicting labels for 32 texts
2022-12-19 23:25:32,758 INFO There are 7/7 active rules
2022-12-19 23:25:32,759 INFO Coverage: 100.0% (32/32)
2022-12-19 23:25:32,759 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:25:32,788 INFO DONE, Getting attention scores...
2022-12-19 23:25:32,842 INFO Evaluating teacher dev iter11 on 32 examples
2022-12-19 23:25:32,847 INFO teacher dev iter11 performance: 81.25
2022-12-19 23:25:32,847 INFO teacher dev iter11 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:25:32,847 INFO teacher dev iter11 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:25:32,848 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:25:32,848 INFO Predicting labels for 19 texts
2022-12-19 23:25:32,951 INFO There are 7/7 active rules
2022-12-19 23:25:32,951 INFO Coverage: 100.0% (19/19)
2022-12-19 23:25:32,952 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:25:32,976 INFO DONE, Getting attention scores...
2022-12-19 23:25:33,034 INFO Evaluating teacher test iter11 on 19 examples
2022-12-19 23:25:33,039 INFO teacher test iter11 performance: 89.47
2022-12-19 23:25:33,039 INFO teacher test iter11 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:25:33,039 INFO teacher test iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:25:33,039 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:25:33,042 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:25:33,044 INFO Balancing Pseudo Dataset to keep 516 items...
2022-12-19 23:25:33,048 INFO PSEUDO-DATASET:
516 examples
PSEUDO-LABELS:
1    258
0    258
Name: label, dtype: int64
2022-12-19 23:25:33,048 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:25:34,958 INFO fine-tuning the student on clean labeled data
2022-12-19 23:25:36,974 INFO Predicting labels for 32 texts
2022-12-19 23:25:37,091 INFO Evaluating student dev iter11 on 32 examples
2022-12-19 23:25:37,096 INFO student dev iter11 performance: 81.25
2022-12-19 23:25:37,096 INFO student dev iter11 confusion matrix:
[[26  4]
 [ 2  0]]
2022-12-19 23:25:37,097 INFO student dev iter11 report:
              precision    recall  f1-score   support

           0       0.93      0.87      0.90        30
           1       0.00      0.00      0.00         2

    accuracy                           0.81        32
   macro avg       0.46      0.43      0.45        32
weighted avg       0.87      0.81      0.84        32

2022-12-19 23:25:37,097 INFO Predicting labels for 19 texts
2022-12-19 23:25:37,200 INFO Evaluating student test iter11 on 19 examples
2022-12-19 23:25:37,205 INFO student test iter11 performance: 73.68
2022-12-19 23:25:37,205 INFO student test iter11 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:25:37,205 INFO student test iter11 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:25:37,205 INFO Student Dev performance on iter 11: 81.25
2022-12-19 23:25:37,205 INFO Student Test performance on iter 11: 73.68421052631578
2022-12-19 23:25:37,205 INFO 

	 *** Starting loop 12 ***
2022-12-19 23:25:37,205 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:25:37,205 INFO Downsampling 444 data
2022-12-19 23:25:37,206 INFO Adding Student as extra rule in Teacher
2022-12-19 23:25:37,206 INFO Getting rule predictions
2022-12-19 23:25:37,206 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:25:37,207 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:37,208 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:37,208 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:25:37,210 INFO Predicting labels for 741 texts
2022-12-19 23:25:38,337 INFO Predicting labels for 32 texts
2022-12-19 23:25:38,440 INFO Predicting labels for 444 texts
2022-12-19 23:25:38,545 INFO Training Rule Attention Network
2022-12-19 23:25:38,657 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:25:38,658 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:25:38,663 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:25:38,663 INFO 

		*** Training RAN ***
2022-12-19 23:25:41,614 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:41,615 INFO Predicting labels for 444 texts
2022-12-19 23:25:41,723 INFO There are 3/7 active rules
2022-12-19 23:25:41,723 INFO Coverage: 100.0% (444/444)
2022-12-19 23:25:41,730 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:25:41,818 INFO DONE, Getting attention scores...
2022-12-19 23:25:41,876 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:41,876 INFO Predicting labels for 32 texts
2022-12-19 23:25:41,996 INFO There are 7/7 active rules
2022-12-19 23:25:41,997 INFO Coverage: 100.0% (32/32)
2022-12-19 23:25:41,997 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:25:42,022 INFO DONE, Getting attention scores...
2022-12-19 23:25:42,082 INFO Evaluating teacher dev iter12 on 32 examples
2022-12-19 23:25:42,086 INFO teacher dev iter12 performance: 81.25
2022-12-19 23:25:42,086 INFO teacher dev iter12 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:25:42,086 INFO teacher dev iter12 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:25:42,087 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:25:42,087 INFO Predicting labels for 19 texts
2022-12-19 23:25:42,192 INFO There are 7/7 active rules
2022-12-19 23:25:42,192 INFO Coverage: 100.0% (19/19)
2022-12-19 23:25:42,193 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:25:42,217 INFO DONE, Getting attention scores...
2022-12-19 23:25:42,271 INFO Evaluating teacher test iter12 on 19 examples
2022-12-19 23:25:42,275 INFO teacher test iter12 performance: 89.47
2022-12-19 23:25:42,276 INFO teacher test iter12 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:25:42,276 INFO teacher test iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:25:42,276 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:25:42,279 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:25:42,281 INFO Balancing Pseudo Dataset to keep 516 items...
2022-12-19 23:25:42,285 INFO PSEUDO-DATASET:
516 examples
PSEUDO-LABELS:
1    258
0    258
Name: label, dtype: int64
2022-12-19 23:25:42,285 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:25:43,032 INFO fine-tuning the student on clean labeled data
2022-12-19 23:25:43,945 INFO Predicting labels for 32 texts
2022-12-19 23:25:44,052 INFO Evaluating student dev iter12 on 32 examples
2022-12-19 23:25:44,057 INFO student dev iter12 performance: 81.25
2022-12-19 23:25:44,057 INFO student dev iter12 confusion matrix:
[[26  4]
 [ 2  0]]
2022-12-19 23:25:44,057 INFO student dev iter12 report:
              precision    recall  f1-score   support

           0       0.93      0.87      0.90        30
           1       0.00      0.00      0.00         2

    accuracy                           0.81        32
   macro avg       0.46      0.43      0.45        32
weighted avg       0.87      0.81      0.84        32

2022-12-19 23:25:44,057 INFO Predicting labels for 19 texts
2022-12-19 23:25:44,160 INFO Evaluating student test iter12 on 19 examples
2022-12-19 23:25:44,164 INFO student test iter12 performance: 73.68
2022-12-19 23:25:44,164 INFO student test iter12 confusion matrix:
[[12  1]
 [ 4  2]]
2022-12-19 23:25:44,164 INFO student test iter12 report:
              precision    recall  f1-score   support

           0       0.75      0.92      0.83        13
           1       0.67      0.33      0.44         6

    accuracy                           0.74        19
   macro avg       0.71      0.63      0.64        19
weighted avg       0.72      0.74      0.71        19

2022-12-19 23:25:44,165 INFO Student Dev performance on iter 12: 81.25
2022-12-19 23:25:44,165 INFO Student Test performance on iter 12: 73.68421052631578
2022-12-19 23:25:44,165 INFO 

	 *** Starting loop 13 ***
2022-12-19 23:25:44,165 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:25:44,165 INFO Downsampling 444 data
2022-12-19 23:25:44,166 INFO Adding Student as extra rule in Teacher
2022-12-19 23:25:44,166 INFO Getting rule predictions
2022-12-19 23:25:44,166 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:25:44,167 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:44,167 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:44,168 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:25:44,169 INFO Predicting labels for 741 texts
2022-12-19 23:25:44,276 INFO Predicting labels for 32 texts
2022-12-19 23:25:44,378 INFO Predicting labels for 444 texts
2022-12-19 23:25:44,486 INFO Training Rule Attention Network
2022-12-19 23:25:44,493 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:25:44,494 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:25:44,499 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:25:44,499 INFO 

		*** Training RAN ***
2022-12-19 23:25:47,690 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:47,691 INFO Predicting labels for 444 texts
2022-12-19 23:25:47,798 INFO There are 3/7 active rules
2022-12-19 23:25:47,798 INFO Coverage: 100.0% (444/444)
2022-12-19 23:25:47,805 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:25:47,894 INFO DONE, Getting attention scores...
2022-12-19 23:25:47,951 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:47,952 INFO Predicting labels for 32 texts
2022-12-19 23:25:48,050 INFO There are 7/7 active rules
2022-12-19 23:25:48,051 INFO Coverage: 100.0% (32/32)
2022-12-19 23:25:48,051 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:25:48,083 INFO DONE, Getting attention scores...
2022-12-19 23:25:48,136 INFO Evaluating teacher dev iter13 on 32 examples
2022-12-19 23:25:48,141 INFO teacher dev iter13 performance: 81.25
2022-12-19 23:25:48,141 INFO teacher dev iter13 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:25:48,141 INFO teacher dev iter13 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:25:48,141 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:25:48,142 INFO Predicting labels for 19 texts
2022-12-19 23:25:48,247 INFO There are 7/7 active rules
2022-12-19 23:25:48,247 INFO Coverage: 100.0% (19/19)
2022-12-19 23:25:48,248 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:25:48,273 INFO DONE, Getting attention scores...
2022-12-19 23:25:48,333 INFO Evaluating teacher test iter13 on 19 examples
2022-12-19 23:25:48,338 INFO teacher test iter13 performance: 89.47
2022-12-19 23:25:48,338 INFO teacher test iter13 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:25:48,338 INFO teacher test iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:25:48,338 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:25:48,342 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:25:48,344 INFO Balancing Pseudo Dataset to keep 516 items...
2022-12-19 23:25:48,347 INFO PSEUDO-DATASET:
516 examples
PSEUDO-LABELS:
1    258
0    258
Name: label, dtype: int64
2022-12-19 23:25:48,348 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:25:50,230 INFO fine-tuning the student on clean labeled data
2022-12-19 23:25:51,129 INFO Predicting labels for 32 texts
2022-12-19 23:25:51,236 INFO Evaluating student dev iter13 on 32 examples
2022-12-19 23:25:51,242 INFO student dev iter13 performance: 81.25
2022-12-19 23:25:51,242 INFO student dev iter13 confusion matrix:
[[26  4]
 [ 2  0]]
2022-12-19 23:25:51,243 INFO student dev iter13 report:
              precision    recall  f1-score   support

           0       0.93      0.87      0.90        30
           1       0.00      0.00      0.00         2

    accuracy                           0.81        32
   macro avg       0.46      0.43      0.45        32
weighted avg       0.87      0.81      0.84        32

2022-12-19 23:25:51,243 INFO Predicting labels for 19 texts
2022-12-19 23:25:51,353 INFO Evaluating student test iter13 on 19 examples
2022-12-19 23:25:51,357 INFO student test iter13 performance: 78.95
2022-12-19 23:25:51,358 INFO student test iter13 confusion matrix:
[[13  0]
 [ 4  2]]
2022-12-19 23:25:51,358 INFO student test iter13 report:
              precision    recall  f1-score   support

           0       0.76      1.00      0.87        13
           1       1.00      0.33      0.50         6

    accuracy                           0.79        19
   macro avg       0.88      0.67      0.68        19
weighted avg       0.84      0.79      0.75        19

2022-12-19 23:25:51,358 INFO Student Dev performance on iter 13: 81.25
2022-12-19 23:25:51,358 INFO Student Test performance on iter 13: 78.94736842105263
2022-12-19 23:25:51,358 INFO 

	 *** Starting loop 14 ***
2022-12-19 23:25:51,358 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:25:51,358 INFO Downsampling 444 data
2022-12-19 23:25:51,359 INFO Adding Student as extra rule in Teacher
2022-12-19 23:25:51,359 INFO Getting rule predictions
2022-12-19 23:25:51,359 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:25:51,360 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:51,361 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:51,361 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:25:51,362 INFO Predicting labels for 741 texts
2022-12-19 23:25:51,469 INFO Predicting labels for 32 texts
2022-12-19 23:25:51,572 INFO Predicting labels for 444 texts
2022-12-19 23:25:51,679 INFO Training Rule Attention Network
2022-12-19 23:25:51,686 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:25:51,687 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:25:51,691 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:25:51,691 INFO 

		*** Training RAN ***
2022-12-19 23:25:54,794 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:54,795 INFO Predicting labels for 444 texts
2022-12-19 23:25:54,912 INFO There are 3/7 active rules
2022-12-19 23:25:54,912 INFO Coverage: 100.0% (444/444)
2022-12-19 23:25:54,917 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:25:55,004 INFO DONE, Getting attention scores...
2022-12-19 23:25:55,062 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:55,062 INFO Predicting labels for 32 texts
2022-12-19 23:25:55,167 INFO There are 7/7 active rules
2022-12-19 23:25:55,167 INFO Coverage: 100.0% (32/32)
2022-12-19 23:25:55,168 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:25:55,194 INFO DONE, Getting attention scores...
2022-12-19 23:25:55,247 INFO Evaluating teacher dev iter14 on 32 examples
2022-12-19 23:25:55,252 INFO teacher dev iter14 performance: 81.25
2022-12-19 23:25:55,252 INFO teacher dev iter14 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:25:55,252 INFO teacher dev iter14 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:25:55,252 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:25:55,252 INFO Predicting labels for 19 texts
2022-12-19 23:25:55,354 INFO There are 7/7 active rules
2022-12-19 23:25:55,354 INFO Coverage: 100.0% (19/19)
2022-12-19 23:25:55,355 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:25:55,379 INFO DONE, Getting attention scores...
2022-12-19 23:25:55,440 INFO Evaluating teacher test iter14 on 19 examples
2022-12-19 23:25:55,445 INFO teacher test iter14 performance: 89.47
2022-12-19 23:25:55,445 INFO teacher test iter14 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:25:55,445 INFO teacher test iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:25:55,445 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:25:55,448 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:25:55,450 INFO Balancing Pseudo Dataset to keep 514 items...
2022-12-19 23:25:55,454 INFO PSEUDO-DATASET:
514 examples
PSEUDO-LABELS:
1    257
0    257
Name: label, dtype: int64
2022-12-19 23:25:55,454 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:25:56,247 INFO fine-tuning the student on clean labeled data
2022-12-19 23:25:57,185 INFO Predicting labels for 32 texts
2022-12-19 23:25:57,299 INFO Evaluating student dev iter14 on 32 examples
2022-12-19 23:25:57,303 INFO student dev iter14 performance: 84.38
2022-12-19 23:25:57,304 INFO student dev iter14 confusion matrix:
[[26  4]
 [ 1  1]]
2022-12-19 23:25:57,304 INFO student dev iter14 report:
              precision    recall  f1-score   support

           0       0.96      0.87      0.91        30
           1       0.20      0.50      0.29         2

    accuracy                           0.84        32
   macro avg       0.58      0.68      0.60        32
weighted avg       0.92      0.84      0.87        32

2022-12-19 23:25:57,304 INFO Predicting labels for 19 texts
2022-12-19 23:25:57,414 INFO Evaluating student test iter14 on 19 examples
2022-12-19 23:25:57,418 INFO student test iter14 performance: 78.95
2022-12-19 23:25:57,419 INFO student test iter14 confusion matrix:
[[13  0]
 [ 4  2]]
2022-12-19 23:25:57,419 INFO student test iter14 report:
              precision    recall  f1-score   support

           0       0.76      1.00      0.87        13
           1       1.00      0.33      0.50         6

    accuracy                           0.79        19
   macro avg       0.88      0.67      0.68        19
weighted avg       0.84      0.79      0.75        19

2022-12-19 23:25:57,419 INFO Student Dev performance on iter 14: 84.375
2022-12-19 23:25:57,419 INFO Student Test performance on iter 14: 78.94736842105263
2022-12-19 23:25:57,419 INFO 

	 *** Starting loop 15 ***
2022-12-19 23:25:57,419 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:25:57,419 INFO Downsampling 444 data
2022-12-19 23:25:57,420 INFO Adding Student as extra rule in Teacher
2022-12-19 23:25:57,420 INFO Getting rule predictions
2022-12-19 23:25:57,420 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:25:57,421 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:25:57,421 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:25:57,422 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:25:57,423 INFO Predicting labels for 741 texts
2022-12-19 23:25:57,531 INFO Predicting labels for 32 texts
2022-12-19 23:25:57,640 INFO Predicting labels for 444 texts
2022-12-19 23:25:57,745 INFO Training Rule Attention Network
2022-12-19 23:25:57,752 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:25:57,754 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:25:57,757 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:25:57,758 INFO 

		*** Training RAN ***
2022-12-19 23:26:00,861 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:00,862 INFO Predicting labels for 444 texts
2022-12-19 23:26:01,989 INFO There are 3/7 active rules
2022-12-19 23:26:01,989 INFO Coverage: 100.0% (444/444)
2022-12-19 23:26:01,994 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:26:02,083 INFO DONE, Getting attention scores...
2022-12-19 23:26:02,143 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:02,144 INFO Predicting labels for 32 texts
2022-12-19 23:26:02,250 INFO There are 7/7 active rules
2022-12-19 23:26:02,250 INFO Coverage: 100.0% (32/32)
2022-12-19 23:26:02,251 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:26:02,274 INFO DONE, Getting attention scores...
2022-12-19 23:26:02,329 INFO Evaluating teacher dev iter15 on 32 examples
2022-12-19 23:26:02,333 INFO teacher dev iter15 performance: 81.25
2022-12-19 23:26:02,334 INFO teacher dev iter15 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:26:02,334 INFO teacher dev iter15 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:26:02,334 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:26:02,334 INFO Predicting labels for 19 texts
2022-12-19 23:26:02,444 INFO There are 7/7 active rules
2022-12-19 23:26:02,444 INFO Coverage: 100.0% (19/19)
2022-12-19 23:26:02,445 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:26:02,469 INFO DONE, Getting attention scores...
2022-12-19 23:26:02,525 INFO Evaluating teacher test iter15 on 19 examples
2022-12-19 23:26:02,530 INFO teacher test iter15 performance: 89.47
2022-12-19 23:26:02,530 INFO teacher test iter15 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:26:02,530 INFO teacher test iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:26:02,530 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:26:02,533 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:26:02,535 INFO Balancing Pseudo Dataset to keep 514 items...
2022-12-19 23:26:02,539 INFO PSEUDO-DATASET:
514 examples
PSEUDO-LABELS:
1    257
0    257
Name: label, dtype: int64
2022-12-19 23:26:02,539 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:26:03,290 INFO fine-tuning the student on clean labeled data
2022-12-19 23:26:04,206 INFO Predicting labels for 32 texts
2022-12-19 23:26:05,334 INFO Evaluating student dev iter15 on 32 examples
2022-12-19 23:26:05,339 INFO student dev iter15 performance: 84.38
2022-12-19 23:26:05,339 INFO student dev iter15 confusion matrix:
[[25  5]
 [ 0  2]]
2022-12-19 23:26:05,339 INFO student dev iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.83      0.91        30
           1       0.29      1.00      0.44         2

    accuracy                           0.84        32
   macro avg       0.64      0.92      0.68        32
weighted avg       0.96      0.84      0.88        32

2022-12-19 23:26:05,339 INFO Predicting labels for 19 texts
2022-12-19 23:26:05,446 INFO Evaluating student test iter15 on 19 examples
2022-12-19 23:26:05,450 INFO student test iter15 performance: 78.95
2022-12-19 23:26:05,451 INFO student test iter15 confusion matrix:
[[13  0]
 [ 4  2]]
2022-12-19 23:26:05,451 INFO student test iter15 report:
              precision    recall  f1-score   support

           0       0.76      1.00      0.87        13
           1       1.00      0.33      0.50         6

    accuracy                           0.79        19
   macro avg       0.88      0.67      0.68        19
weighted avg       0.84      0.79      0.75        19

2022-12-19 23:26:05,451 INFO Student Dev performance on iter 15: 84.375
2022-12-19 23:26:05,451 INFO Student Test performance on iter 15: 78.94736842105263
2022-12-19 23:26:05,451 INFO 

	 *** Starting loop 16 ***
2022-12-19 23:26:05,451 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:26:05,451 INFO Downsampling 444 data
2022-12-19 23:26:05,452 INFO Adding Student as extra rule in Teacher
2022-12-19 23:26:05,452 INFO Getting rule predictions
2022-12-19 23:26:05,452 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:26:05,453 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:05,453 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:05,454 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:26:05,455 INFO Predicting labels for 741 texts
2022-12-19 23:26:05,560 INFO Predicting labels for 32 texts
2022-12-19 23:26:05,665 INFO Predicting labels for 444 texts
2022-12-19 23:26:05,769 INFO Training Rule Attention Network
2022-12-19 23:26:05,776 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:26:05,777 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:26:05,783 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:26:05,783 INFO 

		*** Training RAN ***
2022-12-19 23:26:08,866 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:08,868 INFO Predicting labels for 444 texts
2022-12-19 23:26:08,973 INFO There are 3/7 active rules
2022-12-19 23:26:08,974 INFO Coverage: 100.0% (444/444)
2022-12-19 23:26:08,978 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:26:09,068 INFO DONE, Getting attention scores...
2022-12-19 23:26:09,128 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:09,128 INFO Predicting labels for 32 texts
2022-12-19 23:26:09,230 INFO There are 7/7 active rules
2022-12-19 23:26:09,231 INFO Coverage: 100.0% (32/32)
2022-12-19 23:26:09,232 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:26:09,256 INFO DONE, Getting attention scores...
2022-12-19 23:26:09,310 INFO Evaluating teacher dev iter16 on 32 examples
2022-12-19 23:26:09,315 INFO teacher dev iter16 performance: 81.25
2022-12-19 23:26:09,315 INFO teacher dev iter16 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:26:09,315 INFO teacher dev iter16 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:26:09,315 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:26:09,316 INFO Predicting labels for 19 texts
2022-12-19 23:26:09,533 INFO There are 7/7 active rules
2022-12-19 23:26:09,534 INFO Coverage: 100.0% (19/19)
2022-12-19 23:26:09,534 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:26:09,558 INFO DONE, Getting attention scores...
2022-12-19 23:26:09,615 INFO Evaluating teacher test iter16 on 19 examples
2022-12-19 23:26:09,619 INFO teacher test iter16 performance: 89.47
2022-12-19 23:26:09,620 INFO teacher test iter16 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:26:09,620 INFO teacher test iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:26:09,620 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:26:09,623 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:26:09,624 INFO Balancing Pseudo Dataset to keep 510 items...
2022-12-19 23:26:09,629 INFO PSEUDO-DATASET:
510 examples
PSEUDO-LABELS:
1    255
0    255
Name: label, dtype: int64
2022-12-19 23:26:09,629 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:26:11,390 INFO fine-tuning the student on clean labeled data
2022-12-19 23:26:12,320 INFO Predicting labels for 32 texts
2022-12-19 23:26:12,427 INFO Evaluating student dev iter16 on 32 examples
2022-12-19 23:26:12,432 INFO student dev iter16 performance: 81.25
2022-12-19 23:26:12,432 INFO student dev iter16 confusion matrix:
[[24  6]
 [ 0  2]]
2022-12-19 23:26:12,432 INFO student dev iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.80      0.89        30
           1       0.25      1.00      0.40         2

    accuracy                           0.81        32
   macro avg       0.62      0.90      0.64        32
weighted avg       0.95      0.81      0.86        32

2022-12-19 23:26:12,432 INFO Predicting labels for 19 texts
2022-12-19 23:26:12,542 INFO Evaluating student test iter16 on 19 examples
2022-12-19 23:26:12,548 INFO student test iter16 performance: 78.95
2022-12-19 23:26:12,548 INFO student test iter16 confusion matrix:
[[13  0]
 [ 4  2]]
2022-12-19 23:26:12,548 INFO student test iter16 report:
              precision    recall  f1-score   support

           0       0.76      1.00      0.87        13
           1       1.00      0.33      0.50         6

    accuracy                           0.79        19
   macro avg       0.88      0.67      0.68        19
weighted avg       0.84      0.79      0.75        19

2022-12-19 23:26:12,548 INFO Student Dev performance on iter 16: 81.25
2022-12-19 23:26:12,549 INFO Student Test performance on iter 16: 78.94736842105263
2022-12-19 23:26:12,549 INFO 

	 *** Starting loop 17 ***
2022-12-19 23:26:12,549 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:26:12,549 INFO Downsampling 444 data
2022-12-19 23:26:12,549 INFO Adding Student as extra rule in Teacher
2022-12-19 23:26:12,549 INFO Getting rule predictions
2022-12-19 23:26:12,549 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:26:12,550 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:12,550 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:12,551 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:26:12,552 INFO Predicting labels for 741 texts
2022-12-19 23:26:12,661 INFO Predicting labels for 32 texts
2022-12-19 23:26:13,785 INFO Predicting labels for 444 texts
2022-12-19 23:26:13,888 INFO Training Rule Attention Network
2022-12-19 23:26:13,900 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:26:13,901 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:26:13,905 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:26:13,905 INFO 

		*** Training RAN ***
2022-12-19 23:26:16,909 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:16,910 INFO Predicting labels for 444 texts
2022-12-19 23:26:17,015 INFO There are 3/7 active rules
2022-12-19 23:26:17,015 INFO Coverage: 100.0% (444/444)
2022-12-19 23:26:17,020 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:26:17,114 INFO DONE, Getting attention scores...
2022-12-19 23:26:17,173 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:17,173 INFO Predicting labels for 32 texts
2022-12-19 23:26:17,278 INFO There are 7/7 active rules
2022-12-19 23:26:17,278 INFO Coverage: 100.0% (32/32)
2022-12-19 23:26:17,279 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:26:17,303 INFO DONE, Getting attention scores...
2022-12-19 23:26:17,362 INFO Evaluating teacher dev iter17 on 32 examples
2022-12-19 23:26:17,367 INFO teacher dev iter17 performance: 81.25
2022-12-19 23:26:17,367 INFO teacher dev iter17 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:26:17,367 INFO teacher dev iter17 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:26:17,367 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:26:17,367 INFO Predicting labels for 19 texts
2022-12-19 23:26:17,471 INFO There are 7/7 active rules
2022-12-19 23:26:17,472 INFO Coverage: 100.0% (19/19)
2022-12-19 23:26:17,472 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:26:17,496 INFO DONE, Getting attention scores...
2022-12-19 23:26:17,551 INFO Evaluating teacher test iter17 on 19 examples
2022-12-19 23:26:17,555 INFO teacher test iter17 performance: 89.47
2022-12-19 23:26:17,555 INFO teacher test iter17 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:26:17,556 INFO teacher test iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:26:17,556 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:26:17,559 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:26:17,561 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-19 23:26:17,564 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-19 23:26:17,564 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:26:19,342 INFO fine-tuning the student on clean labeled data
2022-12-19 23:26:22,391 INFO Predicting labels for 32 texts
2022-12-19 23:26:23,521 INFO Evaluating student dev iter17 on 32 examples
2022-12-19 23:26:23,526 INFO student dev iter17 performance: 78.12
2022-12-19 23:26:23,526 INFO student dev iter17 confusion matrix:
[[23  7]
 [ 0  2]]
2022-12-19 23:26:23,527 INFO student dev iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.77      0.87        30
           1       0.22      1.00      0.36         2

    accuracy                           0.78        32
   macro avg       0.61      0.88      0.62        32
weighted avg       0.95      0.78      0.84        32

2022-12-19 23:26:23,527 INFO Predicting labels for 19 texts
2022-12-19 23:26:23,633 INFO Evaluating student test iter17 on 19 examples
2022-12-19 23:26:23,637 INFO student test iter17 performance: 84.21
2022-12-19 23:26:23,638 INFO student test iter17 confusion matrix:
[[13  0]
 [ 3  3]]
2022-12-19 23:26:23,638 INFO student test iter17 report:
              precision    recall  f1-score   support

           0       0.81      1.00      0.90        13
           1       1.00      0.50      0.67         6

    accuracy                           0.84        19
   macro avg       0.91      0.75      0.78        19
weighted avg       0.87      0.84      0.82        19

2022-12-19 23:26:23,638 INFO Student Dev performance on iter 17: 78.125
2022-12-19 23:26:23,638 INFO Student Test performance on iter 17: 84.21052631578947
2022-12-19 23:26:23,638 INFO 

	 *** Starting loop 18 ***
2022-12-19 23:26:23,638 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:26:23,638 INFO Downsampling 444 data
2022-12-19 23:26:23,639 INFO Adding Student as extra rule in Teacher
2022-12-19 23:26:23,639 INFO Getting rule predictions
2022-12-19 23:26:23,639 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:26:23,640 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:23,641 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:23,641 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:26:23,642 INFO Predicting labels for 741 texts
2022-12-19 23:26:23,748 INFO Predicting labels for 32 texts
2022-12-19 23:26:23,854 INFO Predicting labels for 444 texts
2022-12-19 23:26:23,961 INFO Training Rule Attention Network
2022-12-19 23:26:23,968 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:26:23,969 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:26:23,975 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:26:23,976 INFO 

		*** Training RAN ***
2022-12-19 23:26:26,931 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:26,932 INFO Predicting labels for 444 texts
2022-12-19 23:26:27,042 INFO There are 3/7 active rules
2022-12-19 23:26:27,042 INFO Coverage: 100.0% (444/444)
2022-12-19 23:26:27,046 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:26:27,145 INFO DONE, Getting attention scores...
2022-12-19 23:26:27,202 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:27,202 INFO Predicting labels for 32 texts
2022-12-19 23:26:27,303 INFO There are 7/7 active rules
2022-12-19 23:26:27,303 INFO Coverage: 100.0% (32/32)
2022-12-19 23:26:27,304 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:26:27,329 INFO DONE, Getting attention scores...
2022-12-19 23:26:27,389 INFO Evaluating teacher dev iter18 on 32 examples
2022-12-19 23:26:27,394 INFO teacher dev iter18 performance: 81.25
2022-12-19 23:26:27,394 INFO teacher dev iter18 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:26:27,394 INFO teacher dev iter18 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:26:27,394 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:26:27,395 INFO Predicting labels for 19 texts
2022-12-19 23:26:27,500 INFO There are 7/7 active rules
2022-12-19 23:26:27,500 INFO Coverage: 100.0% (19/19)
2022-12-19 23:26:27,501 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:26:27,525 INFO DONE, Getting attention scores...
2022-12-19 23:26:27,579 INFO Evaluating teacher test iter18 on 19 examples
2022-12-19 23:26:27,583 INFO teacher test iter18 performance: 89.47
2022-12-19 23:26:27,584 INFO teacher test iter18 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:26:27,584 INFO teacher test iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:26:27,584 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:26:27,587 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:26:27,589 INFO Balancing Pseudo Dataset to keep 496 items...
2022-12-19 23:26:27,593 INFO PSEUDO-DATASET:
496 examples
PSEUDO-LABELS:
1    248
0    248
Name: label, dtype: int64
2022-12-19 23:26:27,593 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:26:29,366 INFO fine-tuning the student on clean labeled data
2022-12-19 23:26:31,403 INFO Predicting labels for 32 texts
2022-12-19 23:26:31,512 INFO Evaluating student dev iter18 on 32 examples
2022-12-19 23:26:31,517 INFO student dev iter18 performance: 78.12
2022-12-19 23:26:31,518 INFO student dev iter18 confusion matrix:
[[23  7]
 [ 0  2]]
2022-12-19 23:26:31,518 INFO student dev iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.77      0.87        30
           1       0.22      1.00      0.36         2

    accuracy                           0.78        32
   macro avg       0.61      0.88      0.62        32
weighted avg       0.95      0.78      0.84        32

2022-12-19 23:26:31,518 INFO Predicting labels for 19 texts
2022-12-19 23:26:31,624 INFO Evaluating student test iter18 on 19 examples
2022-12-19 23:26:31,629 INFO student test iter18 performance: 84.21
2022-12-19 23:26:31,629 INFO student test iter18 confusion matrix:
[[13  0]
 [ 3  3]]
2022-12-19 23:26:31,629 INFO student test iter18 report:
              precision    recall  f1-score   support

           0       0.81      1.00      0.90        13
           1       1.00      0.50      0.67         6

    accuracy                           0.84        19
   macro avg       0.91      0.75      0.78        19
weighted avg       0.87      0.84      0.82        19

2022-12-19 23:26:31,629 INFO Student Dev performance on iter 18: 78.125
2022-12-19 23:26:31,629 INFO Student Test performance on iter 18: 84.21052631578947
2022-12-19 23:26:31,630 INFO 

	 *** Starting loop 19 ***
2022-12-19 23:26:31,630 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:26:31,630 INFO Downsampling 444 data
2022-12-19 23:26:31,630 INFO Adding Student as extra rule in Teacher
2022-12-19 23:26:31,630 INFO Getting rule predictions
2022-12-19 23:26:31,631 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:26:31,631 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:31,632 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:31,632 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:26:31,633 INFO Predicting labels for 741 texts
2022-12-19 23:26:31,747 INFO Predicting labels for 32 texts
2022-12-19 23:26:31,852 INFO Predicting labels for 444 texts
2022-12-19 23:26:31,965 INFO Training Rule Attention Network
2022-12-19 23:26:31,972 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:26:31,973 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:26:31,978 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:26:31,978 INFO 

		*** Training RAN ***
2022-12-19 23:26:34,972 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:34,973 INFO Predicting labels for 444 texts
2022-12-19 23:26:35,082 INFO There are 3/7 active rules
2022-12-19 23:26:35,082 INFO Coverage: 100.0% (444/444)
2022-12-19 23:26:35,086 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:26:35,173 INFO DONE, Getting attention scores...
2022-12-19 23:26:35,231 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:35,231 INFO Predicting labels for 32 texts
2022-12-19 23:26:35,339 INFO There are 7/7 active rules
2022-12-19 23:26:35,339 INFO Coverage: 100.0% (32/32)
2022-12-19 23:26:35,340 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:26:35,366 INFO DONE, Getting attention scores...
2022-12-19 23:26:35,420 INFO Evaluating teacher dev iter19 on 32 examples
2022-12-19 23:26:35,424 INFO teacher dev iter19 performance: 81.25
2022-12-19 23:26:35,424 INFO teacher dev iter19 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:26:35,424 INFO teacher dev iter19 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:26:35,424 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:26:35,424 INFO Predicting labels for 19 texts
2022-12-19 23:26:36,564 INFO There are 7/7 active rules
2022-12-19 23:26:36,565 INFO Coverage: 100.0% (19/19)
2022-12-19 23:26:36,566 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:26:36,592 INFO DONE, Getting attention scores...
2022-12-19 23:26:36,652 INFO Evaluating teacher test iter19 on 19 examples
2022-12-19 23:26:36,656 INFO teacher test iter19 performance: 89.47
2022-12-19 23:26:36,656 INFO teacher test iter19 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:26:36,657 INFO teacher test iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:26:36,657 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:26:36,659 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:26:36,661 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-19 23:26:36,664 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-19 23:26:36,664 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:26:38,419 INFO fine-tuning the student on clean labeled data
2022-12-19 23:26:40,359 INFO Predicting labels for 32 texts
2022-12-19 23:26:40,475 INFO Evaluating student dev iter19 on 32 examples
2022-12-19 23:26:40,479 INFO student dev iter19 performance: 75.00
2022-12-19 23:26:40,479 INFO student dev iter19 confusion matrix:
[[22  8]
 [ 0  2]]
2022-12-19 23:26:40,479 INFO student dev iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.73      0.85        30
           1       0.20      1.00      0.33         2

    accuracy                           0.75        32
   macro avg       0.60      0.87      0.59        32
weighted avg       0.95      0.75      0.81        32

2022-12-19 23:26:40,479 INFO Predicting labels for 19 texts
2022-12-19 23:26:40,690 INFO Evaluating student test iter19 on 19 examples
2022-12-19 23:26:40,694 INFO student test iter19 performance: 84.21
2022-12-19 23:26:40,695 INFO student test iter19 confusion matrix:
[[13  0]
 [ 3  3]]
2022-12-19 23:26:40,695 INFO student test iter19 report:
              precision    recall  f1-score   support

           0       0.81      1.00      0.90        13
           1       1.00      0.50      0.67         6

    accuracy                           0.84        19
   macro avg       0.91      0.75      0.78        19
weighted avg       0.87      0.84      0.82        19

2022-12-19 23:26:40,695 INFO Student Dev performance on iter 19: 75.0
2022-12-19 23:26:40,695 INFO Student Test performance on iter 19: 84.21052631578947
2022-12-19 23:26:40,695 INFO 

	 *** Starting loop 20 ***
2022-12-19 23:26:40,695 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:26:40,695 INFO Downsampling 444 data
2022-12-19 23:26:40,696 INFO Adding Student as extra rule in Teacher
2022-12-19 23:26:40,696 INFO Getting rule predictions
2022-12-19 23:26:40,696 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:26:40,697 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:40,697 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:40,698 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:26:40,699 INFO Predicting labels for 741 texts
2022-12-19 23:26:40,807 INFO Predicting labels for 32 texts
2022-12-19 23:26:40,914 INFO Predicting labels for 444 texts
2022-12-19 23:26:41,026 INFO Training Rule Attention Network
2022-12-19 23:26:41,034 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:26:41,035 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:26:41,039 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:26:41,039 INFO 

		*** Training RAN ***
2022-12-19 23:26:44,607 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:44,608 INFO Predicting labels for 444 texts
2022-12-19 23:26:45,748 INFO There are 3/7 active rules
2022-12-19 23:26:45,748 INFO Coverage: 100.0% (444/444)
2022-12-19 23:26:45,754 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:26:45,845 INFO DONE, Getting attention scores...
2022-12-19 23:26:45,904 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:45,904 INFO Predicting labels for 32 texts
2022-12-19 23:26:46,015 INFO There are 7/7 active rules
2022-12-19 23:26:46,016 INFO Coverage: 100.0% (32/32)
2022-12-19 23:26:46,017 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:26:46,042 INFO DONE, Getting attention scores...
2022-12-19 23:26:46,100 INFO Evaluating teacher dev iter20 on 32 examples
2022-12-19 23:26:46,106 INFO teacher dev iter20 performance: 81.25
2022-12-19 23:26:46,107 INFO teacher dev iter20 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:26:46,107 INFO teacher dev iter20 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:26:46,107 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:26:46,107 INFO Predicting labels for 19 texts
2022-12-19 23:26:46,215 INFO There are 7/7 active rules
2022-12-19 23:26:46,216 INFO Coverage: 100.0% (19/19)
2022-12-19 23:26:46,216 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:26:46,248 INFO DONE, Getting attention scores...
2022-12-19 23:26:46,305 INFO Evaluating teacher test iter20 on 19 examples
2022-12-19 23:26:46,309 INFO teacher test iter20 performance: 89.47
2022-12-19 23:26:46,310 INFO teacher test iter20 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:26:46,310 INFO teacher test iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:26:46,310 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:26:46,313 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:26:46,314 INFO Balancing Pseudo Dataset to keep 506 items...
2022-12-19 23:26:46,318 INFO PSEUDO-DATASET:
506 examples
PSEUDO-LABELS:
1    253
0    253
Name: label, dtype: int64
2022-12-19 23:26:46,319 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:26:49,460 INFO fine-tuning the student on clean labeled data
2022-12-19 23:26:53,957 INFO Predicting labels for 32 texts
2022-12-19 23:26:55,110 INFO Evaluating student dev iter20 on 32 examples
2022-12-19 23:26:55,115 INFO student dev iter20 performance: 78.12
2022-12-19 23:26:55,115 INFO student dev iter20 confusion matrix:
[[23  7]
 [ 0  2]]
2022-12-19 23:26:55,115 INFO student dev iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.77      0.87        30
           1       0.22      1.00      0.36         2

    accuracy                           0.78        32
   macro avg       0.61      0.88      0.62        32
weighted avg       0.95      0.78      0.84        32

2022-12-19 23:26:55,115 INFO Predicting labels for 19 texts
2022-12-19 23:26:55,235 INFO Evaluating student test iter20 on 19 examples
2022-12-19 23:26:55,239 INFO student test iter20 performance: 84.21
2022-12-19 23:26:55,240 INFO student test iter20 confusion matrix:
[[13  0]
 [ 3  3]]
2022-12-19 23:26:55,240 INFO student test iter20 report:
              precision    recall  f1-score   support

           0       0.81      1.00      0.90        13
           1       1.00      0.50      0.67         6

    accuracy                           0.84        19
   macro avg       0.91      0.75      0.78        19
weighted avg       0.87      0.84      0.82        19

2022-12-19 23:26:55,240 INFO Student Dev performance on iter 20: 78.125
2022-12-19 23:26:55,240 INFO Student Test performance on iter 20: 84.21052631578947
2022-12-19 23:26:55,240 INFO 

	 *** Starting loop 21 ***
2022-12-19 23:26:55,240 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:26:55,240 INFO Downsampling 444 data
2022-12-19 23:26:55,241 INFO Adding Student as extra rule in Teacher
2022-12-19 23:26:55,241 INFO Getting rule predictions
2022-12-19 23:26:55,241 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:26:55,242 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:26:55,242 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:26:55,243 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:26:55,244 INFO Predicting labels for 741 texts
2022-12-19 23:26:56,362 INFO Predicting labels for 32 texts
2022-12-19 23:26:57,517 INFO Predicting labels for 444 texts
2022-12-19 23:26:57,631 INFO Training Rule Attention Network
2022-12-19 23:26:57,639 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:26:57,639 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:26:57,643 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:26:57,644 INFO 

		*** Training RAN ***
2022-12-19 23:27:01,439 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:27:01,440 INFO Predicting labels for 444 texts
2022-12-19 23:27:01,557 INFO There are 3/7 active rules
2022-12-19 23:27:01,557 INFO Coverage: 100.0% (444/444)
2022-12-19 23:27:01,562 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:27:01,658 INFO DONE, Getting attention scores...
2022-12-19 23:27:01,721 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:27:01,721 INFO Predicting labels for 32 texts
2022-12-19 23:27:01,830 INFO There are 7/7 active rules
2022-12-19 23:27:01,830 INFO Coverage: 100.0% (32/32)
2022-12-19 23:27:01,831 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:27:01,858 INFO DONE, Getting attention scores...
2022-12-19 23:27:01,915 INFO Evaluating teacher dev iter21 on 32 examples
2022-12-19 23:27:01,919 INFO teacher dev iter21 performance: 81.25
2022-12-19 23:27:01,920 INFO teacher dev iter21 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:27:01,920 INFO teacher dev iter21 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:27:01,920 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:27:01,920 INFO Predicting labels for 19 texts
2022-12-19 23:27:02,043 INFO There are 7/7 active rules
2022-12-19 23:27:02,043 INFO Coverage: 100.0% (19/19)
2022-12-19 23:27:02,044 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:27:02,076 INFO DONE, Getting attention scores...
2022-12-19 23:27:02,152 INFO Evaluating teacher test iter21 on 19 examples
2022-12-19 23:27:02,157 INFO teacher test iter21 performance: 89.47
2022-12-19 23:27:02,158 INFO teacher test iter21 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:27:02,158 INFO teacher test iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:27:02,158 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:27:02,163 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:27:02,164 INFO Balancing Pseudo Dataset to keep 504 items...
2022-12-19 23:27:02,168 INFO PSEUDO-DATASET:
504 examples
PSEUDO-LABELS:
1    252
0    252
Name: label, dtype: int64
2022-12-19 23:27:02,168 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:27:04,118 INFO fine-tuning the student on clean labeled data
2022-12-19 23:27:06,209 INFO Predicting labels for 32 texts
2022-12-19 23:27:06,334 INFO Evaluating student dev iter21 on 32 examples
2022-12-19 23:27:06,339 INFO student dev iter21 performance: 75.00
2022-12-19 23:27:06,339 INFO student dev iter21 confusion matrix:
[[22  8]
 [ 0  2]]
2022-12-19 23:27:06,339 INFO student dev iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.73      0.85        30
           1       0.20      1.00      0.33         2

    accuracy                           0.75        32
   macro avg       0.60      0.87      0.59        32
weighted avg       0.95      0.75      0.81        32

2022-12-19 23:27:06,339 INFO Predicting labels for 19 texts
2022-12-19 23:27:06,588 INFO Evaluating student test iter21 on 19 examples
2022-12-19 23:27:06,594 INFO student test iter21 performance: 84.21
2022-12-19 23:27:06,595 INFO student test iter21 confusion matrix:
[[13  0]
 [ 3  3]]
2022-12-19 23:27:06,595 INFO student test iter21 report:
              precision    recall  f1-score   support

           0       0.81      1.00      0.90        13
           1       1.00      0.50      0.67         6

    accuracy                           0.84        19
   macro avg       0.91      0.75      0.78        19
weighted avg       0.87      0.84      0.82        19

2022-12-19 23:27:06,595 INFO Student Dev performance on iter 21: 75.0
2022-12-19 23:27:06,595 INFO Student Test performance on iter 21: 84.21052631578947
2022-12-19 23:27:06,595 INFO 

	 *** Starting loop 22 ***
2022-12-19 23:27:06,595 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:27:06,596 INFO Downsampling 444 data
2022-12-19 23:27:06,597 INFO Adding Student as extra rule in Teacher
2022-12-19 23:27:06,597 INFO Getting rule predictions
2022-12-19 23:27:06,597 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:27:06,598 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:27:06,599 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:27:06,599 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:27:06,600 INFO Predicting labels for 741 texts
2022-12-19 23:27:06,764 INFO Predicting labels for 32 texts
2022-12-19 23:27:06,911 INFO Predicting labels for 444 texts
2022-12-19 23:27:07,050 INFO Training Rule Attention Network
2022-12-19 23:27:07,057 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:27:07,058 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:27:07,063 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:27:07,063 INFO 

		*** Training RAN ***
2022-12-19 23:27:10,980 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:27:10,982 INFO Predicting labels for 444 texts
2022-12-19 23:27:12,121 INFO There are 3/7 active rules
2022-12-19 23:27:12,121 INFO Coverage: 100.0% (444/444)
2022-12-19 23:27:12,125 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:27:12,238 INFO DONE, Getting attention scores...
2022-12-19 23:27:12,309 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:27:12,310 INFO Predicting labels for 32 texts
2022-12-19 23:27:12,427 INFO There are 7/7 active rules
2022-12-19 23:27:12,427 INFO Coverage: 100.0% (32/32)
2022-12-19 23:27:12,428 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:27:12,454 INFO DONE, Getting attention scores...
2022-12-19 23:27:12,512 INFO Evaluating teacher dev iter22 on 32 examples
2022-12-19 23:27:12,516 INFO teacher dev iter22 performance: 81.25
2022-12-19 23:27:12,517 INFO teacher dev iter22 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:27:12,517 INFO teacher dev iter22 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:27:12,517 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:27:12,517 INFO Predicting labels for 19 texts
2022-12-19 23:27:12,624 INFO There are 7/7 active rules
2022-12-19 23:27:12,624 INFO Coverage: 100.0% (19/19)
2022-12-19 23:27:12,625 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:27:12,660 INFO DONE, Getting attention scores...
2022-12-19 23:27:12,717 INFO Evaluating teacher test iter22 on 19 examples
2022-12-19 23:27:12,722 INFO teacher test iter22 performance: 89.47
2022-12-19 23:27:12,722 INFO teacher test iter22 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:27:12,722 INFO teacher test iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:27:12,722 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:27:12,726 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:27:12,727 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-19 23:27:12,731 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-19 23:27:12,732 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:27:13,512 INFO fine-tuning the student on clean labeled data
2022-12-19 23:27:15,632 INFO Predicting labels for 32 texts
2022-12-19 23:27:15,748 INFO Evaluating student dev iter22 on 32 examples
2022-12-19 23:27:15,752 INFO student dev iter22 performance: 75.00
2022-12-19 23:27:15,753 INFO student dev iter22 confusion matrix:
[[22  8]
 [ 0  2]]
2022-12-19 23:27:15,753 INFO student dev iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.73      0.85        30
           1       0.20      1.00      0.33         2

    accuracy                           0.75        32
   macro avg       0.60      0.87      0.59        32
weighted avg       0.95      0.75      0.81        32

2022-12-19 23:27:15,753 INFO Predicting labels for 19 texts
2022-12-19 23:27:15,865 INFO Evaluating student test iter22 on 19 examples
2022-12-19 23:27:15,869 INFO student test iter22 performance: 84.21
2022-12-19 23:27:15,869 INFO student test iter22 confusion matrix:
[[13  0]
 [ 3  3]]
2022-12-19 23:27:15,869 INFO student test iter22 report:
              precision    recall  f1-score   support

           0       0.81      1.00      0.90        13
           1       1.00      0.50      0.67         6

    accuracy                           0.84        19
   macro avg       0.91      0.75      0.78        19
weighted avg       0.87      0.84      0.82        19

2022-12-19 23:27:15,869 INFO Student Dev performance on iter 22: 75.0
2022-12-19 23:27:15,869 INFO Student Test performance on iter 22: 84.21052631578947
2022-12-19 23:27:15,869 INFO 

	 *** Starting loop 23 ***
2022-12-19 23:27:15,869 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:27:15,869 INFO Downsampling 444 data
2022-12-19 23:27:15,870 INFO Adding Student as extra rule in Teacher
2022-12-19 23:27:15,870 INFO Getting rule predictions
2022-12-19 23:27:15,870 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:27:15,871 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:27:15,872 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:27:15,872 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:27:15,873 INFO Predicting labels for 741 texts
2022-12-19 23:27:15,985 INFO Predicting labels for 32 texts
2022-12-19 23:27:16,095 INFO Predicting labels for 444 texts
2022-12-19 23:27:16,204 INFO Training Rule Attention Network
2022-12-19 23:27:16,211 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:27:16,212 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:27:16,216 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:27:16,216 INFO 

		*** Training RAN ***
2022-12-19 23:27:19,600 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:27:19,601 INFO Predicting labels for 444 texts
2022-12-19 23:27:19,711 INFO There are 3/7 active rules
2022-12-19 23:27:19,711 INFO Coverage: 100.0% (444/444)
2022-12-19 23:27:19,716 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:27:19,803 INFO DONE, Getting attention scores...
2022-12-19 23:27:19,864 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:27:19,864 INFO Predicting labels for 32 texts
2022-12-19 23:27:21,002 INFO There are 7/7 active rules
2022-12-19 23:27:21,002 INFO Coverage: 100.0% (32/32)
2022-12-19 23:27:21,003 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:27:21,033 INFO DONE, Getting attention scores...
2022-12-19 23:27:21,102 INFO Evaluating teacher dev iter23 on 32 examples
2022-12-19 23:27:21,108 INFO teacher dev iter23 performance: 81.25
2022-12-19 23:27:21,109 INFO teacher dev iter23 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:27:21,109 INFO teacher dev iter23 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:27:21,109 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:27:21,109 INFO Predicting labels for 19 texts
2022-12-19 23:27:22,374 INFO There are 7/7 active rules
2022-12-19 23:27:22,374 INFO Coverage: 100.0% (19/19)
2022-12-19 23:27:22,375 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:27:22,402 INFO DONE, Getting attention scores...
2022-12-19 23:27:22,461 INFO Evaluating teacher test iter23 on 19 examples
2022-12-19 23:27:22,465 INFO teacher test iter23 performance: 89.47
2022-12-19 23:27:22,466 INFO teacher test iter23 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:27:22,466 INFO teacher test iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:27:22,466 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:27:22,468 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:27:22,470 INFO Balancing Pseudo Dataset to keep 502 items...
2022-12-19 23:27:22,474 INFO PSEUDO-DATASET:
502 examples
PSEUDO-LABELS:
1    251
0    251
Name: label, dtype: int64
2022-12-19 23:27:22,474 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:27:24,461 INFO fine-tuning the student on clean labeled data
2022-12-19 23:27:25,518 INFO Predicting labels for 32 texts
2022-12-19 23:27:25,631 INFO Evaluating student dev iter23 on 32 examples
2022-12-19 23:27:25,635 INFO student dev iter23 performance: 71.88
2022-12-19 23:27:25,636 INFO student dev iter23 confusion matrix:
[[21  9]
 [ 0  2]]
2022-12-19 23:27:25,636 INFO student dev iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.70      0.82        30
           1       0.18      1.00      0.31         2

    accuracy                           0.72        32
   macro avg       0.59      0.85      0.57        32
weighted avg       0.95      0.72      0.79        32

2022-12-19 23:27:25,636 INFO Predicting labels for 19 texts
2022-12-19 23:27:25,743 INFO Evaluating student test iter23 on 19 examples
2022-12-19 23:27:25,747 INFO student test iter23 performance: 78.95
2022-12-19 23:27:25,747 INFO student test iter23 confusion matrix:
[[12  1]
 [ 3  3]]
2022-12-19 23:27:25,747 INFO student test iter23 report:
              precision    recall  f1-score   support

           0       0.80      0.92      0.86        13
           1       0.75      0.50      0.60         6

    accuracy                           0.79        19
   macro avg       0.78      0.71      0.73        19
weighted avg       0.78      0.79      0.78        19

2022-12-19 23:27:25,748 INFO Student Dev performance on iter 23: 71.875
2022-12-19 23:27:25,748 INFO Student Test performance on iter 23: 78.94736842105263
2022-12-19 23:27:25,748 INFO 

	 *** Starting loop 24 ***
2022-12-19 23:27:25,748 INFO [WARNING] sample size = 16384 > 444
2022-12-19 23:27:25,748 INFO Downsampling 444 data
2022-12-19 23:27:25,749 INFO Adding Student as extra rule in Teacher
2022-12-19 23:27:25,749 INFO Getting rule predictions
2022-12-19 23:27:25,749 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-19 23:27:25,750 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:27:25,750 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:27:25,751 INFO Getting student predictions on train (and dev) dataset
2022-12-19 23:27:25,752 INFO Predicting labels for 741 texts
2022-12-19 23:27:25,865 INFO Predicting labels for 32 texts
2022-12-19 23:27:25,972 INFO Predicting labels for 444 texts
2022-12-19 23:27:27,108 INFO Training Rule Attention Network
2022-12-19 23:27:27,120 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-19 23:27:27,121 INFO X Dev Shape (32, 7) (32, 8, 2) (32,)
2022-12-19 23:27:27,126 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-19 23:27:27,126 INFO 

		*** Training RAN ***
2022-12-19 23:27:30,457 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-19 23:27:30,458 INFO Predicting labels for 444 texts
2022-12-19 23:27:30,577 INFO There are 3/7 active rules
2022-12-19 23:27:30,577 INFO Coverage: 100.0% (444/444)
2022-12-19 23:27:30,585 INFO RAN - Predicting labels for 444 texts
2022-12-19 23:27:30,672 INFO DONE, Getting attention scores...
2022-12-19 23:27:30,729 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-19 23:27:30,730 INFO Predicting labels for 32 texts
2022-12-19 23:27:30,847 INFO There are 7/7 active rules
2022-12-19 23:27:30,847 INFO Coverage: 100.0% (32/32)
2022-12-19 23:27:30,848 INFO RAN - Predicting labels for 32 texts
2022-12-19 23:27:30,883 INFO DONE, Getting attention scores...
2022-12-19 23:27:30,950 INFO Evaluating teacher dev iter24 on 32 examples
2022-12-19 23:27:30,955 INFO teacher dev iter24 performance: 81.25
2022-12-19 23:27:30,955 INFO teacher dev iter24 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-19 23:27:30,955 INFO teacher dev iter24 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-19 23:27:30,955 INFO Applying Teacher with 7 LF(s) on 19 data
2022-12-19 23:27:30,956 INFO Predicting labels for 19 texts
2022-12-19 23:27:32,100 INFO There are 7/7 active rules
2022-12-19 23:27:32,100 INFO Coverage: 100.0% (19/19)
2022-12-19 23:27:32,100 INFO RAN - Predicting labels for 19 texts
2022-12-19 23:27:32,161 INFO DONE, Getting attention scores...
2022-12-19 23:27:32,235 INFO Evaluating teacher test iter24 on 19 examples
2022-12-19 23:27:32,239 INFO teacher test iter24 performance: 89.47
2022-12-19 23:27:32,240 INFO teacher test iter24 confusion matrix:
[[11  2]
 [ 0  6]]
2022-12-19 23:27:32,240 INFO teacher test iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.85      0.92        13
           1       0.75      1.00      0.86         6

    accuracy                           0.89        19
   macro avg       0.88      0.92      0.89        19
weighted avg       0.92      0.89      0.90        19

2022-12-19 23:27:32,240 INFO Saving attention scores at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_dump
2022-12-19 23:27:32,244 INFO Creating Pseudo Dataset with 444 items...
2022-12-19 23:27:32,246 INFO Balancing Pseudo Dataset to keep 516 items...
2022-12-19 23:27:32,251 INFO PSEUDO-DATASET:
516 examples
PSEUDO-LABELS:
1    258
0    258
Name: label, dtype: int64
2022-12-19 23:27:32,252 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-19 23:27:34,164 INFO fine-tuning the student on clean labeled data
2022-12-19 23:27:37,493 INFO Predicting labels for 32 texts
2022-12-19 23:27:37,609 INFO Evaluating student dev iter24 on 32 examples
2022-12-19 23:27:37,613 INFO student dev iter24 performance: 68.75
2022-12-19 23:27:37,614 INFO student dev iter24 confusion matrix:
[[20 10]
 [ 0  2]]
2022-12-19 23:27:37,614 INFO student dev iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80        30
           1       0.17      1.00      0.29         2

    accuracy                           0.69        32
   macro avg       0.58      0.83      0.54        32
weighted avg       0.95      0.69      0.77        32

2022-12-19 23:27:37,614 INFO Predicting labels for 19 texts
2022-12-19 23:27:37,747 INFO Evaluating student test iter24 on 19 examples
2022-12-19 23:27:37,751 INFO student test iter24 performance: 78.95
2022-12-19 23:27:37,751 INFO student test iter24 confusion matrix:
[[12  1]
 [ 3  3]]
2022-12-19 23:27:37,751 INFO student test iter24 report:
              precision    recall  f1-score   support

           0       0.80      0.92      0.86        13
           1       0.75      0.50      0.60         6

    accuracy                           0.79        19
   macro avg       0.78      0.71      0.73        19
weighted avg       0.78      0.79      0.78        19

2022-12-19 23:27:37,751 INFO Student Dev performance on iter 24: 68.75
2022-12-19 23:27:37,751 INFO Student Test performance on iter 24: 78.94736842105263
2022-12-19 23:27:37,751 INFO Final Results
2022-12-19 23:27:37,752 INFO TEACHER PERFORMANCES:
0:	81.25	89.47
1:	81.25	89.47
2:	81.25	89.47
3:	78.12	89.47
4:	81.25	89.47
5:	81.25	89.47
6:	81.25	89.47
7:	81.25	89.47
8:	81.25	89.47
9:	81.25	89.47
10:	81.25	89.47
11:	81.25	89.47
12:	81.25	89.47
13:	81.25	89.47
14:	81.25	89.47
15:	81.25	89.47
16:	81.25	89.47
17:	81.25	89.47
18:	81.25	89.47
19:	81.25	89.47
20:	81.25	89.47
21:	81.25	89.47
22:	81.25	89.47
23:	81.25	89.47
24:	81.25	89.47
25:	81.25	89.47
2022-12-19 23:27:37,752 INFO STUDENT PERFORMANCES:
0:	87.50	63.16
1:	87.50	68.42
2:	87.50	73.68
3:	90.62	73.68
4:	87.50	73.68
5:	87.50	73.68
6:	87.50	73.68
7:	90.62	73.68
8:	90.62	73.68
9:	90.62	73.68
10:	90.62	73.68
11:	90.62	73.68
12:	81.25	73.68
13:	81.25	73.68
14:	81.25	78.95
15:	84.38	78.95
16:	84.38	78.95
17:	81.25	78.95
18:	78.12	84.21
19:	78.12	84.21
20:	75.00	84.21
21:	78.12	84.21
22:	75.00	84.21
23:	75.00	84.21
24:	71.88	78.95
25:	68.75	78.95
2022-12-19 23:27:37,752 INFO BEST DEV weighted_acc = 90.625 for epoch 11
2022-12-19 23:27:37,752 INFO FINAL TEST weighted_acc = 73.684 for epoch 11 (max=84.21 for epoch 23)
2022-12-19 23:27:37,752 INFO Saving student_last to ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/student_last
2022-12-19 23:27:37,753 INFO Saving model at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/student_last/final_model.h5
2022-12-19 23:27:37,763 INFO Saving teacher at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_last
2022-12-19 23:27:37,763 INFO Saving rule attention network at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/teacher_last/rule_attention_network.h5
2022-12-19 23:27:37,773 INFO 	*** Final Results ***
2022-12-19 23:27:37,773 INFO 
student_train:	{'dev_loss': 0.08666592836380005}
2022-12-19 23:27:37,773 INFO 
supervised_student_dev:	{'acc': 87.5, 'weighted_acc': 87.5, 'prec': 46.666666666666664, 'rec': 46.666666666666664, 'f1': 46.666666666666664, 'weighted_f1': 46.666666666666664, 'ignored': 0, 'total': 32, 'perf': 87.5}
2022-12-19 23:27:37,773 INFO 
supervised_student_test:	{'acc': 63.1578947368421, 'weighted_acc': 63.1578947368421, 'prec': 55.714285714285715, 'rec': 55.12820512820513, 'f1': 55.218855218855225, 'weighted_f1': 55.218855218855225, 'ignored': 0, 'total': 19, 'perf': 63.1578947368421}
2022-12-19 23:27:37,773 INFO 
teacher_train:	{'acc': 88.66396761133603, 'weighted_acc': 88.66396761133603, 'prec': 88.67823765020026, 'rec': 88.38102808691045, 'f1': 88.5055178832602, 'weighted_f1': 88.5055178832602, 'ignored': 0, 'total': 741, 'perf': 88.66396761133603}
2022-12-19 23:27:37,773 INFO 
teacher_dev:	{'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}
2022-12-19 23:27:37,773 INFO 
teacher_test:	{'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}
2022-12-19 23:27:37,773 INFO 
teacher_train_iter:	[{'acc': 88.66396761133603, 'weighted_acc': 88.66396761133603, 'prec': 88.67823765020026, 'rec': 88.38102808691045, 'f1': 88.5055178832602, 'weighted_f1': 88.5055178832602, 'ignored': 0, 'total': 741, 'perf': 88.66396761133603}]
2022-12-19 23:27:37,773 INFO 
teacher_dev_iter:	[{'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}]
2022-12-19 23:27:37,774 INFO 
teacher_test_iter:	[{'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}, {'acc': 89.47368421052632, 'weighted_acc': 89.47368421052632, 'prec': 87.5, 'rec': 92.3076923076923, 'f1': 88.69047619047619, 'weighted_f1': 88.69047619047619, 'ignored': 0, 'total': 19, 'perf': 89.47368421052632}]
2022-12-19 23:27:37,775 INFO 
student_train_iter:	[{'dev_loss': 0.08666592836380005}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]
2022-12-19 23:27:37,775 INFO 
student_dev_iter:	[{'acc': 87.5, 'weighted_acc': 87.5, 'prec': 46.666666666666664, 'rec': 46.666666666666664, 'f1': 46.666666666666664, 'weighted_f1': 46.666666666666664, 'ignored': 0, 'total': 32, 'perf': 87.5}, {'acc': 87.5, 'weighted_acc': 87.5, 'prec': 46.666666666666664, 'rec': 46.666666666666664, 'f1': 46.666666666666664, 'weighted_f1': 46.666666666666664, 'ignored': 0, 'total': 32, 'perf': 87.5}, {'acc': 87.5, 'weighted_acc': 87.5, 'prec': 46.666666666666664, 'rec': 46.666666666666664, 'f1': 46.666666666666664, 'weighted_f1': 46.666666666666664, 'ignored': 0, 'total': 32, 'perf': 87.5}, {'acc': 90.625, 'weighted_acc': 90.625, 'prec': 46.774193548387096, 'rec': 48.333333333333336, 'f1': 47.54098360655738, 'weighted_f1': 47.54098360655738, 'ignored': 0, 'total': 32, 'perf': 90.625}, {'acc': 87.5, 'weighted_acc': 87.5, 'prec': 46.666666666666664, 'rec': 46.666666666666664, 'f1': 46.666666666666664, 'weighted_f1': 46.666666666666664, 'ignored': 0, 'total': 32, 'perf': 87.5}, {'acc': 87.5, 'weighted_acc': 87.5, 'prec': 46.666666666666664, 'rec': 46.666666666666664, 'f1': 46.666666666666664, 'weighted_f1': 46.666666666666664, 'ignored': 0, 'total': 32, 'perf': 87.5}, {'acc': 87.5, 'weighted_acc': 87.5, 'prec': 46.666666666666664, 'rec': 46.666666666666664, 'f1': 46.666666666666664, 'weighted_f1': 46.666666666666664, 'ignored': 0, 'total': 32, 'perf': 87.5}, {'acc': 90.625, 'weighted_acc': 90.625, 'prec': 46.774193548387096, 'rec': 48.333333333333336, 'f1': 47.54098360655738, 'weighted_f1': 47.54098360655738, 'ignored': 0, 'total': 32, 'perf': 90.625}, {'acc': 90.625, 'weighted_acc': 90.625, 'prec': 46.774193548387096, 'rec': 48.333333333333336, 'f1': 47.54098360655738, 'weighted_f1': 47.54098360655738, 'ignored': 0, 'total': 32, 'perf': 90.625}, {'acc': 90.625, 'weighted_acc': 90.625, 'prec': 46.774193548387096, 'rec': 48.333333333333336, 'f1': 47.54098360655738, 'weighted_f1': 47.54098360655738, 'ignored': 0, 'total': 32, 'perf': 90.625}, {'acc': 90.625, 'weighted_acc': 90.625, 'prec': 46.774193548387096, 'rec': 48.333333333333336, 'f1': 47.54098360655738, 'weighted_f1': 47.54098360655738, 'ignored': 0, 'total': 32, 'perf': 90.625}, {'acc': 90.625, 'weighted_acc': 90.625, 'prec': 64.9425287356322, 'rec': 71.66666666666667, 'f1': 67.45762711864407, 'weighted_f1': 67.45762711864407, 'ignored': 0, 'total': 32, 'perf': 90.625}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 46.42857142857143, 'rec': 43.333333333333336, 'f1': 44.827586206896555, 'weighted_f1': 44.827586206896555, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 46.42857142857143, 'rec': 43.333333333333336, 'f1': 44.827586206896555, 'weighted_f1': 44.827586206896555, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 46.42857142857143, 'rec': 43.333333333333336, 'f1': 44.827586206896555, 'weighted_f1': 44.827586206896555, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 84.375, 'weighted_acc': 84.375, 'prec': 58.14814814814815, 'rec': 68.33333333333333, 'f1': 59.899749373433586, 'weighted_f1': 59.899749373433586, 'ignored': 0, 'total': 32, 'perf': 84.375}, {'acc': 84.375, 'weighted_acc': 84.375, 'prec': 64.28571428571428, 'rec': 91.66666666666667, 'f1': 67.67676767676768, 'weighted_f1': 67.67676767676768, 'ignored': 0, 'total': 32, 'perf': 84.375}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 62.5, 'rec': 90.0, 'f1': 64.44444444444444, 'weighted_f1': 64.44444444444444, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 61.111111111111114, 'rec': 88.33333333333333, 'f1': 61.57804459691253, 'weighted_f1': 61.57804459691253, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 61.111111111111114, 'rec': 88.33333333333333, 'f1': 61.57804459691253, 'weighted_f1': 61.57804459691253, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 75.0, 'weighted_acc': 75.0, 'prec': 60.0, 'rec': 86.66666666666667, 'f1': 58.974358974358964, 'weighted_f1': 58.974358974358964, 'ignored': 0, 'total': 32, 'perf': 75.0}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 61.111111111111114, 'rec': 88.33333333333333, 'f1': 61.57804459691253, 'weighted_f1': 61.57804459691253, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 75.0, 'weighted_acc': 75.0, 'prec': 60.0, 'rec': 86.66666666666667, 'f1': 58.974358974358964, 'weighted_f1': 58.974358974358964, 'ignored': 0, 'total': 32, 'perf': 75.0}, {'acc': 75.0, 'weighted_acc': 75.0, 'prec': 60.0, 'rec': 86.66666666666667, 'f1': 58.974358974358964, 'weighted_f1': 58.974358974358964, 'ignored': 0, 'total': 32, 'perf': 75.0}, {'acc': 71.875, 'weighted_acc': 71.875, 'prec': 59.09090909090909, 'rec': 85.0, 'f1': 56.56108597285068, 'weighted_f1': 56.56108597285068, 'ignored': 0, 'total': 32, 'perf': 71.875}, {'acc': 68.75, 'weighted_acc': 68.75, 'prec': 58.333333333333336, 'rec': 83.33333333333333, 'f1': 54.28571428571429, 'weighted_f1': 54.28571428571429, 'ignored': 0, 'total': 32, 'perf': 68.75}]
2022-12-19 23:27:37,775 INFO 
student_test_iter:	[{'acc': 63.1578947368421, 'weighted_acc': 63.1578947368421, 'prec': 55.714285714285715, 'rec': 55.12820512820513, 'f1': 55.218855218855225, 'weighted_f1': 55.218855218855225, 'ignored': 0, 'total': 19, 'perf': 63.1578947368421}, {'acc': 68.42105263157895, 'weighted_acc': 68.42105263157895, 'prec': 61.66666666666667, 'rec': 58.97435897435898, 'f1': 59.28571428571428, 'weighted_f1': 59.28571428571428, 'ignored': 0, 'total': 19, 'perf': 68.42105263157895}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}, {'acc': 78.94736842105263, 'weighted_acc': 78.94736842105263, 'prec': 88.23529411764706, 'rec': 66.66666666666666, 'f1': 68.33333333333333, 'weighted_f1': 68.33333333333333, 'ignored': 0, 'total': 19, 'perf': 78.94736842105263}, {'acc': 78.94736842105263, 'weighted_acc': 78.94736842105263, 'prec': 88.23529411764706, 'rec': 66.66666666666666, 'f1': 68.33333333333333, 'weighted_f1': 68.33333333333333, 'ignored': 0, 'total': 19, 'perf': 78.94736842105263}, {'acc': 78.94736842105263, 'weighted_acc': 78.94736842105263, 'prec': 88.23529411764706, 'rec': 66.66666666666666, 'f1': 68.33333333333333, 'weighted_f1': 68.33333333333333, 'ignored': 0, 'total': 19, 'perf': 78.94736842105263}, {'acc': 78.94736842105263, 'weighted_acc': 78.94736842105263, 'prec': 88.23529411764706, 'rec': 66.66666666666666, 'f1': 68.33333333333333, 'weighted_f1': 68.33333333333333, 'ignored': 0, 'total': 19, 'perf': 78.94736842105263}, {'acc': 84.21052631578947, 'weighted_acc': 84.21052631578947, 'prec': 90.625, 'rec': 75.0, 'f1': 78.16091954022988, 'weighted_f1': 78.16091954022988, 'ignored': 0, 'total': 19, 'perf': 84.21052631578947}, {'acc': 84.21052631578947, 'weighted_acc': 84.21052631578947, 'prec': 90.625, 'rec': 75.0, 'f1': 78.16091954022988, 'weighted_f1': 78.16091954022988, 'ignored': 0, 'total': 19, 'perf': 84.21052631578947}, {'acc': 84.21052631578947, 'weighted_acc': 84.21052631578947, 'prec': 90.625, 'rec': 75.0, 'f1': 78.16091954022988, 'weighted_f1': 78.16091954022988, 'ignored': 0, 'total': 19, 'perf': 84.21052631578947}, {'acc': 84.21052631578947, 'weighted_acc': 84.21052631578947, 'prec': 90.625, 'rec': 75.0, 'f1': 78.16091954022988, 'weighted_f1': 78.16091954022988, 'ignored': 0, 'total': 19, 'perf': 84.21052631578947}, {'acc': 84.21052631578947, 'weighted_acc': 84.21052631578947, 'prec': 90.625, 'rec': 75.0, 'f1': 78.16091954022988, 'weighted_f1': 78.16091954022988, 'ignored': 0, 'total': 19, 'perf': 84.21052631578947}, {'acc': 84.21052631578947, 'weighted_acc': 84.21052631578947, 'prec': 90.625, 'rec': 75.0, 'f1': 78.16091954022988, 'weighted_f1': 78.16091954022988, 'ignored': 0, 'total': 19, 'perf': 84.21052631578947}, {'acc': 78.94736842105263, 'weighted_acc': 78.94736842105263, 'prec': 77.5, 'rec': 71.15384615384616, 'f1': 72.85714285714285, 'weighted_f1': 72.85714285714285, 'ignored': 0, 'total': 19, 'perf': 78.94736842105263}, {'acc': 78.94736842105263, 'weighted_acc': 78.94736842105263, 'prec': 77.5, 'rec': 71.15384615384616, 'f1': 72.85714285714285, 'weighted_f1': 72.85714285714285, 'ignored': 0, 'total': 19, 'perf': 78.94736842105263}]
2022-12-19 23:27:37,776 INFO 
student_dev:	{'acc': 90.625, 'weighted_acc': 90.625, 'prec': 64.9425287356322, 'rec': 71.66666666666667, 'f1': 67.45762711864407, 'weighted_f1': 67.45762711864407, 'ignored': 0, 'total': 32, 'perf': 90.625}
2022-12-19 23:27:37,776 INFO 
student_test:	{'acc': 73.68421052631578, 'weighted_acc': 73.68421052631578, 'prec': 70.83333333333333, 'rec': 62.82051282051282, 'f1': 63.601532567049816, 'weighted_f1': 63.601532567049816, 'ignored': 0, 'total': 19, 'perf': 73.68421052631578}
2022-12-19 23:27:37,776 INFO Saving results at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/results.pkl
2022-12-19 23:27:37,798 INFO Dataset: econ_mean
2022-12-19 23:27:37,798 INFO Weak Sources: ['econ_meanrules']
2022-12-19 23:27:37,799 INFO Model: bert

2022-12-19 23:27:37,799 INFO Teacher Train weighted_acc: 88.7
2022-12-19 23:27:37,799 INFO Teacher Dev weighted_acc: 81.2
2022-12-19 23:27:37,799 INFO Teacher Test weighted_acc: 89.5

2022-12-19 23:27:37,799 INFO Student Dev weighted_acc: 90.6
2022-12-19 23:27:37,799 INFO Student Test weighted_acc: 73.7
2022-12-19 23:27:37,799 INFO Saved report at ../experiments/econ_mean/Dec19_23-14_ECON_experiments/seed0/2022_12_19-23_23_stBERT/results.txt
