2022-12-18 23:45:58,142 INFO 

		 *** NEW EXPERIMENT ***
args=Namespace(adam_epsilon=1e-08, convert_abstain_to_random=False, datapath='../data', dataset='econ_mean', debug=False, device=device(type='cuda'), downsample=1.0, eval_batch_size=16, experiment_folder='../experiments/econ_mean', finetuning_rate=0.0001, fp16=False, hard_student_rule=False, learning_rate=0.0001, logdir='../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT', logging_steps=500, loss_weights=False, lower_case=False, max_grad_norm=1.0, max_rule_seq_length=10, max_seq_length=64, max_size=1000, metric='weighted_acc', n_gpu=1, no_cuda=False, num_epochs=15, num_iter=25, num_labels=2, num_supervised_trials=5, num_unsup_epochs=25, oversample=3, overwrite=False, sample_size=16384, seed=0, soft_labels=False, student_name='bert', teacher_name='ran', tokenizer_method='clean', train_batch_size=16, unsup_batch_size=128, warmup_steps=0, weak_sources=None, weight_decay=0.0)
2022-12-18 23:45:58,142 INFO building student: bert
2022-12-18 23:45:58,142 INFO building teacher
2022-12-18 23:45:58,142 INFO No weak sources specified for Teacher. Using default: ['econ_meanrules']
2022-12-18 23:45:58,142 INFO loading data
2022-12-18 23:45:58,145 INFO Pre-processing train data for student...
2022-12-18 23:45:58,149 INFO train DATASET: 247 examples
2022-12-18 23:45:58,151 INFO train LABELS:
1    136
0    111
Name: label, dtype: int64
2022-12-18 23:45:58,152 INFO Oversampling train data 3 times
2022-12-18 23:45:58,155 INFO train DATASET: 741 examples
2022-12-18 23:45:58,156 INFO train LABELS:
1    408
0    333
Name: label, dtype: int64
2022-12-18 23:45:58,157 INFO Pre-processing dev data for student...
2022-12-18 23:45:58,159 INFO dev DATASET: 18 examples
2022-12-18 23:45:58,160 INFO dev LABELS:
0    12
1     6
Name: label, dtype: int64
2022-12-18 23:45:58,161 INFO Pre-processing test data for student...
2022-12-18 23:45:58,164 INFO test DATASET: 32 examples
2022-12-18 23:45:58,165 INFO test LABELS:
0    30
1     2
Name: label, dtype: int64
2022-12-18 23:45:58,166 INFO Pre-processing unlabeled data for student...
2022-12-18 23:45:58,169 INFO unlabeled DATASET: 444 examples
2022-12-18 23:45:58,170 INFO unlabeled LABELS:
Series([], Name: label, dtype: int64)
2022-12-18 23:45:58,170 INFO creating pseudo-dataset
2022-12-18 23:45:58,171 INFO copying data from unlabeled dataset
2022-12-18 23:45:58,180 INFO done
2022-12-18 23:45:58,180 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:45:58,180 INFO Downsampling 444 data
2022-12-18 23:45:58,180 INFO copying data from train dataset
2022-12-18 23:45:58,190 INFO done
2022-12-18 23:45:58,191 INFO Balancing Pseudo Dataset to keep 816 items...
2022-12-18 23:45:58,194 INFO PSEUDO-DATASET:
816 examples
PSEUDO-LABELS:
1    408
0    408
Name: label, dtype: int64
2022-12-18 23:45:58,195 INFO Class labels: 2
2022-12-18 23:45:58,196 INFO X Train Shape (816, 7) (816,)
2022-12-18 23:45:58,196 INFO X Dev Shape (18, 7) (18,)
2022-12-18 23:46:10,741 INFO Saving supervised_student to ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/supervised_student
2022-12-18 23:46:10,741 INFO Saving model at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/supervised_student/final_model.h5
2022-12-18 23:46:10,748 INFO 

	*** Evaluating on dev data ***
2022-12-18 23:46:10,748 INFO Predicting labels for 18 texts
2022-12-18 23:46:10,852 INFO Evaluating student dev on 18 examples
2022-12-18 23:46:10,856 INFO student dev performance: 77.78
2022-12-18 23:46:10,857 INFO student dev confusion matrix:
[[11  1]
 [ 3  3]]
2022-12-18 23:46:10,857 INFO student dev report:
              precision    recall  f1-score   support

           0       0.79      0.92      0.85        12
           1       0.75      0.50      0.60         6

    accuracy                           0.78        18
   macro avg       0.77      0.71      0.72        18
weighted avg       0.77      0.78      0.76        18

2022-12-18 23:46:10,857 INFO 

	*** Evaluating on test data ***
2022-12-18 23:46:10,857 INFO Predicting labels for 32 texts
2022-12-18 23:46:10,959 INFO Evaluating student test on 32 examples
2022-12-18 23:46:10,963 INFO student test performance: 71.88
2022-12-18 23:46:10,963 INFO student test confusion matrix:
[[22  8]
 [ 1  1]]
2022-12-18 23:46:10,963 INFO student test report:
              precision    recall  f1-score   support

           0       0.96      0.73      0.83        30
           1       0.11      0.50      0.18         2

    accuracy                           0.72        32
   macro avg       0.53      0.62      0.51        32
weighted avg       0.90      0.72      0.79        32

2022-12-18 23:46:10,963 INFO initializing teacher on unlabeled data with majority voting
2022-12-18 23:46:10,963 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:10,964 INFO There are 3/7 active rules
2022-12-18 23:46:10,964 INFO Coverage: 100.0% (444/444)
2022-12-18 23:46:10,975 INFO evaluating majority voting
2022-12-18 23:46:10,975 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:46:10,976 INFO There are 7/7 active rules
2022-12-18 23:46:10,976 INFO Coverage: 100.0% (741/741)
2022-12-18 23:46:10,996 INFO Evaluating teacher train on 741 examples
2022-12-18 23:46:11,005 INFO teacher train performance: 88.66
2022-12-18 23:46:11,005 INFO teacher train confusion matrix:
[[285  48]
 [ 36 372]]
2022-12-18 23:46:11,005 INFO teacher train report:
              precision    recall  f1-score   support

           0       0.89      0.86      0.87       333
           1       0.89      0.91      0.90       408

    accuracy                           0.89       741
   macro avg       0.89      0.88      0.89       741
weighted avg       0.89      0.89      0.89       741

2022-12-18 23:46:11,006 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:11,006 INFO There are 7/7 active rules
2022-12-18 23:46:11,006 INFO Coverage: 100.0% (18/18)
2022-12-18 23:46:11,006 INFO Evaluating teacher dev on 18 examples
2022-12-18 23:46:11,010 INFO teacher dev performance: 94.44
2022-12-18 23:46:11,011 INFO teacher dev confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:46:11,011 INFO teacher dev report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:46:11,011 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:46:11,011 INFO There are 7/7 active rules
2022-12-18 23:46:11,011 INFO Coverage: 100.0% (32/32)
2022-12-18 23:46:11,012 INFO Evaluating teacher test on 32 examples
2022-12-18 23:46:11,017 INFO teacher test performance: 81.25
2022-12-18 23:46:11,018 INFO teacher test confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-18 23:46:11,018 INFO teacher test report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-18 23:46:11,018 INFO 

	 *** Starting loop 0 ***
2022-12-18 23:46:11,018 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:46:11,018 INFO Downsampling 444 data
2022-12-18 23:46:11,018 INFO Adding Student as extra rule in Teacher
2022-12-18 23:46:11,018 INFO Getting rule predictions
2022-12-18 23:46:11,019 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:46:11,019 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:11,020 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:11,020 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:46:11,021 INFO Predicting labels for 741 texts
2022-12-18 23:46:11,125 INFO Predicting labels for 18 texts
2022-12-18 23:46:11,225 INFO Predicting labels for 444 texts
2022-12-18 23:46:11,328 INFO Training Rule Attention Network
2022-12-18 23:46:11,336 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:46:11,337 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:46:11,340 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:46:11,412 INFO 

		*** Training RAN ***
2022-12-18 23:46:14,230 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:14,231 INFO Predicting labels for 444 texts
2022-12-18 23:46:14,334 INFO There are 3/7 active rules
2022-12-18 23:46:14,334 INFO Coverage: 100.0% (444/444)
2022-12-18 23:46:14,338 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:46:14,422 INFO DONE, Getting attention scores...
2022-12-18 23:46:14,478 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:14,478 INFO Predicting labels for 18 texts
2022-12-18 23:46:14,582 INFO There are 7/7 active rules
2022-12-18 23:46:14,582 INFO Coverage: 100.0% (18/18)
2022-12-18 23:46:14,583 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:46:14,607 INFO DONE, Getting attention scores...
2022-12-18 23:46:14,658 INFO Evaluating teacher dev iter0 on 18 examples
2022-12-18 23:46:14,662 INFO teacher dev iter0 performance: 94.44
2022-12-18 23:46:14,662 INFO teacher dev iter0 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:46:14,662 INFO teacher dev iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:46:14,662 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:46:14,663 INFO Predicting labels for 32 texts
2022-12-18 23:46:14,762 INFO There are 7/7 active rules
2022-12-18 23:46:14,762 INFO Coverage: 100.0% (32/32)
2022-12-18 23:46:14,763 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:46:14,792 INFO DONE, Getting attention scores...
2022-12-18 23:46:14,844 INFO Evaluating teacher test iter0 on 32 examples
2022-12-18 23:46:14,848 INFO teacher test iter0 performance: 81.25
2022-12-18 23:46:14,849 INFO teacher test iter0 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-18 23:46:14,849 INFO teacher test iter0 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-18 23:46:14,849 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:46:14,853 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:46:14,854 INFO Balancing Pseudo Dataset to keep 520 items...
2022-12-18 23:46:14,858 INFO PSEUDO-DATASET:
520 examples
PSEUDO-LABELS:
1    260
0    260
Name: label, dtype: int64
2022-12-18 23:46:14,858 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:46:17,284 INFO fine-tuning the student on clean labeled data
2022-12-18 23:46:21,758 INFO Predicting labels for 18 texts
2022-12-18 23:46:21,860 INFO Evaluating student dev iter0 on 18 examples
2022-12-18 23:46:21,864 INFO student dev iter0 performance: 77.78
2022-12-18 23:46:21,864 INFO student dev iter0 confusion matrix:
[[8 4]
 [0 6]]
2022-12-18 23:46:21,864 INFO student dev iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.67      0.80        12
           1       0.60      1.00      0.75         6

    accuracy                           0.78        18
   macro avg       0.80      0.83      0.77        18
weighted avg       0.87      0.78      0.78        18

2022-12-18 23:46:21,865 INFO Predicting labels for 32 texts
2022-12-18 23:46:21,969 INFO Evaluating student test iter0 on 32 examples
2022-12-18 23:46:21,973 INFO student test iter0 performance: 56.25
2022-12-18 23:46:21,973 INFO student test iter0 confusion matrix:
[[16 14]
 [ 0  2]]
2022-12-18 23:46:21,973 INFO student test iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.53      0.70        30
           1       0.12      1.00      0.22         2

    accuracy                           0.56        32
   macro avg       0.56      0.77      0.46        32
weighted avg       0.95      0.56      0.67        32

2022-12-18 23:46:21,973 INFO Student Dev performance on iter 0: 77.77777777777779
2022-12-18 23:46:21,973 INFO Student Test performance on iter 0: 56.25
2022-12-18 23:46:21,973 INFO 

	 *** Starting loop 1 ***
2022-12-18 23:46:21,973 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:46:21,974 INFO Downsampling 444 data
2022-12-18 23:46:21,974 INFO Adding Student as extra rule in Teacher
2022-12-18 23:46:21,974 INFO Getting rule predictions
2022-12-18 23:46:21,974 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:46:21,975 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:21,975 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:21,976 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:46:21,977 INFO Predicting labels for 741 texts
2022-12-18 23:46:22,077 INFO Predicting labels for 18 texts
2022-12-18 23:46:22,178 INFO Predicting labels for 444 texts
2022-12-18 23:46:22,283 INFO Training Rule Attention Network
2022-12-18 23:46:22,291 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:46:22,292 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:46:22,296 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:46:22,296 INFO 

		*** Training RAN ***
2022-12-18 23:46:25,073 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:25,074 INFO Predicting labels for 444 texts
2022-12-18 23:46:25,178 INFO There are 3/7 active rules
2022-12-18 23:46:25,178 INFO Coverage: 100.0% (444/444)
2022-12-18 23:46:25,182 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:46:25,268 INFO DONE, Getting attention scores...
2022-12-18 23:46:25,329 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:25,329 INFO Predicting labels for 18 texts
2022-12-18 23:46:25,434 INFO There are 7/7 active rules
2022-12-18 23:46:25,435 INFO Coverage: 100.0% (18/18)
2022-12-18 23:46:25,435 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:46:25,461 INFO DONE, Getting attention scores...
2022-12-18 23:46:25,521 INFO Evaluating teacher dev iter1 on 18 examples
2022-12-18 23:46:25,525 INFO teacher dev iter1 performance: 94.44
2022-12-18 23:46:25,526 INFO teacher dev iter1 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:46:25,526 INFO teacher dev iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:46:25,526 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:46:25,526 INFO Predicting labels for 32 texts
2022-12-18 23:46:25,632 INFO There are 7/7 active rules
2022-12-18 23:46:25,633 INFO Coverage: 100.0% (32/32)
2022-12-18 23:46:25,633 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:46:25,657 INFO DONE, Getting attention scores...
2022-12-18 23:46:25,710 INFO Evaluating teacher test iter1 on 32 examples
2022-12-18 23:46:25,714 INFO teacher test iter1 performance: 78.12
2022-12-18 23:46:25,714 INFO teacher test iter1 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:46:25,715 INFO teacher test iter1 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:46:25,715 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:46:25,718 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:46:25,720 INFO Balancing Pseudo Dataset to keep 520 items...
2022-12-18 23:46:25,724 INFO PSEUDO-DATASET:
520 examples
PSEUDO-LABELS:
1    260
0    260
Name: label, dtype: int64
2022-12-18 23:46:25,724 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:46:27,089 INFO fine-tuning the student on clean labeled data
2022-12-18 23:46:29,533 INFO Predicting labels for 18 texts
2022-12-18 23:46:29,636 INFO Evaluating student dev iter1 on 18 examples
2022-12-18 23:46:29,640 INFO student dev iter1 performance: 66.67
2022-12-18 23:46:29,641 INFO student dev iter1 confusion matrix:
[[6 6]
 [0 6]]
2022-12-18 23:46:29,642 INFO student dev iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.50      1.00      0.67         6

    accuracy                           0.67        18
   macro avg       0.75      0.75      0.67        18
weighted avg       0.83      0.67      0.67        18

2022-12-18 23:46:29,642 INFO Predicting labels for 32 texts
2022-12-18 23:46:29,746 INFO Evaluating student test iter1 on 32 examples
2022-12-18 23:46:29,751 INFO student test iter1 performance: 43.75
2022-12-18 23:46:29,751 INFO student test iter1 confusion matrix:
[[12 18]
 [ 0  2]]
2022-12-18 23:46:29,751 INFO student test iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.40      0.57        30
           1       0.10      1.00      0.18         2

    accuracy                           0.44        32
   macro avg       0.55      0.70      0.38        32
weighted avg       0.94      0.44      0.55        32

2022-12-18 23:46:29,751 INFO Student Dev performance on iter 1: 66.66666666666666
2022-12-18 23:46:29,751 INFO Student Test performance on iter 1: 43.75
2022-12-18 23:46:29,751 INFO 

	 *** Starting loop 2 ***
2022-12-18 23:46:29,752 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:46:29,752 INFO Downsampling 444 data
2022-12-18 23:46:29,752 INFO Adding Student as extra rule in Teacher
2022-12-18 23:46:29,752 INFO Getting rule predictions
2022-12-18 23:46:29,753 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:46:29,754 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:29,754 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:29,754 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:46:29,755 INFO Predicting labels for 741 texts
2022-12-18 23:46:29,861 INFO Predicting labels for 18 texts
2022-12-18 23:46:29,963 INFO Predicting labels for 444 texts
2022-12-18 23:46:30,072 INFO Training Rule Attention Network
2022-12-18 23:46:30,079 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:46:30,079 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:46:30,083 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:46:30,083 INFO 

		*** Training RAN ***
2022-12-18 23:46:32,805 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:32,806 INFO Predicting labels for 444 texts
2022-12-18 23:46:32,912 INFO There are 3/7 active rules
2022-12-18 23:46:32,912 INFO Coverage: 100.0% (444/444)
2022-12-18 23:46:32,916 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:46:32,999 INFO DONE, Getting attention scores...
2022-12-18 23:46:33,055 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:33,055 INFO Predicting labels for 18 texts
2022-12-18 23:46:33,168 INFO There are 7/7 active rules
2022-12-18 23:46:33,168 INFO Coverage: 100.0% (18/18)
2022-12-18 23:46:33,170 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:46:33,195 INFO DONE, Getting attention scores...
2022-12-18 23:46:33,248 INFO Evaluating teacher dev iter2 on 18 examples
2022-12-18 23:46:33,252 INFO teacher dev iter2 performance: 94.44
2022-12-18 23:46:33,252 INFO teacher dev iter2 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:46:33,252 INFO teacher dev iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:46:33,253 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:46:33,253 INFO Predicting labels for 32 texts
2022-12-18 23:46:33,359 INFO There are 7/7 active rules
2022-12-18 23:46:33,359 INFO Coverage: 100.0% (32/32)
2022-12-18 23:46:33,360 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:46:33,384 INFO DONE, Getting attention scores...
2022-12-18 23:46:33,437 INFO Evaluating teacher test iter2 on 32 examples
2022-12-18 23:46:33,441 INFO teacher test iter2 performance: 78.12
2022-12-18 23:46:33,442 INFO teacher test iter2 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:46:33,442 INFO teacher test iter2 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:46:33,442 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:46:33,445 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:46:33,447 INFO Balancing Pseudo Dataset to keep 516 items...
2022-12-18 23:46:33,451 INFO PSEUDO-DATASET:
516 examples
PSEUDO-LABELS:
1    258
0    258
Name: label, dtype: int64
2022-12-18 23:46:33,451 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:46:34,905 INFO fine-tuning the student on clean labeled data
2022-12-18 23:46:37,356 INFO Predicting labels for 18 texts
2022-12-18 23:46:37,460 INFO Evaluating student dev iter2 on 18 examples
2022-12-18 23:46:37,464 INFO student dev iter2 performance: 66.67
2022-12-18 23:46:37,464 INFO student dev iter2 confusion matrix:
[[6 6]
 [0 6]]
2022-12-18 23:46:37,464 INFO student dev iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.50      1.00      0.67         6

    accuracy                           0.67        18
   macro avg       0.75      0.75      0.67        18
weighted avg       0.83      0.67      0.67        18

2022-12-18 23:46:37,465 INFO Predicting labels for 32 texts
2022-12-18 23:46:37,566 INFO Evaluating student test iter2 on 32 examples
2022-12-18 23:46:37,570 INFO student test iter2 performance: 31.25
2022-12-18 23:46:37,571 INFO student test iter2 confusion matrix:
[[ 8 22]
 [ 0  2]]
2022-12-18 23:46:37,571 INFO student test iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.27      0.42        30
           1       0.08      1.00      0.15         2

    accuracy                           0.31        32
   macro avg       0.54      0.63      0.29        32
weighted avg       0.94      0.31      0.40        32

2022-12-18 23:46:37,571 INFO Student Dev performance on iter 2: 66.66666666666666
2022-12-18 23:46:37,571 INFO Student Test performance on iter 2: 31.25
2022-12-18 23:46:37,571 INFO 

	 *** Starting loop 3 ***
2022-12-18 23:46:37,571 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:46:37,571 INFO Downsampling 444 data
2022-12-18 23:46:37,572 INFO Adding Student as extra rule in Teacher
2022-12-18 23:46:37,572 INFO Getting rule predictions
2022-12-18 23:46:37,572 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:46:37,573 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:37,574 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:37,574 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:46:37,575 INFO Predicting labels for 741 texts
2022-12-18 23:46:38,702 INFO Predicting labels for 18 texts
2022-12-18 23:46:39,830 INFO Predicting labels for 444 texts
2022-12-18 23:46:39,930 INFO Training Rule Attention Network
2022-12-18 23:46:39,940 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:46:39,941 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:46:39,945 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:46:39,945 INFO 

		*** Training RAN ***
2022-12-18 23:46:42,758 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:42,759 INFO Predicting labels for 444 texts
2022-12-18 23:46:42,864 INFO There are 3/7 active rules
2022-12-18 23:46:42,864 INFO Coverage: 100.0% (444/444)
2022-12-18 23:46:42,868 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:46:42,952 INFO DONE, Getting attention scores...
2022-12-18 23:46:43,007 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:43,008 INFO Predicting labels for 18 texts
2022-12-18 23:46:43,113 INFO There are 7/7 active rules
2022-12-18 23:46:43,113 INFO Coverage: 100.0% (18/18)
2022-12-18 23:46:43,114 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:46:43,138 INFO DONE, Getting attention scores...
2022-12-18 23:46:43,193 INFO Evaluating teacher dev iter3 on 18 examples
2022-12-18 23:46:43,197 INFO teacher dev iter3 performance: 94.44
2022-12-18 23:46:43,198 INFO teacher dev iter3 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:46:43,198 INFO teacher dev iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:46:43,198 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:46:43,198 INFO Predicting labels for 32 texts
2022-12-18 23:46:43,302 INFO There are 7/7 active rules
2022-12-18 23:46:43,302 INFO Coverage: 100.0% (32/32)
2022-12-18 23:46:43,303 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:46:43,326 INFO DONE, Getting attention scores...
2022-12-18 23:46:43,382 INFO Evaluating teacher test iter3 on 32 examples
2022-12-18 23:46:43,386 INFO teacher test iter3 performance: 78.12
2022-12-18 23:46:43,386 INFO teacher test iter3 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:46:43,386 INFO teacher test iter3 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:46:43,387 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:46:43,389 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:46:43,391 INFO Balancing Pseudo Dataset to keep 520 items...
2022-12-18 23:46:43,394 INFO PSEUDO-DATASET:
520 examples
PSEUDO-LABELS:
1    260
0    260
Name: label, dtype: int64
2022-12-18 23:46:43,394 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:46:44,826 INFO fine-tuning the student on clean labeled data
2022-12-18 23:46:47,529 INFO Predicting labels for 18 texts
2022-12-18 23:46:47,636 INFO Evaluating student dev iter3 on 18 examples
2022-12-18 23:46:47,640 INFO student dev iter3 performance: 66.67
2022-12-18 23:46:47,641 INFO student dev iter3 confusion matrix:
[[6 6]
 [0 6]]
2022-12-18 23:46:47,641 INFO student dev iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.50      1.00      0.67         6

    accuracy                           0.67        18
   macro avg       0.75      0.75      0.67        18
weighted avg       0.83      0.67      0.67        18

2022-12-18 23:46:47,641 INFO Predicting labels for 32 texts
2022-12-18 23:46:47,745 INFO Evaluating student test iter3 on 32 examples
2022-12-18 23:46:47,749 INFO student test iter3 performance: 28.12
2022-12-18 23:46:47,749 INFO student test iter3 confusion matrix:
[[ 7 23]
 [ 0  2]]
2022-12-18 23:46:47,750 INFO student test iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.23      0.38        30
           1       0.08      1.00      0.15         2

    accuracy                           0.28        32
   macro avg       0.54      0.62      0.26        32
weighted avg       0.94      0.28      0.36        32

2022-12-18 23:46:47,750 INFO Student Dev performance on iter 3: 66.66666666666666
2022-12-18 23:46:47,750 INFO Student Test performance on iter 3: 28.125
2022-12-18 23:46:47,750 INFO 

	 *** Starting loop 4 ***
2022-12-18 23:46:47,750 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:46:47,750 INFO Downsampling 444 data
2022-12-18 23:46:47,751 INFO Adding Student as extra rule in Teacher
2022-12-18 23:46:47,751 INFO Getting rule predictions
2022-12-18 23:46:47,751 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:46:47,752 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:47,752 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:47,753 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:46:47,753 INFO Predicting labels for 741 texts
2022-12-18 23:46:47,858 INFO Predicting labels for 18 texts
2022-12-18 23:46:47,962 INFO Predicting labels for 444 texts
2022-12-18 23:46:48,067 INFO Training Rule Attention Network
2022-12-18 23:46:48,074 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:46:48,075 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:46:48,079 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:46:48,079 INFO 

		*** Training RAN ***
2022-12-18 23:46:50,813 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:50,814 INFO Predicting labels for 444 texts
2022-12-18 23:46:50,919 INFO There are 3/7 active rules
2022-12-18 23:46:50,919 INFO Coverage: 100.0% (444/444)
2022-12-18 23:46:50,923 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:46:51,009 INFO DONE, Getting attention scores...
2022-12-18 23:46:51,065 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:51,065 INFO Predicting labels for 18 texts
2022-12-18 23:46:51,165 INFO There are 7/7 active rules
2022-12-18 23:46:51,165 INFO Coverage: 100.0% (18/18)
2022-12-18 23:46:51,166 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:46:51,190 INFO DONE, Getting attention scores...
2022-12-18 23:46:51,247 INFO Evaluating teacher dev iter4 on 18 examples
2022-12-18 23:46:51,251 INFO teacher dev iter4 performance: 94.44
2022-12-18 23:46:51,252 INFO teacher dev iter4 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:46:51,252 INFO teacher dev iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:46:51,252 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:46:51,252 INFO Predicting labels for 32 texts
2022-12-18 23:46:51,354 INFO There are 7/7 active rules
2022-12-18 23:46:51,355 INFO Coverage: 100.0% (32/32)
2022-12-18 23:46:51,356 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:46:51,379 INFO DONE, Getting attention scores...
2022-12-18 23:46:51,434 INFO Evaluating teacher test iter4 on 32 examples
2022-12-18 23:46:51,437 INFO teacher test iter4 performance: 78.12
2022-12-18 23:46:51,438 INFO teacher test iter4 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:46:51,438 INFO teacher test iter4 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:46:51,438 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:46:51,441 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:46:51,442 INFO Balancing Pseudo Dataset to keep 520 items...
2022-12-18 23:46:51,446 INFO PSEUDO-DATASET:
520 examples
PSEUDO-LABELS:
1    260
0    260
Name: label, dtype: int64
2022-12-18 23:46:51,446 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:46:52,906 INFO fine-tuning the student on clean labeled data
2022-12-18 23:46:54,262 INFO Predicting labels for 18 texts
2022-12-18 23:46:55,398 INFO Evaluating student dev iter4 on 18 examples
2022-12-18 23:46:55,402 INFO student dev iter4 performance: 61.11
2022-12-18 23:46:55,402 INFO student dev iter4 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:46:55,402 INFO student dev iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:46:55,403 INFO Predicting labels for 32 texts
2022-12-18 23:46:55,505 INFO Evaluating student test iter4 on 32 examples
2022-12-18 23:46:55,509 INFO student test iter4 performance: 25.00
2022-12-18 23:46:55,509 INFO student test iter4 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:46:55,510 INFO student test iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:46:55,510 INFO Student Dev performance on iter 4: 61.111111111111114
2022-12-18 23:46:55,510 INFO Student Test performance on iter 4: 25.0
2022-12-18 23:46:55,510 INFO 

	 *** Starting loop 5 ***
2022-12-18 23:46:55,510 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:46:55,510 INFO Downsampling 444 data
2022-12-18 23:46:55,511 INFO Adding Student as extra rule in Teacher
2022-12-18 23:46:55,511 INFO Getting rule predictions
2022-12-18 23:46:55,511 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:46:55,512 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:55,512 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:55,513 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:46:55,514 INFO Predicting labels for 741 texts
2022-12-18 23:46:55,619 INFO Predicting labels for 18 texts
2022-12-18 23:46:55,720 INFO Predicting labels for 444 texts
2022-12-18 23:46:55,821 INFO Training Rule Attention Network
2022-12-18 23:46:55,924 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:46:55,925 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:46:55,929 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:46:55,929 INFO 

		*** Training RAN ***
2022-12-18 23:46:58,714 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:46:58,716 INFO Predicting labels for 444 texts
2022-12-18 23:46:58,820 INFO There are 3/7 active rules
2022-12-18 23:46:58,820 INFO Coverage: 100.0% (444/444)
2022-12-18 23:46:58,824 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:46:58,909 INFO DONE, Getting attention scores...
2022-12-18 23:46:58,967 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:46:58,967 INFO Predicting labels for 18 texts
2022-12-18 23:46:59,073 INFO There are 7/7 active rules
2022-12-18 23:46:59,074 INFO Coverage: 100.0% (18/18)
2022-12-18 23:46:59,074 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:46:59,098 INFO DONE, Getting attention scores...
2022-12-18 23:46:59,151 INFO Evaluating teacher dev iter5 on 18 examples
2022-12-18 23:46:59,155 INFO teacher dev iter5 performance: 94.44
2022-12-18 23:46:59,155 INFO teacher dev iter5 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:46:59,155 INFO teacher dev iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:46:59,155 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:46:59,155 INFO Predicting labels for 32 texts
2022-12-18 23:46:59,261 INFO There are 7/7 active rules
2022-12-18 23:46:59,261 INFO Coverage: 100.0% (32/32)
2022-12-18 23:46:59,262 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:46:59,287 INFO DONE, Getting attention scores...
2022-12-18 23:46:59,341 INFO Evaluating teacher test iter5 on 32 examples
2022-12-18 23:46:59,345 INFO teacher test iter5 performance: 78.12
2022-12-18 23:46:59,345 INFO teacher test iter5 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:46:59,346 INFO teacher test iter5 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:46:59,346 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:46:59,349 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:46:59,350 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-18 23:46:59,355 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-18 23:46:59,355 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:00,098 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:02,492 INFO Predicting labels for 18 texts
2022-12-18 23:47:02,597 INFO Evaluating student dev iter5 on 18 examples
2022-12-18 23:47:02,602 INFO student dev iter5 performance: 61.11
2022-12-18 23:47:02,602 INFO student dev iter5 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:47:02,602 INFO student dev iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:47:02,602 INFO Predicting labels for 32 texts
2022-12-18 23:47:02,705 INFO Evaluating student test iter5 on 32 examples
2022-12-18 23:47:02,709 INFO student test iter5 performance: 25.00
2022-12-18 23:47:02,710 INFO student test iter5 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:02,710 INFO student test iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:02,710 INFO Student Dev performance on iter 5: 61.111111111111114
2022-12-18 23:47:02,710 INFO Student Test performance on iter 5: 25.0
2022-12-18 23:47:02,710 INFO 

	 *** Starting loop 6 ***
2022-12-18 23:47:02,710 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:02,710 INFO Downsampling 444 data
2022-12-18 23:47:02,711 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:02,711 INFO Getting rule predictions
2022-12-18 23:47:02,711 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:02,712 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:02,712 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:02,713 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:02,714 INFO Predicting labels for 741 texts
2022-12-18 23:47:02,817 INFO Predicting labels for 18 texts
2022-12-18 23:47:02,919 INFO Predicting labels for 444 texts
2022-12-18 23:47:03,027 INFO Training Rule Attention Network
2022-12-18 23:47:03,034 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:03,034 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:03,039 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:03,039 INFO 

		*** Training RAN ***
2022-12-18 23:47:05,904 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:05,905 INFO Predicting labels for 444 texts
2022-12-18 23:47:06,009 INFO There are 3/7 active rules
2022-12-18 23:47:06,010 INFO Coverage: 100.0% (444/444)
2022-12-18 23:47:06,014 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:47:06,105 INFO DONE, Getting attention scores...
2022-12-18 23:47:06,161 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:06,161 INFO Predicting labels for 18 texts
2022-12-18 23:47:06,263 INFO There are 7/7 active rules
2022-12-18 23:47:06,263 INFO Coverage: 100.0% (18/18)
2022-12-18 23:47:06,263 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:47:06,286 INFO DONE, Getting attention scores...
2022-12-18 23:47:06,343 INFO Evaluating teacher dev iter6 on 18 examples
2022-12-18 23:47:06,347 INFO teacher dev iter6 performance: 94.44
2022-12-18 23:47:06,347 INFO teacher dev iter6 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:47:06,347 INFO teacher dev iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:47:06,347 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:47:06,347 INFO Predicting labels for 32 texts
2022-12-18 23:47:06,449 INFO There are 7/7 active rules
2022-12-18 23:47:06,449 INFO Coverage: 100.0% (32/32)
2022-12-18 23:47:06,450 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:47:06,473 INFO DONE, Getting attention scores...
2022-12-18 23:47:06,526 INFO Evaluating teacher test iter6 on 32 examples
2022-12-18 23:47:06,530 INFO teacher test iter6 performance: 78.12
2022-12-18 23:47:06,530 INFO teacher test iter6 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:47:06,530 INFO teacher test iter6 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:47:06,531 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:47:06,534 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:47:06,536 INFO Balancing Pseudo Dataset to keep 508 items...
2022-12-18 23:47:06,539 INFO PSEUDO-DATASET:
508 examples
PSEUDO-LABELS:
1    254
0    254
Name: label, dtype: int64
2022-12-18 23:47:06,539 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:07,353 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:08,790 INFO Predicting labels for 18 texts
2022-12-18 23:47:08,892 INFO Evaluating student dev iter6 on 18 examples
2022-12-18 23:47:08,897 INFO student dev iter6 performance: 55.56
2022-12-18 23:47:08,897 INFO student dev iter6 confusion matrix:
[[4 8]
 [0 6]]
2022-12-18 23:47:08,897 INFO student dev iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.43      1.00      0.60         6

    accuracy                           0.56        18
   macro avg       0.71      0.67      0.55        18
weighted avg       0.81      0.56      0.53        18

2022-12-18 23:47:08,897 INFO Predicting labels for 32 texts
2022-12-18 23:47:08,997 INFO Evaluating student test iter6 on 32 examples
2022-12-18 23:47:09,002 INFO student test iter6 performance: 25.00
2022-12-18 23:47:09,002 INFO student test iter6 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:09,002 INFO student test iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:09,002 INFO Student Dev performance on iter 6: 55.55555555555556
2022-12-18 23:47:09,002 INFO Student Test performance on iter 6: 25.0
2022-12-18 23:47:09,002 INFO 

	 *** Starting loop 7 ***
2022-12-18 23:47:09,002 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:09,002 INFO Downsampling 444 data
2022-12-18 23:47:09,003 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:09,003 INFO Getting rule predictions
2022-12-18 23:47:09,003 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:09,004 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:09,005 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:09,005 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:09,006 INFO Predicting labels for 741 texts
2022-12-18 23:47:09,111 INFO Predicting labels for 18 texts
2022-12-18 23:47:09,212 INFO Predicting labels for 444 texts
2022-12-18 23:47:09,316 INFO Training Rule Attention Network
2022-12-18 23:47:09,323 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:09,324 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:09,328 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:09,328 INFO 

		*** Training RAN ***
2022-12-18 23:47:12,159 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:12,161 INFO Predicting labels for 444 texts
2022-12-18 23:47:13,282 INFO There are 3/7 active rules
2022-12-18 23:47:13,282 INFO Coverage: 100.0% (444/444)
2022-12-18 23:47:13,286 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:47:13,373 INFO DONE, Getting attention scores...
2022-12-18 23:47:13,429 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:13,430 INFO Predicting labels for 18 texts
2022-12-18 23:47:13,530 INFO There are 7/7 active rules
2022-12-18 23:47:13,531 INFO Coverage: 100.0% (18/18)
2022-12-18 23:47:13,531 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:47:13,554 INFO DONE, Getting attention scores...
2022-12-18 23:47:13,609 INFO Evaluating teacher dev iter7 on 18 examples
2022-12-18 23:47:13,613 INFO teacher dev iter7 performance: 94.44
2022-12-18 23:47:13,613 INFO teacher dev iter7 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:47:13,613 INFO teacher dev iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:47:13,613 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:47:13,614 INFO Predicting labels for 32 texts
2022-12-18 23:47:13,720 INFO There are 7/7 active rules
2022-12-18 23:47:13,720 INFO Coverage: 100.0% (32/32)
2022-12-18 23:47:13,721 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:47:13,745 INFO DONE, Getting attention scores...
2022-12-18 23:47:13,796 INFO Evaluating teacher test iter7 on 32 examples
2022-12-18 23:47:13,800 INFO teacher test iter7 performance: 78.12
2022-12-18 23:47:13,800 INFO teacher test iter7 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:47:13,801 INFO teacher test iter7 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:47:13,801 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:47:13,804 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:47:13,806 INFO Balancing Pseudo Dataset to keep 520 items...
2022-12-18 23:47:13,809 INFO PSEUDO-DATASET:
520 examples
PSEUDO-LABELS:
1    260
0    260
Name: label, dtype: int64
2022-12-18 23:47:13,810 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:15,606 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:16,926 INFO Predicting labels for 18 texts
2022-12-18 23:47:17,035 INFO Evaluating student dev iter7 on 18 examples
2022-12-18 23:47:17,039 INFO student dev iter7 performance: 55.56
2022-12-18 23:47:17,039 INFO student dev iter7 confusion matrix:
[[4 8]
 [0 6]]
2022-12-18 23:47:17,039 INFO student dev iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.43      1.00      0.60         6

    accuracy                           0.56        18
   macro avg       0.71      0.67      0.55        18
weighted avg       0.81      0.56      0.53        18

2022-12-18 23:47:17,039 INFO Predicting labels for 32 texts
2022-12-18 23:47:17,148 INFO Evaluating student test iter7 on 32 examples
2022-12-18 23:47:17,153 INFO student test iter7 performance: 25.00
2022-12-18 23:47:17,153 INFO student test iter7 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:17,153 INFO student test iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:17,153 INFO Student Dev performance on iter 7: 55.55555555555556
2022-12-18 23:47:17,153 INFO Student Test performance on iter 7: 25.0
2022-12-18 23:47:17,154 INFO 

	 *** Starting loop 8 ***
2022-12-18 23:47:17,154 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:17,154 INFO Downsampling 444 data
2022-12-18 23:47:17,155 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:17,155 INFO Getting rule predictions
2022-12-18 23:47:17,155 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:17,156 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:17,156 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:17,156 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:17,157 INFO Predicting labels for 741 texts
2022-12-18 23:47:17,270 INFO Predicting labels for 18 texts
2022-12-18 23:47:17,379 INFO Predicting labels for 444 texts
2022-12-18 23:47:17,483 INFO Training Rule Attention Network
2022-12-18 23:47:17,492 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:17,493 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:17,497 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:17,497 INFO 

		*** Training RAN ***
2022-12-18 23:47:20,366 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:20,368 INFO Predicting labels for 444 texts
2022-12-18 23:47:20,477 INFO There are 3/7 active rules
2022-12-18 23:47:20,477 INFO Coverage: 100.0% (444/444)
2022-12-18 23:47:20,482 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:47:20,568 INFO DONE, Getting attention scores...
2022-12-18 23:47:20,625 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:20,625 INFO Predicting labels for 18 texts
2022-12-18 23:47:20,730 INFO There are 7/7 active rules
2022-12-18 23:47:20,730 INFO Coverage: 100.0% (18/18)
2022-12-18 23:47:20,731 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:47:20,754 INFO DONE, Getting attention scores...
2022-12-18 23:47:20,809 INFO Evaluating teacher dev iter8 on 18 examples
2022-12-18 23:47:20,813 INFO teacher dev iter8 performance: 94.44
2022-12-18 23:47:20,813 INFO teacher dev iter8 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:47:20,814 INFO teacher dev iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:47:20,814 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:47:20,814 INFO Predicting labels for 32 texts
2022-12-18 23:47:20,921 INFO There are 7/7 active rules
2022-12-18 23:47:20,922 INFO Coverage: 100.0% (32/32)
2022-12-18 23:47:20,923 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:47:20,948 INFO DONE, Getting attention scores...
2022-12-18 23:47:21,002 INFO Evaluating teacher test iter8 on 32 examples
2022-12-18 23:47:21,006 INFO teacher test iter8 performance: 78.12
2022-12-18 23:47:21,007 INFO teacher test iter8 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:47:21,007 INFO teacher test iter8 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:47:21,007 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:47:21,011 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:47:21,012 INFO Balancing Pseudo Dataset to keep 494 items...
2022-12-18 23:47:21,016 INFO PSEUDO-DATASET:
494 examples
PSEUDO-LABELS:
1    247
0    247
Name: label, dtype: int64
2022-12-18 23:47:21,016 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:21,747 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:24,119 INFO Predicting labels for 18 texts
2022-12-18 23:47:24,227 INFO Evaluating student dev iter8 on 18 examples
2022-12-18 23:47:24,231 INFO student dev iter8 performance: 55.56
2022-12-18 23:47:24,231 INFO student dev iter8 confusion matrix:
[[4 8]
 [0 6]]
2022-12-18 23:47:24,232 INFO student dev iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.43      1.00      0.60         6

    accuracy                           0.56        18
   macro avg       0.71      0.67      0.55        18
weighted avg       0.81      0.56      0.53        18

2022-12-18 23:47:24,232 INFO Predicting labels for 32 texts
2022-12-18 23:47:24,335 INFO Evaluating student test iter8 on 32 examples
2022-12-18 23:47:24,340 INFO student test iter8 performance: 25.00
2022-12-18 23:47:24,340 INFO student test iter8 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:24,340 INFO student test iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:24,340 INFO Student Dev performance on iter 8: 55.55555555555556
2022-12-18 23:47:24,340 INFO Student Test performance on iter 8: 25.0
2022-12-18 23:47:24,340 INFO 

	 *** Starting loop 9 ***
2022-12-18 23:47:24,340 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:24,340 INFO Downsampling 444 data
2022-12-18 23:47:24,341 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:24,341 INFO Getting rule predictions
2022-12-18 23:47:24,341 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:24,342 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:24,343 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:24,343 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:24,344 INFO Predicting labels for 741 texts
2022-12-18 23:47:24,448 INFO Predicting labels for 18 texts
2022-12-18 23:47:24,550 INFO Predicting labels for 444 texts
2022-12-18 23:47:24,652 INFO Training Rule Attention Network
2022-12-18 23:47:24,662 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:24,663 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:24,667 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:24,667 INFO 

		*** Training RAN ***
2022-12-18 23:47:27,451 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:27,452 INFO Predicting labels for 444 texts
2022-12-18 23:47:28,686 INFO There are 3/7 active rules
2022-12-18 23:47:28,686 INFO Coverage: 100.0% (444/444)
2022-12-18 23:47:28,690 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:47:28,778 INFO DONE, Getting attention scores...
2022-12-18 23:47:28,838 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:28,838 INFO Predicting labels for 18 texts
2022-12-18 23:47:28,950 INFO There are 7/7 active rules
2022-12-18 23:47:28,950 INFO Coverage: 100.0% (18/18)
2022-12-18 23:47:28,951 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:47:28,976 INFO DONE, Getting attention scores...
2022-12-18 23:47:29,030 INFO Evaluating teacher dev iter9 on 18 examples
2022-12-18 23:47:29,034 INFO teacher dev iter9 performance: 94.44
2022-12-18 23:47:29,035 INFO teacher dev iter9 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:47:29,035 INFO teacher dev iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:47:29,035 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:47:29,035 INFO Predicting labels for 32 texts
2022-12-18 23:47:29,137 INFO There are 7/7 active rules
2022-12-18 23:47:29,138 INFO Coverage: 100.0% (32/32)
2022-12-18 23:47:29,139 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:47:29,169 INFO DONE, Getting attention scores...
2022-12-18 23:47:29,224 INFO Evaluating teacher test iter9 on 32 examples
2022-12-18 23:47:29,229 INFO teacher test iter9 performance: 78.12
2022-12-18 23:47:29,229 INFO teacher test iter9 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:47:29,229 INFO teacher test iter9 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:47:29,230 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:47:29,233 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:47:29,235 INFO Balancing Pseudo Dataset to keep 510 items...
2022-12-18 23:47:29,238 INFO PSEUDO-DATASET:
510 examples
PSEUDO-LABELS:
1    255
0    255
Name: label, dtype: int64
2022-12-18 23:47:29,238 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:29,973 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:32,426 INFO Predicting labels for 18 texts
2022-12-18 23:47:32,536 INFO Evaluating student dev iter9 on 18 examples
2022-12-18 23:47:32,540 INFO student dev iter9 performance: 55.56
2022-12-18 23:47:32,540 INFO student dev iter9 confusion matrix:
[[4 8]
 [0 6]]
2022-12-18 23:47:32,541 INFO student dev iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.43      1.00      0.60         6

    accuracy                           0.56        18
   macro avg       0.71      0.67      0.55        18
weighted avg       0.81      0.56      0.53        18

2022-12-18 23:47:32,541 INFO Predicting labels for 32 texts
2022-12-18 23:47:32,646 INFO Evaluating student test iter9 on 32 examples
2022-12-18 23:47:32,650 INFO student test iter9 performance: 25.00
2022-12-18 23:47:32,651 INFO student test iter9 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:32,651 INFO student test iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:32,651 INFO Student Dev performance on iter 9: 55.55555555555556
2022-12-18 23:47:32,651 INFO Student Test performance on iter 9: 25.0
2022-12-18 23:47:32,651 INFO 

	 *** Starting loop 10 ***
2022-12-18 23:47:32,651 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:32,651 INFO Downsampling 444 data
2022-12-18 23:47:32,652 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:32,652 INFO Getting rule predictions
2022-12-18 23:47:32,652 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:32,653 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:32,653 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:32,654 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:32,655 INFO Predicting labels for 741 texts
2022-12-18 23:47:32,757 INFO Predicting labels for 18 texts
2022-12-18 23:47:32,862 INFO Predicting labels for 444 texts
2022-12-18 23:47:32,968 INFO Training Rule Attention Network
2022-12-18 23:47:32,975 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:32,975 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:32,982 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:32,982 INFO 

		*** Training RAN ***
2022-12-18 23:47:35,803 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:35,805 INFO Predicting labels for 444 texts
2022-12-18 23:47:35,910 INFO There are 3/7 active rules
2022-12-18 23:47:35,910 INFO Coverage: 100.0% (444/444)
2022-12-18 23:47:35,915 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:47:35,999 INFO DONE, Getting attention scores...
2022-12-18 23:47:36,054 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:36,055 INFO Predicting labels for 18 texts
2022-12-18 23:47:36,159 INFO There are 7/7 active rules
2022-12-18 23:47:36,159 INFO Coverage: 100.0% (18/18)
2022-12-18 23:47:36,160 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:47:36,183 INFO DONE, Getting attention scores...
2022-12-18 23:47:36,236 INFO Evaluating teacher dev iter10 on 18 examples
2022-12-18 23:47:36,240 INFO teacher dev iter10 performance: 94.44
2022-12-18 23:47:36,240 INFO teacher dev iter10 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:47:36,241 INFO teacher dev iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:47:36,241 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:47:36,241 INFO Predicting labels for 32 texts
2022-12-18 23:47:36,342 INFO There are 7/7 active rules
2022-12-18 23:47:36,343 INFO Coverage: 100.0% (32/32)
2022-12-18 23:47:36,344 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:47:36,368 INFO DONE, Getting attention scores...
2022-12-18 23:47:36,518 INFO Evaluating teacher test iter10 on 32 examples
2022-12-18 23:47:36,522 INFO teacher test iter10 performance: 78.12
2022-12-18 23:47:36,523 INFO teacher test iter10 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:47:36,523 INFO teacher test iter10 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:47:36,523 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:47:36,527 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:47:36,528 INFO Balancing Pseudo Dataset to keep 496 items...
2022-12-18 23:47:36,533 INFO PSEUDO-DATASET:
496 examples
PSEUDO-LABELS:
1    248
0    248
Name: label, dtype: int64
2022-12-18 23:47:36,533 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:37,271 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:38,776 INFO Predicting labels for 18 texts
2022-12-18 23:47:38,883 INFO Evaluating student dev iter10 on 18 examples
2022-12-18 23:47:38,888 INFO student dev iter10 performance: 55.56
2022-12-18 23:47:38,888 INFO student dev iter10 confusion matrix:
[[4 8]
 [0 6]]
2022-12-18 23:47:38,888 INFO student dev iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.43      1.00      0.60         6

    accuracy                           0.56        18
   macro avg       0.71      0.67      0.55        18
weighted avg       0.81      0.56      0.53        18

2022-12-18 23:47:38,888 INFO Predicting labels for 32 texts
2022-12-18 23:47:38,992 INFO Evaluating student test iter10 on 32 examples
2022-12-18 23:47:38,996 INFO student test iter10 performance: 25.00
2022-12-18 23:47:38,997 INFO student test iter10 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:38,997 INFO student test iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:38,997 INFO Student Dev performance on iter 10: 55.55555555555556
2022-12-18 23:47:38,997 INFO Student Test performance on iter 10: 25.0
2022-12-18 23:47:38,997 INFO 

	 *** Starting loop 11 ***
2022-12-18 23:47:38,997 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:38,997 INFO Downsampling 444 data
2022-12-18 23:47:38,998 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:38,998 INFO Getting rule predictions
2022-12-18 23:47:38,998 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:38,999 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:38,999 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:39,000 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:39,001 INFO Predicting labels for 741 texts
2022-12-18 23:47:39,103 INFO Predicting labels for 18 texts
2022-12-18 23:47:39,206 INFO Predicting labels for 444 texts
2022-12-18 23:47:39,309 INFO Training Rule Attention Network
2022-12-18 23:47:39,316 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:39,317 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:39,321 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:39,321 INFO 

		*** Training RAN ***
2022-12-18 23:47:42,121 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:42,122 INFO Predicting labels for 444 texts
2022-12-18 23:47:42,228 INFO There are 3/7 active rules
2022-12-18 23:47:42,228 INFO Coverage: 100.0% (444/444)
2022-12-18 23:47:42,233 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:47:42,325 INFO DONE, Getting attention scores...
2022-12-18 23:47:42,387 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:42,387 INFO Predicting labels for 18 texts
2022-12-18 23:47:42,495 INFO There are 7/7 active rules
2022-12-18 23:47:42,495 INFO Coverage: 100.0% (18/18)
2022-12-18 23:47:42,496 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:47:42,519 INFO DONE, Getting attention scores...
2022-12-18 23:47:42,573 INFO Evaluating teacher dev iter11 on 18 examples
2022-12-18 23:47:42,577 INFO teacher dev iter11 performance: 94.44
2022-12-18 23:47:42,578 INFO teacher dev iter11 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:47:42,578 INFO teacher dev iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:47:42,578 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:47:42,578 INFO Predicting labels for 32 texts
2022-12-18 23:47:42,684 INFO There are 7/7 active rules
2022-12-18 23:47:42,684 INFO Coverage: 100.0% (32/32)
2022-12-18 23:47:42,685 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:47:42,708 INFO DONE, Getting attention scores...
2022-12-18 23:47:42,765 INFO Evaluating teacher test iter11 on 32 examples
2022-12-18 23:47:42,770 INFO teacher test iter11 performance: 78.12
2022-12-18 23:47:42,770 INFO teacher test iter11 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:47:42,770 INFO teacher test iter11 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:47:42,770 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:47:42,773 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:47:42,775 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-18 23:47:42,778 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-18 23:47:42,778 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:43,548 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:45,029 INFO Predicting labels for 18 texts
2022-12-18 23:47:45,138 INFO Evaluating student dev iter11 on 18 examples
2022-12-18 23:47:45,142 INFO student dev iter11 performance: 55.56
2022-12-18 23:47:45,142 INFO student dev iter11 confusion matrix:
[[4 8]
 [0 6]]
2022-12-18 23:47:45,142 INFO student dev iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.43      1.00      0.60         6

    accuracy                           0.56        18
   macro avg       0.71      0.67      0.55        18
weighted avg       0.81      0.56      0.53        18

2022-12-18 23:47:45,142 INFO Predicting labels for 32 texts
2022-12-18 23:47:45,249 INFO Evaluating student test iter11 on 32 examples
2022-12-18 23:47:45,253 INFO student test iter11 performance: 25.00
2022-12-18 23:47:45,253 INFO student test iter11 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:45,253 INFO student test iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:45,253 INFO Student Dev performance on iter 11: 55.55555555555556
2022-12-18 23:47:45,253 INFO Student Test performance on iter 11: 25.0
2022-12-18 23:47:45,254 INFO 

	 *** Starting loop 12 ***
2022-12-18 23:47:45,254 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:45,254 INFO Downsampling 444 data
2022-12-18 23:47:45,254 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:45,255 INFO Getting rule predictions
2022-12-18 23:47:45,255 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:45,256 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:45,256 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:45,257 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:45,258 INFO Predicting labels for 741 texts
2022-12-18 23:47:45,363 INFO Predicting labels for 18 texts
2022-12-18 23:47:45,466 INFO Predicting labels for 444 texts
2022-12-18 23:47:45,574 INFO Training Rule Attention Network
2022-12-18 23:47:45,582 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:45,583 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:45,587 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:45,587 INFO 

		*** Training RAN ***
2022-12-18 23:47:48,446 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:48,447 INFO Predicting labels for 444 texts
2022-12-18 23:47:48,558 INFO There are 3/7 active rules
2022-12-18 23:47:48,558 INFO Coverage: 100.0% (444/444)
2022-12-18 23:47:48,562 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:47:48,647 INFO DONE, Getting attention scores...
2022-12-18 23:47:48,703 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:48,703 INFO Predicting labels for 18 texts
2022-12-18 23:47:48,803 INFO There are 7/7 active rules
2022-12-18 23:47:48,804 INFO Coverage: 100.0% (18/18)
2022-12-18 23:47:48,804 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:47:48,827 INFO DONE, Getting attention scores...
2022-12-18 23:47:48,884 INFO Evaluating teacher dev iter12 on 18 examples
2022-12-18 23:47:48,888 INFO teacher dev iter12 performance: 94.44
2022-12-18 23:47:48,888 INFO teacher dev iter12 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:47:48,888 INFO teacher dev iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:47:48,888 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:47:48,889 INFO Predicting labels for 32 texts
2022-12-18 23:47:48,991 INFO There are 7/7 active rules
2022-12-18 23:47:48,991 INFO Coverage: 100.0% (32/32)
2022-12-18 23:47:48,992 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:47:49,016 INFO DONE, Getting attention scores...
2022-12-18 23:47:49,069 INFO Evaluating teacher test iter12 on 32 examples
2022-12-18 23:47:49,073 INFO teacher test iter12 performance: 78.12
2022-12-18 23:47:49,074 INFO teacher test iter12 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:47:49,074 INFO teacher test iter12 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:47:49,074 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:47:49,078 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:47:49,079 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-18 23:47:49,082 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-18 23:47:49,083 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:49,751 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:51,060 INFO Predicting labels for 18 texts
2022-12-18 23:47:51,163 INFO Evaluating student dev iter12 on 18 examples
2022-12-18 23:47:51,167 INFO student dev iter12 performance: 55.56
2022-12-18 23:47:51,168 INFO student dev iter12 confusion matrix:
[[4 8]
 [0 6]]
2022-12-18 23:47:51,168 INFO student dev iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.43      1.00      0.60         6

    accuracy                           0.56        18
   macro avg       0.71      0.67      0.55        18
weighted avg       0.81      0.56      0.53        18

2022-12-18 23:47:51,168 INFO Predicting labels for 32 texts
2022-12-18 23:47:51,276 INFO Evaluating student test iter12 on 32 examples
2022-12-18 23:47:51,280 INFO student test iter12 performance: 25.00
2022-12-18 23:47:51,281 INFO student test iter12 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:51,281 INFO student test iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:51,281 INFO Student Dev performance on iter 12: 55.55555555555556
2022-12-18 23:47:51,281 INFO Student Test performance on iter 12: 25.0
2022-12-18 23:47:51,281 INFO 

	 *** Starting loop 13 ***
2022-12-18 23:47:51,281 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:51,281 INFO Downsampling 444 data
2022-12-18 23:47:51,282 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:51,282 INFO Getting rule predictions
2022-12-18 23:47:51,282 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:51,283 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:51,283 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:51,284 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:51,285 INFO Predicting labels for 741 texts
2022-12-18 23:47:51,395 INFO Predicting labels for 18 texts
2022-12-18 23:47:51,493 INFO Predicting labels for 444 texts
2022-12-18 23:47:51,599 INFO Training Rule Attention Network
2022-12-18 23:47:51,607 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:51,607 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:51,611 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:51,611 INFO 

		*** Training RAN ***
2022-12-18 23:47:54,401 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:54,402 INFO Predicting labels for 444 texts
2022-12-18 23:47:54,506 INFO There are 3/7 active rules
2022-12-18 23:47:54,507 INFO Coverage: 100.0% (444/444)
2022-12-18 23:47:54,511 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:47:54,599 INFO DONE, Getting attention scores...
2022-12-18 23:47:54,654 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:54,654 INFO Predicting labels for 18 texts
2022-12-18 23:47:54,755 INFO There are 7/7 active rules
2022-12-18 23:47:54,755 INFO Coverage: 100.0% (18/18)
2022-12-18 23:47:54,756 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:47:54,781 INFO DONE, Getting attention scores...
2022-12-18 23:47:54,839 INFO Evaluating teacher dev iter13 on 18 examples
2022-12-18 23:47:54,843 INFO teacher dev iter13 performance: 94.44
2022-12-18 23:47:54,844 INFO teacher dev iter13 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:47:54,844 INFO teacher dev iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:47:54,844 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:47:54,844 INFO Predicting labels for 32 texts
2022-12-18 23:47:54,946 INFO There are 7/7 active rules
2022-12-18 23:47:54,947 INFO Coverage: 100.0% (32/32)
2022-12-18 23:47:54,948 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:47:54,971 INFO DONE, Getting attention scores...
2022-12-18 23:47:55,025 INFO Evaluating teacher test iter13 on 32 examples
2022-12-18 23:47:55,032 INFO teacher test iter13 performance: 78.12
2022-12-18 23:47:55,032 INFO teacher test iter13 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:47:55,033 INFO teacher test iter13 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:47:55,033 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:47:55,036 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:47:55,037 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-18 23:47:55,041 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-18 23:47:55,041 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:47:55,713 INFO fine-tuning the student on clean labeled data
2022-12-18 23:47:56,950 INFO Predicting labels for 18 texts
2022-12-18 23:47:57,058 INFO Evaluating student dev iter13 on 18 examples
2022-12-18 23:47:57,062 INFO student dev iter13 performance: 55.56
2022-12-18 23:47:57,062 INFO student dev iter13 confusion matrix:
[[4 8]
 [0 6]]
2022-12-18 23:47:57,062 INFO student dev iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.43      1.00      0.60         6

    accuracy                           0.56        18
   macro avg       0.71      0.67      0.55        18
weighted avg       0.81      0.56      0.53        18

2022-12-18 23:47:57,062 INFO Predicting labels for 32 texts
2022-12-18 23:47:57,162 INFO Evaluating student test iter13 on 32 examples
2022-12-18 23:47:57,167 INFO student test iter13 performance: 25.00
2022-12-18 23:47:57,167 INFO student test iter13 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:47:57,167 INFO student test iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:47:57,167 INFO Student Dev performance on iter 13: 55.55555555555556
2022-12-18 23:47:57,167 INFO Student Test performance on iter 13: 25.0
2022-12-18 23:47:57,168 INFO 

	 *** Starting loop 14 ***
2022-12-18 23:47:57,168 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:47:57,168 INFO Downsampling 444 data
2022-12-18 23:47:57,169 INFO Adding Student as extra rule in Teacher
2022-12-18 23:47:57,169 INFO Getting rule predictions
2022-12-18 23:47:57,169 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:47:57,170 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:47:57,170 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:47:57,171 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:47:57,172 INFO Predicting labels for 741 texts
2022-12-18 23:47:57,289 INFO Predicting labels for 18 texts
2022-12-18 23:47:57,389 INFO Predicting labels for 444 texts
2022-12-18 23:47:57,495 INFO Training Rule Attention Network
2022-12-18 23:47:57,605 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:47:57,606 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:47:57,611 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:47:57,611 INFO 

		*** Training RAN ***
2022-12-18 23:48:00,513 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:00,515 INFO Predicting labels for 444 texts
2022-12-18 23:48:00,619 INFO There are 3/7 active rules
2022-12-18 23:48:00,619 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:00,623 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:00,716 INFO DONE, Getting attention scores...
2022-12-18 23:48:00,772 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:00,773 INFO Predicting labels for 18 texts
2022-12-18 23:48:00,876 INFO There are 7/7 active rules
2022-12-18 23:48:00,876 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:00,878 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:00,903 INFO DONE, Getting attention scores...
2022-12-18 23:48:00,962 INFO Evaluating teacher dev iter14 on 18 examples
2022-12-18 23:48:00,966 INFO teacher dev iter14 performance: 94.44
2022-12-18 23:48:00,966 INFO teacher dev iter14 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:00,967 INFO teacher dev iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:00,967 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:00,967 INFO Predicting labels for 32 texts
2022-12-18 23:48:01,069 INFO There are 7/7 active rules
2022-12-18 23:48:01,069 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:01,070 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:01,094 INFO DONE, Getting attention scores...
2022-12-18 23:48:01,149 INFO Evaluating teacher test iter14 on 32 examples
2022-12-18 23:48:01,153 INFO teacher test iter14 performance: 78.12
2022-12-18 23:48:01,153 INFO teacher test iter14 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:48:01,153 INFO teacher test iter14 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:48:01,154 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:01,157 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:01,159 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-18 23:48:01,162 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-18 23:48:01,162 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:01,833 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:03,073 INFO Predicting labels for 18 texts
2022-12-18 23:48:03,180 INFO Evaluating student dev iter14 on 18 examples
2022-12-18 23:48:03,184 INFO student dev iter14 performance: 61.11
2022-12-18 23:48:03,185 INFO student dev iter14 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:03,185 INFO student dev iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:03,185 INFO Predicting labels for 32 texts
2022-12-18 23:48:03,284 INFO Evaluating student test iter14 on 32 examples
2022-12-18 23:48:03,288 INFO student test iter14 performance: 25.00
2022-12-18 23:48:03,289 INFO student test iter14 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:48:03,289 INFO student test iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:48:03,289 INFO Student Dev performance on iter 14: 61.111111111111114
2022-12-18 23:48:03,289 INFO Student Test performance on iter 14: 25.0
2022-12-18 23:48:03,289 INFO 

	 *** Starting loop 15 ***
2022-12-18 23:48:03,289 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:03,289 INFO Downsampling 444 data
2022-12-18 23:48:03,290 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:03,290 INFO Getting rule predictions
2022-12-18 23:48:03,290 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:03,291 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:03,292 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:03,292 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:03,293 INFO Predicting labels for 741 texts
2022-12-18 23:48:03,401 INFO Predicting labels for 18 texts
2022-12-18 23:48:03,503 INFO Predicting labels for 444 texts
2022-12-18 23:48:03,608 INFO Training Rule Attention Network
2022-12-18 23:48:03,615 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:03,616 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:03,620 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:03,621 INFO 

		*** Training RAN ***
2022-12-18 23:48:06,457 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:06,458 INFO Predicting labels for 444 texts
2022-12-18 23:48:06,564 INFO There are 3/7 active rules
2022-12-18 23:48:06,564 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:06,569 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:06,656 INFO DONE, Getting attention scores...
2022-12-18 23:48:06,713 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:06,713 INFO Predicting labels for 18 texts
2022-12-18 23:48:06,814 INFO There are 7/7 active rules
2022-12-18 23:48:06,815 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:06,815 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:06,838 INFO DONE, Getting attention scores...
2022-12-18 23:48:06,897 INFO Evaluating teacher dev iter15 on 18 examples
2022-12-18 23:48:06,901 INFO teacher dev iter15 performance: 94.44
2022-12-18 23:48:06,901 INFO teacher dev iter15 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:06,901 INFO teacher dev iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:06,901 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:06,902 INFO Predicting labels for 32 texts
2022-12-18 23:48:07,005 INFO There are 7/7 active rules
2022-12-18 23:48:07,005 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:07,006 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:07,031 INFO DONE, Getting attention scores...
2022-12-18 23:48:07,085 INFO Evaluating teacher test iter15 on 32 examples
2022-12-18 23:48:07,089 INFO teacher test iter15 performance: 78.12
2022-12-18 23:48:07,089 INFO teacher test iter15 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:48:07,089 INFO teacher test iter15 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:48:07,090 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:07,093 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:07,095 INFO Balancing Pseudo Dataset to keep 474 items...
2022-12-18 23:48:07,098 INFO PSEUDO-DATASET:
474 examples
PSEUDO-LABELS:
1    237
0    237
Name: label, dtype: int64
2022-12-18 23:48:07,099 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:07,843 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:09,131 INFO Predicting labels for 18 texts
2022-12-18 23:48:10,263 INFO Evaluating student dev iter15 on 18 examples
2022-12-18 23:48:10,267 INFO student dev iter15 performance: 61.11
2022-12-18 23:48:10,268 INFO student dev iter15 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:10,268 INFO student dev iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:10,268 INFO Predicting labels for 32 texts
2022-12-18 23:48:10,370 INFO Evaluating student test iter15 on 32 examples
2022-12-18 23:48:10,374 INFO student test iter15 performance: 25.00
2022-12-18 23:48:10,375 INFO student test iter15 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:48:10,375 INFO student test iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:48:10,375 INFO Student Dev performance on iter 15: 61.111111111111114
2022-12-18 23:48:10,375 INFO Student Test performance on iter 15: 25.0
2022-12-18 23:48:10,375 INFO 

	 *** Starting loop 16 ***
2022-12-18 23:48:10,375 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:10,375 INFO Downsampling 444 data
2022-12-18 23:48:10,376 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:10,376 INFO Getting rule predictions
2022-12-18 23:48:10,376 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:10,377 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:10,378 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:10,378 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:10,379 INFO Predicting labels for 741 texts
2022-12-18 23:48:10,486 INFO Predicting labels for 18 texts
2022-12-18 23:48:10,585 INFO Predicting labels for 444 texts
2022-12-18 23:48:10,692 INFO Training Rule Attention Network
2022-12-18 23:48:10,699 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:10,700 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:10,704 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:10,705 INFO 

		*** Training RAN ***
2022-12-18 23:48:13,627 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:13,628 INFO Predicting labels for 444 texts
2022-12-18 23:48:13,734 INFO There are 3/7 active rules
2022-12-18 23:48:13,734 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:13,739 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:13,825 INFO DONE, Getting attention scores...
2022-12-18 23:48:13,881 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:13,882 INFO Predicting labels for 18 texts
2022-12-18 23:48:13,985 INFO There are 7/7 active rules
2022-12-18 23:48:13,985 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:13,986 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:14,009 INFO DONE, Getting attention scores...
2022-12-18 23:48:14,067 INFO Evaluating teacher dev iter16 on 18 examples
2022-12-18 23:48:14,071 INFO teacher dev iter16 performance: 94.44
2022-12-18 23:48:14,071 INFO teacher dev iter16 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:14,071 INFO teacher dev iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:14,072 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:14,072 INFO Predicting labels for 32 texts
2022-12-18 23:48:14,172 INFO There are 7/7 active rules
2022-12-18 23:48:14,173 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:14,173 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:14,197 INFO DONE, Getting attention scores...
2022-12-18 23:48:14,250 INFO Evaluating teacher test iter16 on 32 examples
2022-12-18 23:48:14,254 INFO teacher test iter16 performance: 78.12
2022-12-18 23:48:14,254 INFO teacher test iter16 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:48:14,254 INFO teacher test iter16 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:48:14,255 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:14,258 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:14,259 INFO Balancing Pseudo Dataset to keep 446 items...
2022-12-18 23:48:14,262 INFO PSEUDO-DATASET:
446 examples
PSEUDO-LABELS:
1    223
0    223
Name: label, dtype: int64
2022-12-18 23:48:14,263 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:14,990 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:16,193 INFO Predicting labels for 18 texts
2022-12-18 23:48:16,297 INFO Evaluating student dev iter16 on 18 examples
2022-12-18 23:48:16,301 INFO student dev iter16 performance: 61.11
2022-12-18 23:48:16,301 INFO student dev iter16 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:16,301 INFO student dev iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:16,302 INFO Predicting labels for 32 texts
2022-12-18 23:48:16,408 INFO Evaluating student test iter16 on 32 examples
2022-12-18 23:48:16,412 INFO student test iter16 performance: 25.00
2022-12-18 23:48:16,412 INFO student test iter16 confusion matrix:
[[ 6 24]
 [ 0  2]]
2022-12-18 23:48:16,413 INFO student test iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.20      0.33        30
           1       0.08      1.00      0.14         2

    accuracy                           0.25        32
   macro avg       0.54      0.60      0.24        32
weighted avg       0.94      0.25      0.32        32

2022-12-18 23:48:16,413 INFO Student Dev performance on iter 16: 61.111111111111114
2022-12-18 23:48:16,413 INFO Student Test performance on iter 16: 25.0
2022-12-18 23:48:16,413 INFO 

	 *** Starting loop 17 ***
2022-12-18 23:48:16,413 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:16,413 INFO Downsampling 444 data
2022-12-18 23:48:16,414 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:16,414 INFO Getting rule predictions
2022-12-18 23:48:16,414 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:16,415 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:16,415 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:16,416 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:16,417 INFO Predicting labels for 741 texts
2022-12-18 23:48:16,520 INFO Predicting labels for 18 texts
2022-12-18 23:48:16,623 INFO Predicting labels for 444 texts
2022-12-18 23:48:16,725 INFO Training Rule Attention Network
2022-12-18 23:48:16,732 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:16,733 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:16,737 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:16,738 INFO 

		*** Training RAN ***
2022-12-18 23:48:19,579 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:19,581 INFO Predicting labels for 444 texts
2022-12-18 23:48:19,696 INFO There are 3/7 active rules
2022-12-18 23:48:19,696 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:19,701 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:19,788 INFO DONE, Getting attention scores...
2022-12-18 23:48:19,845 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:19,845 INFO Predicting labels for 18 texts
2022-12-18 23:48:19,951 INFO There are 7/7 active rules
2022-12-18 23:48:19,952 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:19,952 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:20,088 INFO DONE, Getting attention scores...
2022-12-18 23:48:20,140 INFO Evaluating teacher dev iter17 on 18 examples
2022-12-18 23:48:20,144 INFO teacher dev iter17 performance: 94.44
2022-12-18 23:48:20,145 INFO teacher dev iter17 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:20,145 INFO teacher dev iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:20,145 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:20,145 INFO Predicting labels for 32 texts
2022-12-18 23:48:20,254 INFO There are 7/7 active rules
2022-12-18 23:48:20,254 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:20,255 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:20,279 INFO DONE, Getting attention scores...
2022-12-18 23:48:20,342 INFO Evaluating teacher test iter17 on 32 examples
2022-12-18 23:48:20,346 INFO teacher test iter17 performance: 81.25
2022-12-18 23:48:20,346 INFO teacher test iter17 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-18 23:48:20,346 INFO teacher test iter17 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-18 23:48:20,347 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:20,350 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:20,351 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-18 23:48:20,355 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-18 23:48:20,355 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:21,037 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:22,334 INFO Predicting labels for 18 texts
2022-12-18 23:48:22,456 INFO Evaluating student dev iter17 on 18 examples
2022-12-18 23:48:22,460 INFO student dev iter17 performance: 61.11
2022-12-18 23:48:22,461 INFO student dev iter17 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:22,461 INFO student dev iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:22,461 INFO Predicting labels for 32 texts
2022-12-18 23:48:22,567 INFO Evaluating student test iter17 on 32 examples
2022-12-18 23:48:22,571 INFO student test iter17 performance: 21.88
2022-12-18 23:48:22,571 INFO student test iter17 confusion matrix:
[[ 5 25]
 [ 0  2]]
2022-12-18 23:48:22,571 INFO student test iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.17      0.29        30
           1       0.07      1.00      0.14         2

    accuracy                           0.22        32
   macro avg       0.54      0.58      0.21        32
weighted avg       0.94      0.22      0.28        32

2022-12-18 23:48:22,571 INFO Student Dev performance on iter 17: 61.111111111111114
2022-12-18 23:48:22,572 INFO Student Test performance on iter 17: 21.875
2022-12-18 23:48:22,572 INFO 

	 *** Starting loop 18 ***
2022-12-18 23:48:22,572 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:22,572 INFO Downsampling 444 data
2022-12-18 23:48:22,572 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:22,573 INFO Getting rule predictions
2022-12-18 23:48:22,573 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:22,574 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:22,574 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:22,575 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:22,576 INFO Predicting labels for 741 texts
2022-12-18 23:48:22,682 INFO Predicting labels for 18 texts
2022-12-18 23:48:22,787 INFO Predicting labels for 444 texts
2022-12-18 23:48:23,937 INFO Training Rule Attention Network
2022-12-18 23:48:23,944 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:23,945 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:23,949 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:23,949 INFO 

		*** Training RAN ***
2022-12-18 23:48:26,736 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:26,737 INFO Predicting labels for 444 texts
2022-12-18 23:48:26,850 INFO There are 3/7 active rules
2022-12-18 23:48:26,850 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:26,854 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:26,938 INFO DONE, Getting attention scores...
2022-12-18 23:48:26,995 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:26,995 INFO Predicting labels for 18 texts
2022-12-18 23:48:27,098 INFO There are 7/7 active rules
2022-12-18 23:48:27,098 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:27,099 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:27,123 INFO DONE, Getting attention scores...
2022-12-18 23:48:27,177 INFO Evaluating teacher dev iter18 on 18 examples
2022-12-18 23:48:27,181 INFO teacher dev iter18 performance: 94.44
2022-12-18 23:48:27,182 INFO teacher dev iter18 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:27,182 INFO teacher dev iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:27,182 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:27,182 INFO Predicting labels for 32 texts
2022-12-18 23:48:27,290 INFO There are 7/7 active rules
2022-12-18 23:48:27,290 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:27,291 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:27,316 INFO DONE, Getting attention scores...
2022-12-18 23:48:27,370 INFO Evaluating teacher test iter18 on 32 examples
2022-12-18 23:48:27,374 INFO teacher test iter18 performance: 78.12
2022-12-18 23:48:27,375 INFO teacher test iter18 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:48:27,375 INFO teacher test iter18 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:48:27,375 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:27,379 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:27,380 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-18 23:48:27,384 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-18 23:48:27,384 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:30,281 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:31,444 INFO Predicting labels for 18 texts
2022-12-18 23:48:31,552 INFO Evaluating student dev iter18 on 18 examples
2022-12-18 23:48:31,556 INFO student dev iter18 performance: 61.11
2022-12-18 23:48:31,556 INFO student dev iter18 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:31,557 INFO student dev iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:31,557 INFO Predicting labels for 32 texts
2022-12-18 23:48:31,659 INFO Evaluating student test iter18 on 32 examples
2022-12-18 23:48:31,663 INFO student test iter18 performance: 21.88
2022-12-18 23:48:31,664 INFO student test iter18 confusion matrix:
[[ 5 25]
 [ 0  2]]
2022-12-18 23:48:31,664 INFO student test iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.17      0.29        30
           1       0.07      1.00      0.14         2

    accuracy                           0.22        32
   macro avg       0.54      0.58      0.21        32
weighted avg       0.94      0.22      0.28        32

2022-12-18 23:48:31,664 INFO Student Dev performance on iter 18: 61.111111111111114
2022-12-18 23:48:31,664 INFO Student Test performance on iter 18: 21.875
2022-12-18 23:48:31,664 INFO 

	 *** Starting loop 19 ***
2022-12-18 23:48:31,664 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:31,664 INFO Downsampling 444 data
2022-12-18 23:48:31,665 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:31,665 INFO Getting rule predictions
2022-12-18 23:48:31,665 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:31,666 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:31,666 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:31,667 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:31,668 INFO Predicting labels for 741 texts
2022-12-18 23:48:31,776 INFO Predicting labels for 18 texts
2022-12-18 23:48:31,877 INFO Predicting labels for 444 texts
2022-12-18 23:48:31,978 INFO Training Rule Attention Network
2022-12-18 23:48:31,989 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:31,990 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:31,994 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:31,994 INFO 

		*** Training RAN ***
2022-12-18 23:48:34,829 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:34,830 INFO Predicting labels for 444 texts
2022-12-18 23:48:34,932 INFO There are 3/7 active rules
2022-12-18 23:48:34,932 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:34,936 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:35,020 INFO DONE, Getting attention scores...
2022-12-18 23:48:35,084 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:35,084 INFO Predicting labels for 18 texts
2022-12-18 23:48:35,187 INFO There are 7/7 active rules
2022-12-18 23:48:35,187 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:35,188 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:35,211 INFO DONE, Getting attention scores...
2022-12-18 23:48:35,266 INFO Evaluating teacher dev iter19 on 18 examples
2022-12-18 23:48:35,270 INFO teacher dev iter19 performance: 94.44
2022-12-18 23:48:35,271 INFO teacher dev iter19 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:35,271 INFO teacher dev iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:35,271 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:35,271 INFO Predicting labels for 32 texts
2022-12-18 23:48:35,375 INFO There are 7/7 active rules
2022-12-18 23:48:35,376 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:35,377 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:35,402 INFO DONE, Getting attention scores...
2022-12-18 23:48:35,455 INFO Evaluating teacher test iter19 on 32 examples
2022-12-18 23:48:35,459 INFO teacher test iter19 performance: 78.12
2022-12-18 23:48:35,460 INFO teacher test iter19 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:48:35,460 INFO teacher test iter19 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:48:35,460 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:35,463 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:35,465 INFO Balancing Pseudo Dataset to keep 448 items...
2022-12-18 23:48:35,468 INFO PSEUDO-DATASET:
448 examples
PSEUDO-LABELS:
1    224
0    224
Name: label, dtype: int64
2022-12-18 23:48:35,469 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:36,136 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:38,304 INFO Predicting labels for 18 texts
2022-12-18 23:48:38,407 INFO Evaluating student dev iter19 on 18 examples
2022-12-18 23:48:38,411 INFO student dev iter19 performance: 61.11
2022-12-18 23:48:38,412 INFO student dev iter19 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:38,412 INFO student dev iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:38,412 INFO Predicting labels for 32 texts
2022-12-18 23:48:38,514 INFO Evaluating student test iter19 on 32 examples
2022-12-18 23:48:38,518 INFO student test iter19 performance: 21.88
2022-12-18 23:48:38,519 INFO student test iter19 confusion matrix:
[[ 5 25]
 [ 0  2]]
2022-12-18 23:48:38,519 INFO student test iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.17      0.29        30
           1       0.07      1.00      0.14         2

    accuracy                           0.22        32
   macro avg       0.54      0.58      0.21        32
weighted avg       0.94      0.22      0.28        32

2022-12-18 23:48:38,519 INFO Student Dev performance on iter 19: 61.111111111111114
2022-12-18 23:48:38,519 INFO Student Test performance on iter 19: 21.875
2022-12-18 23:48:38,519 INFO 

	 *** Starting loop 20 ***
2022-12-18 23:48:38,519 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:38,519 INFO Downsampling 444 data
2022-12-18 23:48:38,520 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:38,520 INFO Getting rule predictions
2022-12-18 23:48:38,520 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:38,521 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:38,521 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:38,522 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:38,523 INFO Predicting labels for 741 texts
2022-12-18 23:48:38,732 INFO Predicting labels for 18 texts
2022-12-18 23:48:38,839 INFO Predicting labels for 444 texts
2022-12-18 23:48:38,950 INFO Training Rule Attention Network
2022-12-18 23:48:38,957 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:38,957 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:38,961 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:38,962 INFO 

		*** Training RAN ***
2022-12-18 23:48:41,846 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:41,847 INFO Predicting labels for 444 texts
2022-12-18 23:48:41,954 INFO There are 3/7 active rules
2022-12-18 23:48:41,955 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:41,959 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:42,046 INFO DONE, Getting attention scores...
2022-12-18 23:48:42,102 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:42,102 INFO Predicting labels for 18 texts
2022-12-18 23:48:42,206 INFO There are 7/7 active rules
2022-12-18 23:48:42,206 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:42,207 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:42,233 INFO DONE, Getting attention scores...
2022-12-18 23:48:42,295 INFO Evaluating teacher dev iter20 on 18 examples
2022-12-18 23:48:42,299 INFO teacher dev iter20 performance: 94.44
2022-12-18 23:48:42,300 INFO teacher dev iter20 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:42,300 INFO teacher dev iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:42,300 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:42,300 INFO Predicting labels for 32 texts
2022-12-18 23:48:42,409 INFO There are 7/7 active rules
2022-12-18 23:48:42,409 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:42,410 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:42,434 INFO DONE, Getting attention scores...
2022-12-18 23:48:42,487 INFO Evaluating teacher test iter20 on 32 examples
2022-12-18 23:48:42,492 INFO teacher test iter20 performance: 78.12
2022-12-18 23:48:42,492 INFO teacher test iter20 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:48:42,492 INFO teacher test iter20 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:48:42,493 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:42,496 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:42,497 INFO Balancing Pseudo Dataset to keep 492 items...
2022-12-18 23:48:42,501 INFO PSEUDO-DATASET:
492 examples
PSEUDO-LABELS:
1    246
0    246
Name: label, dtype: int64
2022-12-18 23:48:42,502 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:43,268 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:44,485 INFO Predicting labels for 18 texts
2022-12-18 23:48:44,592 INFO Evaluating student dev iter20 on 18 examples
2022-12-18 23:48:44,597 INFO student dev iter20 performance: 61.11
2022-12-18 23:48:44,597 INFO student dev iter20 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:44,598 INFO student dev iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:44,598 INFO Predicting labels for 32 texts
2022-12-18 23:48:44,704 INFO Evaluating student test iter20 on 32 examples
2022-12-18 23:48:44,708 INFO student test iter20 performance: 21.88
2022-12-18 23:48:44,709 INFO student test iter20 confusion matrix:
[[ 5 25]
 [ 0  2]]
2022-12-18 23:48:44,709 INFO student test iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.17      0.29        30
           1       0.07      1.00      0.14         2

    accuracy                           0.22        32
   macro avg       0.54      0.58      0.21        32
weighted avg       0.94      0.22      0.28        32

2022-12-18 23:48:44,709 INFO Student Dev performance on iter 20: 61.111111111111114
2022-12-18 23:48:44,709 INFO Student Test performance on iter 20: 21.875
2022-12-18 23:48:44,709 INFO 

	 *** Starting loop 21 ***
2022-12-18 23:48:44,709 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:44,709 INFO Downsampling 444 data
2022-12-18 23:48:44,710 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:44,710 INFO Getting rule predictions
2022-12-18 23:48:44,710 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:44,713 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:44,713 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:44,716 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:44,719 INFO Predicting labels for 741 texts
2022-12-18 23:48:44,823 INFO Predicting labels for 18 texts
2022-12-18 23:48:44,925 INFO Predicting labels for 444 texts
2022-12-18 23:48:45,024 INFO Training Rule Attention Network
2022-12-18 23:48:45,032 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:45,032 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:45,037 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:45,037 INFO 

		*** Training RAN ***
2022-12-18 23:48:47,958 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:47,960 INFO Predicting labels for 444 texts
2022-12-18 23:48:48,066 INFO There are 3/7 active rules
2022-12-18 23:48:48,066 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:48,070 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:48,155 INFO DONE, Getting attention scores...
2022-12-18 23:48:48,212 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:48,212 INFO Predicting labels for 18 texts
2022-12-18 23:48:48,318 INFO There are 7/7 active rules
2022-12-18 23:48:48,319 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:48,319 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:48,342 INFO DONE, Getting attention scores...
2022-12-18 23:48:48,397 INFO Evaluating teacher dev iter21 on 18 examples
2022-12-18 23:48:48,401 INFO teacher dev iter21 performance: 94.44
2022-12-18 23:48:48,402 INFO teacher dev iter21 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:48,402 INFO teacher dev iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:48,402 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:48,402 INFO Predicting labels for 32 texts
2022-12-18 23:48:48,514 INFO There are 7/7 active rules
2022-12-18 23:48:48,514 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:48,515 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:48,540 INFO DONE, Getting attention scores...
2022-12-18 23:48:48,593 INFO Evaluating teacher test iter21 on 32 examples
2022-12-18 23:48:48,598 INFO teacher test iter21 performance: 78.12
2022-12-18 23:48:48,598 INFO teacher test iter21 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:48:48,598 INFO teacher test iter21 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:48:48,598 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:48,601 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:48,602 INFO Balancing Pseudo Dataset to keep 476 items...
2022-12-18 23:48:48,606 INFO PSEUDO-DATASET:
476 examples
PSEUDO-LABELS:
1    238
0    238
Name: label, dtype: int64
2022-12-18 23:48:48,606 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:50,452 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:51,741 INFO Predicting labels for 18 texts
2022-12-18 23:48:51,846 INFO Evaluating student dev iter21 on 18 examples
2022-12-18 23:48:51,850 INFO student dev iter21 performance: 61.11
2022-12-18 23:48:51,851 INFO student dev iter21 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:51,851 INFO student dev iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:51,851 INFO Predicting labels for 32 texts
2022-12-18 23:48:51,958 INFO Evaluating student test iter21 on 32 examples
2022-12-18 23:48:51,962 INFO student test iter21 performance: 21.88
2022-12-18 23:48:51,962 INFO student test iter21 confusion matrix:
[[ 5 25]
 [ 0  2]]
2022-12-18 23:48:51,963 INFO student test iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.17      0.29        30
           1       0.07      1.00      0.14         2

    accuracy                           0.22        32
   macro avg       0.54      0.58      0.21        32
weighted avg       0.94      0.22      0.28        32

2022-12-18 23:48:51,963 INFO Student Dev performance on iter 21: 61.111111111111114
2022-12-18 23:48:51,963 INFO Student Test performance on iter 21: 21.875
2022-12-18 23:48:51,963 INFO 

	 *** Starting loop 22 ***
2022-12-18 23:48:51,963 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:51,963 INFO Downsampling 444 data
2022-12-18 23:48:51,964 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:51,964 INFO Getting rule predictions
2022-12-18 23:48:51,964 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:51,965 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:51,965 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:51,966 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:51,967 INFO Predicting labels for 741 texts
2022-12-18 23:48:52,077 INFO Predicting labels for 18 texts
2022-12-18 23:48:52,179 INFO Predicting labels for 444 texts
2022-12-18 23:48:52,289 INFO Training Rule Attention Network
2022-12-18 23:48:52,296 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:52,297 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:52,301 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:52,301 INFO 

		*** Training RAN ***
2022-12-18 23:48:55,231 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:55,232 INFO Predicting labels for 444 texts
2022-12-18 23:48:55,336 INFO There are 3/7 active rules
2022-12-18 23:48:55,336 INFO Coverage: 100.0% (444/444)
2022-12-18 23:48:55,340 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:48:55,432 INFO DONE, Getting attention scores...
2022-12-18 23:48:55,487 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:55,488 INFO Predicting labels for 18 texts
2022-12-18 23:48:55,590 INFO There are 7/7 active rules
2022-12-18 23:48:55,591 INFO Coverage: 100.0% (18/18)
2022-12-18 23:48:55,591 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:48:55,614 INFO DONE, Getting attention scores...
2022-12-18 23:48:55,672 INFO Evaluating teacher dev iter22 on 18 examples
2022-12-18 23:48:55,676 INFO teacher dev iter22 performance: 94.44
2022-12-18 23:48:55,676 INFO teacher dev iter22 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:48:55,676 INFO teacher dev iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:48:55,676 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:48:55,676 INFO Predicting labels for 32 texts
2022-12-18 23:48:55,779 INFO There are 7/7 active rules
2022-12-18 23:48:55,779 INFO Coverage: 100.0% (32/32)
2022-12-18 23:48:55,780 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:48:55,804 INFO DONE, Getting attention scores...
2022-12-18 23:48:55,858 INFO Evaluating teacher test iter22 on 32 examples
2022-12-18 23:48:55,863 INFO teacher test iter22 performance: 78.12
2022-12-18 23:48:55,863 INFO teacher test iter22 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:48:55,864 INFO teacher test iter22 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:48:55,864 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:48:55,867 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:48:55,868 INFO Balancing Pseudo Dataset to keep 512 items...
2022-12-18 23:48:55,873 INFO PSEUDO-DATASET:
512 examples
PSEUDO-LABELS:
1    256
0    256
Name: label, dtype: int64
2022-12-18 23:48:55,873 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:48:57,625 INFO fine-tuning the student on clean labeled data
2022-12-18 23:48:58,765 INFO Predicting labels for 18 texts
2022-12-18 23:48:58,870 INFO Evaluating student dev iter22 on 18 examples
2022-12-18 23:48:58,875 INFO student dev iter22 performance: 61.11
2022-12-18 23:48:58,875 INFO student dev iter22 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:48:58,875 INFO student dev iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:48:58,875 INFO Predicting labels for 32 texts
2022-12-18 23:48:58,981 INFO Evaluating student test iter22 on 32 examples
2022-12-18 23:48:58,985 INFO student test iter22 performance: 21.88
2022-12-18 23:48:58,986 INFO student test iter22 confusion matrix:
[[ 5 25]
 [ 0  2]]
2022-12-18 23:48:58,987 INFO student test iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.17      0.29        30
           1       0.07      1.00      0.14         2

    accuracy                           0.22        32
   macro avg       0.54      0.58      0.21        32
weighted avg       0.94      0.22      0.28        32

2022-12-18 23:48:58,987 INFO Student Dev performance on iter 22: 61.111111111111114
2022-12-18 23:48:58,987 INFO Student Test performance on iter 22: 21.875
2022-12-18 23:48:58,987 INFO 

	 *** Starting loop 23 ***
2022-12-18 23:48:58,988 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:48:58,988 INFO Downsampling 444 data
2022-12-18 23:48:58,989 INFO Adding Student as extra rule in Teacher
2022-12-18 23:48:58,989 INFO Getting rule predictions
2022-12-18 23:48:58,989 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:48:58,991 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:48:58,991 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:48:58,991 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:48:58,992 INFO Predicting labels for 741 texts
2022-12-18 23:48:59,097 INFO Predicting labels for 18 texts
2022-12-18 23:48:59,199 INFO Predicting labels for 444 texts
2022-12-18 23:48:59,303 INFO Training Rule Attention Network
2022-12-18 23:48:59,310 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:48:59,311 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:48:59,315 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:48:59,315 INFO 

		*** Training RAN ***
2022-12-18 23:49:02,245 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:49:02,247 INFO Predicting labels for 444 texts
2022-12-18 23:49:02,484 INFO There are 3/7 active rules
2022-12-18 23:49:02,484 INFO Coverage: 100.0% (444/444)
2022-12-18 23:49:02,488 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:49:02,578 INFO DONE, Getting attention scores...
2022-12-18 23:49:02,638 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:49:02,638 INFO Predicting labels for 18 texts
2022-12-18 23:49:02,747 INFO There are 7/7 active rules
2022-12-18 23:49:02,747 INFO Coverage: 100.0% (18/18)
2022-12-18 23:49:02,748 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:49:02,773 INFO DONE, Getting attention scores...
2022-12-18 23:49:02,829 INFO Evaluating teacher dev iter23 on 18 examples
2022-12-18 23:49:02,833 INFO teacher dev iter23 performance: 94.44
2022-12-18 23:49:02,833 INFO teacher dev iter23 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:49:02,833 INFO teacher dev iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:49:02,833 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:49:02,834 INFO Predicting labels for 32 texts
2022-12-18 23:49:02,935 INFO There are 7/7 active rules
2022-12-18 23:49:02,935 INFO Coverage: 100.0% (32/32)
2022-12-18 23:49:02,936 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:49:02,959 INFO DONE, Getting attention scores...
2022-12-18 23:49:03,020 INFO Evaluating teacher test iter23 on 32 examples
2022-12-18 23:49:03,024 INFO teacher test iter23 performance: 81.25
2022-12-18 23:49:03,024 INFO teacher test iter23 confusion matrix:
[[25  5]
 [ 1  1]]
2022-12-18 23:49:03,024 INFO teacher test iter23 report:
              precision    recall  f1-score   support

           0       0.96      0.83      0.89        30
           1       0.17      0.50      0.25         2

    accuracy                           0.81        32
   macro avg       0.56      0.67      0.57        32
weighted avg       0.91      0.81      0.85        32

2022-12-18 23:49:03,025 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:49:03,027 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:49:03,029 INFO Balancing Pseudo Dataset to keep 492 items...
2022-12-18 23:49:03,032 INFO PSEUDO-DATASET:
492 examples
PSEUDO-LABELS:
1    246
0    246
Name: label, dtype: int64
2022-12-18 23:49:03,032 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:49:03,798 INFO fine-tuning the student on clean labeled data
2022-12-18 23:49:05,059 INFO Predicting labels for 18 texts
2022-12-18 23:49:05,171 INFO Evaluating student dev iter23 on 18 examples
2022-12-18 23:49:05,175 INFO student dev iter23 performance: 61.11
2022-12-18 23:49:05,176 INFO student dev iter23 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:49:05,176 INFO student dev iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:49:05,176 INFO Predicting labels for 32 texts
2022-12-18 23:49:05,281 INFO Evaluating student test iter23 on 32 examples
2022-12-18 23:49:05,285 INFO student test iter23 performance: 21.88
2022-12-18 23:49:05,285 INFO student test iter23 confusion matrix:
[[ 5 25]
 [ 0  2]]
2022-12-18 23:49:05,285 INFO student test iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.17      0.29        30
           1       0.07      1.00      0.14         2

    accuracy                           0.22        32
   macro avg       0.54      0.58      0.21        32
weighted avg       0.94      0.22      0.28        32

2022-12-18 23:49:05,285 INFO Student Dev performance on iter 23: 61.111111111111114
2022-12-18 23:49:05,285 INFO Student Test performance on iter 23: 21.875
2022-12-18 23:49:05,286 INFO 

	 *** Starting loop 24 ***
2022-12-18 23:49:05,286 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:49:05,286 INFO Downsampling 444 data
2022-12-18 23:49:05,287 INFO Adding Student as extra rule in Teacher
2022-12-18 23:49:05,287 INFO Getting rule predictions
2022-12-18 23:49:05,287 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:49:05,288 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:49:05,288 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:49:05,289 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:49:05,290 INFO Predicting labels for 741 texts
2022-12-18 23:49:05,397 INFO Predicting labels for 18 texts
2022-12-18 23:49:05,497 INFO Predicting labels for 444 texts
2022-12-18 23:49:05,599 INFO Training Rule Attention Network
2022-12-18 23:49:05,608 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:49:05,609 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:49:05,613 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:49:05,613 INFO 

		*** Training RAN ***
2022-12-18 23:49:08,535 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:49:08,536 INFO Predicting labels for 444 texts
2022-12-18 23:49:08,640 INFO There are 3/7 active rules
2022-12-18 23:49:08,640 INFO Coverage: 100.0% (444/444)
2022-12-18 23:49:08,645 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:49:08,732 INFO DONE, Getting attention scores...
2022-12-18 23:49:08,789 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:49:08,789 INFO Predicting labels for 18 texts
2022-12-18 23:49:08,892 INFO There are 7/7 active rules
2022-12-18 23:49:08,892 INFO Coverage: 100.0% (18/18)
2022-12-18 23:49:08,893 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:49:08,917 INFO DONE, Getting attention scores...
2022-12-18 23:49:08,975 INFO Evaluating teacher dev iter24 on 18 examples
2022-12-18 23:49:08,979 INFO teacher dev iter24 performance: 94.44
2022-12-18 23:49:08,979 INFO teacher dev iter24 confusion matrix:
[[11  1]
 [ 0  6]]
2022-12-18 23:49:08,979 INFO teacher dev iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.92      0.96        12
           1       0.86      1.00      0.92         6

    accuracy                           0.94        18
   macro avg       0.93      0.96      0.94        18
weighted avg       0.95      0.94      0.95        18

2022-12-18 23:49:08,979 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:49:08,979 INFO Predicting labels for 32 texts
2022-12-18 23:49:09,081 INFO There are 7/7 active rules
2022-12-18 23:49:09,081 INFO Coverage: 100.0% (32/32)
2022-12-18 23:49:09,082 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:49:09,104 INFO DONE, Getting attention scores...
2022-12-18 23:49:09,156 INFO Evaluating teacher test iter24 on 32 examples
2022-12-18 23:49:09,160 INFO teacher test iter24 performance: 78.12
2022-12-18 23:49:09,161 INFO teacher test iter24 confusion matrix:
[[24  6]
 [ 1  1]]
2022-12-18 23:49:09,161 INFO teacher test iter24 report:
              precision    recall  f1-score   support

           0       0.96      0.80      0.87        30
           1       0.14      0.50      0.22         2

    accuracy                           0.78        32
   macro avg       0.55      0.65      0.55        32
weighted avg       0.91      0.78      0.83        32

2022-12-18 23:49:09,161 INFO Saving attention scores at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_dump
2022-12-18 23:49:09,164 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:49:09,165 INFO Balancing Pseudo Dataset to keep 500 items...
2022-12-18 23:49:09,168 INFO PSEUDO-DATASET:
500 examples
PSEUDO-LABELS:
1    250
0    250
Name: label, dtype: int64
2022-12-18 23:49:09,168 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:49:10,106 INFO fine-tuning the student on clean labeled data
2022-12-18 23:49:11,364 INFO Predicting labels for 18 texts
2022-12-18 23:49:11,489 INFO Evaluating student dev iter24 on 18 examples
2022-12-18 23:49:11,493 INFO student dev iter24 performance: 61.11
2022-12-18 23:49:11,494 INFO student dev iter24 confusion matrix:
[[5 7]
 [0 6]]
2022-12-18 23:49:11,494 INFO student dev iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.46      1.00      0.63         6

    accuracy                           0.61        18
   macro avg       0.73      0.71      0.61        18
weighted avg       0.82      0.61      0.60        18

2022-12-18 23:49:11,494 INFO Predicting labels for 32 texts
2022-12-18 23:49:11,602 INFO Evaluating student test iter24 on 32 examples
2022-12-18 23:49:11,606 INFO student test iter24 performance: 21.88
2022-12-18 23:49:11,607 INFO student test iter24 confusion matrix:
[[ 5 25]
 [ 0  2]]
2022-12-18 23:49:11,607 INFO student test iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.17      0.29        30
           1       0.07      1.00      0.14         2

    accuracy                           0.22        32
   macro avg       0.54      0.58      0.21        32
weighted avg       0.94      0.22      0.28        32

2022-12-18 23:49:11,607 INFO Student Dev performance on iter 24: 61.111111111111114
2022-12-18 23:49:11,607 INFO Student Test performance on iter 24: 21.875
2022-12-18 23:49:11,607 INFO Final Results
2022-12-18 23:49:11,607 INFO TEACHER PERFORMANCES:
0:	94.44	81.25
1:	94.44	81.25
2:	94.44	78.12
3:	94.44	78.12
4:	94.44	78.12
5:	94.44	78.12
6:	94.44	78.12
7:	94.44	78.12
8:	94.44	78.12
9:	94.44	78.12
10:	94.44	78.12
11:	94.44	78.12
12:	94.44	78.12
13:	94.44	78.12
14:	94.44	78.12
15:	94.44	78.12
16:	94.44	78.12
17:	94.44	78.12
18:	94.44	81.25
19:	94.44	78.12
20:	94.44	78.12
21:	94.44	78.12
22:	94.44	78.12
23:	94.44	78.12
24:	94.44	81.25
25:	94.44	78.12
2022-12-18 23:49:11,607 INFO STUDENT PERFORMANCES:
0:	77.78	71.88
1:	77.78	56.25
2:	66.67	43.75
3:	66.67	31.25
4:	66.67	28.12
5:	61.11	25.00
6:	61.11	25.00
7:	55.56	25.00
8:	55.56	25.00
9:	55.56	25.00
10:	55.56	25.00
11:	55.56	25.00
12:	55.56	25.00
13:	55.56	25.00
14:	55.56	25.00
15:	61.11	25.00
16:	61.11	25.00
17:	61.11	25.00
18:	61.11	21.88
19:	61.11	21.88
20:	61.11	21.88
21:	61.11	21.88
22:	61.11	21.88
23:	61.11	21.88
24:	61.11	21.88
25:	61.11	21.88
2022-12-18 23:49:11,608 INFO BEST DEV weighted_acc = 77.778 for epoch 1
2022-12-18 23:49:11,608 INFO FINAL TEST weighted_acc = 56.250 for epoch 1 (max=71.88 for epoch 0)
2022-12-18 23:49:11,608 INFO Saving student_last to ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/student_last
2022-12-18 23:49:11,608 INFO Saving model at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/student_last/final_model.h5
2022-12-18 23:49:11,616 INFO Saving teacher at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_last
2022-12-18 23:49:11,617 INFO Saving rule attention network at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/teacher_last/rule_attention_network.h5
2022-12-18 23:49:11,624 INFO 	*** Final Results ***
2022-12-18 23:49:11,624 INFO 
student_train:	{'dev_loss': 0.46270549297332764}
2022-12-18 23:49:11,624 INFO 
supervised_student_dev:	{'acc': 77.77777777777779, 'weighted_acc': 77.77777777777779, 'prec': 76.78571428571428, 'rec': 70.83333333333333, 'f1': 72.3076923076923, 'weighted_f1': 72.3076923076923, 'ignored': 0, 'total': 18, 'perf': 77.77777777777779}
2022-12-18 23:49:11,625 INFO 
supervised_student_test:	{'acc': 71.875, 'weighted_acc': 71.875, 'prec': 53.3816425120773, 'rec': 61.66666666666667, 'f1': 50.60034305317325, 'weighted_f1': 50.60034305317325, 'ignored': 0, 'total': 32, 'perf': 71.875}
2022-12-18 23:49:11,625 INFO 
teacher_train:	{'acc': 88.66396761133603, 'weighted_acc': 88.66396761133603, 'prec': 88.67823765020026, 'rec': 88.38102808691045, 'f1': 88.5055178832602, 'weighted_f1': 88.5055178832602, 'ignored': 0, 'total': 741, 'perf': 88.66396761133603}
2022-12-18 23:49:11,625 INFO 
teacher_dev:	{'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}
2022-12-18 23:49:11,625 INFO 
teacher_test:	{'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}
2022-12-18 23:49:11,625 INFO 
teacher_train_iter:	[{'acc': 88.66396761133603, 'weighted_acc': 88.66396761133603, 'prec': 88.67823765020026, 'rec': 88.38102808691045, 'f1': 88.5055178832602, 'weighted_f1': 88.5055178832602, 'ignored': 0, 'total': 741, 'perf': 88.66396761133603}]
2022-12-18 23:49:11,625 INFO 
teacher_dev_iter:	[{'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}, {'acc': 94.44444444444444, 'weighted_acc': 94.44444444444444, 'prec': 92.85714285714286, 'rec': 95.83333333333333, 'f1': 93.9799331103679, 'weighted_f1': 93.9799331103679, 'ignored': 0, 'total': 18, 'perf': 94.44444444444444}]
2022-12-18 23:49:11,626 INFO 
teacher_test_iter:	[{'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 81.25, 'weighted_acc': 81.25, 'prec': 56.41025641025641, 'rec': 66.66666666666667, 'f1': 57.14285714285714, 'weighted_f1': 57.14285714285714, 'ignored': 0, 'total': 32, 'perf': 81.25}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 55.14285714285714, 'rec': 65.0, 'f1': 54.747474747474755, 'weighted_f1': 54.747474747474755, 'ignored': 0, 'total': 32, 'perf': 78.125}]
2022-12-18 23:49:11,626 INFO 
student_train_iter:	[{'dev_loss': 0.46270549297332764}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]
2022-12-18 23:49:11,627 INFO 
student_dev_iter:	[{'acc': 77.77777777777779, 'weighted_acc': 77.77777777777779, 'prec': 76.78571428571428, 'rec': 70.83333333333333, 'f1': 72.3076923076923, 'weighted_f1': 72.3076923076923, 'ignored': 0, 'total': 18, 'perf': 77.77777777777779}, {'acc': 77.77777777777779, 'weighted_acc': 77.77777777777779, 'prec': 80.0, 'rec': 83.33333333333333, 'f1': 77.49999999999999, 'weighted_f1': 77.49999999999999, 'ignored': 0, 'total': 18, 'perf': 77.77777777777779}, {'acc': 66.66666666666666, 'weighted_acc': 66.66666666666666, 'prec': 75.0, 'rec': 75.0, 'f1': 66.66666666666666, 'weighted_f1': 66.66666666666666, 'ignored': 0, 'total': 18, 'perf': 66.66666666666666}, {'acc': 66.66666666666666, 'weighted_acc': 66.66666666666666, 'prec': 75.0, 'rec': 75.0, 'f1': 66.66666666666666, 'weighted_f1': 66.66666666666666, 'ignored': 0, 'total': 18, 'perf': 66.66666666666666}, {'acc': 66.66666666666666, 'weighted_acc': 66.66666666666666, 'prec': 75.0, 'rec': 75.0, 'f1': 66.66666666666666, 'weighted_f1': 66.66666666666666, 'ignored': 0, 'total': 18, 'perf': 66.66666666666666}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 55.55555555555556, 'weighted_acc': 55.55555555555556, 'prec': 71.42857142857143, 'rec': 66.66666666666666, 'f1': 55.00000000000001, 'weighted_f1': 55.00000000000001, 'ignored': 0, 'total': 18, 'perf': 55.55555555555556}, {'acc': 55.55555555555556, 'weighted_acc': 55.55555555555556, 'prec': 71.42857142857143, 'rec': 66.66666666666666, 'f1': 55.00000000000001, 'weighted_f1': 55.00000000000001, 'ignored': 0, 'total': 18, 'perf': 55.55555555555556}, {'acc': 55.55555555555556, 'weighted_acc': 55.55555555555556, 'prec': 71.42857142857143, 'rec': 66.66666666666666, 'f1': 55.00000000000001, 'weighted_f1': 55.00000000000001, 'ignored': 0, 'total': 18, 'perf': 55.55555555555556}, {'acc': 55.55555555555556, 'weighted_acc': 55.55555555555556, 'prec': 71.42857142857143, 'rec': 66.66666666666666, 'f1': 55.00000000000001, 'weighted_f1': 55.00000000000001, 'ignored': 0, 'total': 18, 'perf': 55.55555555555556}, {'acc': 55.55555555555556, 'weighted_acc': 55.55555555555556, 'prec': 71.42857142857143, 'rec': 66.66666666666666, 'f1': 55.00000000000001, 'weighted_f1': 55.00000000000001, 'ignored': 0, 'total': 18, 'perf': 55.55555555555556}, {'acc': 55.55555555555556, 'weighted_acc': 55.55555555555556, 'prec': 71.42857142857143, 'rec': 66.66666666666666, 'f1': 55.00000000000001, 'weighted_f1': 55.00000000000001, 'ignored': 0, 'total': 18, 'perf': 55.55555555555556}, {'acc': 55.55555555555556, 'weighted_acc': 55.55555555555556, 'prec': 71.42857142857143, 'rec': 66.66666666666666, 'f1': 55.00000000000001, 'weighted_f1': 55.00000000000001, 'ignored': 0, 'total': 18, 'perf': 55.55555555555556}, {'acc': 55.55555555555556, 'weighted_acc': 55.55555555555556, 'prec': 71.42857142857143, 'rec': 66.66666666666666, 'f1': 55.00000000000001, 'weighted_f1': 55.00000000000001, 'ignored': 0, 'total': 18, 'perf': 55.55555555555556}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}, {'acc': 61.111111111111114, 'weighted_acc': 61.111111111111114, 'prec': 73.07692307692308, 'rec': 70.83333333333334, 'f1': 60.9907120743034, 'weighted_f1': 60.9907120743034, 'ignored': 0, 'total': 18, 'perf': 61.111111111111114}]
2022-12-18 23:49:11,628 INFO 
student_test_iter:	[{'acc': 71.875, 'weighted_acc': 71.875, 'prec': 53.3816425120773, 'rec': 61.66666666666667, 'f1': 50.60034305317325, 'weighted_f1': 50.60034305317325, 'ignored': 0, 'total': 32, 'perf': 71.875}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 56.25, 'rec': 76.66666666666666, 'f1': 45.893719806763286, 'weighted_f1': 45.893719806763286, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 43.75, 'weighted_acc': 43.75, 'prec': 55.00000000000001, 'rec': 70.0, 'f1': 37.66233766233766, 'weighted_f1': 37.66233766233766, 'ignored': 0, 'total': 32, 'perf': 43.75}, {'acc': 31.25, 'weighted_acc': 31.25, 'prec': 54.166666666666664, 'rec': 63.33333333333333, 'f1': 28.744939271255067, 'weighted_f1': 28.744939271255067, 'ignored': 0, 'total': 32, 'perf': 31.25}, {'acc': 28.125, 'weighted_acc': 28.125, 'prec': 54.0, 'rec': 61.66666666666667, 'f1': 26.32632632632632, 'weighted_f1': 26.32632632632632, 'ignored': 0, 'total': 32, 'perf': 28.125}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 25.0, 'weighted_acc': 25.0, 'prec': 53.84615384615385, 'rec': 60.0, 'f1': 23.809523809523814, 'weighted_f1': 23.809523809523814, 'ignored': 0, 'total': 32, 'perf': 25.0}, {'acc': 21.875, 'weighted_acc': 21.875, 'prec': 53.703703703703695, 'rec': 58.333333333333336, 'f1': 21.182266009852217, 'weighted_f1': 21.182266009852217, 'ignored': 0, 'total': 32, 'perf': 21.875}, {'acc': 21.875, 'weighted_acc': 21.875, 'prec': 53.703703703703695, 'rec': 58.333333333333336, 'f1': 21.182266009852217, 'weighted_f1': 21.182266009852217, 'ignored': 0, 'total': 32, 'perf': 21.875}, {'acc': 21.875, 'weighted_acc': 21.875, 'prec': 53.703703703703695, 'rec': 58.333333333333336, 'f1': 21.182266009852217, 'weighted_f1': 21.182266009852217, 'ignored': 0, 'total': 32, 'perf': 21.875}, {'acc': 21.875, 'weighted_acc': 21.875, 'prec': 53.703703703703695, 'rec': 58.333333333333336, 'f1': 21.182266009852217, 'weighted_f1': 21.182266009852217, 'ignored': 0, 'total': 32, 'perf': 21.875}, {'acc': 21.875, 'weighted_acc': 21.875, 'prec': 53.703703703703695, 'rec': 58.333333333333336, 'f1': 21.182266009852217, 'weighted_f1': 21.182266009852217, 'ignored': 0, 'total': 32, 'perf': 21.875}, {'acc': 21.875, 'weighted_acc': 21.875, 'prec': 53.703703703703695, 'rec': 58.333333333333336, 'f1': 21.182266009852217, 'weighted_f1': 21.182266009852217, 'ignored': 0, 'total': 32, 'perf': 21.875}, {'acc': 21.875, 'weighted_acc': 21.875, 'prec': 53.703703703703695, 'rec': 58.333333333333336, 'f1': 21.182266009852217, 'weighted_f1': 21.182266009852217, 'ignored': 0, 'total': 32, 'perf': 21.875}, {'acc': 21.875, 'weighted_acc': 21.875, 'prec': 53.703703703703695, 'rec': 58.333333333333336, 'f1': 21.182266009852217, 'weighted_f1': 21.182266009852217, 'ignored': 0, 'total': 32, 'perf': 21.875}]
2022-12-18 23:49:11,629 INFO 
student_dev:	{'acc': 77.77777777777779, 'weighted_acc': 77.77777777777779, 'prec': 80.0, 'rec': 83.33333333333333, 'f1': 77.49999999999999, 'weighted_f1': 77.49999999999999, 'ignored': 0, 'total': 18, 'perf': 77.77777777777779}
2022-12-18 23:49:11,629 INFO 
student_test:	{'acc': 56.25, 'weighted_acc': 56.25, 'prec': 56.25, 'rec': 76.66666666666666, 'f1': 45.893719806763286, 'weighted_f1': 45.893719806763286, 'ignored': 0, 'total': 32, 'perf': 56.25}
2022-12-18 23:49:11,629 INFO Saving results at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/results.pkl
2022-12-18 23:49:11,650 INFO Dataset: econ_mean
2022-12-18 23:49:11,650 INFO Weak Sources: ['econ_meanrules']
2022-12-18 23:49:11,650 INFO Model: bert

2022-12-18 23:49:11,650 INFO Teacher Train weighted_acc: 88.7
2022-12-18 23:49:11,650 INFO Teacher Dev weighted_acc: 94.4
2022-12-18 23:49:11,650 INFO Teacher Test weighted_acc: 81.2

2022-12-18 23:49:11,650 INFO Student Dev weighted_acc: 77.8
2022-12-18 23:49:11,650 INFO Student Test weighted_acc: 56.2
2022-12-18 23:49:11,651 INFO Saved report at ../experiments/econ_mean/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_45_stBERT/results.txt
