2022-12-04 19:37:06,945 INFO 

		 *** NEW EXPERIMENT ***
args=Namespace(adam_epsilon=1e-08, convert_abstain_to_random=False, datapath='../data', dataset='econ', debug=False, device=device(type='cuda'), downsample=1.0, eval_batch_size=16, experiment_folder='../experiments/econ', finetuning_rate=0.0001, fp16=False, hard_student_rule=False, learning_rate=0.0001, logdir='../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT', logging_steps=500, loss_weights=False, lower_case=False, max_grad_norm=1.0, max_rule_seq_length=10, max_seq_length=64, max_size=1000, metric='weighted_acc', n_gpu=1, no_cuda=False, num_epochs=15, num_iter=25, num_labels=2, num_supervised_trials=5, num_unsup_epochs=25, oversample=3, overwrite=False, sample_size=16384, seed=0, soft_labels=False, student_name='bert', teacher_name='ran', tokenizer_method='clean', train_batch_size=16, unsup_batch_size=128, warmup_steps=0, weak_sources=None, weight_decay=0.0)
2022-12-04 19:37:06,946 INFO building student: bert
2022-12-04 19:37:06,946 INFO building teacher
2022-12-04 19:37:06,946 INFO No weak sources specified for Teacher. Using default: ['econrules']
2022-12-04 19:37:06,946 INFO loading data
2022-12-04 19:37:06,951 INFO Pre-processing train data for student...
2022-12-04 19:37:06,956 INFO train DATASET: 247 examples
2022-12-04 19:37:06,959 INFO train LABELS:
1    182
0     65
Name: label, dtype: int64
2022-12-04 19:37:06,959 INFO Oversampling train data 3 times
2022-12-04 19:37:06,962 INFO train DATASET: 741 examples
2022-12-04 19:37:06,963 INFO train LABELS:
1    546
0    195
Name: label, dtype: int64
2022-12-04 19:37:06,965 INFO Pre-processing dev data for student...
2022-12-04 19:37:06,968 INFO dev DATASET: 18 examples
2022-12-04 19:37:06,970 INFO dev LABELS:
1    11
0     7
Name: label, dtype: int64
2022-12-04 19:37:06,973 INFO Pre-processing test data for student...
2022-12-04 19:37:06,976 INFO test DATASET: 32 examples
2022-12-04 19:37:06,977 INFO test LABELS:
1    18
0    14
Name: label, dtype: int64
2022-12-04 19:37:06,980 INFO Pre-processing unlabeled data for student...
2022-12-04 19:37:06,983 INFO unlabeled DATASET: 444 examples
2022-12-04 19:37:06,985 INFO unlabeled LABELS:
Series([], Name: label, dtype: int64)
2022-12-04 19:37:06,985 INFO creating pseudo-dataset
2022-12-04 19:37:06,985 INFO copying data from unlabeled dataset
2022-12-04 19:37:06,996 INFO done
2022-12-04 19:37:06,996 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:37:06,996 INFO Downsampling 444 data
2022-12-04 19:37:06,997 INFO copying data from train dataset
2022-12-04 19:37:07,006 INFO done
2022-12-04 19:37:07,007 INFO Balancing Pseudo Dataset to keep 1092 items...
2022-12-04 19:37:07,011 INFO PSEUDO-DATASET:
1092 examples
PSEUDO-LABELS:
1    546
0    546
Name: label, dtype: int64
2022-12-04 19:37:07,011 INFO Class labels: 2
2022-12-04 19:37:07,013 INFO X Train Shape (1092, 7) (1092,)
2022-12-04 19:37:07,013 INFO X Dev Shape (18, 7) (18,)
2022-12-04 19:37:19,274 INFO Saving supervised_student to ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/supervised_student
2022-12-04 19:37:19,275 INFO Saving model at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/supervised_student/final_model.h5
2022-12-04 19:37:19,282 INFO 

	*** Evaluating on dev data ***
2022-12-04 19:37:19,282 INFO Predicting labels for 18 texts
2022-12-04 19:37:19,384 INFO Evaluating student dev on 18 examples
2022-12-04 19:37:19,393 INFO student dev performance: 50.00
2022-12-04 19:37:19,393 INFO student dev confusion matrix:
[[3 4]
 [5 6]]
2022-12-04 19:37:19,393 INFO student dev report:
              precision    recall  f1-score   support

           0       0.38      0.43      0.40         7
           1       0.60      0.55      0.57        11

    accuracy                           0.50        18
   macro avg       0.49      0.49      0.49        18
weighted avg       0.51      0.50      0.50        18

2022-12-04 19:37:19,393 INFO 

	*** Evaluating on test data ***
2022-12-04 19:37:19,394 INFO Predicting labels for 32 texts
2022-12-04 19:37:19,649 INFO Evaluating student test on 32 examples
2022-12-04 19:37:19,653 INFO student test performance: 59.38
2022-12-04 19:37:19,653 INFO student test confusion matrix:
[[ 2 12]
 [ 1 17]]
2022-12-04 19:37:19,653 INFO student test report:
              precision    recall  f1-score   support

           0       0.67      0.14      0.24        14
           1       0.59      0.94      0.72        18

    accuracy                           0.59        32
   macro avg       0.63      0.54      0.48        32
weighted avg       0.62      0.59      0.51        32

2022-12-04 19:37:19,653 INFO initializing teacher on unlabeled data with majority voting
2022-12-04 19:37:19,654 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:19,654 INFO There are 3/7 active rules
2022-12-04 19:37:19,654 INFO Coverage: 100.0% (444/444)
2022-12-04 19:37:19,668 INFO evaluating majority voting
2022-12-04 19:37:19,668 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:37:19,669 INFO There are 7/7 active rules
2022-12-04 19:37:19,669 INFO Coverage: 100.0% (741/741)
2022-12-04 19:37:19,693 INFO Evaluating teacher train on 741 examples
2022-12-04 19:37:19,703 INFO teacher train performance: 90.69
2022-12-04 19:37:19,703 INFO teacher train confusion matrix:
[[150  45]
 [ 24 522]]
2022-12-04 19:37:19,703 INFO teacher train report:
              precision    recall  f1-score   support

           0       0.86      0.77      0.81       195
           1       0.92      0.96      0.94       546

    accuracy                           0.91       741
   macro avg       0.89      0.86      0.88       741
weighted avg       0.91      0.91      0.91       741

2022-12-04 19:37:19,703 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:19,704 INFO There are 7/7 active rules
2022-12-04 19:37:19,704 INFO Coverage: 100.0% (18/18)
2022-12-04 19:37:19,705 INFO Evaluating teacher dev on 18 examples
2022-12-04 19:37:19,710 INFO teacher dev performance: 88.89
2022-12-04 19:37:19,710 INFO teacher dev confusion matrix:
[[ 5  2]
 [ 0 11]]
2022-12-04 19:37:19,711 INFO teacher dev report:
              precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.85      1.00      0.92        11

    accuracy                           0.89        18
   macro avg       0.92      0.86      0.88        18
weighted avg       0.91      0.89      0.88        18

2022-12-04 19:37:19,711 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:37:19,711 INFO There are 7/7 active rules
2022-12-04 19:37:19,711 INFO Coverage: 100.0% (32/32)
2022-12-04 19:37:19,712 INFO Evaluating teacher test on 32 examples
2022-12-04 19:37:19,718 INFO teacher test performance: 78.12
2022-12-04 19:37:19,718 INFO teacher test confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:37:19,718 INFO teacher test report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:37:19,718 INFO 

	 *** Starting loop 0 ***
2022-12-04 19:37:19,718 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:37:19,718 INFO Downsampling 444 data
2022-12-04 19:37:19,719 INFO Adding Student as extra rule in Teacher
2022-12-04 19:37:19,719 INFO Getting rule predictions
2022-12-04 19:37:19,719 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:37:19,720 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:19,720 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:19,721 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:37:19,721 INFO Predicting labels for 741 texts
2022-12-04 19:37:20,842 INFO Predicting labels for 18 texts
2022-12-04 19:37:20,956 INFO Predicting labels for 444 texts
2022-12-04 19:37:21,078 INFO Training Rule Attention Network
2022-12-04 19:37:21,087 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:37:21,088 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:37:21,092 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:37:21,211 INFO 

		*** Training RAN ***
2022-12-04 19:37:24,555 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:24,557 INFO Predicting labels for 444 texts
2022-12-04 19:37:24,668 INFO There are 3/7 active rules
2022-12-04 19:37:24,669 INFO Coverage: 100.0% (444/444)
2022-12-04 19:37:24,673 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:37:24,767 INFO DONE, Getting attention scores...
2022-12-04 19:37:24,833 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:24,833 INFO Predicting labels for 18 texts
2022-12-04 19:37:24,938 INFO There are 7/7 active rules
2022-12-04 19:37:24,938 INFO Coverage: 100.0% (18/18)
2022-12-04 19:37:24,939 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:37:24,966 INFO DONE, Getting attention scores...
2022-12-04 19:37:25,026 INFO Evaluating teacher dev iter0 on 18 examples
2022-12-04 19:37:25,031 INFO teacher dev iter0 performance: 83.33
2022-12-04 19:37:25,031 INFO teacher dev iter0 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:37:25,031 INFO teacher dev iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:37:25,031 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:37:25,031 INFO Predicting labels for 32 texts
2022-12-04 19:37:25,145 INFO There are 7/7 active rules
2022-12-04 19:37:25,146 INFO Coverage: 100.0% (32/32)
2022-12-04 19:37:25,146 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:37:25,170 INFO DONE, Getting attention scores...
2022-12-04 19:37:25,227 INFO Evaluating teacher test iter0 on 32 examples
2022-12-04 19:37:25,232 INFO teacher test iter0 performance: 78.12
2022-12-04 19:37:25,233 INFO teacher test iter0 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:37:25,233 INFO teacher test iter0 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:37:25,233 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:37:25,236 INFO Balancing Pseudo Dataset to keep 744 items...
2022-12-04 19:37:25,240 INFO PSEUDO-DATASET:
744 examples
PSEUDO-LABELS:
1    372
0    372
Name: label, dtype: int64
2022-12-04 19:37:25,240 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:37:26,760 INFO fine-tuning the student on clean labeled data
2022-12-04 19:37:29,575 INFO Predicting labels for 18 texts
2022-12-04 19:37:29,675 INFO Evaluating student dev iter0 on 18 examples
2022-12-04 19:37:29,679 INFO student dev iter0 performance: 83.33
2022-12-04 19:37:29,679 INFO student dev iter0 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:37:29,679 INFO student dev iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:37:29,680 INFO Predicting labels for 32 texts
2022-12-04 19:37:29,851 INFO Evaluating student test iter0 on 32 examples
2022-12-04 19:37:29,856 INFO student test iter0 performance: 56.25
2022-12-04 19:37:29,856 INFO student test iter0 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:37:29,856 INFO student test iter0 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:37:29,857 INFO Student Dev performance on iter 0: 83.33333333333334
2022-12-04 19:37:29,857 INFO Student Test performance on iter 0: 56.25
2022-12-04 19:37:29,857 INFO Improved dev performance from 50.00 to 83.33
2022-12-04 19:37:29,857 INFO Saving student_best to ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/student_best
2022-12-04 19:37:29,857 INFO Saving model at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/student_best/final_model.h5
2022-12-04 19:37:29,864 INFO Saving teacher at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/teacher_best
2022-12-04 19:37:29,864 INFO Saving rule attention network at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/teacher_best/rule_attention_network.h5
2022-12-04 19:37:29,871 INFO 

	 *** Starting loop 1 ***
2022-12-04 19:37:29,871 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:37:29,871 INFO Downsampling 444 data
2022-12-04 19:37:29,872 INFO Adding Student as extra rule in Teacher
2022-12-04 19:37:29,872 INFO Getting rule predictions
2022-12-04 19:37:29,872 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:37:29,873 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:29,873 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:29,874 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:37:29,875 INFO Predicting labels for 741 texts
2022-12-04 19:37:29,979 INFO Predicting labels for 18 texts
2022-12-04 19:37:30,077 INFO Predicting labels for 444 texts
2022-12-04 19:37:30,177 INFO Training Rule Attention Network
2022-12-04 19:37:30,184 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:37:30,185 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:37:30,189 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:37:30,189 INFO 

		*** Training RAN ***
2022-12-04 19:37:33,795 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:33,796 INFO Predicting labels for 444 texts
2022-12-04 19:37:33,915 INFO There are 3/7 active rules
2022-12-04 19:37:33,916 INFO Coverage: 100.0% (444/444)
2022-12-04 19:37:33,922 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:37:34,021 INFO DONE, Getting attention scores...
2022-12-04 19:37:34,085 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:34,085 INFO Predicting labels for 18 texts
2022-12-04 19:37:34,199 INFO There are 7/7 active rules
2022-12-04 19:37:34,199 INFO Coverage: 100.0% (18/18)
2022-12-04 19:37:34,200 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:37:34,230 INFO DONE, Getting attention scores...
2022-12-04 19:37:34,288 INFO Evaluating teacher dev iter1 on 18 examples
2022-12-04 19:37:34,292 INFO teacher dev iter1 performance: 83.33
2022-12-04 19:37:34,293 INFO teacher dev iter1 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:37:34,293 INFO teacher dev iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:37:34,293 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:37:34,293 INFO Predicting labels for 32 texts
2022-12-04 19:37:34,407 INFO There are 7/7 active rules
2022-12-04 19:37:34,407 INFO Coverage: 100.0% (32/32)
2022-12-04 19:37:34,408 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:37:34,432 INFO DONE, Getting attention scores...
2022-12-04 19:37:34,495 INFO Evaluating teacher test iter1 on 32 examples
2022-12-04 19:37:34,499 INFO teacher test iter1 performance: 78.12
2022-12-04 19:37:34,499 INFO teacher test iter1 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:37:34,499 INFO teacher test iter1 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:37:34,500 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:37:34,501 INFO Balancing Pseudo Dataset to keep 682 items...
2022-12-04 19:37:34,506 INFO PSEUDO-DATASET:
682 examples
PSEUDO-LABELS:
1    341
0    341
Name: label, dtype: int64
2022-12-04 19:37:34,506 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:37:37,024 INFO fine-tuning the student on clean labeled data
2022-12-04 19:37:40,774 INFO Predicting labels for 18 texts
2022-12-04 19:37:40,966 INFO Evaluating student dev iter1 on 18 examples
2022-12-04 19:37:40,970 INFO student dev iter1 performance: 83.33
2022-12-04 19:37:40,971 INFO student dev iter1 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:37:40,971 INFO student dev iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:37:40,971 INFO Predicting labels for 32 texts
2022-12-04 19:37:41,071 INFO Evaluating student test iter1 on 32 examples
2022-12-04 19:37:41,076 INFO student test iter1 performance: 56.25
2022-12-04 19:37:41,076 INFO student test iter1 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:37:41,076 INFO student test iter1 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:37:41,076 INFO Student Dev performance on iter 1: 83.33333333333334
2022-12-04 19:37:41,076 INFO Student Test performance on iter 1: 56.25
2022-12-04 19:37:41,076 INFO 

	 *** Starting loop 2 ***
2022-12-04 19:37:41,076 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:37:41,076 INFO Downsampling 444 data
2022-12-04 19:37:41,077 INFO Adding Student as extra rule in Teacher
2022-12-04 19:37:41,077 INFO Getting rule predictions
2022-12-04 19:37:41,077 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:37:41,078 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:41,078 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:41,079 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:37:41,080 INFO Predicting labels for 741 texts
2022-12-04 19:37:41,183 INFO Predicting labels for 18 texts
2022-12-04 19:37:41,282 INFO Predicting labels for 444 texts
2022-12-04 19:37:41,382 INFO Training Rule Attention Network
2022-12-04 19:37:41,389 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:37:41,390 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:37:41,394 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:37:41,394 INFO 

		*** Training RAN ***
2022-12-04 19:37:44,239 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:44,240 INFO Predicting labels for 444 texts
2022-12-04 19:37:44,338 INFO There are 3/7 active rules
2022-12-04 19:37:44,339 INFO Coverage: 100.0% (444/444)
2022-12-04 19:37:44,343 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:37:44,428 INFO DONE, Getting attention scores...
2022-12-04 19:37:44,486 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:44,487 INFO Predicting labels for 18 texts
2022-12-04 19:37:44,583 INFO There are 7/7 active rules
2022-12-04 19:37:44,583 INFO Coverage: 100.0% (18/18)
2022-12-04 19:37:44,584 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:37:44,608 INFO DONE, Getting attention scores...
2022-12-04 19:37:44,660 INFO Evaluating teacher dev iter2 on 18 examples
2022-12-04 19:37:44,665 INFO teacher dev iter2 performance: 83.33
2022-12-04 19:37:44,665 INFO teacher dev iter2 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:37:44,665 INFO teacher dev iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:37:44,666 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:37:44,666 INFO Predicting labels for 32 texts
2022-12-04 19:37:44,771 INFO There are 7/7 active rules
2022-12-04 19:37:44,772 INFO Coverage: 100.0% (32/32)
2022-12-04 19:37:44,772 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:37:44,796 INFO DONE, Getting attention scores...
2022-12-04 19:37:44,850 INFO Evaluating teacher test iter2 on 32 examples
2022-12-04 19:37:44,854 INFO teacher test iter2 performance: 78.12
2022-12-04 19:37:44,855 INFO teacher test iter2 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:37:44,855 INFO teacher test iter2 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:37:44,855 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:37:44,857 INFO Balancing Pseudo Dataset to keep 742 items...
2022-12-04 19:37:44,861 INFO PSEUDO-DATASET:
742 examples
PSEUDO-LABELS:
1    371
0    371
Name: label, dtype: int64
2022-12-04 19:37:44,862 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:37:47,487 INFO fine-tuning the student on clean labeled data
2022-12-04 19:37:50,203 INFO Predicting labels for 18 texts
2022-12-04 19:37:50,303 INFO Evaluating student dev iter2 on 18 examples
2022-12-04 19:37:50,308 INFO student dev iter2 performance: 83.33
2022-12-04 19:37:50,308 INFO student dev iter2 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:37:50,308 INFO student dev iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:37:50,308 INFO Predicting labels for 32 texts
2022-12-04 19:37:50,487 INFO Evaluating student test iter2 on 32 examples
2022-12-04 19:37:50,492 INFO student test iter2 performance: 56.25
2022-12-04 19:37:50,492 INFO student test iter2 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:37:50,492 INFO student test iter2 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:37:50,493 INFO Student Dev performance on iter 2: 83.33333333333334
2022-12-04 19:37:50,493 INFO Student Test performance on iter 2: 56.25
2022-12-04 19:37:50,493 INFO 

	 *** Starting loop 3 ***
2022-12-04 19:37:50,493 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:37:50,493 INFO Downsampling 444 data
2022-12-04 19:37:50,494 INFO Adding Student as extra rule in Teacher
2022-12-04 19:37:50,494 INFO Getting rule predictions
2022-12-04 19:37:50,494 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:37:50,495 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:50,495 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:50,496 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:37:50,497 INFO Predicting labels for 741 texts
2022-12-04 19:37:50,603 INFO Predicting labels for 18 texts
2022-12-04 19:37:50,703 INFO Predicting labels for 444 texts
2022-12-04 19:37:50,806 INFO Training Rule Attention Network
2022-12-04 19:37:50,813 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:37:50,814 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:37:50,818 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:37:50,818 INFO 

		*** Training RAN ***
2022-12-04 19:37:53,636 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:53,637 INFO Predicting labels for 444 texts
2022-12-04 19:37:53,738 INFO There are 3/7 active rules
2022-12-04 19:37:53,738 INFO Coverage: 100.0% (444/444)
2022-12-04 19:37:53,742 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:37:53,855 INFO DONE, Getting attention scores...
2022-12-04 19:37:53,914 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:53,914 INFO Predicting labels for 18 texts
2022-12-04 19:37:54,009 INFO There are 7/7 active rules
2022-12-04 19:37:54,010 INFO Coverage: 100.0% (18/18)
2022-12-04 19:37:54,010 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:37:54,034 INFO DONE, Getting attention scores...
2022-12-04 19:37:54,092 INFO Evaluating teacher dev iter3 on 18 examples
2022-12-04 19:37:54,096 INFO teacher dev iter3 performance: 83.33
2022-12-04 19:37:54,096 INFO teacher dev iter3 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:37:54,096 INFO teacher dev iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:37:54,097 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:37:54,097 INFO Predicting labels for 32 texts
2022-12-04 19:37:54,195 INFO There are 7/7 active rules
2022-12-04 19:37:54,195 INFO Coverage: 100.0% (32/32)
2022-12-04 19:37:54,196 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:37:54,219 INFO DONE, Getting attention scores...
2022-12-04 19:37:54,274 INFO Evaluating teacher test iter3 on 32 examples
2022-12-04 19:37:54,279 INFO teacher test iter3 performance: 78.12
2022-12-04 19:37:54,279 INFO teacher test iter3 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:37:54,279 INFO teacher test iter3 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:37:54,280 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:37:54,281 INFO Balancing Pseudo Dataset to keep 710 items...
2022-12-04 19:37:54,285 INFO PSEUDO-DATASET:
710 examples
PSEUDO-LABELS:
1    355
0    355
Name: label, dtype: int64
2022-12-04 19:37:54,285 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:37:55,775 INFO fine-tuning the student on clean labeled data
2022-12-04 19:37:56,967 INFO Predicting labels for 18 texts
2022-12-04 19:37:57,067 INFO Evaluating student dev iter3 on 18 examples
2022-12-04 19:37:57,072 INFO student dev iter3 performance: 83.33
2022-12-04 19:37:57,072 INFO student dev iter3 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:37:57,072 INFO student dev iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:37:57,072 INFO Predicting labels for 32 texts
2022-12-04 19:37:57,174 INFO Evaluating student test iter3 on 32 examples
2022-12-04 19:37:57,179 INFO student test iter3 performance: 56.25
2022-12-04 19:37:57,179 INFO student test iter3 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:37:57,180 INFO student test iter3 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:37:57,180 INFO Student Dev performance on iter 3: 83.33333333333334
2022-12-04 19:37:57,180 INFO Student Test performance on iter 3: 56.25
2022-12-04 19:37:57,180 INFO 

	 *** Starting loop 4 ***
2022-12-04 19:37:57,181 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:37:57,181 INFO Downsampling 444 data
2022-12-04 19:37:57,181 INFO Adding Student as extra rule in Teacher
2022-12-04 19:37:57,182 INFO Getting rule predictions
2022-12-04 19:37:57,182 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:37:57,183 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:37:57,183 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:37:57,184 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:37:57,185 INFO Predicting labels for 741 texts
2022-12-04 19:37:57,286 INFO Predicting labels for 18 texts
2022-12-04 19:37:57,383 INFO Predicting labels for 444 texts
2022-12-04 19:37:57,482 INFO Training Rule Attention Network
2022-12-04 19:37:57,489 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:37:57,490 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:37:57,494 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:37:57,494 INFO 

		*** Training RAN ***
2022-12-04 19:38:00,329 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:00,331 INFO Predicting labels for 444 texts
2022-12-04 19:38:00,433 INFO There are 3/7 active rules
2022-12-04 19:38:00,433 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:00,437 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:00,522 INFO DONE, Getting attention scores...
2022-12-04 19:38:00,579 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:00,579 INFO Predicting labels for 18 texts
2022-12-04 19:38:00,680 INFO There are 7/7 active rules
2022-12-04 19:38:00,680 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:00,681 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:00,705 INFO DONE, Getting attention scores...
2022-12-04 19:38:00,759 INFO Evaluating teacher dev iter4 on 18 examples
2022-12-04 19:38:00,763 INFO teacher dev iter4 performance: 83.33
2022-12-04 19:38:00,763 INFO teacher dev iter4 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:00,763 INFO teacher dev iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:00,763 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:00,764 INFO Predicting labels for 32 texts
2022-12-04 19:38:00,866 INFO There are 7/7 active rules
2022-12-04 19:38:00,866 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:00,867 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:00,890 INFO DONE, Getting attention scores...
2022-12-04 19:38:00,945 INFO Evaluating teacher test iter4 on 32 examples
2022-12-04 19:38:00,950 INFO teacher test iter4 performance: 78.12
2022-12-04 19:38:00,951 INFO teacher test iter4 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:38:00,951 INFO teacher test iter4 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:38:00,951 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:38:00,953 INFO Balancing Pseudo Dataset to keep 686 items...
2022-12-04 19:38:00,958 INFO PSEUDO-DATASET:
686 examples
PSEUDO-LABELS:
1    343
0    343
Name: label, dtype: int64
2022-12-04 19:38:00,958 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:38:03,504 INFO fine-tuning the student on clean labeled data
2022-12-04 19:38:04,541 INFO Predicting labels for 18 texts
2022-12-04 19:38:04,640 INFO Evaluating student dev iter4 on 18 examples
2022-12-04 19:38:04,645 INFO student dev iter4 performance: 83.33
2022-12-04 19:38:04,645 INFO student dev iter4 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:04,645 INFO student dev iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:04,645 INFO Predicting labels for 32 texts
2022-12-04 19:38:04,747 INFO Evaluating student test iter4 on 32 examples
2022-12-04 19:38:04,751 INFO student test iter4 performance: 56.25
2022-12-04 19:38:04,752 INFO student test iter4 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:38:04,752 INFO student test iter4 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:38:04,752 INFO Student Dev performance on iter 4: 83.33333333333334
2022-12-04 19:38:04,752 INFO Student Test performance on iter 4: 56.25
2022-12-04 19:38:04,752 INFO 

	 *** Starting loop 5 ***
2022-12-04 19:38:04,752 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:38:04,752 INFO Downsampling 444 data
2022-12-04 19:38:04,753 INFO Adding Student as extra rule in Teacher
2022-12-04 19:38:04,753 INFO Getting rule predictions
2022-12-04 19:38:04,753 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:38:04,754 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:04,754 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:04,755 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:38:04,756 INFO Predicting labels for 741 texts
2022-12-04 19:38:04,856 INFO Predicting labels for 18 texts
2022-12-04 19:38:04,957 INFO Predicting labels for 444 texts
2022-12-04 19:38:05,057 INFO Training Rule Attention Network
2022-12-04 19:38:05,064 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:38:05,065 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:38:05,068 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:38:05,069 INFO 

		*** Training RAN ***
2022-12-04 19:38:07,937 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:07,938 INFO Predicting labels for 444 texts
2022-12-04 19:38:08,038 INFO There are 3/7 active rules
2022-12-04 19:38:08,038 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:08,043 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:08,128 INFO DONE, Getting attention scores...
2022-12-04 19:38:08,186 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:08,186 INFO Predicting labels for 18 texts
2022-12-04 19:38:08,282 INFO There are 7/7 active rules
2022-12-04 19:38:08,282 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:08,283 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:08,307 INFO DONE, Getting attention scores...
2022-12-04 19:38:08,366 INFO Evaluating teacher dev iter5 on 18 examples
2022-12-04 19:38:08,370 INFO teacher dev iter5 performance: 83.33
2022-12-04 19:38:08,370 INFO teacher dev iter5 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:08,370 INFO teacher dev iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:08,370 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:08,370 INFO Predicting labels for 32 texts
2022-12-04 19:38:08,468 INFO There are 7/7 active rules
2022-12-04 19:38:08,468 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:08,469 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:08,492 INFO DONE, Getting attention scores...
2022-12-04 19:38:08,545 INFO Evaluating teacher test iter5 on 32 examples
2022-12-04 19:38:08,549 INFO teacher test iter5 performance: 78.12
2022-12-04 19:38:08,549 INFO teacher test iter5 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:38:08,549 INFO teacher test iter5 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:38:08,550 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:38:08,551 INFO Balancing Pseudo Dataset to keep 684 items...
2022-12-04 19:38:08,555 INFO PSEUDO-DATASET:
684 examples
PSEUDO-LABELS:
1    342
0    342
Name: label, dtype: int64
2022-12-04 19:38:08,556 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:38:10,029 INFO fine-tuning the student on clean labeled data
2022-12-04 19:38:11,053 INFO Predicting labels for 18 texts
2022-12-04 19:38:11,152 INFO Evaluating student dev iter5 on 18 examples
2022-12-04 19:38:11,157 INFO student dev iter5 performance: 83.33
2022-12-04 19:38:11,157 INFO student dev iter5 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:11,157 INFO student dev iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:11,157 INFO Predicting labels for 32 texts
2022-12-04 19:38:11,253 INFO Evaluating student test iter5 on 32 examples
2022-12-04 19:38:11,258 INFO student test iter5 performance: 56.25
2022-12-04 19:38:11,258 INFO student test iter5 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:38:11,258 INFO student test iter5 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:38:11,258 INFO Student Dev performance on iter 5: 83.33333333333334
2022-12-04 19:38:11,258 INFO Student Test performance on iter 5: 56.25
2022-12-04 19:38:11,258 INFO 

	 *** Starting loop 6 ***
2022-12-04 19:38:11,259 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:38:11,259 INFO Downsampling 444 data
2022-12-04 19:38:11,259 INFO Adding Student as extra rule in Teacher
2022-12-04 19:38:11,259 INFO Getting rule predictions
2022-12-04 19:38:11,259 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:38:11,260 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:11,261 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:11,261 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:38:11,262 INFO Predicting labels for 741 texts
2022-12-04 19:38:11,362 INFO Predicting labels for 18 texts
2022-12-04 19:38:11,459 INFO Predicting labels for 444 texts
2022-12-04 19:38:11,563 INFO Training Rule Attention Network
2022-12-04 19:38:11,571 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:38:11,571 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:38:11,575 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:38:11,576 INFO 

		*** Training RAN ***
2022-12-04 19:38:14,482 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:14,484 INFO Predicting labels for 444 texts
2022-12-04 19:38:14,590 INFO There are 3/7 active rules
2022-12-04 19:38:14,590 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:14,594 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:14,677 INFO DONE, Getting attention scores...
2022-12-04 19:38:14,736 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:14,736 INFO Predicting labels for 18 texts
2022-12-04 19:38:14,833 INFO There are 7/7 active rules
2022-12-04 19:38:14,833 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:14,834 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:14,858 INFO DONE, Getting attention scores...
2022-12-04 19:38:14,911 INFO Evaluating teacher dev iter6 on 18 examples
2022-12-04 19:38:14,916 INFO teacher dev iter6 performance: 83.33
2022-12-04 19:38:14,916 INFO teacher dev iter6 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:14,916 INFO teacher dev iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:14,916 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:14,916 INFO Predicting labels for 32 texts
2022-12-04 19:38:15,020 INFO There are 7/7 active rules
2022-12-04 19:38:15,020 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:15,021 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:15,047 INFO DONE, Getting attention scores...
2022-12-04 19:38:15,100 INFO Evaluating teacher test iter6 on 32 examples
2022-12-04 19:38:15,105 INFO teacher test iter6 performance: 78.12
2022-12-04 19:38:15,105 INFO teacher test iter6 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:38:15,105 INFO teacher test iter6 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:38:15,105 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:38:15,107 INFO Balancing Pseudo Dataset to keep 676 items...
2022-12-04 19:38:15,112 INFO PSEUDO-DATASET:
676 examples
PSEUDO-LABELS:
1    338
0    338
Name: label, dtype: int64
2022-12-04 19:38:15,112 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:38:17,633 INFO fine-tuning the student on clean labeled data
2022-12-04 19:38:18,704 INFO Predicting labels for 18 texts
2022-12-04 19:38:18,806 INFO Evaluating student dev iter6 on 18 examples
2022-12-04 19:38:18,810 INFO student dev iter6 performance: 83.33
2022-12-04 19:38:18,811 INFO student dev iter6 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:18,811 INFO student dev iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:18,811 INFO Predicting labels for 32 texts
2022-12-04 19:38:18,909 INFO Evaluating student test iter6 on 32 examples
2022-12-04 19:38:18,913 INFO student test iter6 performance: 56.25
2022-12-04 19:38:18,914 INFO student test iter6 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:38:18,914 INFO student test iter6 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:38:18,914 INFO Student Dev performance on iter 6: 83.33333333333334
2022-12-04 19:38:18,914 INFO Student Test performance on iter 6: 56.25
2022-12-04 19:38:18,914 INFO 

	 *** Starting loop 7 ***
2022-12-04 19:38:18,914 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:38:18,914 INFO Downsampling 444 data
2022-12-04 19:38:18,915 INFO Adding Student as extra rule in Teacher
2022-12-04 19:38:18,915 INFO Getting rule predictions
2022-12-04 19:38:18,915 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:38:18,916 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:18,916 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:18,917 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:38:18,918 INFO Predicting labels for 741 texts
2022-12-04 19:38:19,016 INFO Predicting labels for 18 texts
2022-12-04 19:38:19,113 INFO Predicting labels for 444 texts
2022-12-04 19:38:19,210 INFO Training Rule Attention Network
2022-12-04 19:38:19,220 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:38:19,220 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:38:19,224 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:38:19,224 INFO 

		*** Training RAN ***
2022-12-04 19:38:22,208 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:22,209 INFO Predicting labels for 444 texts
2022-12-04 19:38:22,330 INFO There are 3/7 active rules
2022-12-04 19:38:22,330 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:22,334 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:22,423 INFO DONE, Getting attention scores...
2022-12-04 19:38:22,479 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:22,479 INFO Predicting labels for 18 texts
2022-12-04 19:38:22,580 INFO There are 7/7 active rules
2022-12-04 19:38:22,580 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:22,580 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:22,604 INFO DONE, Getting attention scores...
2022-12-04 19:38:22,659 INFO Evaluating teacher dev iter7 on 18 examples
2022-12-04 19:38:22,663 INFO teacher dev iter7 performance: 83.33
2022-12-04 19:38:22,664 INFO teacher dev iter7 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:22,664 INFO teacher dev iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:22,664 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:22,664 INFO Predicting labels for 32 texts
2022-12-04 19:38:22,767 INFO There are 7/7 active rules
2022-12-04 19:38:22,767 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:22,768 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:22,793 INFO DONE, Getting attention scores...
2022-12-04 19:38:22,848 INFO Evaluating teacher test iter7 on 32 examples
2022-12-04 19:38:22,852 INFO teacher test iter7 performance: 78.12
2022-12-04 19:38:22,852 INFO teacher test iter7 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:38:22,852 INFO teacher test iter7 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:38:22,852 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:38:22,854 INFO Balancing Pseudo Dataset to keep 626 items...
2022-12-04 19:38:22,859 INFO PSEUDO-DATASET:
626 examples
PSEUDO-LABELS:
1    313
0    313
Name: label, dtype: int64
2022-12-04 19:38:22,859 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:38:25,275 INFO fine-tuning the student on clean labeled data
2022-12-04 19:38:26,341 INFO Predicting labels for 18 texts
2022-12-04 19:38:26,440 INFO Evaluating student dev iter7 on 18 examples
2022-12-04 19:38:26,445 INFO student dev iter7 performance: 83.33
2022-12-04 19:38:26,445 INFO student dev iter7 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:26,445 INFO student dev iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:26,445 INFO Predicting labels for 32 texts
2022-12-04 19:38:26,544 INFO Evaluating student test iter7 on 32 examples
2022-12-04 19:38:26,548 INFO student test iter7 performance: 56.25
2022-12-04 19:38:26,548 INFO student test iter7 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:38:26,549 INFO student test iter7 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:38:26,549 INFO Student Dev performance on iter 7: 83.33333333333334
2022-12-04 19:38:26,549 INFO Student Test performance on iter 7: 56.25
2022-12-04 19:38:26,549 INFO 

	 *** Starting loop 8 ***
2022-12-04 19:38:26,549 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:38:26,549 INFO Downsampling 444 data
2022-12-04 19:38:26,550 INFO Adding Student as extra rule in Teacher
2022-12-04 19:38:26,550 INFO Getting rule predictions
2022-12-04 19:38:26,550 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:38:26,551 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:26,551 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:26,552 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:38:26,553 INFO Predicting labels for 741 texts
2022-12-04 19:38:26,655 INFO Predicting labels for 18 texts
2022-12-04 19:38:26,755 INFO Predicting labels for 444 texts
2022-12-04 19:38:26,853 INFO Training Rule Attention Network
2022-12-04 19:38:26,860 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:38:26,861 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:38:26,867 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:38:26,867 INFO 

		*** Training RAN ***
2022-12-04 19:38:29,766 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:29,768 INFO Predicting labels for 444 texts
2022-12-04 19:38:29,870 INFO There are 3/7 active rules
2022-12-04 19:38:29,870 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:29,874 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:29,963 INFO DONE, Getting attention scores...
2022-12-04 19:38:30,020 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:30,021 INFO Predicting labels for 18 texts
2022-12-04 19:38:30,123 INFO There are 7/7 active rules
2022-12-04 19:38:30,123 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:30,124 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:30,148 INFO DONE, Getting attention scores...
2022-12-04 19:38:30,203 INFO Evaluating teacher dev iter8 on 18 examples
2022-12-04 19:38:30,208 INFO teacher dev iter8 performance: 83.33
2022-12-04 19:38:30,208 INFO teacher dev iter8 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:30,208 INFO teacher dev iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:30,208 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:30,209 INFO Predicting labels for 32 texts
2022-12-04 19:38:30,310 INFO There are 7/7 active rules
2022-12-04 19:38:30,310 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:30,311 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:30,340 INFO DONE, Getting attention scores...
2022-12-04 19:38:30,393 INFO Evaluating teacher test iter8 on 32 examples
2022-12-04 19:38:30,397 INFO teacher test iter8 performance: 78.12
2022-12-04 19:38:30,397 INFO teacher test iter8 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:38:30,397 INFO teacher test iter8 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:38:30,398 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:38:30,399 INFO Balancing Pseudo Dataset to keep 684 items...
2022-12-04 19:38:30,403 INFO PSEUDO-DATASET:
684 examples
PSEUDO-LABELS:
1    342
0    342
Name: label, dtype: int64
2022-12-04 19:38:30,403 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:38:31,877 INFO fine-tuning the student on clean labeled data
2022-12-04 19:38:33,018 INFO Predicting labels for 18 texts
2022-12-04 19:38:33,117 INFO Evaluating student dev iter8 on 18 examples
2022-12-04 19:38:33,121 INFO student dev iter8 performance: 83.33
2022-12-04 19:38:33,121 INFO student dev iter8 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:33,122 INFO student dev iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:33,122 INFO Predicting labels for 32 texts
2022-12-04 19:38:33,219 INFO Evaluating student test iter8 on 32 examples
2022-12-04 19:38:33,223 INFO student test iter8 performance: 56.25
2022-12-04 19:38:33,224 INFO student test iter8 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:38:33,224 INFO student test iter8 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:38:33,224 INFO Student Dev performance on iter 8: 83.33333333333334
2022-12-04 19:38:33,224 INFO Student Test performance on iter 8: 56.25
2022-12-04 19:38:33,224 INFO 

	 *** Starting loop 9 ***
2022-12-04 19:38:33,224 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:38:33,225 INFO Downsampling 444 data
2022-12-04 19:38:33,225 INFO Adding Student as extra rule in Teacher
2022-12-04 19:38:33,225 INFO Getting rule predictions
2022-12-04 19:38:33,226 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:38:33,226 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:33,227 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:33,227 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:38:33,228 INFO Predicting labels for 741 texts
2022-12-04 19:38:33,329 INFO Predicting labels for 18 texts
2022-12-04 19:38:33,429 INFO Predicting labels for 444 texts
2022-12-04 19:38:33,526 INFO Training Rule Attention Network
2022-12-04 19:38:33,533 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:38:33,534 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:38:33,538 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:38:33,538 INFO 

		*** Training RAN ***
2022-12-04 19:38:36,410 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:36,412 INFO Predicting labels for 444 texts
2022-12-04 19:38:36,515 INFO There are 3/7 active rules
2022-12-04 19:38:36,515 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:36,620 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:36,705 INFO DONE, Getting attention scores...
2022-12-04 19:38:36,764 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:36,764 INFO Predicting labels for 18 texts
2022-12-04 19:38:36,871 INFO There are 7/7 active rules
2022-12-04 19:38:36,871 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:36,872 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:36,896 INFO DONE, Getting attention scores...
2022-12-04 19:38:36,950 INFO Evaluating teacher dev iter9 on 18 examples
2022-12-04 19:38:36,954 INFO teacher dev iter9 performance: 83.33
2022-12-04 19:38:36,954 INFO teacher dev iter9 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:36,954 INFO teacher dev iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:36,954 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:36,955 INFO Predicting labels for 32 texts
2022-12-04 19:38:37,054 INFO There are 7/7 active rules
2022-12-04 19:38:37,054 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:37,055 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:37,080 INFO DONE, Getting attention scores...
2022-12-04 19:38:37,141 INFO Evaluating teacher test iter9 on 32 examples
2022-12-04 19:38:37,145 INFO teacher test iter9 performance: 78.12
2022-12-04 19:38:37,146 INFO teacher test iter9 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:38:37,146 INFO teacher test iter9 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:38:37,146 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:38:37,147 INFO Balancing Pseudo Dataset to keep 640 items...
2022-12-04 19:38:37,152 INFO PSEUDO-DATASET:
640 examples
PSEUDO-LABELS:
1    320
0    320
Name: label, dtype: int64
2022-12-04 19:38:37,153 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:38:38,474 INFO fine-tuning the student on clean labeled data
2022-12-04 19:38:39,527 INFO Predicting labels for 18 texts
2022-12-04 19:38:39,628 INFO Evaluating student dev iter9 on 18 examples
2022-12-04 19:38:39,632 INFO student dev iter9 performance: 83.33
2022-12-04 19:38:39,633 INFO student dev iter9 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:39,633 INFO student dev iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:39,633 INFO Predicting labels for 32 texts
2022-12-04 19:38:39,734 INFO Evaluating student test iter9 on 32 examples
2022-12-04 19:38:39,739 INFO student test iter9 performance: 56.25
2022-12-04 19:38:39,739 INFO student test iter9 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:38:39,739 INFO student test iter9 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:38:39,739 INFO Student Dev performance on iter 9: 83.33333333333334
2022-12-04 19:38:39,739 INFO Student Test performance on iter 9: 56.25
2022-12-04 19:38:39,739 INFO 

	 *** Starting loop 10 ***
2022-12-04 19:38:39,739 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:38:39,740 INFO Downsampling 444 data
2022-12-04 19:38:39,740 INFO Adding Student as extra rule in Teacher
2022-12-04 19:38:39,740 INFO Getting rule predictions
2022-12-04 19:38:39,741 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:38:39,741 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:39,742 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:39,742 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:38:39,743 INFO Predicting labels for 741 texts
2022-12-04 19:38:39,842 INFO Predicting labels for 18 texts
2022-12-04 19:38:39,937 INFO Predicting labels for 444 texts
2022-12-04 19:38:40,039 INFO Training Rule Attention Network
2022-12-04 19:38:40,046 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:38:40,046 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:38:40,050 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:38:40,050 INFO 

		*** Training RAN ***
2022-12-04 19:38:42,916 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:42,917 INFO Predicting labels for 444 texts
2022-12-04 19:38:43,026 INFO There are 3/7 active rules
2022-12-04 19:38:43,026 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:43,031 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:43,124 INFO DONE, Getting attention scores...
2022-12-04 19:38:43,181 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:43,181 INFO Predicting labels for 18 texts
2022-12-04 19:38:43,278 INFO There are 7/7 active rules
2022-12-04 19:38:43,278 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:43,279 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:43,303 INFO DONE, Getting attention scores...
2022-12-04 19:38:43,363 INFO Evaluating teacher dev iter10 on 18 examples
2022-12-04 19:38:43,367 INFO teacher dev iter10 performance: 83.33
2022-12-04 19:38:43,367 INFO teacher dev iter10 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:43,367 INFO teacher dev iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:43,367 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:43,367 INFO Predicting labels for 32 texts
2022-12-04 19:38:43,555 INFO There are 7/7 active rules
2022-12-04 19:38:43,555 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:43,556 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:43,580 INFO DONE, Getting attention scores...
2022-12-04 19:38:43,636 INFO Evaluating teacher test iter10 on 32 examples
2022-12-04 19:38:43,640 INFO teacher test iter10 performance: 78.12
2022-12-04 19:38:43,641 INFO teacher test iter10 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:38:43,641 INFO teacher test iter10 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:38:43,641 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:38:43,643 INFO Balancing Pseudo Dataset to keep 746 items...
2022-12-04 19:38:43,647 INFO PSEUDO-DATASET:
746 examples
PSEUDO-LABELS:
1    373
0    373
Name: label, dtype: int64
2022-12-04 19:38:43,648 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:38:46,237 INFO fine-tuning the student on clean labeled data
2022-12-04 19:38:48,325 INFO Predicting labels for 18 texts
2022-12-04 19:38:48,426 INFO Evaluating student dev iter10 on 18 examples
2022-12-04 19:38:48,430 INFO student dev iter10 performance: 83.33
2022-12-04 19:38:48,431 INFO student dev iter10 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:48,431 INFO student dev iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:48,431 INFO Predicting labels for 32 texts
2022-12-04 19:38:48,532 INFO Evaluating student test iter10 on 32 examples
2022-12-04 19:38:48,537 INFO student test iter10 performance: 56.25
2022-12-04 19:38:48,537 INFO student test iter10 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:38:48,537 INFO student test iter10 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:38:48,537 INFO Student Dev performance on iter 10: 83.33333333333334
2022-12-04 19:38:48,537 INFO Student Test performance on iter 10: 56.25
2022-12-04 19:38:48,538 INFO 

	 *** Starting loop 11 ***
2022-12-04 19:38:48,538 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:38:48,538 INFO Downsampling 444 data
2022-12-04 19:38:48,538 INFO Adding Student as extra rule in Teacher
2022-12-04 19:38:48,539 INFO Getting rule predictions
2022-12-04 19:38:48,539 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:38:48,540 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:48,540 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:48,540 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:38:48,541 INFO Predicting labels for 741 texts
2022-12-04 19:38:48,648 INFO Predicting labels for 18 texts
2022-12-04 19:38:48,745 INFO Predicting labels for 444 texts
2022-12-04 19:38:48,849 INFO Training Rule Attention Network
2022-12-04 19:38:48,857 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:38:48,858 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:38:48,862 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:38:48,862 INFO 

		*** Training RAN ***
2022-12-04 19:38:51,735 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:51,737 INFO Predicting labels for 444 texts
2022-12-04 19:38:51,839 INFO There are 3/7 active rules
2022-12-04 19:38:51,839 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:51,844 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:51,932 INFO DONE, Getting attention scores...
2022-12-04 19:38:51,991 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:51,991 INFO Predicting labels for 18 texts
2022-12-04 19:38:52,089 INFO There are 7/7 active rules
2022-12-04 19:38:52,089 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:52,090 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:52,113 INFO DONE, Getting attention scores...
2022-12-04 19:38:52,167 INFO Evaluating teacher dev iter11 on 18 examples
2022-12-04 19:38:52,172 INFO teacher dev iter11 performance: 83.33
2022-12-04 19:38:52,172 INFO teacher dev iter11 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:52,172 INFO teacher dev iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:52,173 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:52,173 INFO Predicting labels for 32 texts
2022-12-04 19:38:52,286 INFO There are 7/7 active rules
2022-12-04 19:38:52,294 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:52,297 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:52,326 INFO DONE, Getting attention scores...
2022-12-04 19:38:52,385 INFO Evaluating teacher test iter11 on 32 examples
2022-12-04 19:38:52,389 INFO teacher test iter11 performance: 78.12
2022-12-04 19:38:52,390 INFO teacher test iter11 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:38:52,390 INFO teacher test iter11 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:38:52,390 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:38:52,392 INFO Balancing Pseudo Dataset to keep 654 items...
2022-12-04 19:38:52,396 INFO PSEUDO-DATASET:
654 examples
PSEUDO-LABELS:
1    327
0    327
Name: label, dtype: int64
2022-12-04 19:38:52,397 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:38:53,873 INFO fine-tuning the student on clean labeled data
2022-12-04 19:38:55,024 INFO Predicting labels for 18 texts
2022-12-04 19:38:56,150 INFO Evaluating student dev iter11 on 18 examples
2022-12-04 19:38:56,154 INFO student dev iter11 performance: 83.33
2022-12-04 19:38:56,155 INFO student dev iter11 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:56,155 INFO student dev iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:56,155 INFO Predicting labels for 32 texts
2022-12-04 19:38:56,255 INFO Evaluating student test iter11 on 32 examples
2022-12-04 19:38:56,260 INFO student test iter11 performance: 56.25
2022-12-04 19:38:56,260 INFO student test iter11 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:38:56,260 INFO student test iter11 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:38:56,260 INFO Student Dev performance on iter 11: 83.33333333333334
2022-12-04 19:38:56,260 INFO Student Test performance on iter 11: 56.25
2022-12-04 19:38:56,260 INFO 

	 *** Starting loop 12 ***
2022-12-04 19:38:56,261 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:38:56,261 INFO Downsampling 444 data
2022-12-04 19:38:56,261 INFO Adding Student as extra rule in Teacher
2022-12-04 19:38:56,262 INFO Getting rule predictions
2022-12-04 19:38:56,262 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:38:56,263 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:56,263 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:56,263 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:38:56,264 INFO Predicting labels for 741 texts
2022-12-04 19:38:56,367 INFO Predicting labels for 18 texts
2022-12-04 19:38:56,465 INFO Predicting labels for 444 texts
2022-12-04 19:38:56,564 INFO Training Rule Attention Network
2022-12-04 19:38:56,575 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:38:56,576 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:38:56,580 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:38:56,580 INFO 

		*** Training RAN ***
2022-12-04 19:38:59,369 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:38:59,370 INFO Predicting labels for 444 texts
2022-12-04 19:38:59,484 INFO There are 3/7 active rules
2022-12-04 19:38:59,484 INFO Coverage: 100.0% (444/444)
2022-12-04 19:38:59,488 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:38:59,573 INFO DONE, Getting attention scores...
2022-12-04 19:38:59,632 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:38:59,632 INFO Predicting labels for 18 texts
2022-12-04 19:38:59,748 INFO There are 7/7 active rules
2022-12-04 19:38:59,749 INFO Coverage: 100.0% (18/18)
2022-12-04 19:38:59,749 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:38:59,773 INFO DONE, Getting attention scores...
2022-12-04 19:38:59,826 INFO Evaluating teacher dev iter12 on 18 examples
2022-12-04 19:38:59,830 INFO teacher dev iter12 performance: 83.33
2022-12-04 19:38:59,831 INFO teacher dev iter12 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:38:59,831 INFO teacher dev iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:38:59,831 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:38:59,831 INFO Predicting labels for 32 texts
2022-12-04 19:38:59,936 INFO There are 7/7 active rules
2022-12-04 19:38:59,936 INFO Coverage: 100.0% (32/32)
2022-12-04 19:38:59,937 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:38:59,963 INFO DONE, Getting attention scores...
2022-12-04 19:39:00,019 INFO Evaluating teacher test iter12 on 32 examples
2022-12-04 19:39:00,024 INFO teacher test iter12 performance: 78.12
2022-12-04 19:39:00,024 INFO teacher test iter12 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:39:00,024 INFO teacher test iter12 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:39:00,024 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:00,026 INFO Balancing Pseudo Dataset to keep 784 items...
2022-12-04 19:39:00,030 INFO PSEUDO-DATASET:
784 examples
PSEUDO-LABELS:
1    392
0    392
Name: label, dtype: int64
2022-12-04 19:39:00,031 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:01,626 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:03,884 INFO Predicting labels for 18 texts
2022-12-04 19:39:03,988 INFO Evaluating student dev iter12 on 18 examples
2022-12-04 19:39:03,992 INFO student dev iter12 performance: 83.33
2022-12-04 19:39:03,992 INFO student dev iter12 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:03,992 INFO student dev iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:03,993 INFO Predicting labels for 32 texts
2022-12-04 19:39:04,095 INFO Evaluating student test iter12 on 32 examples
2022-12-04 19:39:04,100 INFO student test iter12 performance: 56.25
2022-12-04 19:39:04,100 INFO student test iter12 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:39:04,100 INFO student test iter12 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:39:04,101 INFO Student Dev performance on iter 12: 83.33333333333334
2022-12-04 19:39:04,101 INFO Student Test performance on iter 12: 56.25
2022-12-04 19:39:04,101 INFO 

	 *** Starting loop 13 ***
2022-12-04 19:39:04,101 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:39:04,101 INFO Downsampling 444 data
2022-12-04 19:39:04,102 INFO Adding Student as extra rule in Teacher
2022-12-04 19:39:04,102 INFO Getting rule predictions
2022-12-04 19:39:04,102 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:39:04,103 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:04,103 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:04,104 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:39:04,104 INFO Predicting labels for 741 texts
2022-12-04 19:39:04,208 INFO Predicting labels for 18 texts
2022-12-04 19:39:04,309 INFO Predicting labels for 444 texts
2022-12-04 19:39:04,409 INFO Training Rule Attention Network
2022-12-04 19:39:04,420 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:39:04,421 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:39:04,425 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:39:04,425 INFO 

		*** Training RAN ***
2022-12-04 19:39:07,245 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:07,246 INFO Predicting labels for 444 texts
2022-12-04 19:39:07,348 INFO There are 3/7 active rules
2022-12-04 19:39:07,348 INFO Coverage: 100.0% (444/444)
2022-12-04 19:39:07,352 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:39:07,437 INFO DONE, Getting attention scores...
2022-12-04 19:39:07,496 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:07,497 INFO Predicting labels for 18 texts
2022-12-04 19:39:07,595 INFO There are 7/7 active rules
2022-12-04 19:39:07,595 INFO Coverage: 100.0% (18/18)
2022-12-04 19:39:07,596 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:39:07,621 INFO DONE, Getting attention scores...
2022-12-04 19:39:07,675 INFO Evaluating teacher dev iter13 on 18 examples
2022-12-04 19:39:07,680 INFO teacher dev iter13 performance: 83.33
2022-12-04 19:39:07,680 INFO teacher dev iter13 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:07,680 INFO teacher dev iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:07,680 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:39:07,681 INFO Predicting labels for 32 texts
2022-12-04 19:39:07,785 INFO There are 7/7 active rules
2022-12-04 19:39:07,786 INFO Coverage: 100.0% (32/32)
2022-12-04 19:39:07,787 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:39:07,809 INFO DONE, Getting attention scores...
2022-12-04 19:39:07,862 INFO Evaluating teacher test iter13 on 32 examples
2022-12-04 19:39:07,866 INFO teacher test iter13 performance: 78.12
2022-12-04 19:39:07,866 INFO teacher test iter13 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:39:07,866 INFO teacher test iter13 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:39:07,867 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:07,868 INFO Balancing Pseudo Dataset to keep 730 items...
2022-12-04 19:39:07,873 INFO PSEUDO-DATASET:
730 examples
PSEUDO-LABELS:
1    365
0    365
Name: label, dtype: int64
2022-12-04 19:39:07,873 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:09,447 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:10,517 INFO Predicting labels for 18 texts
2022-12-04 19:39:10,621 INFO Evaluating student dev iter13 on 18 examples
2022-12-04 19:39:10,625 INFO student dev iter13 performance: 83.33
2022-12-04 19:39:10,625 INFO student dev iter13 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:10,625 INFO student dev iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:10,626 INFO Predicting labels for 32 texts
2022-12-04 19:39:10,724 INFO Evaluating student test iter13 on 32 examples
2022-12-04 19:39:10,729 INFO student test iter13 performance: 56.25
2022-12-04 19:39:10,729 INFO student test iter13 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:39:10,730 INFO student test iter13 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:39:10,730 INFO Student Dev performance on iter 13: 83.33333333333334
2022-12-04 19:39:10,730 INFO Student Test performance on iter 13: 56.25
2022-12-04 19:39:10,730 INFO 

	 *** Starting loop 14 ***
2022-12-04 19:39:10,730 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:39:10,730 INFO Downsampling 444 data
2022-12-04 19:39:10,731 INFO Adding Student as extra rule in Teacher
2022-12-04 19:39:10,731 INFO Getting rule predictions
2022-12-04 19:39:10,731 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:39:10,732 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:10,732 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:10,733 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:39:10,734 INFO Predicting labels for 741 texts
2022-12-04 19:39:10,838 INFO Predicting labels for 18 texts
2022-12-04 19:39:11,038 INFO Predicting labels for 444 texts
2022-12-04 19:39:11,141 INFO Training Rule Attention Network
2022-12-04 19:39:11,151 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:39:11,152 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:39:11,156 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:39:11,156 INFO 

		*** Training RAN ***
2022-12-04 19:39:14,030 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:14,032 INFO Predicting labels for 444 texts
2022-12-04 19:39:14,140 INFO There are 3/7 active rules
2022-12-04 19:39:14,140 INFO Coverage: 100.0% (444/444)
2022-12-04 19:39:14,145 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:39:14,233 INFO DONE, Getting attention scores...
2022-12-04 19:39:14,296 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:14,296 INFO Predicting labels for 18 texts
2022-12-04 19:39:14,396 INFO There are 7/7 active rules
2022-12-04 19:39:14,396 INFO Coverage: 100.0% (18/18)
2022-12-04 19:39:14,396 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:39:14,423 INFO DONE, Getting attention scores...
2022-12-04 19:39:14,477 INFO Evaluating teacher dev iter14 on 18 examples
2022-12-04 19:39:14,482 INFO teacher dev iter14 performance: 83.33
2022-12-04 19:39:14,482 INFO teacher dev iter14 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:14,482 INFO teacher dev iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:14,483 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:39:14,483 INFO Predicting labels for 32 texts
2022-12-04 19:39:14,592 INFO There are 7/7 active rules
2022-12-04 19:39:14,592 INFO Coverage: 100.0% (32/32)
2022-12-04 19:39:14,593 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:39:14,617 INFO DONE, Getting attention scores...
2022-12-04 19:39:14,671 INFO Evaluating teacher test iter14 on 32 examples
2022-12-04 19:39:14,676 INFO teacher test iter14 performance: 78.12
2022-12-04 19:39:14,676 INFO teacher test iter14 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:39:14,676 INFO teacher test iter14 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:39:14,677 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:14,678 INFO Balancing Pseudo Dataset to keep 672 items...
2022-12-04 19:39:14,682 INFO PSEUDO-DATASET:
672 examples
PSEUDO-LABELS:
1    336
0    336
Name: label, dtype: int64
2022-12-04 19:39:14,683 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:16,099 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:17,176 INFO Predicting labels for 18 texts
2022-12-04 19:39:17,283 INFO Evaluating student dev iter14 on 18 examples
2022-12-04 19:39:17,287 INFO student dev iter14 performance: 83.33
2022-12-04 19:39:17,288 INFO student dev iter14 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:17,288 INFO student dev iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:17,288 INFO Predicting labels for 32 texts
2022-12-04 19:39:17,390 INFO Evaluating student test iter14 on 32 examples
2022-12-04 19:39:17,395 INFO student test iter14 performance: 56.25
2022-12-04 19:39:17,395 INFO student test iter14 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:39:17,395 INFO student test iter14 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:39:17,396 INFO Student Dev performance on iter 14: 83.33333333333334
2022-12-04 19:39:17,396 INFO Student Test performance on iter 14: 56.25
2022-12-04 19:39:17,396 INFO 

	 *** Starting loop 15 ***
2022-12-04 19:39:17,396 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:39:17,396 INFO Downsampling 444 data
2022-12-04 19:39:17,397 INFO Adding Student as extra rule in Teacher
2022-12-04 19:39:17,397 INFO Getting rule predictions
2022-12-04 19:39:17,397 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:39:17,398 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:17,398 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:17,399 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:39:17,400 INFO Predicting labels for 741 texts
2022-12-04 19:39:17,499 INFO Predicting labels for 18 texts
2022-12-04 19:39:17,599 INFO Predicting labels for 444 texts
2022-12-04 19:39:17,697 INFO Training Rule Attention Network
2022-12-04 19:39:17,704 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:39:17,705 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:39:17,709 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:39:17,709 INFO 

		*** Training RAN ***
2022-12-04 19:39:20,606 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:20,607 INFO Predicting labels for 444 texts
2022-12-04 19:39:20,714 INFO There are 3/7 active rules
2022-12-04 19:39:20,714 INFO Coverage: 100.0% (444/444)
2022-12-04 19:39:20,718 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:39:20,805 INFO DONE, Getting attention scores...
2022-12-04 19:39:20,860 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:20,860 INFO Predicting labels for 18 texts
2022-12-04 19:39:20,961 INFO There are 7/7 active rules
2022-12-04 19:39:20,962 INFO Coverage: 100.0% (18/18)
2022-12-04 19:39:20,962 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:39:20,986 INFO DONE, Getting attention scores...
2022-12-04 19:39:21,040 INFO Evaluating teacher dev iter15 on 18 examples
2022-12-04 19:39:21,044 INFO teacher dev iter15 performance: 83.33
2022-12-04 19:39:21,044 INFO teacher dev iter15 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:21,044 INFO teacher dev iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:21,044 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:39:21,045 INFO Predicting labels for 32 texts
2022-12-04 19:39:21,147 INFO There are 7/7 active rules
2022-12-04 19:39:21,147 INFO Coverage: 100.0% (32/32)
2022-12-04 19:39:21,148 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:39:21,172 INFO DONE, Getting attention scores...
2022-12-04 19:39:21,228 INFO Evaluating teacher test iter15 on 32 examples
2022-12-04 19:39:21,232 INFO teacher test iter15 performance: 78.12
2022-12-04 19:39:21,233 INFO teacher test iter15 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:39:21,233 INFO teacher test iter15 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:39:21,233 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:21,235 INFO Balancing Pseudo Dataset to keep 678 items...
2022-12-04 19:39:21,239 INFO PSEUDO-DATASET:
678 examples
PSEUDO-LABELS:
1    339
0    339
Name: label, dtype: int64
2022-12-04 19:39:21,239 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:22,777 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:24,909 INFO Predicting labels for 18 texts
2022-12-04 19:39:25,011 INFO Evaluating student dev iter15 on 18 examples
2022-12-04 19:39:25,015 INFO student dev iter15 performance: 83.33
2022-12-04 19:39:25,015 INFO student dev iter15 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:25,015 INFO student dev iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:25,016 INFO Predicting labels for 32 texts
2022-12-04 19:39:25,113 INFO Evaluating student test iter15 on 32 examples
2022-12-04 19:39:25,118 INFO student test iter15 performance: 56.25
2022-12-04 19:39:25,118 INFO student test iter15 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:39:25,118 INFO student test iter15 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:39:25,119 INFO Student Dev performance on iter 15: 83.33333333333334
2022-12-04 19:39:25,119 INFO Student Test performance on iter 15: 56.25
2022-12-04 19:39:25,119 INFO 

	 *** Starting loop 16 ***
2022-12-04 19:39:25,119 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:39:25,119 INFO Downsampling 444 data
2022-12-04 19:39:25,120 INFO Adding Student as extra rule in Teacher
2022-12-04 19:39:25,120 INFO Getting rule predictions
2022-12-04 19:39:25,120 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:39:25,121 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:25,121 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:25,122 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:39:25,123 INFO Predicting labels for 741 texts
2022-12-04 19:39:25,226 INFO Predicting labels for 18 texts
2022-12-04 19:39:25,323 INFO Predicting labels for 444 texts
2022-12-04 19:39:25,421 INFO Training Rule Attention Network
2022-12-04 19:39:25,431 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:39:25,432 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:39:25,436 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:39:25,436 INFO 

		*** Training RAN ***
2022-12-04 19:39:28,389 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:28,390 INFO Predicting labels for 444 texts
2022-12-04 19:39:28,495 INFO There are 3/7 active rules
2022-12-04 19:39:28,496 INFO Coverage: 100.0% (444/444)
2022-12-04 19:39:28,500 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:39:28,588 INFO DONE, Getting attention scores...
2022-12-04 19:39:28,650 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:28,650 INFO Predicting labels for 18 texts
2022-12-04 19:39:28,748 INFO There are 7/7 active rules
2022-12-04 19:39:28,749 INFO Coverage: 100.0% (18/18)
2022-12-04 19:39:28,749 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:39:28,774 INFO DONE, Getting attention scores...
2022-12-04 19:39:28,829 INFO Evaluating teacher dev iter16 on 18 examples
2022-12-04 19:39:28,834 INFO teacher dev iter16 performance: 83.33
2022-12-04 19:39:28,834 INFO teacher dev iter16 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:28,834 INFO teacher dev iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:28,835 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:39:28,835 INFO Predicting labels for 32 texts
2022-12-04 19:39:28,939 INFO There are 7/7 active rules
2022-12-04 19:39:28,939 INFO Coverage: 100.0% (32/32)
2022-12-04 19:39:28,940 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:39:28,965 INFO DONE, Getting attention scores...
2022-12-04 19:39:29,020 INFO Evaluating teacher test iter16 on 32 examples
2022-12-04 19:39:29,025 INFO teacher test iter16 performance: 78.12
2022-12-04 19:39:29,025 INFO teacher test iter16 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:39:29,025 INFO teacher test iter16 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:39:29,025 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:29,027 INFO Balancing Pseudo Dataset to keep 682 items...
2022-12-04 19:39:29,031 INFO PSEUDO-DATASET:
682 examples
PSEUDO-LABELS:
1    341
0    341
Name: label, dtype: int64
2022-12-04 19:39:29,032 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:30,454 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:31,591 INFO Predicting labels for 18 texts
2022-12-04 19:39:31,690 INFO Evaluating student dev iter16 on 18 examples
2022-12-04 19:39:31,694 INFO student dev iter16 performance: 83.33
2022-12-04 19:39:31,695 INFO student dev iter16 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:31,695 INFO student dev iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:31,695 INFO Predicting labels for 32 texts
2022-12-04 19:39:31,794 INFO Evaluating student test iter16 on 32 examples
2022-12-04 19:39:31,798 INFO student test iter16 performance: 56.25
2022-12-04 19:39:31,798 INFO student test iter16 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:39:31,798 INFO student test iter16 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:39:31,798 INFO Student Dev performance on iter 16: 83.33333333333334
2022-12-04 19:39:31,798 INFO Student Test performance on iter 16: 56.25
2022-12-04 19:39:31,799 INFO 

	 *** Starting loop 17 ***
2022-12-04 19:39:31,799 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:39:31,799 INFO Downsampling 444 data
2022-12-04 19:39:31,799 INFO Adding Student as extra rule in Teacher
2022-12-04 19:39:31,800 INFO Getting rule predictions
2022-12-04 19:39:31,800 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:39:31,801 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:31,801 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:31,801 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:39:31,802 INFO Predicting labels for 741 texts
2022-12-04 19:39:31,906 INFO Predicting labels for 18 texts
2022-12-04 19:39:32,003 INFO Predicting labels for 444 texts
2022-12-04 19:39:32,103 INFO Training Rule Attention Network
2022-12-04 19:39:32,110 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:39:32,111 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:39:32,115 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:39:32,115 INFO 

		*** Training RAN ***
2022-12-04 19:39:35,155 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:35,156 INFO Predicting labels for 444 texts
2022-12-04 19:39:35,264 INFO There are 3/7 active rules
2022-12-04 19:39:35,264 INFO Coverage: 100.0% (444/444)
2022-12-04 19:39:35,269 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:39:35,361 INFO DONE, Getting attention scores...
2022-12-04 19:39:35,422 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:35,422 INFO Predicting labels for 18 texts
2022-12-04 19:39:35,522 INFO There are 7/7 active rules
2022-12-04 19:39:35,523 INFO Coverage: 100.0% (18/18)
2022-12-04 19:39:35,523 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:39:35,548 INFO DONE, Getting attention scores...
2022-12-04 19:39:35,604 INFO Evaluating teacher dev iter17 on 18 examples
2022-12-04 19:39:35,609 INFO teacher dev iter17 performance: 83.33
2022-12-04 19:39:35,609 INFO teacher dev iter17 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:35,609 INFO teacher dev iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:35,609 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:39:35,610 INFO Predicting labels for 32 texts
2022-12-04 19:39:35,717 INFO There are 7/7 active rules
2022-12-04 19:39:35,717 INFO Coverage: 100.0% (32/32)
2022-12-04 19:39:35,718 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:39:35,743 INFO DONE, Getting attention scores...
2022-12-04 19:39:35,797 INFO Evaluating teacher test iter17 on 32 examples
2022-12-04 19:39:35,802 INFO teacher test iter17 performance: 75.00
2022-12-04 19:39:35,802 INFO teacher test iter17 confusion matrix:
[[ 8  6]
 [ 2 16]]
2022-12-04 19:39:35,802 INFO teacher test iter17 report:
              precision    recall  f1-score   support

           0       0.80      0.57      0.67        14
           1       0.73      0.89      0.80        18

    accuracy                           0.75        32
   macro avg       0.76      0.73      0.73        32
weighted avg       0.76      0.75      0.74        32

2022-12-04 19:39:35,802 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:35,804 INFO Balancing Pseudo Dataset to keep 642 items...
2022-12-04 19:39:35,808 INFO PSEUDO-DATASET:
642 examples
PSEUDO-LABELS:
1    321
0    321
Name: label, dtype: int64
2022-12-04 19:39:35,808 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:37,270 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:38,365 INFO Predicting labels for 18 texts
2022-12-04 19:39:38,468 INFO Evaluating student dev iter17 on 18 examples
2022-12-04 19:39:38,472 INFO student dev iter17 performance: 83.33
2022-12-04 19:39:38,472 INFO student dev iter17 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:38,472 INFO student dev iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:38,473 INFO Predicting labels for 32 texts
2022-12-04 19:39:38,572 INFO Evaluating student test iter17 on 32 examples
2022-12-04 19:39:38,577 INFO student test iter17 performance: 56.25
2022-12-04 19:39:38,577 INFO student test iter17 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:39:38,577 INFO student test iter17 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:39:38,577 INFO Student Dev performance on iter 17: 83.33333333333334
2022-12-04 19:39:38,577 INFO Student Test performance on iter 17: 56.25
2022-12-04 19:39:38,577 INFO 

	 *** Starting loop 18 ***
2022-12-04 19:39:38,577 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:39:38,577 INFO Downsampling 444 data
2022-12-04 19:39:38,578 INFO Adding Student as extra rule in Teacher
2022-12-04 19:39:38,578 INFO Getting rule predictions
2022-12-04 19:39:38,578 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:39:38,579 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:38,579 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:38,580 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:39:38,580 INFO Predicting labels for 741 texts
2022-12-04 19:39:38,680 INFO Predicting labels for 18 texts
2022-12-04 19:39:38,774 INFO Predicting labels for 444 texts
2022-12-04 19:39:38,875 INFO Training Rule Attention Network
2022-12-04 19:39:38,883 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:39:38,883 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:39:38,888 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:39:38,888 INFO 

		*** Training RAN ***
2022-12-04 19:39:41,748 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:41,749 INFO Predicting labels for 444 texts
2022-12-04 19:39:41,849 INFO There are 3/7 active rules
2022-12-04 19:39:41,849 INFO Coverage: 100.0% (444/444)
2022-12-04 19:39:41,853 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:39:41,942 INFO DONE, Getting attention scores...
2022-12-04 19:39:41,999 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:41,999 INFO Predicting labels for 18 texts
2022-12-04 19:39:42,096 INFO There are 7/7 active rules
2022-12-04 19:39:42,096 INFO Coverage: 100.0% (18/18)
2022-12-04 19:39:42,097 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:39:42,122 INFO DONE, Getting attention scores...
2022-12-04 19:39:42,180 INFO Evaluating teacher dev iter18 on 18 examples
2022-12-04 19:39:42,184 INFO teacher dev iter18 performance: 83.33
2022-12-04 19:39:42,184 INFO teacher dev iter18 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:42,184 INFO teacher dev iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:42,184 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:39:42,184 INFO Predicting labels for 32 texts
2022-12-04 19:39:42,289 INFO There are 7/7 active rules
2022-12-04 19:39:42,289 INFO Coverage: 100.0% (32/32)
2022-12-04 19:39:42,290 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:39:42,316 INFO DONE, Getting attention scores...
2022-12-04 19:39:42,377 INFO Evaluating teacher test iter18 on 32 examples
2022-12-04 19:39:42,381 INFO teacher test iter18 performance: 78.12
2022-12-04 19:39:42,382 INFO teacher test iter18 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:39:42,382 INFO teacher test iter18 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:39:42,382 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:42,383 INFO Balancing Pseudo Dataset to keep 676 items...
2022-12-04 19:39:42,388 INFO PSEUDO-DATASET:
676 examples
PSEUDO-LABELS:
1    338
0    338
Name: label, dtype: int64
2022-12-04 19:39:42,388 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:43,995 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:45,098 INFO Predicting labels for 18 texts
2022-12-04 19:39:45,212 INFO Evaluating student dev iter18 on 18 examples
2022-12-04 19:39:45,216 INFO student dev iter18 performance: 83.33
2022-12-04 19:39:45,217 INFO student dev iter18 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:45,217 INFO student dev iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:45,217 INFO Predicting labels for 32 texts
2022-12-04 19:39:45,333 INFO Evaluating student test iter18 on 32 examples
2022-12-04 19:39:45,337 INFO student test iter18 performance: 56.25
2022-12-04 19:39:45,337 INFO student test iter18 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:39:45,337 INFO student test iter18 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:39:45,338 INFO Student Dev performance on iter 18: 83.33333333333334
2022-12-04 19:39:45,338 INFO Student Test performance on iter 18: 56.25
2022-12-04 19:39:45,338 INFO 

	 *** Starting loop 19 ***
2022-12-04 19:39:45,338 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:39:45,338 INFO Downsampling 444 data
2022-12-04 19:39:45,339 INFO Adding Student as extra rule in Teacher
2022-12-04 19:39:45,339 INFO Getting rule predictions
2022-12-04 19:39:45,339 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:39:45,340 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:45,340 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:45,341 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:39:45,342 INFO Predicting labels for 741 texts
2022-12-04 19:39:45,442 INFO Predicting labels for 18 texts
2022-12-04 19:39:45,544 INFO Predicting labels for 444 texts
2022-12-04 19:39:45,646 INFO Training Rule Attention Network
2022-12-04 19:39:45,653 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:39:45,653 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:39:45,657 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:39:45,658 INFO 

		*** Training RAN ***
2022-12-04 19:39:48,558 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:48,559 INFO Predicting labels for 444 texts
2022-12-04 19:39:48,663 INFO There are 3/7 active rules
2022-12-04 19:39:48,664 INFO Coverage: 100.0% (444/444)
2022-12-04 19:39:48,668 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:39:48,754 INFO DONE, Getting attention scores...
2022-12-04 19:39:48,812 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:48,812 INFO Predicting labels for 18 texts
2022-12-04 19:39:48,912 INFO There are 7/7 active rules
2022-12-04 19:39:48,912 INFO Coverage: 100.0% (18/18)
2022-12-04 19:39:48,914 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:39:48,939 INFO DONE, Getting attention scores...
2022-12-04 19:39:48,995 INFO Evaluating teacher dev iter19 on 18 examples
2022-12-04 19:39:49,000 INFO teacher dev iter19 performance: 83.33
2022-12-04 19:39:49,000 INFO teacher dev iter19 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:49,001 INFO teacher dev iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:49,002 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:39:49,003 INFO Predicting labels for 32 texts
2022-12-04 19:39:49,108 INFO There are 7/7 active rules
2022-12-04 19:39:49,108 INFO Coverage: 100.0% (32/32)
2022-12-04 19:39:49,109 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:39:49,133 INFO DONE, Getting attention scores...
2022-12-04 19:39:49,189 INFO Evaluating teacher test iter19 on 32 examples
2022-12-04 19:39:49,194 INFO teacher test iter19 performance: 78.12
2022-12-04 19:39:49,194 INFO teacher test iter19 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:39:49,194 INFO teacher test iter19 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:39:49,194 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:49,196 INFO Balancing Pseudo Dataset to keep 642 items...
2022-12-04 19:39:49,200 INFO PSEUDO-DATASET:
642 examples
PSEUDO-LABELS:
1    321
0    321
Name: label, dtype: int64
2022-12-04 19:39:49,200 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:50,659 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:51,781 INFO Predicting labels for 18 texts
2022-12-04 19:39:51,988 INFO Evaluating student dev iter19 on 18 examples
2022-12-04 19:39:51,992 INFO student dev iter19 performance: 83.33
2022-12-04 19:39:51,992 INFO student dev iter19 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:51,993 INFO student dev iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:51,993 INFO Predicting labels for 32 texts
2022-12-04 19:39:52,094 INFO Evaluating student test iter19 on 32 examples
2022-12-04 19:39:52,098 INFO student test iter19 performance: 56.25
2022-12-04 19:39:52,099 INFO student test iter19 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:39:52,099 INFO student test iter19 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:39:52,099 INFO Student Dev performance on iter 19: 83.33333333333334
2022-12-04 19:39:52,099 INFO Student Test performance on iter 19: 56.25
2022-12-04 19:39:52,099 INFO 

	 *** Starting loop 20 ***
2022-12-04 19:39:52,099 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:39:52,100 INFO Downsampling 444 data
2022-12-04 19:39:52,100 INFO Adding Student as extra rule in Teacher
2022-12-04 19:39:52,100 INFO Getting rule predictions
2022-12-04 19:39:52,100 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:39:52,101 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:52,102 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:52,102 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:39:52,103 INFO Predicting labels for 741 texts
2022-12-04 19:39:52,217 INFO Predicting labels for 18 texts
2022-12-04 19:39:52,335 INFO Predicting labels for 444 texts
2022-12-04 19:39:52,436 INFO Training Rule Attention Network
2022-12-04 19:39:52,449 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:39:52,449 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:39:52,453 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:39:52,453 INFO 

		*** Training RAN ***
2022-12-04 19:39:55,300 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:39:55,301 INFO Predicting labels for 444 texts
2022-12-04 19:39:55,406 INFO There are 3/7 active rules
2022-12-04 19:39:55,406 INFO Coverage: 100.0% (444/444)
2022-12-04 19:39:55,411 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:39:55,506 INFO DONE, Getting attention scores...
2022-12-04 19:39:55,569 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:39:55,569 INFO Predicting labels for 18 texts
2022-12-04 19:39:55,674 INFO There are 7/7 active rules
2022-12-04 19:39:55,674 INFO Coverage: 100.0% (18/18)
2022-12-04 19:39:55,675 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:39:55,703 INFO DONE, Getting attention scores...
2022-12-04 19:39:55,762 INFO Evaluating teacher dev iter20 on 18 examples
2022-12-04 19:39:55,766 INFO teacher dev iter20 performance: 83.33
2022-12-04 19:39:55,767 INFO teacher dev iter20 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:39:55,767 INFO teacher dev iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:39:55,767 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:39:55,767 INFO Predicting labels for 32 texts
2022-12-04 19:39:55,867 INFO There are 7/7 active rules
2022-12-04 19:39:55,867 INFO Coverage: 100.0% (32/32)
2022-12-04 19:39:55,868 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:39:55,893 INFO DONE, Getting attention scores...
2022-12-04 19:39:55,949 INFO Evaluating teacher test iter20 on 32 examples
2022-12-04 19:39:55,953 INFO teacher test iter20 performance: 78.12
2022-12-04 19:39:55,954 INFO teacher test iter20 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:39:55,954 INFO teacher test iter20 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:39:55,954 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:39:55,956 INFO Balancing Pseudo Dataset to keep 694 items...
2022-12-04 19:39:55,961 INFO PSEUDO-DATASET:
694 examples
PSEUDO-LABELS:
1    347
0    347
Name: label, dtype: int64
2022-12-04 19:39:55,961 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:39:58,422 INFO fine-tuning the student on clean labeled data
2022-12-04 19:39:59,467 INFO Predicting labels for 18 texts
2022-12-04 19:40:00,586 INFO Evaluating student dev iter20 on 18 examples
2022-12-04 19:40:00,591 INFO student dev iter20 performance: 83.33
2022-12-04 19:40:00,591 INFO student dev iter20 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:00,591 INFO student dev iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:00,591 INFO Predicting labels for 32 texts
2022-12-04 19:40:00,695 INFO Evaluating student test iter20 on 32 examples
2022-12-04 19:40:00,700 INFO student test iter20 performance: 56.25
2022-12-04 19:40:00,700 INFO student test iter20 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:40:00,700 INFO student test iter20 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:40:00,700 INFO Student Dev performance on iter 20: 83.33333333333334
2022-12-04 19:40:00,700 INFO Student Test performance on iter 20: 56.25
2022-12-04 19:40:00,701 INFO 

	 *** Starting loop 21 ***
2022-12-04 19:40:00,701 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:40:00,701 INFO Downsampling 444 data
2022-12-04 19:40:00,701 INFO Adding Student as extra rule in Teacher
2022-12-04 19:40:00,702 INFO Getting rule predictions
2022-12-04 19:40:00,702 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:40:00,703 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:40:00,703 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:40:00,703 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:40:00,704 INFO Predicting labels for 741 texts
2022-12-04 19:40:00,803 INFO Predicting labels for 18 texts
2022-12-04 19:40:00,900 INFO Predicting labels for 444 texts
2022-12-04 19:40:01,002 INFO Training Rule Attention Network
2022-12-04 19:40:01,009 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:40:01,010 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:40:01,014 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:40:01,014 INFO 

		*** Training RAN ***
2022-12-04 19:40:04,079 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:40:04,080 INFO Predicting labels for 444 texts
2022-12-04 19:40:04,186 INFO There are 3/7 active rules
2022-12-04 19:40:04,187 INFO Coverage: 100.0% (444/444)
2022-12-04 19:40:04,191 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:40:04,281 INFO DONE, Getting attention scores...
2022-12-04 19:40:04,338 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:40:04,339 INFO Predicting labels for 18 texts
2022-12-04 19:40:04,441 INFO There are 7/7 active rules
2022-12-04 19:40:04,442 INFO Coverage: 100.0% (18/18)
2022-12-04 19:40:04,443 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:40:04,468 INFO DONE, Getting attention scores...
2022-12-04 19:40:04,523 INFO Evaluating teacher dev iter21 on 18 examples
2022-12-04 19:40:04,528 INFO teacher dev iter21 performance: 83.33
2022-12-04 19:40:04,528 INFO teacher dev iter21 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:04,528 INFO teacher dev iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:04,529 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:40:04,529 INFO Predicting labels for 32 texts
2022-12-04 19:40:04,629 INFO There are 7/7 active rules
2022-12-04 19:40:04,629 INFO Coverage: 100.0% (32/32)
2022-12-04 19:40:04,630 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:40:04,654 INFO DONE, Getting attention scores...
2022-12-04 19:40:04,714 INFO Evaluating teacher test iter21 on 32 examples
2022-12-04 19:40:04,718 INFO teacher test iter21 performance: 78.12
2022-12-04 19:40:04,718 INFO teacher test iter21 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:40:04,718 INFO teacher test iter21 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:40:04,719 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:40:04,720 INFO Balancing Pseudo Dataset to keep 692 items...
2022-12-04 19:40:04,724 INFO PSEUDO-DATASET:
692 examples
PSEUDO-LABELS:
1    346
0    346
Name: label, dtype: int64
2022-12-04 19:40:04,724 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:40:05,514 INFO fine-tuning the student on clean labeled data
2022-12-04 19:40:07,609 INFO Predicting labels for 18 texts
2022-12-04 19:40:07,710 INFO Evaluating student dev iter21 on 18 examples
2022-12-04 19:40:07,714 INFO student dev iter21 performance: 83.33
2022-12-04 19:40:07,715 INFO student dev iter21 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:07,715 INFO student dev iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:07,715 INFO Predicting labels for 32 texts
2022-12-04 19:40:07,815 INFO Evaluating student test iter21 on 32 examples
2022-12-04 19:40:07,819 INFO student test iter21 performance: 56.25
2022-12-04 19:40:07,820 INFO student test iter21 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:40:07,820 INFO student test iter21 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:40:07,820 INFO Student Dev performance on iter 21: 83.33333333333334
2022-12-04 19:40:07,820 INFO Student Test performance on iter 21: 56.25
2022-12-04 19:40:07,820 INFO 

	 *** Starting loop 22 ***
2022-12-04 19:40:07,820 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:40:07,820 INFO Downsampling 444 data
2022-12-04 19:40:07,821 INFO Adding Student as extra rule in Teacher
2022-12-04 19:40:07,821 INFO Getting rule predictions
2022-12-04 19:40:07,821 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:40:07,822 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:40:07,822 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:40:07,823 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:40:07,824 INFO Predicting labels for 741 texts
2022-12-04 19:40:07,925 INFO Predicting labels for 18 texts
2022-12-04 19:40:08,023 INFO Predicting labels for 444 texts
2022-12-04 19:40:08,122 INFO Training Rule Attention Network
2022-12-04 19:40:08,133 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:40:08,134 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:40:08,138 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:40:08,138 INFO 

		*** Training RAN ***
2022-12-04 19:40:11,093 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:40:11,094 INFO Predicting labels for 444 texts
2022-12-04 19:40:11,195 INFO There are 3/7 active rules
2022-12-04 19:40:11,196 INFO Coverage: 100.0% (444/444)
2022-12-04 19:40:11,200 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:40:11,292 INFO DONE, Getting attention scores...
2022-12-04 19:40:11,347 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:40:11,348 INFO Predicting labels for 18 texts
2022-12-04 19:40:11,445 INFO There are 7/7 active rules
2022-12-04 19:40:11,445 INFO Coverage: 100.0% (18/18)
2022-12-04 19:40:11,446 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:40:11,469 INFO DONE, Getting attention scores...
2022-12-04 19:40:11,529 INFO Evaluating teacher dev iter22 on 18 examples
2022-12-04 19:40:11,533 INFO teacher dev iter22 performance: 83.33
2022-12-04 19:40:11,533 INFO teacher dev iter22 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:11,533 INFO teacher dev iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:11,533 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:40:11,533 INFO Predicting labels for 32 texts
2022-12-04 19:40:11,639 INFO There are 7/7 active rules
2022-12-04 19:40:11,639 INFO Coverage: 100.0% (32/32)
2022-12-04 19:40:11,640 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:40:11,664 INFO DONE, Getting attention scores...
2022-12-04 19:40:11,719 INFO Evaluating teacher test iter22 on 32 examples
2022-12-04 19:40:11,724 INFO teacher test iter22 performance: 78.12
2022-12-04 19:40:11,724 INFO teacher test iter22 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:40:11,724 INFO teacher test iter22 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:40:11,724 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:40:11,726 INFO Balancing Pseudo Dataset to keep 688 items...
2022-12-04 19:40:11,731 INFO PSEUDO-DATASET:
688 examples
PSEUDO-LABELS:
1    344
0    344
Name: label, dtype: int64
2022-12-04 19:40:11,731 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:40:15,410 INFO fine-tuning the student on clean labeled data
2022-12-04 19:40:16,538 INFO Predicting labels for 18 texts
2022-12-04 19:40:17,662 INFO Evaluating student dev iter22 on 18 examples
2022-12-04 19:40:17,666 INFO student dev iter22 performance: 83.33
2022-12-04 19:40:17,667 INFO student dev iter22 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:17,667 INFO student dev iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:17,667 INFO Predicting labels for 32 texts
2022-12-04 19:40:17,772 INFO Evaluating student test iter22 on 32 examples
2022-12-04 19:40:17,776 INFO student test iter22 performance: 56.25
2022-12-04 19:40:17,777 INFO student test iter22 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:40:17,777 INFO student test iter22 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:40:17,777 INFO Student Dev performance on iter 22: 83.33333333333334
2022-12-04 19:40:17,777 INFO Student Test performance on iter 22: 56.25
2022-12-04 19:40:17,777 INFO 

	 *** Starting loop 23 ***
2022-12-04 19:40:17,777 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:40:17,777 INFO Downsampling 444 data
2022-12-04 19:40:17,778 INFO Adding Student as extra rule in Teacher
2022-12-04 19:40:17,778 INFO Getting rule predictions
2022-12-04 19:40:17,778 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:40:17,779 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:40:17,779 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:40:17,780 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:40:17,781 INFO Predicting labels for 741 texts
2022-12-04 19:40:17,883 INFO Predicting labels for 18 texts
2022-12-04 19:40:17,983 INFO Predicting labels for 444 texts
2022-12-04 19:40:18,086 INFO Training Rule Attention Network
2022-12-04 19:40:18,093 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:40:18,094 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:40:18,098 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:40:18,098 INFO 

		*** Training RAN ***
2022-12-04 19:40:21,070 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:40:21,072 INFO Predicting labels for 444 texts
2022-12-04 19:40:21,177 INFO There are 3/7 active rules
2022-12-04 19:40:21,177 INFO Coverage: 100.0% (444/444)
2022-12-04 19:40:21,181 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:40:21,268 INFO DONE, Getting attention scores...
2022-12-04 19:40:21,328 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:40:21,328 INFO Predicting labels for 18 texts
2022-12-04 19:40:21,430 INFO There are 7/7 active rules
2022-12-04 19:40:21,430 INFO Coverage: 100.0% (18/18)
2022-12-04 19:40:21,431 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:40:21,456 INFO DONE, Getting attention scores...
2022-12-04 19:40:21,511 INFO Evaluating teacher dev iter23 on 18 examples
2022-12-04 19:40:21,515 INFO teacher dev iter23 performance: 83.33
2022-12-04 19:40:21,515 INFO teacher dev iter23 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:21,516 INFO teacher dev iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:21,516 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:40:21,516 INFO Predicting labels for 32 texts
2022-12-04 19:40:22,644 INFO There are 7/7 active rules
2022-12-04 19:40:22,645 INFO Coverage: 100.0% (32/32)
2022-12-04 19:40:22,646 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:40:22,669 INFO DONE, Getting attention scores...
2022-12-04 19:40:22,722 INFO Evaluating teacher test iter23 on 32 examples
2022-12-04 19:40:22,727 INFO teacher test iter23 performance: 75.00
2022-12-04 19:40:22,728 INFO teacher test iter23 confusion matrix:
[[ 8  6]
 [ 2 16]]
2022-12-04 19:40:22,728 INFO teacher test iter23 report:
              precision    recall  f1-score   support

           0       0.80      0.57      0.67        14
           1       0.73      0.89      0.80        18

    accuracy                           0.75        32
   macro avg       0.76      0.73      0.73        32
weighted avg       0.76      0.75      0.74        32

2022-12-04 19:40:22,728 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:40:22,730 INFO Balancing Pseudo Dataset to keep 646 items...
2022-12-04 19:40:22,734 INFO PSEUDO-DATASET:
646 examples
PSEUDO-LABELS:
1    323
0    323
Name: label, dtype: int64
2022-12-04 19:40:22,734 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:40:24,159 INFO fine-tuning the student on clean labeled data
2022-12-04 19:40:25,245 INFO Predicting labels for 18 texts
2022-12-04 19:40:25,343 INFO Evaluating student dev iter23 on 18 examples
2022-12-04 19:40:25,347 INFO student dev iter23 performance: 83.33
2022-12-04 19:40:25,348 INFO student dev iter23 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:25,348 INFO student dev iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:25,348 INFO Predicting labels for 32 texts
2022-12-04 19:40:25,445 INFO Evaluating student test iter23 on 32 examples
2022-12-04 19:40:25,450 INFO student test iter23 performance: 56.25
2022-12-04 19:40:25,450 INFO student test iter23 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:40:25,450 INFO student test iter23 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:40:25,450 INFO Student Dev performance on iter 23: 83.33333333333334
2022-12-04 19:40:25,451 INFO Student Test performance on iter 23: 56.25
2022-12-04 19:40:25,451 INFO 

	 *** Starting loop 24 ***
2022-12-04 19:40:25,451 INFO [WARNING] sample size = 16384 > 444
2022-12-04 19:40:25,451 INFO Downsampling 444 data
2022-12-04 19:40:25,452 INFO Adding Student as extra rule in Teacher
2022-12-04 19:40:25,452 INFO Getting rule predictions
2022-12-04 19:40:25,452 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-04 19:40:25,453 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:40:25,453 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:40:25,454 INFO Getting student predictions on train (and dev) dataset
2022-12-04 19:40:25,454 INFO Predicting labels for 741 texts
2022-12-04 19:40:25,559 INFO Predicting labels for 18 texts
2022-12-04 19:40:25,659 INFO Predicting labels for 444 texts
2022-12-04 19:40:25,761 INFO Training Rule Attention Network
2022-12-04 19:40:25,768 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-04 19:40:25,768 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-04 19:40:25,772 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-04 19:40:25,772 INFO 

		*** Training RAN ***
2022-12-04 19:40:28,758 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-04 19:40:28,759 INFO Predicting labels for 444 texts
2022-12-04 19:40:28,866 INFO There are 3/7 active rules
2022-12-04 19:40:28,866 INFO Coverage: 100.0% (444/444)
2022-12-04 19:40:28,870 INFO RAN - Predicting labels for 444 texts
2022-12-04 19:40:28,963 INFO DONE, Getting attention scores...
2022-12-04 19:40:29,022 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-04 19:40:29,022 INFO Predicting labels for 18 texts
2022-12-04 19:40:29,121 INFO There are 7/7 active rules
2022-12-04 19:40:29,122 INFO Coverage: 100.0% (18/18)
2022-12-04 19:40:29,122 INFO RAN - Predicting labels for 18 texts
2022-12-04 19:40:29,145 INFO DONE, Getting attention scores...
2022-12-04 19:40:29,205 INFO Evaluating teacher dev iter24 on 18 examples
2022-12-04 19:40:29,209 INFO teacher dev iter24 performance: 83.33
2022-12-04 19:40:29,209 INFO teacher dev iter24 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:29,210 INFO teacher dev iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:29,210 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-04 19:40:29,210 INFO Predicting labels for 32 texts
2022-12-04 19:40:29,313 INFO There are 7/7 active rules
2022-12-04 19:40:29,313 INFO Coverage: 100.0% (32/32)
2022-12-04 19:40:29,314 INFO RAN - Predicting labels for 32 texts
2022-12-04 19:40:29,338 INFO DONE, Getting attention scores...
2022-12-04 19:40:29,392 INFO Evaluating teacher test iter24 on 32 examples
2022-12-04 19:40:29,397 INFO teacher test iter24 performance: 78.12
2022-12-04 19:40:29,397 INFO teacher test iter24 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-04 19:40:29,397 INFO teacher test iter24 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-04 19:40:29,397 INFO Creating Pseudo Dataset with 444 items...
2022-12-04 19:40:29,399 INFO Balancing Pseudo Dataset to keep 652 items...
2022-12-04 19:40:29,403 INFO PSEUDO-DATASET:
652 examples
PSEUDO-LABELS:
1    326
0    326
Name: label, dtype: int64
2022-12-04 19:40:29,403 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-04 19:40:30,819 INFO fine-tuning the student on clean labeled data
2022-12-04 19:40:32,994 INFO Predicting labels for 18 texts
2022-12-04 19:40:33,098 INFO Evaluating student dev iter24 on 18 examples
2022-12-04 19:40:33,103 INFO student dev iter24 performance: 83.33
2022-12-04 19:40:33,104 INFO student dev iter24 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-04 19:40:33,104 INFO student dev iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-04 19:40:33,104 INFO Predicting labels for 32 texts
2022-12-04 19:40:34,222 INFO Evaluating student test iter24 on 32 examples
2022-12-04 19:40:34,226 INFO student test iter24 performance: 56.25
2022-12-04 19:40:34,227 INFO student test iter24 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-04 19:40:34,227 INFO student test iter24 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-04 19:40:34,227 INFO Student Dev performance on iter 24: 83.33333333333334
2022-12-04 19:40:34,227 INFO Student Test performance on iter 24: 56.25
2022-12-04 19:40:34,227 INFO Final Results
2022-12-04 19:40:34,227 INFO TEACHER PERFORMANCES:
0:	88.89	78.12
1:	83.33	78.12
2:	83.33	78.12
3:	83.33	78.12
4:	83.33	78.12
5:	83.33	78.12
6:	83.33	78.12
7:	83.33	78.12
8:	83.33	78.12
9:	83.33	78.12
10:	83.33	78.12
11:	83.33	78.12
12:	83.33	78.12
13:	83.33	78.12
14:	83.33	78.12
15:	83.33	78.12
16:	83.33	78.12
17:	83.33	78.12
18:	83.33	75.00
19:	83.33	78.12
20:	83.33	78.12
21:	83.33	78.12
22:	83.33	78.12
23:	83.33	78.12
24:	83.33	75.00
25:	83.33	78.12
2022-12-04 19:40:34,228 INFO STUDENT PERFORMANCES:
0:	50.00	59.38
1:	83.33	56.25
2:	83.33	56.25
3:	83.33	56.25
4:	83.33	56.25
5:	83.33	56.25
6:	83.33	56.25
7:	83.33	56.25
8:	83.33	56.25
9:	83.33	56.25
10:	83.33	56.25
11:	83.33	56.25
12:	83.33	56.25
13:	83.33	56.25
14:	83.33	56.25
15:	83.33	56.25
16:	83.33	56.25
17:	83.33	56.25
18:	83.33	56.25
19:	83.33	56.25
20:	83.33	56.25
21:	83.33	56.25
22:	83.33	56.25
23:	83.33	56.25
24:	83.33	56.25
25:	83.33	56.25
2022-12-04 19:40:34,228 INFO BEST DEV weighted_acc = 83.333 for epoch 25
2022-12-04 19:40:34,228 INFO FINAL TEST weighted_acc = 56.250 for epoch 25 (max=59.38 for epoch 0)
2022-12-04 19:40:34,228 INFO Saving student_last to ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/student_last
2022-12-04 19:40:34,228 INFO Saving model at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/student_last/final_model.h5
2022-12-04 19:40:34,235 INFO Saving teacher at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/teacher_last
2022-12-04 19:40:34,235 INFO Saving rule attention network at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/teacher_last/rule_attention_network.h5
2022-12-04 19:40:34,243 INFO 	*** Final Results ***
2022-12-04 19:40:34,243 INFO 
student_train:	{'dev_loss': 0.8489859700202942}
2022-12-04 19:40:34,244 INFO 
supervised_student_dev:	{'acc': 50.0, 'weighted_acc': 50.0, 'prec': 48.75, 'rec': 48.701298701298704, 'f1': 48.57142857142856, 'weighted_f1': 48.57142857142856, 'ignored': 0, 'total': 18, 'perf': 50.0}
2022-12-04 19:40:34,244 INFO 
supervised_student_test:	{'acc': 59.375, 'weighted_acc': 59.375, 'prec': 62.643678160919535, 'rec': 54.36507936507936, 'f1': 47.934918648310386, 'weighted_f1': 47.934918648310386, 'ignored': 0, 'total': 32, 'perf': 59.375}
2022-12-04 19:40:34,244 INFO 
teacher_train:	{'acc': 90.68825910931174, 'weighted_acc': 90.68825910931174, 'prec': 89.1351943076081, 'rec': 86.26373626373626, 'f1': 87.55067604584401, 'weighted_f1': 87.55067604584401, 'ignored': 0, 'total': 741, 'perf': 90.68825910931174}
2022-12-04 19:40:34,244 INFO 
teacher_dev:	{'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}
2022-12-04 19:40:34,244 INFO 
teacher_test:	{'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}
2022-12-04 19:40:34,244 INFO 
teacher_train_iter:	[{'acc': 90.68825910931174, 'weighted_acc': 90.68825910931174, 'prec': 89.1351943076081, 'rec': 86.26373626373626, 'f1': 87.55067604584401, 'weighted_f1': 87.55067604584401, 'ignored': 0, 'total': 741, 'perf': 90.68825910931174}]
2022-12-04 19:40:34,244 INFO 
teacher_dev_iter:	[{'acc': 88.88888888888889, 'weighted_acc': 88.88888888888889, 'prec': 92.3076923076923, 'rec': 85.71428571428572, 'f1': 87.5, 'weighted_f1': 87.5, 'ignored': 0, 'total': 18, 'perf': 88.88888888888889}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}]
2022-12-04 19:40:34,245 INFO 
teacher_test_iter:	[{'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 75.0, 'weighted_acc': 75.0, 'prec': 76.36363636363637, 'rec': 73.01587301587301, 'f1': 73.33333333333333, 'weighted_f1': 73.33333333333333, 'ignored': 0, 'total': 32, 'perf': 75.0}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 75.0, 'weighted_acc': 75.0, 'prec': 76.36363636363637, 'rec': 73.01587301587301, 'f1': 73.33333333333333, 'weighted_f1': 73.33333333333333, 'ignored': 0, 'total': 32, 'perf': 75.0}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}]
2022-12-04 19:40:34,245 INFO 
student_train_iter:	[{'dev_loss': 0.8489859700202942}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]
2022-12-04 19:40:34,246 INFO 
student_dev_iter:	[{'acc': 50.0, 'weighted_acc': 50.0, 'prec': 48.75, 'rec': 48.701298701298704, 'f1': 48.57142857142856, 'weighted_f1': 48.57142857142856, 'ignored': 0, 'total': 18, 'perf': 50.0}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}]
2022-12-04 19:40:34,264 INFO 
student_test_iter:	[{'acc': 59.375, 'weighted_acc': 59.375, 'prec': 62.643678160919535, 'rec': 54.36507936507936, 'f1': 47.934918648310386, 'weighted_f1': 47.934918648310386, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}]
2022-12-04 19:40:34,280 INFO 
student_dev:	{'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}
2022-12-04 19:40:34,282 INFO 
student_test:	{'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}
2022-12-04 19:40:34,283 INFO Saving results at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/results.pkl
2022-12-04 19:40:34,310 INFO Dataset: econ
2022-12-04 19:40:34,310 INFO Weak Sources: ['econrules']
2022-12-04 19:40:34,310 INFO Model: bert

2022-12-04 19:40:34,310 INFO Teacher Train weighted_acc: 90.7
2022-12-04 19:40:34,310 INFO Teacher Dev weighted_acc: 83.3
2022-12-04 19:40:34,310 INFO Teacher Test weighted_acc: 78.1

2022-12-04 19:40:34,311 INFO Student Dev weighted_acc: 83.3
2022-12-04 19:40:34,311 INFO Student Test weighted_acc: 56.2
2022-12-04 19:40:34,313 INFO Saved report at ../experiments/econ/Dec04_19-37_ECON_experiments/seed0/2022_12_04-19_37_stBERT/results.txt
