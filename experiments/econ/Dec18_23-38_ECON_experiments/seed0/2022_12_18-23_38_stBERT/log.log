2022-12-18 23:38:11,857 INFO 

		 *** NEW EXPERIMENT ***
args=Namespace(adam_epsilon=1e-08, convert_abstain_to_random=False, datapath='../data', dataset='econ', debug=False, device=device(type='cuda'), downsample=1.0, eval_batch_size=16, experiment_folder='../experiments/econ', finetuning_rate=0.0001, fp16=False, hard_student_rule=False, learning_rate=0.0001, logdir='../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT', logging_steps=500, loss_weights=False, lower_case=False, max_grad_norm=1.0, max_rule_seq_length=10, max_seq_length=64, max_size=1000, metric='weighted_acc', n_gpu=1, no_cuda=False, num_epochs=15, num_iter=25, num_labels=2, num_supervised_trials=5, num_unsup_epochs=25, oversample=3, overwrite=False, sample_size=16384, seed=0, soft_labels=False, student_name='bert', teacher_name='ran', tokenizer_method='clean', train_batch_size=16, unsup_batch_size=128, warmup_steps=0, weak_sources=None, weight_decay=0.0)
2022-12-18 23:38:11,857 INFO building student: bert
2022-12-18 23:38:11,857 INFO building teacher
2022-12-18 23:38:11,857 INFO No weak sources specified for Teacher. Using default: ['econrules']
2022-12-18 23:38:11,857 INFO loading data
2022-12-18 23:38:11,860 INFO Pre-processing train data for student...
2022-12-18 23:38:11,863 INFO train DATASET: 247 examples
2022-12-18 23:38:11,866 INFO train LABELS:
1    182
0     65
Name: label, dtype: int64
2022-12-18 23:38:11,866 INFO Oversampling train data 3 times
2022-12-18 23:38:11,870 INFO train DATASET: 741 examples
2022-12-18 23:38:11,871 INFO train LABELS:
1    546
0    195
Name: label, dtype: int64
2022-12-18 23:38:11,872 INFO Pre-processing dev data for student...
2022-12-18 23:38:11,874 INFO dev DATASET: 18 examples
2022-12-18 23:38:11,875 INFO dev LABELS:
1    11
0     7
Name: label, dtype: int64
2022-12-18 23:38:11,876 INFO Pre-processing test data for student...
2022-12-18 23:38:11,880 INFO test DATASET: 32 examples
2022-12-18 23:38:11,881 INFO test LABELS:
1    18
0    14
Name: label, dtype: int64
2022-12-18 23:38:11,883 INFO Pre-processing unlabeled data for student...
2022-12-18 23:38:11,885 INFO unlabeled DATASET: 444 examples
2022-12-18 23:38:11,886 INFO unlabeled LABELS:
Series([], Name: label, dtype: int64)
2022-12-18 23:38:11,886 INFO creating pseudo-dataset
2022-12-18 23:38:11,886 INFO copying data from unlabeled dataset
2022-12-18 23:38:11,896 INFO done
2022-12-18 23:38:11,897 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:38:11,897 INFO Downsampling 444 data
2022-12-18 23:38:11,897 INFO copying data from train dataset
2022-12-18 23:38:11,907 INFO done
2022-12-18 23:38:11,907 INFO Balancing Pseudo Dataset to keep 1092 items...
2022-12-18 23:38:11,911 INFO PSEUDO-DATASET:
1092 examples
PSEUDO-LABELS:
1    546
0    546
Name: label, dtype: int64
2022-12-18 23:38:11,912 INFO Class labels: 2
2022-12-18 23:38:11,913 INFO X Train Shape (1092, 7) (1092,)
2022-12-18 23:38:11,913 INFO X Dev Shape (18, 7) (18,)
2022-12-18 23:38:23,209 INFO Saving supervised_student to ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/supervised_student
2022-12-18 23:38:23,209 INFO Saving model at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/supervised_student/final_model.h5
2022-12-18 23:38:23,215 INFO 

	*** Evaluating on dev data ***
2022-12-18 23:38:23,215 INFO Predicting labels for 18 texts
2022-12-18 23:38:23,321 INFO Evaluating student dev on 18 examples
2022-12-18 23:38:23,325 INFO student dev performance: 50.00
2022-12-18 23:38:23,325 INFO student dev confusion matrix:
[[6 1]
 [8 3]]
2022-12-18 23:38:23,325 INFO student dev report:
              precision    recall  f1-score   support

           0       0.43      0.86      0.57         7
           1       0.75      0.27      0.40        11

    accuracy                           0.50        18
   macro avg       0.59      0.56      0.49        18
weighted avg       0.62      0.50      0.47        18

2022-12-18 23:38:23,325 INFO 

	*** Evaluating on test data ***
2022-12-18 23:38:23,325 INFO Predicting labels for 32 texts
2022-12-18 23:38:23,427 INFO Evaluating student test on 32 examples
2022-12-18 23:38:23,431 INFO student test performance: 53.12
2022-12-18 23:38:23,431 INFO student test confusion matrix:
[[12  2]
 [13  5]]
2022-12-18 23:38:23,431 INFO student test report:
              precision    recall  f1-score   support

           0       0.48      0.86      0.62        14
           1       0.71      0.28      0.40        18

    accuracy                           0.53        32
   macro avg       0.60      0.57      0.51        32
weighted avg       0.61      0.53      0.49        32

2022-12-18 23:38:23,431 INFO initializing teacher on unlabeled data with majority voting
2022-12-18 23:38:23,431 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:23,432 INFO There are 3/7 active rules
2022-12-18 23:38:23,432 INFO Coverage: 100.0% (444/444)
2022-12-18 23:38:23,443 INFO evaluating majority voting
2022-12-18 23:38:23,443 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:38:23,444 INFO There are 7/7 active rules
2022-12-18 23:38:23,444 INFO Coverage: 100.0% (741/741)
2022-12-18 23:38:23,464 INFO Evaluating teacher train on 741 examples
2022-12-18 23:38:23,473 INFO teacher train performance: 90.69
2022-12-18 23:38:23,473 INFO teacher train confusion matrix:
[[150  45]
 [ 24 522]]
2022-12-18 23:38:23,473 INFO teacher train report:
              precision    recall  f1-score   support

           0       0.86      0.77      0.81       195
           1       0.92      0.96      0.94       546

    accuracy                           0.91       741
   macro avg       0.89      0.86      0.88       741
weighted avg       0.91      0.91      0.91       741

2022-12-18 23:38:23,474 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:23,474 INFO There are 7/7 active rules
2022-12-18 23:38:23,474 INFO Coverage: 100.0% (18/18)
2022-12-18 23:38:23,475 INFO Evaluating teacher dev on 18 examples
2022-12-18 23:38:23,479 INFO teacher dev performance: 88.89
2022-12-18 23:38:23,479 INFO teacher dev confusion matrix:
[[ 5  2]
 [ 0 11]]
2022-12-18 23:38:23,479 INFO teacher dev report:
              precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.85      1.00      0.92        11

    accuracy                           0.89        18
   macro avg       0.92      0.86      0.88        18
weighted avg       0.91      0.89      0.88        18

2022-12-18 23:38:23,479 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:38:23,480 INFO There are 7/7 active rules
2022-12-18 23:38:23,480 INFO Coverage: 100.0% (32/32)
2022-12-18 23:38:23,481 INFO Evaluating teacher test on 32 examples
2022-12-18 23:38:23,485 INFO teacher test performance: 78.12
2022-12-18 23:38:23,486 INFO teacher test confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:38:23,486 INFO teacher test report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:38:23,486 INFO 

	 *** Starting loop 0 ***
2022-12-18 23:38:23,486 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:38:23,486 INFO Downsampling 444 data
2022-12-18 23:38:23,486 INFO Adding Student as extra rule in Teacher
2022-12-18 23:38:23,486 INFO Getting rule predictions
2022-12-18 23:38:23,486 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:38:23,487 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:23,488 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:23,488 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:38:23,489 INFO Predicting labels for 741 texts
2022-12-18 23:38:23,598 INFO Predicting labels for 18 texts
2022-12-18 23:38:23,701 INFO Predicting labels for 444 texts
2022-12-18 23:38:23,804 INFO Training Rule Attention Network
2022-12-18 23:38:23,812 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:38:23,813 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:38:23,816 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:38:23,889 INFO 

		*** Training RAN ***
2022-12-18 23:38:26,602 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:26,603 INFO Predicting labels for 444 texts
2022-12-18 23:38:26,708 INFO There are 3/7 active rules
2022-12-18 23:38:26,709 INFO Coverage: 100.0% (444/444)
2022-12-18 23:38:26,713 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:38:26,796 INFO DONE, Getting attention scores...
2022-12-18 23:38:26,852 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:26,853 INFO Predicting labels for 18 texts
2022-12-18 23:38:26,955 INFO There are 7/7 active rules
2022-12-18 23:38:26,955 INFO Coverage: 100.0% (18/18)
2022-12-18 23:38:26,956 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:38:26,979 INFO DONE, Getting attention scores...
2022-12-18 23:38:27,033 INFO Evaluating teacher dev iter0 on 18 examples
2022-12-18 23:38:27,037 INFO teacher dev iter0 performance: 83.33
2022-12-18 23:38:27,037 INFO teacher dev iter0 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:38:27,037 INFO teacher dev iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:38:27,037 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:38:27,038 INFO Predicting labels for 32 texts
2022-12-18 23:38:27,137 INFO There are 7/7 active rules
2022-12-18 23:38:27,137 INFO Coverage: 100.0% (32/32)
2022-12-18 23:38:27,138 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:38:27,161 INFO DONE, Getting attention scores...
2022-12-18 23:38:27,219 INFO Evaluating teacher test iter0 on 32 examples
2022-12-18 23:38:27,223 INFO teacher test iter0 performance: 78.12
2022-12-18 23:38:27,223 INFO teacher test iter0 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:38:27,223 INFO teacher test iter0 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:38:27,224 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:38:27,227 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:38:27,229 INFO Balancing Pseudo Dataset to keep 684 items...
2022-12-18 23:38:27,232 INFO PSEUDO-DATASET:
684 examples
PSEUDO-LABELS:
1    342
0    342
Name: label, dtype: int64
2022-12-18 23:38:27,232 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:38:28,877 INFO fine-tuning the student on clean labeled data
2022-12-18 23:38:31,823 INFO Predicting labels for 18 texts
2022-12-18 23:38:31,924 INFO Evaluating student dev iter0 on 18 examples
2022-12-18 23:38:31,928 INFO student dev iter0 performance: 88.89
2022-12-18 23:38:31,928 INFO student dev iter0 confusion matrix:
[[ 5  2]
 [ 0 11]]
2022-12-18 23:38:31,928 INFO student dev iter0 report:
              precision    recall  f1-score   support

           0       1.00      0.71      0.83         7
           1       0.85      1.00      0.92        11

    accuracy                           0.89        18
   macro avg       0.92      0.86      0.88        18
weighted avg       0.91      0.89      0.88        18

2022-12-18 23:38:31,928 INFO Predicting labels for 32 texts
2022-12-18 23:38:32,029 INFO Evaluating student test iter0 on 32 examples
2022-12-18 23:38:32,033 INFO student test iter0 performance: 59.38
2022-12-18 23:38:32,034 INFO student test iter0 confusion matrix:
[[ 6  8]
 [ 5 13]]
2022-12-18 23:38:32,034 INFO student test iter0 report:
              precision    recall  f1-score   support

           0       0.55      0.43      0.48        14
           1       0.62      0.72      0.67        18

    accuracy                           0.59        32
   macro avg       0.58      0.58      0.57        32
weighted avg       0.59      0.59      0.58        32

2022-12-18 23:38:32,034 INFO Student Dev performance on iter 0: 88.88888888888889
2022-12-18 23:38:32,034 INFO Student Test performance on iter 0: 59.375
2022-12-18 23:38:32,034 INFO Improved dev performance from 50.00 to 88.89
2022-12-18 23:38:32,034 INFO Saving student_best to ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/student_best
2022-12-18 23:38:32,035 INFO Saving model at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/student_best/final_model.h5
2022-12-18 23:38:32,043 INFO Saving teacher at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_best
2022-12-18 23:38:32,043 INFO Saving rule attention network at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_best/rule_attention_network.h5
2022-12-18 23:38:32,051 INFO 

	 *** Starting loop 1 ***
2022-12-18 23:38:32,052 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:38:32,052 INFO Downsampling 444 data
2022-12-18 23:38:32,052 INFO Adding Student as extra rule in Teacher
2022-12-18 23:38:32,052 INFO Getting rule predictions
2022-12-18 23:38:32,053 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:38:32,054 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:32,054 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:32,054 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:38:32,055 INFO Predicting labels for 741 texts
2022-12-18 23:38:32,160 INFO Predicting labels for 18 texts
2022-12-18 23:38:32,261 INFO Predicting labels for 444 texts
2022-12-18 23:38:32,377 INFO Training Rule Attention Network
2022-12-18 23:38:32,388 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:38:32,388 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:38:32,392 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:38:32,392 INFO 

		*** Training RAN ***
2022-12-18 23:38:35,326 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:35,328 INFO Predicting labels for 444 texts
2022-12-18 23:38:35,433 INFO There are 3/7 active rules
2022-12-18 23:38:35,433 INFO Coverage: 100.0% (444/444)
2022-12-18 23:38:35,438 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:38:35,520 INFO DONE, Getting attention scores...
2022-12-18 23:38:35,576 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:35,576 INFO Predicting labels for 18 texts
2022-12-18 23:38:35,678 INFO There are 7/7 active rules
2022-12-18 23:38:35,678 INFO Coverage: 100.0% (18/18)
2022-12-18 23:38:35,679 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:38:35,703 INFO DONE, Getting attention scores...
2022-12-18 23:38:35,755 INFO Evaluating teacher dev iter1 on 18 examples
2022-12-18 23:38:35,760 INFO teacher dev iter1 performance: 83.33
2022-12-18 23:38:35,760 INFO teacher dev iter1 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:38:35,760 INFO teacher dev iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:38:35,760 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:38:35,760 INFO Predicting labels for 32 texts
2022-12-18 23:38:35,861 INFO There are 7/7 active rules
2022-12-18 23:38:35,861 INFO Coverage: 100.0% (32/32)
2022-12-18 23:38:35,862 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:38:35,885 INFO DONE, Getting attention scores...
2022-12-18 23:38:36,023 INFO Evaluating teacher test iter1 on 32 examples
2022-12-18 23:38:36,028 INFO teacher test iter1 performance: 78.12
2022-12-18 23:38:36,028 INFO teacher test iter1 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:38:36,028 INFO teacher test iter1 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:38:36,029 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:38:36,032 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:38:36,034 INFO Balancing Pseudo Dataset to keep 690 items...
2022-12-18 23:38:36,038 INFO PSEUDO-DATASET:
690 examples
PSEUDO-LABELS:
1    345
0    345
Name: label, dtype: int64
2022-12-18 23:38:36,038 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:38:37,466 INFO fine-tuning the student on clean labeled data
2022-12-18 23:38:40,391 INFO Predicting labels for 18 texts
2022-12-18 23:38:40,497 INFO Evaluating student dev iter1 on 18 examples
2022-12-18 23:38:40,501 INFO student dev iter1 performance: 83.33
2022-12-18 23:38:40,501 INFO student dev iter1 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:38:40,501 INFO student dev iter1 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:38:40,502 INFO Predicting labels for 32 texts
2022-12-18 23:38:40,603 INFO Evaluating student test iter1 on 32 examples
2022-12-18 23:38:40,607 INFO student test iter1 performance: 56.25
2022-12-18 23:38:40,608 INFO student test iter1 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-18 23:38:40,608 INFO student test iter1 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-18 23:38:40,608 INFO Student Dev performance on iter 1: 83.33333333333334
2022-12-18 23:38:40,608 INFO Student Test performance on iter 1: 56.25
2022-12-18 23:38:40,608 INFO 

	 *** Starting loop 2 ***
2022-12-18 23:38:40,608 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:38:40,608 INFO Downsampling 444 data
2022-12-18 23:38:40,609 INFO Adding Student as extra rule in Teacher
2022-12-18 23:38:40,609 INFO Getting rule predictions
2022-12-18 23:38:40,609 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:38:40,610 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:40,610 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:40,611 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:38:40,612 INFO Predicting labels for 741 texts
2022-12-18 23:38:40,713 INFO Predicting labels for 18 texts
2022-12-18 23:38:41,836 INFO Predicting labels for 444 texts
2022-12-18 23:38:41,937 INFO Training Rule Attention Network
2022-12-18 23:38:41,944 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:38:41,945 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:38:41,948 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:38:41,948 INFO 

		*** Training RAN ***
2022-12-18 23:38:44,718 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:44,719 INFO Predicting labels for 444 texts
2022-12-18 23:38:44,824 INFO There are 3/7 active rules
2022-12-18 23:38:44,824 INFO Coverage: 100.0% (444/444)
2022-12-18 23:38:44,828 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:38:44,914 INFO DONE, Getting attention scores...
2022-12-18 23:38:44,971 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:44,971 INFO Predicting labels for 18 texts
2022-12-18 23:38:45,080 INFO There are 7/7 active rules
2022-12-18 23:38:45,080 INFO Coverage: 100.0% (18/18)
2022-12-18 23:38:45,080 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:38:45,104 INFO DONE, Getting attention scores...
2022-12-18 23:38:45,162 INFO Evaluating teacher dev iter2 on 18 examples
2022-12-18 23:38:45,166 INFO teacher dev iter2 performance: 83.33
2022-12-18 23:38:45,166 INFO teacher dev iter2 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:38:45,166 INFO teacher dev iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:38:45,166 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:38:45,167 INFO Predicting labels for 32 texts
2022-12-18 23:38:45,272 INFO There are 7/7 active rules
2022-12-18 23:38:45,272 INFO Coverage: 100.0% (32/32)
2022-12-18 23:38:45,273 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:38:45,298 INFO DONE, Getting attention scores...
2022-12-18 23:38:45,351 INFO Evaluating teacher test iter2 on 32 examples
2022-12-18 23:38:45,356 INFO teacher test iter2 performance: 78.12
2022-12-18 23:38:45,356 INFO teacher test iter2 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:38:45,356 INFO teacher test iter2 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:38:45,357 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:38:45,360 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:38:45,362 INFO Balancing Pseudo Dataset to keep 684 items...
2022-12-18 23:38:45,365 INFO PSEUDO-DATASET:
684 examples
PSEUDO-LABELS:
1    342
0    342
Name: label, dtype: int64
2022-12-18 23:38:45,366 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:38:47,048 INFO fine-tuning the student on clean labeled data
2022-12-18 23:38:49,939 INFO Predicting labels for 18 texts
2022-12-18 23:38:51,070 INFO Evaluating student dev iter2 on 18 examples
2022-12-18 23:38:51,074 INFO student dev iter2 performance: 83.33
2022-12-18 23:38:51,074 INFO student dev iter2 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:38:51,075 INFO student dev iter2 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:38:51,075 INFO Predicting labels for 32 texts
2022-12-18 23:38:51,177 INFO Evaluating student test iter2 on 32 examples
2022-12-18 23:38:51,182 INFO student test iter2 performance: 56.25
2022-12-18 23:38:51,182 INFO student test iter2 confusion matrix:
[[ 1 13]
 [ 1 17]]
2022-12-18 23:38:51,182 INFO student test iter2 report:
              precision    recall  f1-score   support

           0       0.50      0.07      0.12        14
           1       0.57      0.94      0.71        18

    accuracy                           0.56        32
   macro avg       0.53      0.51      0.42        32
weighted avg       0.54      0.56      0.45        32

2022-12-18 23:38:51,182 INFO Student Dev performance on iter 2: 83.33333333333334
2022-12-18 23:38:51,182 INFO Student Test performance on iter 2: 56.25
2022-12-18 23:38:51,182 INFO 

	 *** Starting loop 3 ***
2022-12-18 23:38:51,183 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:38:51,183 INFO Downsampling 444 data
2022-12-18 23:38:51,183 INFO Adding Student as extra rule in Teacher
2022-12-18 23:38:51,184 INFO Getting rule predictions
2022-12-18 23:38:51,184 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:38:51,184 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:51,185 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:51,185 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:38:51,186 INFO Predicting labels for 741 texts
2022-12-18 23:38:51,286 INFO Predicting labels for 18 texts
2022-12-18 23:38:51,389 INFO Predicting labels for 444 texts
2022-12-18 23:38:51,491 INFO Training Rule Attention Network
2022-12-18 23:38:51,499 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:38:51,499 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:38:51,505 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:38:51,505 INFO 

		*** Training RAN ***
2022-12-18 23:38:54,255 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:38:54,257 INFO Predicting labels for 444 texts
2022-12-18 23:38:54,358 INFO There are 3/7 active rules
2022-12-18 23:38:54,358 INFO Coverage: 100.0% (444/444)
2022-12-18 23:38:54,365 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:38:54,450 INFO DONE, Getting attention scores...
2022-12-18 23:38:54,506 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:38:54,506 INFO Predicting labels for 18 texts
2022-12-18 23:38:54,605 INFO There are 7/7 active rules
2022-12-18 23:38:54,605 INFO Coverage: 100.0% (18/18)
2022-12-18 23:38:54,606 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:38:54,635 INFO DONE, Getting attention scores...
2022-12-18 23:38:54,762 INFO Evaluating teacher dev iter3 on 18 examples
2022-12-18 23:38:54,766 INFO teacher dev iter3 performance: 83.33
2022-12-18 23:38:54,767 INFO teacher dev iter3 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:38:54,767 INFO teacher dev iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:38:54,767 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:38:54,767 INFO Predicting labels for 32 texts
2022-12-18 23:38:54,872 INFO There are 7/7 active rules
2022-12-18 23:38:54,872 INFO Coverage: 100.0% (32/32)
2022-12-18 23:38:54,873 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:38:54,897 INFO DONE, Getting attention scores...
2022-12-18 23:38:54,951 INFO Evaluating teacher test iter3 on 32 examples
2022-12-18 23:38:54,956 INFO teacher test iter3 performance: 78.12
2022-12-18 23:38:54,956 INFO teacher test iter3 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:38:54,956 INFO teacher test iter3 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:38:54,956 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:38:54,959 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:38:54,961 INFO Balancing Pseudo Dataset to keep 806 items...
2022-12-18 23:38:54,966 INFO PSEUDO-DATASET:
806 examples
PSEUDO-LABELS:
1    403
0    403
Name: label, dtype: int64
2022-12-18 23:38:54,966 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:38:57,665 INFO fine-tuning the student on clean labeled data
2022-12-18 23:39:01,562 INFO Predicting labels for 18 texts
2022-12-18 23:39:01,661 INFO Evaluating student dev iter3 on 18 examples
2022-12-18 23:39:01,666 INFO student dev iter3 performance: 83.33
2022-12-18 23:39:01,666 INFO student dev iter3 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:01,666 INFO student dev iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:01,666 INFO Predicting labels for 32 texts
2022-12-18 23:39:01,771 INFO Evaluating student test iter3 on 32 examples
2022-12-18 23:39:01,776 INFO student test iter3 performance: 59.38
2022-12-18 23:39:01,776 INFO student test iter3 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:39:01,776 INFO student test iter3 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:39:01,776 INFO Student Dev performance on iter 3: 83.33333333333334
2022-12-18 23:39:01,776 INFO Student Test performance on iter 3: 59.375
2022-12-18 23:39:01,776 INFO 

	 *** Starting loop 4 ***
2022-12-18 23:39:01,777 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:39:01,777 INFO Downsampling 444 data
2022-12-18 23:39:01,777 INFO Adding Student as extra rule in Teacher
2022-12-18 23:39:01,778 INFO Getting rule predictions
2022-12-18 23:39:01,778 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:39:01,779 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:01,779 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:01,779 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:39:01,780 INFO Predicting labels for 741 texts
2022-12-18 23:39:01,883 INFO Predicting labels for 18 texts
2022-12-18 23:39:01,987 INFO Predicting labels for 444 texts
2022-12-18 23:39:02,093 INFO Training Rule Attention Network
2022-12-18 23:39:02,100 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:39:02,101 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:39:02,105 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:39:02,105 INFO 

		*** Training RAN ***
2022-12-18 23:39:04,901 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:04,903 INFO Predicting labels for 444 texts
2022-12-18 23:39:05,009 INFO There are 3/7 active rules
2022-12-18 23:39:05,009 INFO Coverage: 100.0% (444/444)
2022-12-18 23:39:05,013 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:39:05,100 INFO DONE, Getting attention scores...
2022-12-18 23:39:05,156 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:05,156 INFO Predicting labels for 18 texts
2022-12-18 23:39:05,256 INFO There are 7/7 active rules
2022-12-18 23:39:05,256 INFO Coverage: 100.0% (18/18)
2022-12-18 23:39:05,257 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:39:05,280 INFO DONE, Getting attention scores...
2022-12-18 23:39:05,418 INFO Evaluating teacher dev iter4 on 18 examples
2022-12-18 23:39:05,422 INFO teacher dev iter4 performance: 83.33
2022-12-18 23:39:05,422 INFO teacher dev iter4 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:05,422 INFO teacher dev iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:05,422 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:39:05,423 INFO Predicting labels for 32 texts
2022-12-18 23:39:05,525 INFO There are 7/7 active rules
2022-12-18 23:39:05,525 INFO Coverage: 100.0% (32/32)
2022-12-18 23:39:05,526 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:39:05,550 INFO DONE, Getting attention scores...
2022-12-18 23:39:05,604 INFO Evaluating teacher test iter4 on 32 examples
2022-12-18 23:39:05,609 INFO teacher test iter4 performance: 78.12
2022-12-18 23:39:05,609 INFO teacher test iter4 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:39:05,609 INFO teacher test iter4 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:39:05,610 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:39:05,613 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:39:05,615 INFO Balancing Pseudo Dataset to keep 678 items...
2022-12-18 23:39:05,619 INFO PSEUDO-DATASET:
678 examples
PSEUDO-LABELS:
1    339
0    339
Name: label, dtype: int64
2022-12-18 23:39:05,619 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:39:08,181 INFO fine-tuning the student on clean labeled data
2022-12-18 23:39:11,182 INFO Predicting labels for 18 texts
2022-12-18 23:39:11,287 INFO Evaluating student dev iter4 on 18 examples
2022-12-18 23:39:11,292 INFO student dev iter4 performance: 83.33
2022-12-18 23:39:11,292 INFO student dev iter4 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:11,292 INFO student dev iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:11,292 INFO Predicting labels for 32 texts
2022-12-18 23:39:11,394 INFO Evaluating student test iter4 on 32 examples
2022-12-18 23:39:11,399 INFO student test iter4 performance: 59.38
2022-12-18 23:39:11,399 INFO student test iter4 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:39:11,399 INFO student test iter4 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:39:11,399 INFO Student Dev performance on iter 4: 83.33333333333334
2022-12-18 23:39:11,399 INFO Student Test performance on iter 4: 59.375
2022-12-18 23:39:11,399 INFO 

	 *** Starting loop 5 ***
2022-12-18 23:39:11,400 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:39:11,400 INFO Downsampling 444 data
2022-12-18 23:39:11,400 INFO Adding Student as extra rule in Teacher
2022-12-18 23:39:11,401 INFO Getting rule predictions
2022-12-18 23:39:11,401 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:39:11,402 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:11,402 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:11,403 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:39:11,404 INFO Predicting labels for 741 texts
2022-12-18 23:39:11,508 INFO Predicting labels for 18 texts
2022-12-18 23:39:11,613 INFO Predicting labels for 444 texts
2022-12-18 23:39:11,714 INFO Training Rule Attention Network
2022-12-18 23:39:11,722 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:39:11,723 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:39:11,727 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:39:11,728 INFO 

		*** Training RAN ***
2022-12-18 23:39:14,457 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:14,458 INFO Predicting labels for 444 texts
2022-12-18 23:39:14,562 INFO There are 3/7 active rules
2022-12-18 23:39:14,562 INFO Coverage: 100.0% (444/444)
2022-12-18 23:39:14,566 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:39:14,654 INFO DONE, Getting attention scores...
2022-12-18 23:39:14,713 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:14,713 INFO Predicting labels for 18 texts
2022-12-18 23:39:14,814 INFO There are 7/7 active rules
2022-12-18 23:39:14,815 INFO Coverage: 100.0% (18/18)
2022-12-18 23:39:14,815 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:39:14,840 INFO DONE, Getting attention scores...
2022-12-18 23:39:14,900 INFO Evaluating teacher dev iter5 on 18 examples
2022-12-18 23:39:14,904 INFO teacher dev iter5 performance: 83.33
2022-12-18 23:39:14,904 INFO teacher dev iter5 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:14,904 INFO teacher dev iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:14,904 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:39:14,905 INFO Predicting labels for 32 texts
2022-12-18 23:39:15,008 INFO There are 7/7 active rules
2022-12-18 23:39:15,008 INFO Coverage: 100.0% (32/32)
2022-12-18 23:39:15,009 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:39:15,032 INFO DONE, Getting attention scores...
2022-12-18 23:39:15,086 INFO Evaluating teacher test iter5 on 32 examples
2022-12-18 23:39:15,091 INFO teacher test iter5 performance: 78.12
2022-12-18 23:39:15,091 INFO teacher test iter5 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:39:15,091 INFO teacher test iter5 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:39:15,092 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:39:15,095 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:39:15,096 INFO Balancing Pseudo Dataset to keep 668 items...
2022-12-18 23:39:15,100 INFO PSEUDO-DATASET:
668 examples
PSEUDO-LABELS:
1    334
0    334
Name: label, dtype: int64
2022-12-18 23:39:15,100 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:39:19,806 INFO fine-tuning the student on clean labeled data
2022-12-18 23:39:23,709 INFO Predicting labels for 18 texts
2022-12-18 23:39:23,819 INFO Evaluating student dev iter5 on 18 examples
2022-12-18 23:39:23,823 INFO student dev iter5 performance: 83.33
2022-12-18 23:39:23,824 INFO student dev iter5 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:23,824 INFO student dev iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:23,824 INFO Predicting labels for 32 texts
2022-12-18 23:39:23,929 INFO Evaluating student test iter5 on 32 examples
2022-12-18 23:39:23,933 INFO student test iter5 performance: 59.38
2022-12-18 23:39:23,933 INFO student test iter5 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:39:23,934 INFO student test iter5 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:39:23,934 INFO Student Dev performance on iter 5: 83.33333333333334
2022-12-18 23:39:23,934 INFO Student Test performance on iter 5: 59.375
2022-12-18 23:39:23,934 INFO 

	 *** Starting loop 6 ***
2022-12-18 23:39:23,934 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:39:23,934 INFO Downsampling 444 data
2022-12-18 23:39:23,934 INFO Adding Student as extra rule in Teacher
2022-12-18 23:39:23,935 INFO Getting rule predictions
2022-12-18 23:39:23,935 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:39:23,936 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:23,936 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:23,936 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:39:23,937 INFO Predicting labels for 741 texts
2022-12-18 23:39:24,044 INFO Predicting labels for 18 texts
2022-12-18 23:39:24,147 INFO Predicting labels for 444 texts
2022-12-18 23:39:24,250 INFO Training Rule Attention Network
2022-12-18 23:39:24,257 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:39:24,258 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:39:24,262 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:39:24,262 INFO 

		*** Training RAN ***
2022-12-18 23:39:26,983 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:26,984 INFO Predicting labels for 444 texts
2022-12-18 23:39:27,085 INFO There are 3/7 active rules
2022-12-18 23:39:27,086 INFO Coverage: 100.0% (444/444)
2022-12-18 23:39:27,090 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:39:27,178 INFO DONE, Getting attention scores...
2022-12-18 23:39:27,234 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:27,235 INFO Predicting labels for 18 texts
2022-12-18 23:39:27,331 INFO There are 7/7 active rules
2022-12-18 23:39:27,332 INFO Coverage: 100.0% (18/18)
2022-12-18 23:39:27,332 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:39:27,355 INFO DONE, Getting attention scores...
2022-12-18 23:39:27,411 INFO Evaluating teacher dev iter6 on 18 examples
2022-12-18 23:39:27,415 INFO teacher dev iter6 performance: 83.33
2022-12-18 23:39:27,416 INFO teacher dev iter6 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:27,416 INFO teacher dev iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:27,416 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:39:27,416 INFO Predicting labels for 32 texts
2022-12-18 23:39:27,518 INFO There are 7/7 active rules
2022-12-18 23:39:27,518 INFO Coverage: 100.0% (32/32)
2022-12-18 23:39:27,519 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:39:27,543 INFO DONE, Getting attention scores...
2022-12-18 23:39:27,596 INFO Evaluating teacher test iter6 on 32 examples
2022-12-18 23:39:27,601 INFO teacher test iter6 performance: 78.12
2022-12-18 23:39:27,601 INFO teacher test iter6 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:39:27,601 INFO teacher test iter6 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:39:27,601 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:39:27,604 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:39:27,606 INFO Balancing Pseudo Dataset to keep 672 items...
2022-12-18 23:39:27,610 INFO PSEUDO-DATASET:
672 examples
PSEUDO-LABELS:
1    336
0    336
Name: label, dtype: int64
2022-12-18 23:39:27,611 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:39:29,117 INFO fine-tuning the student on clean labeled data
2022-12-18 23:39:31,357 INFO Predicting labels for 18 texts
2022-12-18 23:39:31,463 INFO Evaluating student dev iter6 on 18 examples
2022-12-18 23:39:31,467 INFO student dev iter6 performance: 83.33
2022-12-18 23:39:31,468 INFO student dev iter6 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:31,468 INFO student dev iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:31,468 INFO Predicting labels for 32 texts
2022-12-18 23:39:31,568 INFO Evaluating student test iter6 on 32 examples
2022-12-18 23:39:31,573 INFO student test iter6 performance: 59.38
2022-12-18 23:39:31,573 INFO student test iter6 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:39:31,573 INFO student test iter6 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:39:31,573 INFO Student Dev performance on iter 6: 83.33333333333334
2022-12-18 23:39:31,573 INFO Student Test performance on iter 6: 59.375
2022-12-18 23:39:31,574 INFO 

	 *** Starting loop 7 ***
2022-12-18 23:39:31,574 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:39:31,574 INFO Downsampling 444 data
2022-12-18 23:39:31,574 INFO Adding Student as extra rule in Teacher
2022-12-18 23:39:31,575 INFO Getting rule predictions
2022-12-18 23:39:31,575 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:39:31,576 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:31,576 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:31,576 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:39:31,577 INFO Predicting labels for 741 texts
2022-12-18 23:39:31,686 INFO Predicting labels for 18 texts
2022-12-18 23:39:31,787 INFO Predicting labels for 444 texts
2022-12-18 23:39:31,888 INFO Training Rule Attention Network
2022-12-18 23:39:31,896 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:39:31,897 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:39:31,901 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:39:31,901 INFO 

		*** Training RAN ***
2022-12-18 23:39:34,633 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:34,634 INFO Predicting labels for 444 texts
2022-12-18 23:39:34,741 INFO There are 3/7 active rules
2022-12-18 23:39:34,741 INFO Coverage: 100.0% (444/444)
2022-12-18 23:39:34,745 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:39:34,827 INFO DONE, Getting attention scores...
2022-12-18 23:39:34,884 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:34,885 INFO Predicting labels for 18 texts
2022-12-18 23:39:34,986 INFO There are 7/7 active rules
2022-12-18 23:39:34,986 INFO Coverage: 100.0% (18/18)
2022-12-18 23:39:34,987 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:39:35,010 INFO DONE, Getting attention scores...
2022-12-18 23:39:35,062 INFO Evaluating teacher dev iter7 on 18 examples
2022-12-18 23:39:35,067 INFO teacher dev iter7 performance: 83.33
2022-12-18 23:39:35,067 INFO teacher dev iter7 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:35,067 INFO teacher dev iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:35,067 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:39:35,067 INFO Predicting labels for 32 texts
2022-12-18 23:39:35,174 INFO There are 7/7 active rules
2022-12-18 23:39:35,175 INFO Coverage: 100.0% (32/32)
2022-12-18 23:39:35,176 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:39:35,200 INFO DONE, Getting attention scores...
2022-12-18 23:39:35,253 INFO Evaluating teacher test iter7 on 32 examples
2022-12-18 23:39:35,257 INFO teacher test iter7 performance: 78.12
2022-12-18 23:39:35,258 INFO teacher test iter7 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:39:35,258 INFO teacher test iter7 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:39:35,258 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:39:35,261 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:39:35,263 INFO Balancing Pseudo Dataset to keep 672 items...
2022-12-18 23:39:35,267 INFO PSEUDO-DATASET:
672 examples
PSEUDO-LABELS:
1    336
0    336
Name: label, dtype: int64
2022-12-18 23:39:35,267 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:39:36,723 INFO fine-tuning the student on clean labeled data
2022-12-18 23:39:37,836 INFO Predicting labels for 18 texts
2022-12-18 23:39:38,028 INFO Evaluating student dev iter7 on 18 examples
2022-12-18 23:39:38,032 INFO student dev iter7 performance: 83.33
2022-12-18 23:39:38,032 INFO student dev iter7 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:38,033 INFO student dev iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:38,033 INFO Predicting labels for 32 texts
2022-12-18 23:39:38,141 INFO Evaluating student test iter7 on 32 examples
2022-12-18 23:39:38,145 INFO student test iter7 performance: 59.38
2022-12-18 23:39:38,145 INFO student test iter7 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:39:38,145 INFO student test iter7 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:39:38,145 INFO Student Dev performance on iter 7: 83.33333333333334
2022-12-18 23:39:38,146 INFO Student Test performance on iter 7: 59.375
2022-12-18 23:39:38,146 INFO 

	 *** Starting loop 8 ***
2022-12-18 23:39:38,146 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:39:38,146 INFO Downsampling 444 data
2022-12-18 23:39:38,147 INFO Adding Student as extra rule in Teacher
2022-12-18 23:39:38,147 INFO Getting rule predictions
2022-12-18 23:39:38,147 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:39:38,148 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:38,148 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:38,149 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:39:38,150 INFO Predicting labels for 741 texts
2022-12-18 23:39:38,261 INFO Predicting labels for 18 texts
2022-12-18 23:39:38,361 INFO Predicting labels for 444 texts
2022-12-18 23:39:38,465 INFO Training Rule Attention Network
2022-12-18 23:39:38,476 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:39:38,477 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:39:38,480 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:39:38,481 INFO 

		*** Training RAN ***
2022-12-18 23:39:41,184 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:41,185 INFO Predicting labels for 444 texts
2022-12-18 23:39:41,293 INFO There are 3/7 active rules
2022-12-18 23:39:41,294 INFO Coverage: 100.0% (444/444)
2022-12-18 23:39:41,298 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:39:41,386 INFO DONE, Getting attention scores...
2022-12-18 23:39:41,446 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:41,446 INFO Predicting labels for 18 texts
2022-12-18 23:39:41,546 INFO There are 7/7 active rules
2022-12-18 23:39:41,546 INFO Coverage: 100.0% (18/18)
2022-12-18 23:39:41,547 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:39:41,571 INFO DONE, Getting attention scores...
2022-12-18 23:39:41,623 INFO Evaluating teacher dev iter8 on 18 examples
2022-12-18 23:39:41,627 INFO teacher dev iter8 performance: 83.33
2022-12-18 23:39:41,627 INFO teacher dev iter8 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:41,627 INFO teacher dev iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:41,627 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:39:41,628 INFO Predicting labels for 32 texts
2022-12-18 23:39:41,733 INFO There are 7/7 active rules
2022-12-18 23:39:41,733 INFO Coverage: 100.0% (32/32)
2022-12-18 23:39:41,734 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:39:41,759 INFO DONE, Getting attention scores...
2022-12-18 23:39:41,811 INFO Evaluating teacher test iter8 on 32 examples
2022-12-18 23:39:41,816 INFO teacher test iter8 performance: 78.12
2022-12-18 23:39:41,816 INFO teacher test iter8 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:39:41,816 INFO teacher test iter8 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:39:41,817 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:39:41,820 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:39:41,821 INFO Balancing Pseudo Dataset to keep 732 items...
2022-12-18 23:39:41,826 INFO PSEUDO-DATASET:
732 examples
PSEUDO-LABELS:
1    366
0    366
Name: label, dtype: int64
2022-12-18 23:39:41,826 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:39:43,282 INFO fine-tuning the student on clean labeled data
2022-12-18 23:39:45,434 INFO Predicting labels for 18 texts
2022-12-18 23:39:45,542 INFO Evaluating student dev iter8 on 18 examples
2022-12-18 23:39:45,546 INFO student dev iter8 performance: 83.33
2022-12-18 23:39:45,546 INFO student dev iter8 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:45,546 INFO student dev iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:45,546 INFO Predicting labels for 32 texts
2022-12-18 23:39:45,644 INFO Evaluating student test iter8 on 32 examples
2022-12-18 23:39:45,648 INFO student test iter8 performance: 59.38
2022-12-18 23:39:45,649 INFO student test iter8 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:39:45,649 INFO student test iter8 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:39:45,649 INFO Student Dev performance on iter 8: 83.33333333333334
2022-12-18 23:39:45,649 INFO Student Test performance on iter 8: 59.375
2022-12-18 23:39:45,649 INFO 

	 *** Starting loop 9 ***
2022-12-18 23:39:45,649 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:39:45,649 INFO Downsampling 444 data
2022-12-18 23:39:45,650 INFO Adding Student as extra rule in Teacher
2022-12-18 23:39:45,650 INFO Getting rule predictions
2022-12-18 23:39:45,650 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:39:45,651 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:45,652 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:45,652 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:39:45,653 INFO Predicting labels for 741 texts
2022-12-18 23:39:45,759 INFO Predicting labels for 18 texts
2022-12-18 23:39:45,860 INFO Predicting labels for 444 texts
2022-12-18 23:39:45,964 INFO Training Rule Attention Network
2022-12-18 23:39:46,067 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:39:46,068 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:39:46,072 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:39:46,072 INFO 

		*** Training RAN ***
2022-12-18 23:39:48,849 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:48,851 INFO Predicting labels for 444 texts
2022-12-18 23:39:48,955 INFO There are 3/7 active rules
2022-12-18 23:39:48,956 INFO Coverage: 100.0% (444/444)
2022-12-18 23:39:48,960 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:39:49,044 INFO DONE, Getting attention scores...
2022-12-18 23:39:49,102 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:49,102 INFO Predicting labels for 18 texts
2022-12-18 23:39:49,205 INFO There are 7/7 active rules
2022-12-18 23:39:49,205 INFO Coverage: 100.0% (18/18)
2022-12-18 23:39:49,206 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:39:49,230 INFO DONE, Getting attention scores...
2022-12-18 23:39:49,282 INFO Evaluating teacher dev iter9 on 18 examples
2022-12-18 23:39:49,287 INFO teacher dev iter9 performance: 83.33
2022-12-18 23:39:49,287 INFO teacher dev iter9 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:49,287 INFO teacher dev iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:49,288 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:39:49,288 INFO Predicting labels for 32 texts
2022-12-18 23:39:49,397 INFO There are 7/7 active rules
2022-12-18 23:39:49,397 INFO Coverage: 100.0% (32/32)
2022-12-18 23:39:49,398 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:39:49,422 INFO DONE, Getting attention scores...
2022-12-18 23:39:49,477 INFO Evaluating teacher test iter9 on 32 examples
2022-12-18 23:39:49,482 INFO teacher test iter9 performance: 78.12
2022-12-18 23:39:49,482 INFO teacher test iter9 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:39:49,483 INFO teacher test iter9 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:39:49,483 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:39:49,486 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:39:49,488 INFO Balancing Pseudo Dataset to keep 782 items...
2022-12-18 23:39:49,492 INFO PSEUDO-DATASET:
782 examples
PSEUDO-LABELS:
1    391
0    391
Name: label, dtype: int64
2022-12-18 23:39:49,492 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:39:50,633 INFO fine-tuning the student on clean labeled data
2022-12-18 23:39:51,871 INFO Predicting labels for 18 texts
2022-12-18 23:39:51,977 INFO Evaluating student dev iter9 on 18 examples
2022-12-18 23:39:51,981 INFO student dev iter9 performance: 83.33
2022-12-18 23:39:51,981 INFO student dev iter9 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:51,981 INFO student dev iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:51,982 INFO Predicting labels for 32 texts
2022-12-18 23:39:52,082 INFO Evaluating student test iter9 on 32 examples
2022-12-18 23:39:52,087 INFO student test iter9 performance: 59.38
2022-12-18 23:39:52,087 INFO student test iter9 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:39:52,087 INFO student test iter9 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:39:52,087 INFO Student Dev performance on iter 9: 83.33333333333334
2022-12-18 23:39:52,087 INFO Student Test performance on iter 9: 59.375
2022-12-18 23:39:52,088 INFO 

	 *** Starting loop 10 ***
2022-12-18 23:39:52,088 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:39:52,088 INFO Downsampling 444 data
2022-12-18 23:39:52,089 INFO Adding Student as extra rule in Teacher
2022-12-18 23:39:52,089 INFO Getting rule predictions
2022-12-18 23:39:52,089 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:39:52,090 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:52,090 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:52,091 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:39:52,092 INFO Predicting labels for 741 texts
2022-12-18 23:39:52,201 INFO Predicting labels for 18 texts
2022-12-18 23:39:52,316 INFO Predicting labels for 444 texts
2022-12-18 23:39:52,425 INFO Training Rule Attention Network
2022-12-18 23:39:52,432 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:39:52,433 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:39:52,437 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:39:52,437 INFO 

		*** Training RAN ***
2022-12-18 23:39:55,334 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:55,335 INFO Predicting labels for 444 texts
2022-12-18 23:39:55,441 INFO There are 3/7 active rules
2022-12-18 23:39:55,441 INFO Coverage: 100.0% (444/444)
2022-12-18 23:39:55,446 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:39:55,529 INFO DONE, Getting attention scores...
2022-12-18 23:39:55,591 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:55,591 INFO Predicting labels for 18 texts
2022-12-18 23:39:55,693 INFO There are 7/7 active rules
2022-12-18 23:39:55,694 INFO Coverage: 100.0% (18/18)
2022-12-18 23:39:55,694 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:39:55,718 INFO DONE, Getting attention scores...
2022-12-18 23:39:55,770 INFO Evaluating teacher dev iter10 on 18 examples
2022-12-18 23:39:55,775 INFO teacher dev iter10 performance: 83.33
2022-12-18 23:39:55,775 INFO teacher dev iter10 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:55,775 INFO teacher dev iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:55,775 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:39:55,775 INFO Predicting labels for 32 texts
2022-12-18 23:39:55,882 INFO There are 7/7 active rules
2022-12-18 23:39:55,883 INFO Coverage: 100.0% (32/32)
2022-12-18 23:39:55,883 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:39:55,907 INFO DONE, Getting attention scores...
2022-12-18 23:39:55,962 INFO Evaluating teacher test iter10 on 32 examples
2022-12-18 23:39:55,967 INFO teacher test iter10 performance: 78.12
2022-12-18 23:39:55,967 INFO teacher test iter10 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:39:55,968 INFO teacher test iter10 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:39:55,968 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:39:55,971 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:39:55,972 INFO Balancing Pseudo Dataset to keep 688 items...
2022-12-18 23:39:55,977 INFO PSEUDO-DATASET:
688 examples
PSEUDO-LABELS:
1    344
0    344
Name: label, dtype: int64
2022-12-18 23:39:55,977 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:39:56,774 INFO fine-tuning the student on clean labeled data
2022-12-18 23:39:57,978 INFO Predicting labels for 18 texts
2022-12-18 23:39:58,083 INFO Evaluating student dev iter10 on 18 examples
2022-12-18 23:39:58,087 INFO student dev iter10 performance: 83.33
2022-12-18 23:39:58,087 INFO student dev iter10 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:39:58,087 INFO student dev iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:39:58,087 INFO Predicting labels for 32 texts
2022-12-18 23:39:58,191 INFO Evaluating student test iter10 on 32 examples
2022-12-18 23:39:58,196 INFO student test iter10 performance: 59.38
2022-12-18 23:39:58,196 INFO student test iter10 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:39:58,196 INFO student test iter10 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:39:58,196 INFO Student Dev performance on iter 10: 83.33333333333334
2022-12-18 23:39:58,196 INFO Student Test performance on iter 10: 59.375
2022-12-18 23:39:58,196 INFO 

	 *** Starting loop 11 ***
2022-12-18 23:39:58,197 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:39:58,197 INFO Downsampling 444 data
2022-12-18 23:39:58,197 INFO Adding Student as extra rule in Teacher
2022-12-18 23:39:58,198 INFO Getting rule predictions
2022-12-18 23:39:58,198 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:39:58,198 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:39:58,199 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:39:58,199 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:39:58,200 INFO Predicting labels for 741 texts
2022-12-18 23:39:58,303 INFO Predicting labels for 18 texts
2022-12-18 23:39:58,403 INFO Predicting labels for 444 texts
2022-12-18 23:39:58,510 INFO Training Rule Attention Network
2022-12-18 23:39:58,517 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:39:58,518 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:39:58,522 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:39:58,522 INFO 

		*** Training RAN ***
2022-12-18 23:40:01,465 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:01,466 INFO Predicting labels for 444 texts
2022-12-18 23:40:01,574 INFO There are 3/7 active rules
2022-12-18 23:40:01,575 INFO Coverage: 100.0% (444/444)
2022-12-18 23:40:01,579 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:40:01,668 INFO DONE, Getting attention scores...
2022-12-18 23:40:01,728 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:01,728 INFO Predicting labels for 18 texts
2022-12-18 23:40:01,841 INFO There are 7/7 active rules
2022-12-18 23:40:01,841 INFO Coverage: 100.0% (18/18)
2022-12-18 23:40:01,842 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:40:01,867 INFO DONE, Getting attention scores...
2022-12-18 23:40:01,925 INFO Evaluating teacher dev iter11 on 18 examples
2022-12-18 23:40:01,930 INFO teacher dev iter11 performance: 83.33
2022-12-18 23:40:01,930 INFO teacher dev iter11 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:01,930 INFO teacher dev iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:01,930 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:40:01,930 INFO Predicting labels for 32 texts
2022-12-18 23:40:02,053 INFO There are 7/7 active rules
2022-12-18 23:40:02,053 INFO Coverage: 100.0% (32/32)
2022-12-18 23:40:02,054 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:40:02,081 INFO DONE, Getting attention scores...
2022-12-18 23:40:02,138 INFO Evaluating teacher test iter11 on 32 examples
2022-12-18 23:40:02,143 INFO teacher test iter11 performance: 78.12
2022-12-18 23:40:02,143 INFO teacher test iter11 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:40:02,143 INFO teacher test iter11 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:40:02,143 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:40:02,147 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:40:02,149 INFO Balancing Pseudo Dataset to keep 708 items...
2022-12-18 23:40:02,152 INFO PSEUDO-DATASET:
708 examples
PSEUDO-LABELS:
1    354
0    354
Name: label, dtype: int64
2022-12-18 23:40:02,153 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:40:02,986 INFO fine-tuning the student on clean labeled data
2022-12-18 23:40:04,120 INFO Predicting labels for 18 texts
2022-12-18 23:40:04,224 INFO Evaluating student dev iter11 on 18 examples
2022-12-18 23:40:04,228 INFO student dev iter11 performance: 83.33
2022-12-18 23:40:04,229 INFO student dev iter11 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:04,229 INFO student dev iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:04,229 INFO Predicting labels for 32 texts
2022-12-18 23:40:04,336 INFO Evaluating student test iter11 on 32 examples
2022-12-18 23:40:04,340 INFO student test iter11 performance: 59.38
2022-12-18 23:40:04,341 INFO student test iter11 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:40:04,341 INFO student test iter11 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:40:04,341 INFO Student Dev performance on iter 11: 83.33333333333334
2022-12-18 23:40:04,341 INFO Student Test performance on iter 11: 59.375
2022-12-18 23:40:04,341 INFO 

	 *** Starting loop 12 ***
2022-12-18 23:40:04,341 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:40:04,341 INFO Downsampling 444 data
2022-12-18 23:40:04,342 INFO Adding Student as extra rule in Teacher
2022-12-18 23:40:04,342 INFO Getting rule predictions
2022-12-18 23:40:04,342 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:40:04,343 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:04,343 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:04,344 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:40:04,345 INFO Predicting labels for 741 texts
2022-12-18 23:40:04,452 INFO Predicting labels for 18 texts
2022-12-18 23:40:04,553 INFO Predicting labels for 444 texts
2022-12-18 23:40:04,660 INFO Training Rule Attention Network
2022-12-18 23:40:04,668 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:40:04,669 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:40:04,673 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:40:04,673 INFO 

		*** Training RAN ***
2022-12-18 23:40:07,612 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:07,613 INFO Predicting labels for 444 texts
2022-12-18 23:40:07,717 INFO There are 3/7 active rules
2022-12-18 23:40:07,717 INFO Coverage: 100.0% (444/444)
2022-12-18 23:40:07,721 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:40:07,808 INFO DONE, Getting attention scores...
2022-12-18 23:40:07,867 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:07,867 INFO Predicting labels for 18 texts
2022-12-18 23:40:07,970 INFO There are 7/7 active rules
2022-12-18 23:40:07,970 INFO Coverage: 100.0% (18/18)
2022-12-18 23:40:07,970 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:40:07,994 INFO DONE, Getting attention scores...
2022-12-18 23:40:08,047 INFO Evaluating teacher dev iter12 on 18 examples
2022-12-18 23:40:08,052 INFO teacher dev iter12 performance: 83.33
2022-12-18 23:40:08,052 INFO teacher dev iter12 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:08,052 INFO teacher dev iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:08,052 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:40:08,052 INFO Predicting labels for 32 texts
2022-12-18 23:40:08,164 INFO There are 7/7 active rules
2022-12-18 23:40:08,164 INFO Coverage: 100.0% (32/32)
2022-12-18 23:40:08,165 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:40:08,190 INFO DONE, Getting attention scores...
2022-12-18 23:40:08,243 INFO Evaluating teacher test iter12 on 32 examples
2022-12-18 23:40:08,248 INFO teacher test iter12 performance: 78.12
2022-12-18 23:40:08,248 INFO teacher test iter12 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:40:08,248 INFO teacher test iter12 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:40:08,249 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:40:08,252 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:40:08,254 INFO Balancing Pseudo Dataset to keep 700 items...
2022-12-18 23:40:08,258 INFO PSEUDO-DATASET:
700 examples
PSEUDO-LABELS:
1    350
0    350
Name: label, dtype: int64
2022-12-18 23:40:08,258 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:40:10,474 INFO fine-tuning the student on clean labeled data
2022-12-18 23:40:12,723 INFO Predicting labels for 18 texts
2022-12-18 23:40:12,829 INFO Evaluating student dev iter12 on 18 examples
2022-12-18 23:40:12,833 INFO student dev iter12 performance: 83.33
2022-12-18 23:40:12,833 INFO student dev iter12 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:12,833 INFO student dev iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:12,834 INFO Predicting labels for 32 texts
2022-12-18 23:40:12,941 INFO Evaluating student test iter12 on 32 examples
2022-12-18 23:40:12,945 INFO student test iter12 performance: 59.38
2022-12-18 23:40:12,945 INFO student test iter12 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:40:12,945 INFO student test iter12 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:40:12,946 INFO Student Dev performance on iter 12: 83.33333333333334
2022-12-18 23:40:12,946 INFO Student Test performance on iter 12: 59.375
2022-12-18 23:40:12,946 INFO 

	 *** Starting loop 13 ***
2022-12-18 23:40:12,946 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:40:12,946 INFO Downsampling 444 data
2022-12-18 23:40:12,947 INFO Adding Student as extra rule in Teacher
2022-12-18 23:40:12,947 INFO Getting rule predictions
2022-12-18 23:40:12,947 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:40:12,948 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:12,948 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:12,949 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:40:12,950 INFO Predicting labels for 741 texts
2022-12-18 23:40:13,055 INFO Predicting labels for 18 texts
2022-12-18 23:40:13,159 INFO Predicting labels for 444 texts
2022-12-18 23:40:13,263 INFO Training Rule Attention Network
2022-12-18 23:40:13,270 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:40:13,271 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:40:13,275 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:40:13,275 INFO 

		*** Training RAN ***
2022-12-18 23:40:16,024 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:16,025 INFO Predicting labels for 444 texts
2022-12-18 23:40:16,129 INFO There are 3/7 active rules
2022-12-18 23:40:16,130 INFO Coverage: 100.0% (444/444)
2022-12-18 23:40:16,134 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:40:16,222 INFO DONE, Getting attention scores...
2022-12-18 23:40:16,278 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:16,279 INFO Predicting labels for 18 texts
2022-12-18 23:40:16,379 INFO There are 7/7 active rules
2022-12-18 23:40:16,380 INFO Coverage: 100.0% (18/18)
2022-12-18 23:40:16,380 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:40:16,403 INFO DONE, Getting attention scores...
2022-12-18 23:40:16,462 INFO Evaluating teacher dev iter13 on 18 examples
2022-12-18 23:40:16,467 INFO teacher dev iter13 performance: 83.33
2022-12-18 23:40:16,467 INFO teacher dev iter13 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:16,467 INFO teacher dev iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:16,467 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:40:16,468 INFO Predicting labels for 32 texts
2022-12-18 23:40:16,572 INFO There are 7/7 active rules
2022-12-18 23:40:16,573 INFO Coverage: 100.0% (32/32)
2022-12-18 23:40:16,574 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:40:16,598 INFO DONE, Getting attention scores...
2022-12-18 23:40:16,652 INFO Evaluating teacher test iter13 on 32 examples
2022-12-18 23:40:16,656 INFO teacher test iter13 performance: 78.12
2022-12-18 23:40:16,657 INFO teacher test iter13 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:40:16,657 INFO teacher test iter13 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:40:16,657 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:40:16,661 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:40:16,662 INFO Balancing Pseudo Dataset to keep 654 items...
2022-12-18 23:40:16,666 INFO PSEUDO-DATASET:
654 examples
PSEUDO-LABELS:
1    327
0    327
Name: label, dtype: int64
2022-12-18 23:40:16,667 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:40:19,266 INFO fine-tuning the student on clean labeled data
2022-12-18 23:40:21,507 INFO Predicting labels for 18 texts
2022-12-18 23:40:21,631 INFO Evaluating student dev iter13 on 18 examples
2022-12-18 23:40:21,635 INFO student dev iter13 performance: 83.33
2022-12-18 23:40:21,636 INFO student dev iter13 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:21,636 INFO student dev iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:21,636 INFO Predicting labels for 32 texts
2022-12-18 23:40:22,762 INFO Evaluating student test iter13 on 32 examples
2022-12-18 23:40:22,767 INFO student test iter13 performance: 59.38
2022-12-18 23:40:22,767 INFO student test iter13 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:40:22,768 INFO student test iter13 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:40:22,768 INFO Student Dev performance on iter 13: 83.33333333333334
2022-12-18 23:40:22,768 INFO Student Test performance on iter 13: 59.375
2022-12-18 23:40:22,768 INFO 

	 *** Starting loop 14 ***
2022-12-18 23:40:22,768 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:40:22,768 INFO Downsampling 444 data
2022-12-18 23:40:22,769 INFO Adding Student as extra rule in Teacher
2022-12-18 23:40:22,769 INFO Getting rule predictions
2022-12-18 23:40:22,769 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:40:22,770 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:22,770 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:22,771 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:40:22,772 INFO Predicting labels for 741 texts
2022-12-18 23:40:22,884 INFO Predicting labels for 18 texts
2022-12-18 23:40:24,010 INFO Predicting labels for 444 texts
2022-12-18 23:40:24,113 INFO Training Rule Attention Network
2022-12-18 23:40:24,120 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:40:24,120 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:40:24,124 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:40:24,124 INFO 

		*** Training RAN ***
2022-12-18 23:40:27,023 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:27,024 INFO Predicting labels for 444 texts
2022-12-18 23:40:27,135 INFO There are 3/7 active rules
2022-12-18 23:40:27,135 INFO Coverage: 100.0% (444/444)
2022-12-18 23:40:27,140 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:40:27,227 INFO DONE, Getting attention scores...
2022-12-18 23:40:27,286 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:27,287 INFO Predicting labels for 18 texts
2022-12-18 23:40:27,390 INFO There are 7/7 active rules
2022-12-18 23:40:27,391 INFO Coverage: 100.0% (18/18)
2022-12-18 23:40:27,391 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:40:27,415 INFO DONE, Getting attention scores...
2022-12-18 23:40:27,472 INFO Evaluating teacher dev iter14 on 18 examples
2022-12-18 23:40:27,477 INFO teacher dev iter14 performance: 77.78
2022-12-18 23:40:27,477 INFO teacher dev iter14 confusion matrix:
[[ 3  4]
 [ 0 11]]
2022-12-18 23:40:27,477 INFO teacher dev iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.43      0.60         7
           1       0.73      1.00      0.85        11

    accuracy                           0.78        18
   macro avg       0.87      0.71      0.72        18
weighted avg       0.84      0.78      0.75        18

2022-12-18 23:40:27,477 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:40:27,478 INFO Predicting labels for 32 texts
2022-12-18 23:40:27,587 INFO There are 7/7 active rules
2022-12-18 23:40:27,588 INFO Coverage: 100.0% (32/32)
2022-12-18 23:40:27,589 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:40:27,618 INFO DONE, Getting attention scores...
2022-12-18 23:40:27,672 INFO Evaluating teacher test iter14 on 32 examples
2022-12-18 23:40:27,677 INFO teacher test iter14 performance: 78.12
2022-12-18 23:40:27,677 INFO teacher test iter14 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:40:27,677 INFO teacher test iter14 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:40:27,677 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:40:27,681 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:40:27,683 INFO Balancing Pseudo Dataset to keep 714 items...
2022-12-18 23:40:27,686 INFO PSEUDO-DATASET:
714 examples
PSEUDO-LABELS:
1    357
0    357
Name: label, dtype: int64
2022-12-18 23:40:27,686 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:40:30,379 INFO fine-tuning the student on clean labeled data
2022-12-18 23:40:31,577 INFO Predicting labels for 18 texts
2022-12-18 23:40:31,698 INFO Evaluating student dev iter14 on 18 examples
2022-12-18 23:40:31,703 INFO student dev iter14 performance: 83.33
2022-12-18 23:40:31,703 INFO student dev iter14 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:31,703 INFO student dev iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:31,703 INFO Predicting labels for 32 texts
2022-12-18 23:40:31,807 INFO Evaluating student test iter14 on 32 examples
2022-12-18 23:40:31,812 INFO student test iter14 performance: 59.38
2022-12-18 23:40:31,812 INFO student test iter14 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:40:31,812 INFO student test iter14 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:40:31,812 INFO Student Dev performance on iter 14: 83.33333333333334
2022-12-18 23:40:31,812 INFO Student Test performance on iter 14: 59.375
2022-12-18 23:40:31,813 INFO 

	 *** Starting loop 15 ***
2022-12-18 23:40:31,813 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:40:31,813 INFO Downsampling 444 data
2022-12-18 23:40:31,813 INFO Adding Student as extra rule in Teacher
2022-12-18 23:40:31,814 INFO Getting rule predictions
2022-12-18 23:40:31,814 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:40:31,815 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:31,815 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:31,816 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:40:31,817 INFO Predicting labels for 741 texts
2022-12-18 23:40:31,932 INFO Predicting labels for 18 texts
2022-12-18 23:40:32,033 INFO Predicting labels for 444 texts
2022-12-18 23:40:32,134 INFO Training Rule Attention Network
2022-12-18 23:40:32,144 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:40:32,144 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:40:32,149 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:40:32,149 INFO 

		*** Training RAN ***
2022-12-18 23:40:35,073 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:35,074 INFO Predicting labels for 444 texts
2022-12-18 23:40:35,180 INFO There are 3/7 active rules
2022-12-18 23:40:35,181 INFO Coverage: 100.0% (444/444)
2022-12-18 23:40:35,185 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:40:35,272 INFO DONE, Getting attention scores...
2022-12-18 23:40:35,331 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:35,331 INFO Predicting labels for 18 texts
2022-12-18 23:40:35,433 INFO There are 7/7 active rules
2022-12-18 23:40:35,434 INFO Coverage: 100.0% (18/18)
2022-12-18 23:40:35,434 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:40:35,457 INFO DONE, Getting attention scores...
2022-12-18 23:40:35,516 INFO Evaluating teacher dev iter15 on 18 examples
2022-12-18 23:40:35,520 INFO teacher dev iter15 performance: 83.33
2022-12-18 23:40:35,520 INFO teacher dev iter15 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:35,520 INFO teacher dev iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:35,521 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:40:35,521 INFO Predicting labels for 32 texts
2022-12-18 23:40:35,625 INFO There are 7/7 active rules
2022-12-18 23:40:35,625 INFO Coverage: 100.0% (32/32)
2022-12-18 23:40:35,626 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:40:35,650 INFO DONE, Getting attention scores...
2022-12-18 23:40:35,703 INFO Evaluating teacher test iter15 on 32 examples
2022-12-18 23:40:35,708 INFO teacher test iter15 performance: 78.12
2022-12-18 23:40:35,708 INFO teacher test iter15 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:40:35,708 INFO teacher test iter15 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:40:35,708 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:40:35,712 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:40:35,713 INFO Balancing Pseudo Dataset to keep 674 items...
2022-12-18 23:40:35,717 INFO PSEUDO-DATASET:
674 examples
PSEUDO-LABELS:
1    337
0    337
Name: label, dtype: int64
2022-12-18 23:40:35,717 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:40:37,410 INFO fine-tuning the student on clean labeled data
2022-12-18 23:40:38,566 INFO Predicting labels for 18 texts
2022-12-18 23:40:38,669 INFO Evaluating student dev iter15 on 18 examples
2022-12-18 23:40:38,674 INFO student dev iter15 performance: 83.33
2022-12-18 23:40:38,674 INFO student dev iter15 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:38,675 INFO student dev iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:38,675 INFO Predicting labels for 32 texts
2022-12-18 23:40:38,881 INFO Evaluating student test iter15 on 32 examples
2022-12-18 23:40:38,885 INFO student test iter15 performance: 59.38
2022-12-18 23:40:38,886 INFO student test iter15 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:40:38,886 INFO student test iter15 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:40:38,886 INFO Student Dev performance on iter 15: 83.33333333333334
2022-12-18 23:40:38,886 INFO Student Test performance on iter 15: 59.375
2022-12-18 23:40:38,886 INFO 

	 *** Starting loop 16 ***
2022-12-18 23:40:38,886 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:40:38,886 INFO Downsampling 444 data
2022-12-18 23:40:38,887 INFO Adding Student as extra rule in Teacher
2022-12-18 23:40:38,887 INFO Getting rule predictions
2022-12-18 23:40:38,888 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:40:38,889 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:38,889 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:38,889 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:40:38,890 INFO Predicting labels for 741 texts
2022-12-18 23:40:38,999 INFO Predicting labels for 18 texts
2022-12-18 23:40:39,106 INFO Predicting labels for 444 texts
2022-12-18 23:40:39,211 INFO Training Rule Attention Network
2022-12-18 23:40:39,219 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:40:39,219 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:40:39,223 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:40:39,224 INFO 

		*** Training RAN ***
2022-12-18 23:40:42,027 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:42,028 INFO Predicting labels for 444 texts
2022-12-18 23:40:42,135 INFO There are 3/7 active rules
2022-12-18 23:40:42,136 INFO Coverage: 100.0% (444/444)
2022-12-18 23:40:42,140 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:40:42,229 INFO DONE, Getting attention scores...
2022-12-18 23:40:42,289 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:42,289 INFO Predicting labels for 18 texts
2022-12-18 23:40:42,402 INFO There are 7/7 active rules
2022-12-18 23:40:42,402 INFO Coverage: 100.0% (18/18)
2022-12-18 23:40:42,403 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:40:42,427 INFO DONE, Getting attention scores...
2022-12-18 23:40:42,480 INFO Evaluating teacher dev iter16 on 18 examples
2022-12-18 23:40:42,485 INFO teacher dev iter16 performance: 83.33
2022-12-18 23:40:42,485 INFO teacher dev iter16 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:42,485 INFO teacher dev iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:42,485 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:40:42,486 INFO Predicting labels for 32 texts
2022-12-18 23:40:42,587 INFO There are 7/7 active rules
2022-12-18 23:40:42,587 INFO Coverage: 100.0% (32/32)
2022-12-18 23:40:42,588 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:40:42,623 INFO DONE, Getting attention scores...
2022-12-18 23:40:42,678 INFO Evaluating teacher test iter16 on 32 examples
2022-12-18 23:40:42,683 INFO teacher test iter16 performance: 78.12
2022-12-18 23:40:42,683 INFO teacher test iter16 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:40:42,684 INFO teacher test iter16 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:40:42,684 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:40:42,687 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:40:42,688 INFO Balancing Pseudo Dataset to keep 698 items...
2022-12-18 23:40:42,693 INFO PSEUDO-DATASET:
698 examples
PSEUDO-LABELS:
1    349
0    349
Name: label, dtype: int64
2022-12-18 23:40:42,693 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:40:44,400 INFO fine-tuning the student on clean labeled data
2022-12-18 23:40:46,551 INFO Predicting labels for 18 texts
2022-12-18 23:40:46,664 INFO Evaluating student dev iter16 on 18 examples
2022-12-18 23:40:46,668 INFO student dev iter16 performance: 83.33
2022-12-18 23:40:46,668 INFO student dev iter16 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:46,668 INFO student dev iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:46,669 INFO Predicting labels for 32 texts
2022-12-18 23:40:46,775 INFO Evaluating student test iter16 on 32 examples
2022-12-18 23:40:46,779 INFO student test iter16 performance: 59.38
2022-12-18 23:40:46,779 INFO student test iter16 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:40:46,780 INFO student test iter16 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:40:46,780 INFO Student Dev performance on iter 16: 83.33333333333334
2022-12-18 23:40:46,780 INFO Student Test performance on iter 16: 59.375
2022-12-18 23:40:46,780 INFO 

	 *** Starting loop 17 ***
2022-12-18 23:40:46,780 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:40:46,780 INFO Downsampling 444 data
2022-12-18 23:40:46,781 INFO Adding Student as extra rule in Teacher
2022-12-18 23:40:46,781 INFO Getting rule predictions
2022-12-18 23:40:46,781 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:40:46,782 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:46,782 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:46,783 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:40:46,784 INFO Predicting labels for 741 texts
2022-12-18 23:40:46,895 INFO Predicting labels for 18 texts
2022-12-18 23:40:46,996 INFO Predicting labels for 444 texts
2022-12-18 23:40:47,099 INFO Training Rule Attention Network
2022-12-18 23:40:47,213 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:40:47,213 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:40:47,217 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:40:47,218 INFO 

		*** Training RAN ***
2022-12-18 23:40:50,034 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:50,035 INFO Predicting labels for 444 texts
2022-12-18 23:40:50,140 INFO There are 3/7 active rules
2022-12-18 23:40:50,140 INFO Coverage: 100.0% (444/444)
2022-12-18 23:40:50,145 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:40:50,231 INFO DONE, Getting attention scores...
2022-12-18 23:40:50,291 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:50,291 INFO Predicting labels for 18 texts
2022-12-18 23:40:50,392 INFO There are 7/7 active rules
2022-12-18 23:40:50,392 INFO Coverage: 100.0% (18/18)
2022-12-18 23:40:50,393 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:40:50,415 INFO DONE, Getting attention scores...
2022-12-18 23:40:50,468 INFO Evaluating teacher dev iter17 on 18 examples
2022-12-18 23:40:50,472 INFO teacher dev iter17 performance: 83.33
2022-12-18 23:40:50,473 INFO teacher dev iter17 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:50,473 INFO teacher dev iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:50,473 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:40:50,473 INFO Predicting labels for 32 texts
2022-12-18 23:40:50,585 INFO There are 7/7 active rules
2022-12-18 23:40:50,585 INFO Coverage: 100.0% (32/32)
2022-12-18 23:40:50,586 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:40:50,611 INFO DONE, Getting attention scores...
2022-12-18 23:40:50,665 INFO Evaluating teacher test iter17 on 32 examples
2022-12-18 23:40:50,670 INFO teacher test iter17 performance: 78.12
2022-12-18 23:40:50,670 INFO teacher test iter17 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:40:50,670 INFO teacher test iter17 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:40:50,671 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:40:50,674 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:40:50,676 INFO Balancing Pseudo Dataset to keep 670 items...
2022-12-18 23:40:50,680 INFO PSEUDO-DATASET:
670 examples
PSEUDO-LABELS:
1    335
0    335
Name: label, dtype: int64
2022-12-18 23:40:50,680 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:40:52,280 INFO fine-tuning the student on clean labeled data
2022-12-18 23:40:53,446 INFO Predicting labels for 18 texts
2022-12-18 23:40:53,549 INFO Evaluating student dev iter17 on 18 examples
2022-12-18 23:40:53,553 INFO student dev iter17 performance: 83.33
2022-12-18 23:40:53,553 INFO student dev iter17 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:53,554 INFO student dev iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:53,554 INFO Predicting labels for 32 texts
2022-12-18 23:40:53,662 INFO Evaluating student test iter17 on 32 examples
2022-12-18 23:40:53,667 INFO student test iter17 performance: 59.38
2022-12-18 23:40:53,668 INFO student test iter17 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:40:53,668 INFO student test iter17 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:40:53,668 INFO Student Dev performance on iter 17: 83.33333333333334
2022-12-18 23:40:53,668 INFO Student Test performance on iter 17: 59.375
2022-12-18 23:40:53,668 INFO 

	 *** Starting loop 18 ***
2022-12-18 23:40:53,668 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:40:53,668 INFO Downsampling 444 data
2022-12-18 23:40:53,669 INFO Adding Student as extra rule in Teacher
2022-12-18 23:40:53,669 INFO Getting rule predictions
2022-12-18 23:40:53,669 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:40:53,670 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:53,671 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:53,671 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:40:53,672 INFO Predicting labels for 741 texts
2022-12-18 23:40:53,786 INFO Predicting labels for 18 texts
2022-12-18 23:40:53,900 INFO Predicting labels for 444 texts
2022-12-18 23:40:54,013 INFO Training Rule Attention Network
2022-12-18 23:40:54,020 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:40:54,021 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:40:54,025 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:40:54,025 INFO 

		*** Training RAN ***
2022-12-18 23:40:57,015 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:40:57,016 INFO Predicting labels for 444 texts
2022-12-18 23:40:57,122 INFO There are 3/7 active rules
2022-12-18 23:40:57,122 INFO Coverage: 100.0% (444/444)
2022-12-18 23:40:57,127 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:40:57,215 INFO DONE, Getting attention scores...
2022-12-18 23:40:57,272 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:40:57,272 INFO Predicting labels for 18 texts
2022-12-18 23:40:57,379 INFO There are 7/7 active rules
2022-12-18 23:40:57,379 INFO Coverage: 100.0% (18/18)
2022-12-18 23:40:57,380 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:40:57,404 INFO DONE, Getting attention scores...
2022-12-18 23:40:57,458 INFO Evaluating teacher dev iter18 on 18 examples
2022-12-18 23:40:57,462 INFO teacher dev iter18 performance: 83.33
2022-12-18 23:40:57,462 INFO teacher dev iter18 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:40:57,462 INFO teacher dev iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:40:57,462 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:40:57,463 INFO Predicting labels for 32 texts
2022-12-18 23:40:57,566 INFO There are 7/7 active rules
2022-12-18 23:40:57,566 INFO Coverage: 100.0% (32/32)
2022-12-18 23:40:57,567 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:40:57,596 INFO DONE, Getting attention scores...
2022-12-18 23:40:57,650 INFO Evaluating teacher test iter18 on 32 examples
2022-12-18 23:40:57,655 INFO teacher test iter18 performance: 78.12
2022-12-18 23:40:57,655 INFO teacher test iter18 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:40:57,656 INFO teacher test iter18 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:40:57,656 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:40:57,659 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:40:57,661 INFO Balancing Pseudo Dataset to keep 666 items...
2022-12-18 23:40:57,665 INFO PSEUDO-DATASET:
666 examples
PSEUDO-LABELS:
1    333
0    333
Name: label, dtype: int64
2022-12-18 23:40:57,665 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:41:00,288 INFO fine-tuning the student on clean labeled data
2022-12-18 23:41:01,406 INFO Predicting labels for 18 texts
2022-12-18 23:41:01,513 INFO Evaluating student dev iter18 on 18 examples
2022-12-18 23:41:01,517 INFO student dev iter18 performance: 83.33
2022-12-18 23:41:01,517 INFO student dev iter18 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:01,518 INFO student dev iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:01,518 INFO Predicting labels for 32 texts
2022-12-18 23:41:01,620 INFO Evaluating student test iter18 on 32 examples
2022-12-18 23:41:01,624 INFO student test iter18 performance: 59.38
2022-12-18 23:41:01,625 INFO student test iter18 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:41:01,625 INFO student test iter18 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:41:01,625 INFO Student Dev performance on iter 18: 83.33333333333334
2022-12-18 23:41:01,625 INFO Student Test performance on iter 18: 59.375
2022-12-18 23:41:01,625 INFO 

	 *** Starting loop 19 ***
2022-12-18 23:41:01,625 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:41:01,625 INFO Downsampling 444 data
2022-12-18 23:41:01,626 INFO Adding Student as extra rule in Teacher
2022-12-18 23:41:01,626 INFO Getting rule predictions
2022-12-18 23:41:01,626 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:41:01,627 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:01,628 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:01,628 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:41:01,629 INFO Predicting labels for 741 texts
2022-12-18 23:41:01,739 INFO Predicting labels for 18 texts
2022-12-18 23:41:01,839 INFO Predicting labels for 444 texts
2022-12-18 23:41:01,946 INFO Training Rule Attention Network
2022-12-18 23:41:01,953 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:41:01,954 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:41:01,958 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:41:01,958 INFO 

		*** Training RAN ***
2022-12-18 23:41:05,088 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:05,089 INFO Predicting labels for 444 texts
2022-12-18 23:41:05,195 INFO There are 3/7 active rules
2022-12-18 23:41:05,196 INFO Coverage: 100.0% (444/444)
2022-12-18 23:41:05,202 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:41:05,289 INFO DONE, Getting attention scores...
2022-12-18 23:41:05,344 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:05,345 INFO Predicting labels for 18 texts
2022-12-18 23:41:05,446 INFO There are 7/7 active rules
2022-12-18 23:41:05,447 INFO Coverage: 100.0% (18/18)
2022-12-18 23:41:05,447 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:41:05,476 INFO DONE, Getting attention scores...
2022-12-18 23:41:05,533 INFO Evaluating teacher dev iter19 on 18 examples
2022-12-18 23:41:05,537 INFO teacher dev iter19 performance: 83.33
2022-12-18 23:41:05,538 INFO teacher dev iter19 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:05,538 INFO teacher dev iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:05,538 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:41:05,538 INFO Predicting labels for 32 texts
2022-12-18 23:41:05,640 INFO There are 7/7 active rules
2022-12-18 23:41:05,640 INFO Coverage: 100.0% (32/32)
2022-12-18 23:41:05,641 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:41:05,665 INFO DONE, Getting attention scores...
2022-12-18 23:41:05,725 INFO Evaluating teacher test iter19 on 32 examples
2022-12-18 23:41:05,729 INFO teacher test iter19 performance: 78.12
2022-12-18 23:41:05,730 INFO teacher test iter19 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:41:05,730 INFO teacher test iter19 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:41:05,730 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:41:05,734 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:41:05,735 INFO Balancing Pseudo Dataset to keep 668 items...
2022-12-18 23:41:05,739 INFO PSEUDO-DATASET:
668 examples
PSEUDO-LABELS:
1    334
0    334
Name: label, dtype: int64
2022-12-18 23:41:05,740 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:41:09,333 INFO fine-tuning the student on clean labeled data
2022-12-18 23:41:10,443 INFO Predicting labels for 18 texts
2022-12-18 23:41:10,548 INFO Evaluating student dev iter19 on 18 examples
2022-12-18 23:41:10,552 INFO student dev iter19 performance: 83.33
2022-12-18 23:41:10,553 INFO student dev iter19 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:10,553 INFO student dev iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:10,553 INFO Predicting labels for 32 texts
2022-12-18 23:41:10,657 INFO Evaluating student test iter19 on 32 examples
2022-12-18 23:41:10,661 INFO student test iter19 performance: 59.38
2022-12-18 23:41:10,662 INFO student test iter19 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:41:10,662 INFO student test iter19 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:41:10,662 INFO Student Dev performance on iter 19: 83.33333333333334
2022-12-18 23:41:10,662 INFO Student Test performance on iter 19: 59.375
2022-12-18 23:41:10,662 INFO 

	 *** Starting loop 20 ***
2022-12-18 23:41:10,662 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:41:10,662 INFO Downsampling 444 data
2022-12-18 23:41:10,663 INFO Adding Student as extra rule in Teacher
2022-12-18 23:41:10,663 INFO Getting rule predictions
2022-12-18 23:41:10,663 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:41:10,664 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:10,664 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:10,665 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:41:10,666 INFO Predicting labels for 741 texts
2022-12-18 23:41:10,776 INFO Predicting labels for 18 texts
2022-12-18 23:41:10,878 INFO Predicting labels for 444 texts
2022-12-18 23:41:10,986 INFO Training Rule Attention Network
2022-12-18 23:41:10,993 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:41:10,994 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:41:10,998 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:41:10,999 INFO 

		*** Training RAN ***
2022-12-18 23:41:14,041 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:14,043 INFO Predicting labels for 444 texts
2022-12-18 23:41:14,148 INFO There are 3/7 active rules
2022-12-18 23:41:14,148 INFO Coverage: 100.0% (444/444)
2022-12-18 23:41:14,152 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:41:14,242 INFO DONE, Getting attention scores...
2022-12-18 23:41:14,298 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:14,298 INFO Predicting labels for 18 texts
2022-12-18 23:41:14,404 INFO There are 7/7 active rules
2022-12-18 23:41:14,404 INFO Coverage: 100.0% (18/18)
2022-12-18 23:41:14,405 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:41:14,430 INFO DONE, Getting attention scores...
2022-12-18 23:41:14,493 INFO Evaluating teacher dev iter20 on 18 examples
2022-12-18 23:41:14,497 INFO teacher dev iter20 performance: 83.33
2022-12-18 23:41:14,497 INFO teacher dev iter20 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:14,498 INFO teacher dev iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:14,498 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:41:14,498 INFO Predicting labels for 32 texts
2022-12-18 23:41:14,610 INFO There are 7/7 active rules
2022-12-18 23:41:14,611 INFO Coverage: 100.0% (32/32)
2022-12-18 23:41:14,612 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:41:14,637 INFO DONE, Getting attention scores...
2022-12-18 23:41:14,694 INFO Evaluating teacher test iter20 on 32 examples
2022-12-18 23:41:14,698 INFO teacher test iter20 performance: 78.12
2022-12-18 23:41:14,698 INFO teacher test iter20 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:41:14,699 INFO teacher test iter20 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:41:14,699 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:41:14,703 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:41:14,704 INFO Balancing Pseudo Dataset to keep 658 items...
2022-12-18 23:41:14,708 INFO PSEUDO-DATASET:
658 examples
PSEUDO-LABELS:
1    329
0    329
Name: label, dtype: int64
2022-12-18 23:41:14,709 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:41:16,278 INFO fine-tuning the student on clean labeled data
2022-12-18 23:41:17,403 INFO Predicting labels for 18 texts
2022-12-18 23:41:17,508 INFO Evaluating student dev iter20 on 18 examples
2022-12-18 23:41:17,512 INFO student dev iter20 performance: 83.33
2022-12-18 23:41:17,512 INFO student dev iter20 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:17,512 INFO student dev iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:17,513 INFO Predicting labels for 32 texts
2022-12-18 23:41:17,615 INFO Evaluating student test iter20 on 32 examples
2022-12-18 23:41:17,620 INFO student test iter20 performance: 59.38
2022-12-18 23:41:17,620 INFO student test iter20 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:41:17,620 INFO student test iter20 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:41:17,620 INFO Student Dev performance on iter 20: 83.33333333333334
2022-12-18 23:41:17,620 INFO Student Test performance on iter 20: 59.375
2022-12-18 23:41:17,620 INFO 

	 *** Starting loop 21 ***
2022-12-18 23:41:17,620 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:41:17,621 INFO Downsampling 444 data
2022-12-18 23:41:17,621 INFO Adding Student as extra rule in Teacher
2022-12-18 23:41:17,622 INFO Getting rule predictions
2022-12-18 23:41:17,622 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:41:17,623 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:17,623 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:17,623 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:41:17,624 INFO Predicting labels for 741 texts
2022-12-18 23:41:17,732 INFO Predicting labels for 18 texts
2022-12-18 23:41:17,832 INFO Predicting labels for 444 texts
2022-12-18 23:41:17,937 INFO Training Rule Attention Network
2022-12-18 23:41:17,947 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:41:17,948 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:41:17,953 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:41:17,953 INFO 

		*** Training RAN ***
2022-12-18 23:41:20,840 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:20,841 INFO Predicting labels for 444 texts
2022-12-18 23:41:20,949 INFO There are 3/7 active rules
2022-12-18 23:41:20,949 INFO Coverage: 100.0% (444/444)
2022-12-18 23:41:20,954 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:41:21,038 INFO DONE, Getting attention scores...
2022-12-18 23:41:21,201 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:21,201 INFO Predicting labels for 18 texts
2022-12-18 23:41:21,310 INFO There are 7/7 active rules
2022-12-18 23:41:21,310 INFO Coverage: 100.0% (18/18)
2022-12-18 23:41:21,311 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:41:21,335 INFO DONE, Getting attention scores...
2022-12-18 23:41:21,392 INFO Evaluating teacher dev iter21 on 18 examples
2022-12-18 23:41:21,396 INFO teacher dev iter21 performance: 83.33
2022-12-18 23:41:21,397 INFO teacher dev iter21 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:21,397 INFO teacher dev iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:21,397 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:41:21,397 INFO Predicting labels for 32 texts
2022-12-18 23:41:21,509 INFO There are 7/7 active rules
2022-12-18 23:41:21,509 INFO Coverage: 100.0% (32/32)
2022-12-18 23:41:21,510 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:41:21,534 INFO DONE, Getting attention scores...
2022-12-18 23:41:21,589 INFO Evaluating teacher test iter21 on 32 examples
2022-12-18 23:41:21,593 INFO teacher test iter21 performance: 78.12
2022-12-18 23:41:21,593 INFO teacher test iter21 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:41:21,593 INFO teacher test iter21 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:41:21,594 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:41:21,596 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:41:21,598 INFO Balancing Pseudo Dataset to keep 666 items...
2022-12-18 23:41:21,601 INFO PSEUDO-DATASET:
666 examples
PSEUDO-LABELS:
1    333
0    333
Name: label, dtype: int64
2022-12-18 23:41:21,601 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:41:24,189 INFO fine-tuning the student on clean labeled data
2022-12-18 23:41:26,331 INFO Predicting labels for 18 texts
2022-12-18 23:41:26,437 INFO Evaluating student dev iter21 on 18 examples
2022-12-18 23:41:26,441 INFO student dev iter21 performance: 83.33
2022-12-18 23:41:26,441 INFO student dev iter21 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:26,441 INFO student dev iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:26,441 INFO Predicting labels for 32 texts
2022-12-18 23:41:26,544 INFO Evaluating student test iter21 on 32 examples
2022-12-18 23:41:26,548 INFO student test iter21 performance: 59.38
2022-12-18 23:41:26,548 INFO student test iter21 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:41:26,549 INFO student test iter21 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:41:26,549 INFO Student Dev performance on iter 21: 83.33333333333334
2022-12-18 23:41:26,549 INFO Student Test performance on iter 21: 59.375
2022-12-18 23:41:26,549 INFO 

	 *** Starting loop 22 ***
2022-12-18 23:41:26,549 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:41:26,549 INFO Downsampling 444 data
2022-12-18 23:41:26,550 INFO Adding Student as extra rule in Teacher
2022-12-18 23:41:26,550 INFO Getting rule predictions
2022-12-18 23:41:26,550 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:41:26,551 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:26,552 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:26,552 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:41:26,553 INFO Predicting labels for 741 texts
2022-12-18 23:41:26,658 INFO Predicting labels for 18 texts
2022-12-18 23:41:26,761 INFO Predicting labels for 444 texts
2022-12-18 23:41:26,865 INFO Training Rule Attention Network
2022-12-18 23:41:26,872 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:41:26,873 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:41:26,879 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:41:26,879 INFO 

		*** Training RAN ***
2022-12-18 23:41:29,773 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:29,774 INFO Predicting labels for 444 texts
2022-12-18 23:41:29,884 INFO There are 3/7 active rules
2022-12-18 23:41:29,884 INFO Coverage: 100.0% (444/444)
2022-12-18 23:41:29,888 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:41:29,976 INFO DONE, Getting attention scores...
2022-12-18 23:41:30,034 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:30,034 INFO Predicting labels for 18 texts
2022-12-18 23:41:30,141 INFO There are 7/7 active rules
2022-12-18 23:41:30,141 INFO Coverage: 100.0% (18/18)
2022-12-18 23:41:30,142 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:41:30,166 INFO DONE, Getting attention scores...
2022-12-18 23:41:30,219 INFO Evaluating teacher dev iter22 on 18 examples
2022-12-18 23:41:30,223 INFO teacher dev iter22 performance: 83.33
2022-12-18 23:41:30,223 INFO teacher dev iter22 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:30,223 INFO teacher dev iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:30,223 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:41:30,223 INFO Predicting labels for 32 texts
2022-12-18 23:41:30,333 INFO There are 7/7 active rules
2022-12-18 23:41:30,334 INFO Coverage: 100.0% (32/32)
2022-12-18 23:41:30,334 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:41:30,359 INFO DONE, Getting attention scores...
2022-12-18 23:41:30,413 INFO Evaluating teacher test iter22 on 32 examples
2022-12-18 23:41:30,417 INFO teacher test iter22 performance: 78.12
2022-12-18 23:41:30,418 INFO teacher test iter22 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:41:30,418 INFO teacher test iter22 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:41:30,418 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:41:30,421 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:41:30,422 INFO Balancing Pseudo Dataset to keep 648 items...
2022-12-18 23:41:30,427 INFO PSEUDO-DATASET:
648 examples
PSEUDO-LABELS:
1    324
0    324
Name: label, dtype: int64
2022-12-18 23:41:30,427 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:41:32,136 INFO fine-tuning the student on clean labeled data
2022-12-18 23:41:33,294 INFO Predicting labels for 18 texts
2022-12-18 23:41:33,395 INFO Evaluating student dev iter22 on 18 examples
2022-12-18 23:41:33,399 INFO student dev iter22 performance: 83.33
2022-12-18 23:41:33,400 INFO student dev iter22 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:33,400 INFO student dev iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:33,400 INFO Predicting labels for 32 texts
2022-12-18 23:41:33,506 INFO Evaluating student test iter22 on 32 examples
2022-12-18 23:41:33,511 INFO student test iter22 performance: 59.38
2022-12-18 23:41:33,511 INFO student test iter22 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:41:33,512 INFO student test iter22 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:41:33,512 INFO Student Dev performance on iter 22: 83.33333333333334
2022-12-18 23:41:33,512 INFO Student Test performance on iter 22: 59.375
2022-12-18 23:41:33,513 INFO 

	 *** Starting loop 23 ***
2022-12-18 23:41:33,513 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:41:33,513 INFO Downsampling 444 data
2022-12-18 23:41:33,514 INFO Adding Student as extra rule in Teacher
2022-12-18 23:41:33,514 INFO Getting rule predictions
2022-12-18 23:41:33,514 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:41:33,515 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:33,516 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:33,516 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:41:33,517 INFO Predicting labels for 741 texts
2022-12-18 23:41:33,623 INFO Predicting labels for 18 texts
2022-12-18 23:41:33,730 INFO Predicting labels for 444 texts
2022-12-18 23:41:33,833 INFO Training Rule Attention Network
2022-12-18 23:41:33,840 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:41:33,841 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:41:33,845 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:41:33,846 INFO 

		*** Training RAN ***
2022-12-18 23:41:36,790 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:36,791 INFO Predicting labels for 444 texts
2022-12-18 23:41:36,901 INFO There are 3/7 active rules
2022-12-18 23:41:36,901 INFO Coverage: 100.0% (444/444)
2022-12-18 23:41:36,906 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:41:36,990 INFO DONE, Getting attention scores...
2022-12-18 23:41:37,047 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:37,047 INFO Predicting labels for 18 texts
2022-12-18 23:41:37,156 INFO There are 7/7 active rules
2022-12-18 23:41:37,157 INFO Coverage: 100.0% (18/18)
2022-12-18 23:41:37,157 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:41:37,183 INFO DONE, Getting attention scores...
2022-12-18 23:41:37,237 INFO Evaluating teacher dev iter23 on 18 examples
2022-12-18 23:41:37,241 INFO teacher dev iter23 performance: 83.33
2022-12-18 23:41:37,242 INFO teacher dev iter23 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:37,242 INFO teacher dev iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:37,242 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:41:37,242 INFO Predicting labels for 32 texts
2022-12-18 23:41:37,346 INFO There are 7/7 active rules
2022-12-18 23:41:37,346 INFO Coverage: 100.0% (32/32)
2022-12-18 23:41:37,347 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:41:37,375 INFO DONE, Getting attention scores...
2022-12-18 23:41:37,432 INFO Evaluating teacher test iter23 on 32 examples
2022-12-18 23:41:37,436 INFO teacher test iter23 performance: 78.12
2022-12-18 23:41:37,436 INFO teacher test iter23 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:41:37,436 INFO teacher test iter23 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:41:37,436 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:41:37,439 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:41:37,441 INFO Balancing Pseudo Dataset to keep 740 items...
2022-12-18 23:41:37,445 INFO PSEUDO-DATASET:
740 examples
PSEUDO-LABELS:
1    370
0    370
Name: label, dtype: int64
2022-12-18 23:41:37,445 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:41:40,175 INFO fine-tuning the student on clean labeled data
2022-12-18 23:41:41,439 INFO Predicting labels for 18 texts
2022-12-18 23:41:41,547 INFO Evaluating student dev iter23 on 18 examples
2022-12-18 23:41:41,551 INFO student dev iter23 performance: 83.33
2022-12-18 23:41:41,552 INFO student dev iter23 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:41,552 INFO student dev iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:41,552 INFO Predicting labels for 32 texts
2022-12-18 23:41:41,659 INFO Evaluating student test iter23 on 32 examples
2022-12-18 23:41:41,663 INFO student test iter23 performance: 59.38
2022-12-18 23:41:41,664 INFO student test iter23 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:41:41,664 INFO student test iter23 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:41:41,664 INFO Student Dev performance on iter 23: 83.33333333333334
2022-12-18 23:41:41,664 INFO Student Test performance on iter 23: 59.375
2022-12-18 23:41:41,664 INFO 

	 *** Starting loop 24 ***
2022-12-18 23:41:41,664 INFO [WARNING] sample size = 16384 > 444
2022-12-18 23:41:41,664 INFO Downsampling 444 data
2022-12-18 23:41:41,665 INFO Adding Student as extra rule in Teacher
2022-12-18 23:41:41,665 INFO Getting rule predictions
2022-12-18 23:41:41,665 INFO Applying Teacher with 7 LF(s) on 741 data
2022-12-18 23:41:41,666 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:41,667 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:41,667 INFO Getting student predictions on train (and dev) dataset
2022-12-18 23:41:41,669 INFO Predicting labels for 741 texts
2022-12-18 23:41:41,781 INFO Predicting labels for 18 texts
2022-12-18 23:41:41,883 INFO Predicting labels for 444 texts
2022-12-18 23:41:41,992 INFO Training Rule Attention Network
2022-12-18 23:41:42,000 INFO X Train Shape (741, 7) (741, 8, 2) (741,)
2022-12-18 23:41:42,001 INFO X Dev Shape (18, 7) (18, 8, 2) (18,)
2022-12-18 23:41:42,005 INFO X Unsup Shape (444, 7) (444, 8, 2)
2022-12-18 23:41:42,005 INFO 

		*** Training RAN ***
2022-12-18 23:41:44,888 INFO Applying Teacher with 7 LF(s) on 444 data
2022-12-18 23:41:44,889 INFO Predicting labels for 444 texts
2022-12-18 23:41:44,995 INFO There are 3/7 active rules
2022-12-18 23:41:44,995 INFO Coverage: 100.0% (444/444)
2022-12-18 23:41:45,002 INFO RAN - Predicting labels for 444 texts
2022-12-18 23:41:45,088 INFO DONE, Getting attention scores...
2022-12-18 23:41:45,145 INFO Applying Teacher with 7 LF(s) on 18 data
2022-12-18 23:41:45,145 INFO Predicting labels for 18 texts
2022-12-18 23:41:45,247 INFO There are 7/7 active rules
2022-12-18 23:41:45,247 INFO Coverage: 100.0% (18/18)
2022-12-18 23:41:45,248 INFO RAN - Predicting labels for 18 texts
2022-12-18 23:41:45,277 INFO DONE, Getting attention scores...
2022-12-18 23:41:45,331 INFO Evaluating teacher dev iter24 on 18 examples
2022-12-18 23:41:45,335 INFO teacher dev iter24 performance: 77.78
2022-12-18 23:41:45,335 INFO teacher dev iter24 confusion matrix:
[[ 3  4]
 [ 0 11]]
2022-12-18 23:41:45,335 INFO teacher dev iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.43      0.60         7
           1       0.73      1.00      0.85        11

    accuracy                           0.78        18
   macro avg       0.87      0.71      0.72        18
weighted avg       0.84      0.78      0.75        18

2022-12-18 23:41:45,335 INFO Applying Teacher with 7 LF(s) on 32 data
2022-12-18 23:41:45,336 INFO Predicting labels for 32 texts
2022-12-18 23:41:45,441 INFO There are 7/7 active rules
2022-12-18 23:41:45,441 INFO Coverage: 100.0% (32/32)
2022-12-18 23:41:45,442 INFO RAN - Predicting labels for 32 texts
2022-12-18 23:41:45,468 INFO DONE, Getting attention scores...
2022-12-18 23:41:45,533 INFO Evaluating teacher test iter24 on 32 examples
2022-12-18 23:41:45,537 INFO teacher test iter24 performance: 78.12
2022-12-18 23:41:45,538 INFO teacher test iter24 confusion matrix:
[[ 8  6]
 [ 1 17]]
2022-12-18 23:41:45,538 INFO teacher test iter24 report:
              precision    recall  f1-score   support

           0       0.89      0.57      0.70        14
           1       0.74      0.94      0.83        18

    accuracy                           0.78        32
   macro avg       0.81      0.76      0.76        32
weighted avg       0.80      0.78      0.77        32

2022-12-18 23:41:45,538 INFO Saving attention scores at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_dump
2022-12-18 23:41:45,541 INFO Creating Pseudo Dataset with 444 items...
2022-12-18 23:41:45,542 INFO Balancing Pseudo Dataset to keep 746 items...
2022-12-18 23:41:45,546 INFO PSEUDO-DATASET:
746 examples
PSEUDO-LABELS:
1    373
0    373
Name: label, dtype: int64
2022-12-18 23:41:45,546 INFO training student on pseudo-labeled instances provided by the teacher
2022-12-18 23:41:48,247 INFO fine-tuning the student on clean labeled data
2022-12-18 23:41:49,384 INFO Predicting labels for 18 texts
2022-12-18 23:41:49,489 INFO Evaluating student dev iter24 on 18 examples
2022-12-18 23:41:49,494 INFO student dev iter24 performance: 83.33
2022-12-18 23:41:49,494 INFO student dev iter24 confusion matrix:
[[ 4  3]
 [ 0 11]]
2022-12-18 23:41:49,494 INFO student dev iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.57      0.73         7
           1       0.79      1.00      0.88        11

    accuracy                           0.83        18
   macro avg       0.89      0.79      0.80        18
weighted avg       0.87      0.83      0.82        18

2022-12-18 23:41:49,494 INFO Predicting labels for 32 texts
2022-12-18 23:41:49,596 INFO Evaluating student test iter24 on 32 examples
2022-12-18 23:41:49,600 INFO student test iter24 performance: 59.38
2022-12-18 23:41:49,600 INFO student test iter24 confusion matrix:
[[ 1 13]
 [ 0 18]]
2022-12-18 23:41:49,601 INFO student test iter24 report:
              precision    recall  f1-score   support

           0       1.00      0.07      0.13        14
           1       0.58      1.00      0.73        18

    accuracy                           0.59        32
   macro avg       0.79      0.54      0.43        32
weighted avg       0.76      0.59      0.47        32

2022-12-18 23:41:49,601 INFO Student Dev performance on iter 24: 83.33333333333334
2022-12-18 23:41:49,601 INFO Student Test performance on iter 24: 59.375
2022-12-18 23:41:49,601 INFO Final Results
2022-12-18 23:41:49,601 INFO TEACHER PERFORMANCES:
0:	88.89	78.12
1:	83.33	78.12
2:	83.33	78.12
3:	83.33	78.12
4:	83.33	78.12
5:	83.33	78.12
6:	83.33	78.12
7:	83.33	78.12
8:	83.33	78.12
9:	83.33	78.12
10:	83.33	78.12
11:	83.33	78.12
12:	83.33	78.12
13:	83.33	78.12
14:	83.33	78.12
15:	77.78	78.12
16:	83.33	78.12
17:	83.33	78.12
18:	83.33	78.12
19:	83.33	78.12
20:	83.33	78.12
21:	83.33	78.12
22:	83.33	78.12
23:	83.33	78.12
24:	83.33	78.12
25:	77.78	78.12
2022-12-18 23:41:49,601 INFO STUDENT PERFORMANCES:
0:	50.00	53.12
1:	88.89	59.38
2:	83.33	56.25
3:	83.33	56.25
4:	83.33	59.38
5:	83.33	59.38
6:	83.33	59.38
7:	83.33	59.38
8:	83.33	59.38
9:	83.33	59.38
10:	83.33	59.38
11:	83.33	59.38
12:	83.33	59.38
13:	83.33	59.38
14:	83.33	59.38
15:	83.33	59.38
16:	83.33	59.38
17:	83.33	59.38
18:	83.33	59.38
19:	83.33	59.38
20:	83.33	59.38
21:	83.33	59.38
22:	83.33	59.38
23:	83.33	59.38
24:	83.33	59.38
25:	83.33	59.38
2022-12-18 23:41:49,602 INFO BEST DEV weighted_acc = 88.889 for epoch 1
2022-12-18 23:41:49,602 INFO FINAL TEST weighted_acc = 59.375 for epoch 1 (max=59.38 for epoch 25)
2022-12-18 23:41:49,602 INFO Saving student_last to ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/student_last
2022-12-18 23:41:49,602 INFO Saving model at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/student_last/final_model.h5
2022-12-18 23:41:49,611 INFO Saving teacher at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_last
2022-12-18 23:41:49,612 INFO Saving rule attention network at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/teacher_last/rule_attention_network.h5
2022-12-18 23:41:49,619 INFO 	*** Final Results ***
2022-12-18 23:41:49,619 INFO 
student_train:	{'dev_loss': 0.8477040529251099}
2022-12-18 23:41:49,619 INFO 
supervised_student_dev:	{'acc': 50.0, 'weighted_acc': 50.0, 'prec': 58.92857142857143, 'rec': 56.49350649350649, 'f1': 48.57142857142856, 'weighted_f1': 48.57142857142856, 'ignored': 0, 'total': 18, 'perf': 50.0}
2022-12-18 23:41:49,619 INFO 
supervised_student_test:	{'acc': 53.125, 'weighted_acc': 53.125, 'prec': 59.71428571428572, 'rec': 56.74603174603175, 'f1': 50.76923076923077, 'weighted_f1': 50.76923076923077, 'ignored': 0, 'total': 32, 'perf': 53.125}
2022-12-18 23:41:49,619 INFO 
teacher_train:	{'acc': 90.68825910931174, 'weighted_acc': 90.68825910931174, 'prec': 89.1351943076081, 'rec': 86.26373626373626, 'f1': 87.55067604584401, 'weighted_f1': 87.55067604584401, 'ignored': 0, 'total': 741, 'perf': 90.68825910931174}
2022-12-18 23:41:49,619 INFO 
teacher_dev:	{'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}
2022-12-18 23:41:49,619 INFO 
teacher_test:	{'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}
2022-12-18 23:41:49,619 INFO 
teacher_train_iter:	[{'acc': 90.68825910931174, 'weighted_acc': 90.68825910931174, 'prec': 89.1351943076081, 'rec': 86.26373626373626, 'f1': 87.55067604584401, 'weighted_f1': 87.55067604584401, 'ignored': 0, 'total': 741, 'perf': 90.68825910931174}]
2022-12-18 23:41:49,620 INFO 
teacher_dev_iter:	[{'acc': 88.88888888888889, 'weighted_acc': 88.88888888888889, 'prec': 92.3076923076923, 'rec': 85.71428571428572, 'f1': 87.5, 'weighted_f1': 87.5, 'ignored': 0, 'total': 18, 'perf': 88.88888888888889}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 77.77777777777779, 'weighted_acc': 77.77777777777779, 'prec': 86.66666666666667, 'rec': 71.42857142857143, 'f1': 72.30769230769229, 'weighted_f1': 72.30769230769229, 'ignored': 0, 'total': 18, 'perf': 77.77777777777779}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 77.77777777777779, 'weighted_acc': 77.77777777777779, 'prec': 86.66666666666667, 'rec': 71.42857142857143, 'f1': 72.30769230769229, 'weighted_f1': 72.30769230769229, 'ignored': 0, 'total': 18, 'perf': 77.77777777777779}]
2022-12-18 23:41:49,620 INFO 
teacher_test_iter:	[{'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}, {'acc': 78.125, 'weighted_acc': 78.125, 'prec': 81.40096618357488, 'rec': 75.79365079365078, 'f1': 76.24602332979852, 'weighted_f1': 76.24602332979852, 'ignored': 0, 'total': 32, 'perf': 78.125}]
2022-12-18 23:41:49,621 INFO 
student_train_iter:	[{'dev_loss': 0.8477040529251099}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]
2022-12-18 23:41:49,621 INFO 
student_dev_iter:	[{'acc': 50.0, 'weighted_acc': 50.0, 'prec': 58.92857142857143, 'rec': 56.49350649350649, 'f1': 48.57142857142856, 'weighted_f1': 48.57142857142856, 'ignored': 0, 'total': 18, 'perf': 50.0}, {'acc': 88.88888888888889, 'weighted_acc': 88.88888888888889, 'prec': 92.3076923076923, 'rec': 85.71428571428572, 'f1': 87.5, 'weighted_f1': 87.5, 'ignored': 0, 'total': 18, 'perf': 88.88888888888889}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}, {'acc': 83.33333333333334, 'weighted_acc': 83.33333333333334, 'prec': 89.28571428571428, 'rec': 78.57142857142857, 'f1': 80.36363636363637, 'weighted_f1': 80.36363636363637, 'ignored': 0, 'total': 18, 'perf': 83.33333333333334}]
2022-12-18 23:41:49,622 INFO 
student_test_iter:	[{'acc': 53.125, 'weighted_acc': 53.125, 'prec': 59.71428571428572, 'rec': 56.74603174603175, 'f1': 50.76923076923077, 'weighted_f1': 50.76923076923077, 'ignored': 0, 'total': 32, 'perf': 53.125}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 58.22510822510822, 'rec': 57.53968253968254, 'f1': 57.33333333333333, 'weighted_f1': 57.33333333333333, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 56.25, 'weighted_acc': 56.25, 'prec': 53.333333333333336, 'rec': 50.79365079365079, 'f1': 41.66666666666667, 'weighted_f1': 41.66666666666667, 'ignored': 0, 'total': 32, 'perf': 56.25}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}, {'acc': 59.375, 'weighted_acc': 59.375, 'prec': 79.03225806451613, 'rec': 53.57142857142857, 'f1': 43.40136054421769, 'weighted_f1': 43.40136054421769, 'ignored': 0, 'total': 32, 'perf': 59.375}]
2022-12-18 23:41:49,622 INFO 
student_dev:	{'acc': 88.88888888888889, 'weighted_acc': 88.88888888888889, 'prec': 92.3076923076923, 'rec': 85.71428571428572, 'f1': 87.5, 'weighted_f1': 87.5, 'ignored': 0, 'total': 18, 'perf': 88.88888888888889}
2022-12-18 23:41:49,623 INFO 
student_test:	{'acc': 59.375, 'weighted_acc': 59.375, 'prec': 58.22510822510822, 'rec': 57.53968253968254, 'f1': 57.33333333333333, 'weighted_f1': 57.33333333333333, 'ignored': 0, 'total': 32, 'perf': 59.375}
2022-12-18 23:41:49,623 INFO Saving results at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/results.pkl
2022-12-18 23:41:49,649 INFO Dataset: econ
2022-12-18 23:41:49,649 INFO Weak Sources: ['econrules']
2022-12-18 23:41:49,649 INFO Model: bert

2022-12-18 23:41:49,649 INFO Teacher Train weighted_acc: 90.7
2022-12-18 23:41:49,649 INFO Teacher Dev weighted_acc: 83.3
2022-12-18 23:41:49,649 INFO Teacher Test weighted_acc: 78.1

2022-12-18 23:41:49,649 INFO Student Dev weighted_acc: 88.9
2022-12-18 23:41:49,649 INFO Student Test weighted_acc: 59.4
2022-12-18 23:41:49,650 INFO Saved report at ../experiments/econ/Dec18_23-38_ECON_experiments/seed0/2022_12_18-23_38_stBERT/results.txt
